{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mathias Andresen - Noter","text":"<p>Velkommen til min side med mine noter fra Aalborg Universitet.</p> <p>Jeg er uddannet Software Ingeni\u00f8r fra Aalborg Universitet.</p> <p>Siden indeholder lige nu noter fra:</p> <ul> <li>3 Semester</li> <li>4 Semester</li> <li>5 Semester</li> <li>6 Semester</li> <li>7 Semester</li> <li>8 Semester</li> </ul> <p></p>"},{"location":"3-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>AD1 - Algorithms and Datastructures</li> <li>DEB - Design and Evaluation of User Interfaces</li> <li>SU - Systems Development</li> </ul> <p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=27324</p> <p></p>"},{"location":"3-semester/AD1/","title":"AD1 - ALGORITHMS AND DATA STRUCTURES","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=27362</p>"},{"location":"3-semester/AD1/01-introduction/","title":"Linear Search","text":"<p>Brute-force algorithm</p>"},{"location":"3-semester/AD1/01-introduction/#binary-search","title":"Binary Search","text":""},{"location":"3-semester/AD1/01-introduction/#running-example","title":"Running Example","text":""},{"location":"3-semester/AD1/02-analysing-algorithms/","title":"Insertion Sort","text":"<p>Input: a sequence of n numbers (a_1, a_2,...,a_n) </p> <p>Output: a permutation (reordering) (a'_1, a'_2 ,...,a'_n)(a'_1, a'_2 ,...,a'_n) of the input sequence such that a'_1\\leq a'_2\\leq...\\leq a'_na'_1\\leq a'_2\\leq...\\leq a'_n</p>"},{"location":"3-semester/AD1/02-analysing-algorithms/#strategy","title":"Strategy","text":"<ul> <li>Start with an \"empty hand\", say left hand.</li> <li>Insert a card in the correct position of left hand, where the numbers are already sorted</li> <li>Continue until all cards are inserted/sorted</li> </ul>"},{"location":"3-semester/AD1/02-analysing-algorithms/#the-ram-model","title":"The RAM Model","text":"<ul> <li> <p>Primitive or atomic operations</p> </li> <li>Each takes constant time, depending on the machine</li> <li> <p>Instructions are executed one after another</p> </li> <li> </li> <li> <p>Arithmetic (add, subtract, multiply, etc.)</p> </li> <li>Data movement (assignment)</li> <li>Control (branch, subroutine call, return)</li> <li> <p>Comparison</p> </li> <li> </li> </ul> <p>## Analysis of Insertion Sort</p> <p></p> <ul> <li> <p>t_jt_j is the number of times of the while loop test in line 5 is executed for a specific value of j.</p> </li> <li> <p>t_jt_j is the number of elements in A[1...j-1]A[1...j-1] which need to be checked in the j-th iteration of the for loop in line 5</p> </li> <li> <p>t_jt_j may be different for different j.</p> </li> <li> <p>t_jt_j may be different for different input instances, e.g., best case or worst case</p> </li> </ul>"},{"location":"3-semester/AD1/02-analysing-algorithms/#instructions","title":"Instructions","text":""},{"location":"3-semester/AD1/02-analysing-algorithms/#we-consider-instructions-commonly-found-in-real-computers","title":"We consider instructions commonly found in real computers","text":""},{"location":"3-semester/AD1/02-analysing-algorithms/#data-types-integers-characters-and-floats","title":"Data types - integers, characters, and floats","text":""},{"location":"3-semester/AD1/02-analysing-algorithms/#bestworstaverage-case","title":"Best/Worst/Average Case","text":"<ul> <li> <p>The maximum running time over all k inputs of size n</p> </li> <li>It is the most interesting/important!</li> </ul>"},{"location":"3-semester/AD1/02-analysing-algorithms/#worst-case-time-complexity-wnmax_1leq-ileq-kt_inwnmax_1leq-ileq-kt_in","title":"Worst case time complexity: W(n)=max_{1\\leq i\\leq k}T_i(n)W(n)=max_{1\\leq i\\leq k}T_i(n)","text":""},{"location":"3-semester/AD1/02-analysing-algorithms/#comparing-algorithms-efficiencies","title":"Comparing Algorithms\u2019 Efficiencies","text":"<p>Question: How to compare two algorithms in terms of efficieny?</p> <p>\u200b   E.g. linear search (linear) vs. binary search (logarithm)</p> <p>Answer: Look at how fast T(n) grows as n grows to a very large number (to the limit)</p> <p>Asymptotic complexity! </p> <p></p>"},{"location":"3-semester/AD1/02-analysing-algorithms/#asymptotic-analysis","title":"Asymptotic Analysis","text":"<p>Goal: To simplyfy analysis of running time by getting rid of \u201cdetails\u201d, which may be affected by specific implementation and hardware</p> <ul> <li> <p>\u201crounding\u201d for numbers: 1.000.001 \\approx 1.000.0001.000.001 \\approx 1.000.000</p> </li> <li> <p>\u201crounding\u201d for functions 3n^2\\approx n^23n^2\\approx n^2</p> </li> </ul> <p></p>"},{"location":"3-semester/AD1/02-analysing-algorithms/#se-clrs-p-56eq-315","title":"SE CLRS, p 56,Eq. 3.15","text":""},{"location":"3-semester/AD1/03-divide-and-conquer/","title":"Divide-and-Conquer (DaC)","text":""},{"location":"3-semester/AD1/03-divide-and-conquer/#basic-idea","title":"Basic Idea","text":"<ul> <li>A problem with very small problem size can be solved trivially</li> <li>Sorting an array with only one single element is trivial</li> <li>Break the original big problem into several sub-problems, that are similar ti the original problem but smaller in size.</li> <li> <p>Solve the sub-problems recusively unitl the sub-problem is with very small problem size that can be solved trivially.</p> </li> <li> <p>Combine the solutions to sub-problems to create a final solution to the original problem.</p> </li> </ul>"},{"location":"3-semester/AD1/03-divide-and-conquer/#example-factorial-n","title":"Example: Factorial n!","text":"<p>Recursive</p> <p></p> <p>Non-recursive </p> <p></p>"},{"location":"3-semester/AD1/03-divide-and-conquer/#divide-and-conquer-method-for-algorithm-design","title":"Divide-and-conquer method for algorithm design","text":"<ul> <li>If the problem size is small enough to solve it in a straightforward manner, solve it. Otherwise do the following:</li> <li>Divide: Divide the problem into a number of disjoint sub-problems</li> <li>Conquer: Use divide-and-conquer recursively to solve the sub-problems.</li> <li>Combine: Take the solutions to the sub-problems and combine these solutions into a solution for the original problem</li> </ul>"},{"location":"3-semester/AD1/03-divide-and-conquer/#analyzing-divide-and-conquer-algorithms","title":"Analyzing divide-and-conquer algorithms","text":""},{"location":"3-semester/AD1/03-divide-and-conquer/#recurrences","title":"Recurrences","text":"<ul> <li> <p>Running times of algorithms with recursive calls can be desribed using recurrences</p> </li> <li> <p>A recurrence is an equation or inequality that describes a function in terms of its value on smaller inputs</p> </li> <li> <p>Assume that:</p> </li> <li> <p>If the problem size is smalle enough, the problem can be solved in constant time, i.e., \\Theta(1)</p> </li> <li>the division of problem yields a sub-problems and each sub-problem is 1/b1/b the size of the original</li> </ul> <p>We have:</p> <p></p>"},{"location":"3-semester/AD1/03-divide-and-conquer/#example-binary-search","title":"Example: Binary Search","text":"<p>a=1,b=2a=1,b=2, having one sub-problem with half elements in the array</p> <p>D(n)=\\Theta(1)D(n)=\\Theta(1), computing the middle index, constant time.</p> <p>C(n)=0C(n)=0, no need to combine</p> <p></p>"},{"location":"3-semester/AD1/03-divide-and-conquer/#merge-sort","title":"Merge sort","text":"<p>An algorithm that can solve the sorting problem and uses the DaC technique</p> <p>Assume that we are going to sort a sequence of numbers in array A:</p> <p>Divide</p> <p>If A has at least two elements, remove all the elements from A an put them into 2 sequences, A_1A_1 and A_2A_2, each containing about half of the elements (i.e. A_1A_1 contains the first \\lceil n/2 \\rceil\\lceil n/2 \\rceil elements and A_2A_2 contains the remaining \\lfloor n/2 \\rfloor\\lfloor n/2 \\rfloor elements)</p> <p>Conquer</p> <p>Sort sequences A_1A_1 and A_2A_2 using Merge Sort.</p> <p>Combine </p> <p>Put back the elements into A by merging the sorted sequences A_1A_1 and A_2A_2 into one sorted sequence</p> <p></p> <p></p>"},{"location":"3-semester/AD1/03-divide-and-conquer/#running-example","title":"Running Example","text":""},{"location":"3-semester/AD1/03-divide-and-conquer/#running-time","title":"Running Time","text":"<p>Analysis in lecture-3 slide 53-55</p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/04-solving-recurrences/","title":"Solving Recurrences","text":"<ul> <li>Repeated substitution method</li> <li>Expanding the recurrence by substition and noticing a patteren w.r.t. the step i.</li> <li>Identifying an appropriate i such that the base case can be plugged in.</li> <li>Recursion-trees</li> <li>Draw a tree to visualize what happens when a recurrence is iterated</li> <li>Master method</li> <li>Templates for different classes of recurrences</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#repeated-substitution","title":"Repeated Substitution","text":"<ul> <li>Substitute</li> <li>Expand</li> <li>Substitute</li> <li>Expand</li> <li>...</li> </ul> <p>Observe a pattern and write how your expression looks after the i-th substitution</p> <p>Find out what the value of i should be to get the base case of the recurrence T(1)</p> <p>Insert the value of T(1) and the expression of i into your expression.</p>"},{"location":"3-semester/AD1/04-solving-recurrences/#example-1","title":"Example 1","text":""},{"location":"3-semester/AD1/04-solving-recurrences/#example-2","title":"Example 2","text":""},{"location":"3-semester/AD1/04-solving-recurrences/#recursion-tree","title":"Recursion Tree","text":"<p>A way to conveniently visualize what happens when a recurrence is iterated.</p> <ul> <li>Each node represents the cost of a single sub-problem.</li> <li>Sum the costs within each level of the tree to obtain a set of per\u2013level costs.</li> <li>Sum all the per-level costs to determine the total cost of all levels of teh recursion.</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#example","title":"Example","text":"T(n)=3*T(n/4)+\\Theta(n^2)=3*T(n/4)+c*n^2  <p>Lower bound - \\Omega(n^2)\\Omega(n^2)</p> <p>We have to at least do level 1, so the lower bound is  \\Omega(n^2)\\Omega(n^2).</p> <p></p> <p></p>"},{"location":"3-semester/AD1/04-solving-recurrences/#key-steps","title":"Key steps","text":"T(n)=aT(n/b)+D(n)+C(n)   T(n)=aT(n/b)+D(n)+C(n)  <ul> <li>How many levels in the tree?</li> <li>log_bn+1log_bn+1</li> <li>What is the cost per non-leaf level?</li> <li>Depends on the cost of dividing and combining</li> <li>What is the cost for the leaf level?</li> <li>Depends on how many leave nodes there are: n^{log_ba}n^{log_ba}</li> <li>Each leave node has constant cost</li> <li>Sum the per-level costs into the final cost</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#the-master-method","title":"The Master Method","text":"<p>Providing a template method for solving recurrences of the form: </p>  T(n)=a*T(n/b)+f(n),   T(n)=a*T(n/b)+f(n),  <p>\u200b   where a\\geq 1a\\geq 1 and b&gt;1b&gt;1 are constant, \u200b   and f(n)f(n) is asymptotically positive.</p> <p>T(n)T(n) is the runtime for an algorithm and we know that:</p> <ul> <li>a subproblems of size n/b are solved recursively, each in time T(n/b)T(n/b) </li> <li>f(n)f(n) is the cost of dividing the problem and combining the results</li> <li>f(n)=D(n)+C(n)f(n)=D(n)+C(n)</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#first-case","title":"First case:","text":"<p>\u200b   if f(n)=O(n^{log_ba-\\epsilon})f(n)=O(n^{log_ba-\\epsilon}) for some constant \\epsilon&gt;0\\epsilon&gt;0, then</p>  T(n)=\\Theta(n^{log_ba})   T(n)=\\Theta(n^{log_ba})"},{"location":"3-semester/AD1/04-solving-recurrences/#second-case","title":"Second case:","text":"<p>\u200b   if f(n)=\\Theta(n^{log_ba})f(n)=\\Theta(n^{log_ba}), then $$ T(n)=\\Theta(n^{log_ba}lg(n)) $$</p>"},{"location":"3-semester/AD1/04-solving-recurrences/#third-case","title":"Third case:","text":"<p>\u200b   if f(n)=\\Omega(n^{log_ba+\\epsilon})f(n)=\\Omega(n^{log_ba+\\epsilon}) for some constant \\epsilon&gt;0\\epsilon&gt;0, and the regularity condition is also satisfied, then $$ T(n)=\\Theta(f(n)) $$ Regularity condition:</p> <ul> <li>a*f(n/b)\\leq c*f(n)a*f(n/b)\\leq c*f(n) for some constant c&lt;1c&lt;1 and all sufficiently large n</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#how-to-use","title":"How to use","text":"<ul> <li>Extract a, b, and f(n) from a given recurrence</li> <li>Determine n^{log_ba}n^{log_ba}</li> <li>Compare f(n) and n^{log_ba}n^{log_ba} asymptotically</li> <li>f(n) increases polynomially slower, case 1</li> <li>The increase similarly, case 2</li> <li>f(n) increases polynomially faster, case 3</li> <li>Determine appropriate MM case and apply.</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#correctness-of-algorithms","title":"Correctness of Algorithms","text":"<p>The algorithm is correct if for any legal input it terminates, and produces the desired output</p>"},{"location":"3-semester/AD1/04-solving-recurrences/#loop-invariants","title":"Loop invariants","text":"<p>Invariants - assertions (i-e, statements about the states of the execution) that are valid any time they are reached ( many times during the execution of an algorithm, e.g. in loops)</p> <p>We must show three things about loop invariants:</p> <ul> <li>Initialization - it is true prior to the first iteration</li> <li>Maintenance - if it is true before an iteration, then it remains true before the next iteration</li> <li>Termination - when loop terminates the invariant gives a useful property to show the correctness of the algorithm</li> </ul>"},{"location":"3-semester/AD1/04-solving-recurrences/#example-insertion-sort","title":"Example - Insertion Sort","text":"<p>Invariant</p> <p>At the start of each for loop, A[1...j-1]A[1...j-1] consists of elements originally in A[1...j-1]A[1...j-1] but in sorted order.</p> <p></p> <p>Initialization</p> <p>j = 2, the invariant trivially holds because A[1] is a sorted array</p> <p>Maintenance</p> <p>The inner while loop moves elements A[j-1],A[j-2],...,A[j-]A[j-1],A[j-2],...,A[j-] by one position to the right without chaning their order until it finds the proper position for A[j]A[j].</p> <p>Then, A[j]A[j] is inserted into k-th position such that A[k-1]\\leq A[k]\\leq A[k+1]A[k-1]\\leq A[k]\\leq A[k+1].</p> <p>Thus, A[1...j]A[1...j] consists of the elements originally in A[1...j]A[1...j] but sorted order.</p> <p>Termination</p> <p>The loop terminates, when j=n+1j=n+1.</p> <p>Then the invariant states:</p> <p>\u200b   A[1...j-1]A[1...j-1] consists of elements originally in A[1...j-1]A[1...j-1] but in sorted order.</p>"},{"location":"3-semester/AD1/05-sorting-algorithms/","title":"Sorting Algorithms","text":"<p>Sorting:</p> <p>Input: A sequence of n numbers</p> <p>Output: A permutation (reordering) of the input sequence</p> <p>(slide 8)</p> <p>When in doubt, sort!</p> <p>- One of the principles of algorithm design.</p> <p>Insertion sort</p> <ul> <li>In-place[^in-place] sorting algorithm</li> <li>Worst case complexity \\Theta(n^2)</li> </ul> <p>Merge sort</p> <ul> <li>Uses the DaC technique</li> <li>Not in-place[^in-place] sorting, which requires additional storage with the size of the input array</li> <li>Worst case complexity \\Theta(n\\cdot lg(n))\\Theta(n\\cdot lg(n))</li> </ul> <p>Important properties</p> <ul> <li>Whether a sorting algorithm is in-place?</li> <li>What is the worst case complexity  \\Theta(n^2)\\Theta(n^2) or \\Theta(n\\cdot lg(n))\\Theta(n\\cdot lg(n))?</li> </ul> <p>[^in-place]: In-place: Only a constant number of elements of the input array are ever stored outside the array. </p>"},{"location":"3-semester/AD1/05-sorting-algorithms/#bubble-sort","title":"Bubble Sort","text":"<ul> <li>Popular but inefficient.</li> <li>Repeatedly swapping adjacent elements that are out of order.</li> </ul>"},{"location":"3-semester/AD1/05-sorting-algorithms/#example","title":"Example","text":""},{"location":"3-semester/AD1/05-sorting-algorithms/#selection-sort","title":"Selection Sort","text":"<p>Pseudo Code:</p> <p></p>"},{"location":"3-semester/AD1/05-sorting-algorithms/#example_1","title":"Example","text":""},{"location":"3-semester/AD1/05-sorting-algorithms/#quick-sort","title":"Quick Sort","text":"<p>A DaC algorithm.</p> <p>Does not require additional array like Merge Sort </p> <ul> <li>Sorts in-place [^in-place]</li> </ul> <p></p> <p></p>"},{"location":"3-semester/AD1/05-sorting-algorithms/#example_2","title":"Example","text":""},{"location":"3-semester/AD1/06-heap-sort/","title":"Heap Sort","text":"<p>Heapsort can be regarded as a selection sort with the help of a heap data structure.</p>"},{"location":"3-semester/AD1/06-heap-sort/#heap","title":"Heap","text":"<p>Binary heap data structure A</p> <ul> <li> <p>Array</p> </li> <li> <p>Can be viewed as a nearly complete binary tree</p> </li> <li> <p>All levels, except the lowest one, are completely filled</p> </li> <li> <p>Heap property</p> </li> <li> <p>Max-heap</p> <ul> <li>The root is greater than or equal to all its children, and the left and right subtrees are again binary heaps.</li> </ul> </li> <li> <p>Min-heap</p> <ul> <li>The root is less than or equal to all its children, and the left and right subtrees are again binary heaps</li> </ul> </li> </ul> <p>Two attributes:</p> <ul> <li> <p>A.length: number of elements in the array</p> </li> <li> <p>A.heapsize: number of elements in the heap that is stored in the array</p> </li> <li> <p>1 \\leq A.heapsize \\leq A.length</p> </li> <li> <p>A[1 ... A.length]A[1 ... A.length] may contain many elements, but only the elements in A[1 ... A.heapsize]A[1 ... A.heapsize] are valid elements of the heap</p> </li> </ul>"},{"location":"3-semester/AD1/06-heap-sort/#example","title":"Example","text":""},{"location":"3-semester/AD1/06-heap-sort/#parent-left-child-right-child","title":"Parent, Left Child, Right Child","text":"<pre><code>PARENT(i)\n    return Floor(i/2)\n\nLEFT(i)\n    return 2*i\n\nRIGHT(i)\n    return 2*i+1\n</code></pre> <p>Heap property:</p> <p>A[Parent(i)] \\ge A[i]A[Parent(i)] \\ge A[i]</p> <p>The value of the node is at most the value of the parent.</p>"},{"location":"3-semester/AD1/06-heap-sort/#maintaining-the-heap-property-heapify","title":"Maintaining the Heap Property (Heapify)","text":"<p>Heapify</p> <p>Input: </p> <ul> <li>Array A and an index i into the array</li> </ul> <p>Assume: </p> <ul> <li>Binary trees rooted at Left(i) and Right(i) are heaps</li> </ul> <p>But, A[i] might be smaller than its two children, thus violating the heap property.</p> <p>The method Heapify makes A a heap by moving A[i] down the heap until the heap property is satisfied again.</p>"},{"location":"3-semester/AD1/06-heap-sort/#pseudocode","title":"Pseudocode","text":""},{"location":"3-semester/AD1/06-heap-sort/#example-heapifya2","title":"Example: Heapify(A,2)","text":""},{"location":"3-semester/AD1/06-heap-sort/#analysis-of-heapify","title":"Analysis of Heapify","text":"<ul> <li>Is Heapify recursive algorithm or not</li> <li>If yes, write down the recurrence and solve the recurrence</li> <li>If no, use the RAM model</li> </ul> <p>Identifying the recurrence for Heapify</p> <ul> <li>Dividing (lines 1-3):</li> <li>Figuring out the relationship among the elements A[i], A[l], and A[r].</li> <li>Can be done in constant time, i.e., \u0398(1).</li> <li>Conquer (lines 4-6):</li> <li>Case 1: If A[i] is the largest among A[i], A[l], A[r] already, do nothing.</li> <li>Case 2: Otherwise, conquer the same problem (i.e., Heapfiy) on one of the subtree of node i.</li> <li>How many subproblems are you going to solve for each case?<ul> <li>Case 1: 0</li> <li>Case 2: 1</li> <li>We at most need to solve 1 subproblem.</li> </ul> </li> </ul>"},{"location":"3-semester/AD1/06-heap-sort/#notes","title":"Notes","text":"<ul> <li>Sometimes, it is more important to write down a correct recurrence than solving the recurrence</li> <li>How many subproblems and what is the size of each subproblem</li> <li>Quick sort: best case v.s worst case</li> <li>Heapify: the largest size subproblem</li> <li>What is the cost of dividing and combining</li> <li>Quicksort: partition, dividing phase</li> <li>Merge sort: merge, combining phase</li> </ul>"},{"location":"3-semester/AD1/06-heap-sort/#building-a-heap-from-an-array","title":"Building a heap from an array","text":"<p>Convert an array A[1 ... n]A[1 ... n] into a heap.</p> <p>Notice that the elements in the subarray A [(\u2514n/2\u2518+1)...n ]A [(\u2514n/2\u2518+1)...n ] are already 1-element heaps to begin with</p> <ul> <li>These elements have no children</li> </ul> <p>Call heapify from the \u2514n/2\u2518-th element down to the first element.</p> <pre><code>00  Build-Heap(A)\n01      for i = floor(n/2) downto 1 do\n02          Heapify(A,i)\n</code></pre>"},{"location":"3-semester/AD1/06-heap-sort/#example_1","title":"Example","text":""},{"location":"3-semester/AD1/06-heap-sort/#sorting","title":"Sorting","text":""},{"location":"3-semester/AD1/06-heap-sort/#running-time","title":"Running time","text":"<p>Running time is</p> <p>\u200b   O(n*lg(n))O(n*lg(n)) </p> <p>like merge sort, but unlike selection-, insertion- or bubble-sorts.</p> <p>Sorts in-place - like insertion-, selection- or bubble-sorts, but unlike merge-sort.</p>"},{"location":"3-semester/AD1/07-data-structures/","title":"Data Structures","text":"<p>An abstract data type (ADT) is a specification of:</p> <ul> <li> <p>A set of data.</p> </li> <li> <p>A set of operations that can be performed on the data.</p> </li> </ul> <p>ADT is abstract in the sense that it is independent of various concrete implementations.</p> <ul> <li>Encapsulates data structures and relecant algorithms.</li> <li>Provides access interface.</li> </ul>"},{"location":"3-semester/AD1/07-data-structures/#stack","title":"Stack","text":"<p>A pile of plates</p> <p>An object added to the stack goes on the \"top\" of the stack. (<code>push</code>)</p> <p>An object removed from the stack is taken from the \"top\" of the stack (<code>pop</code>)</p> <p>LIFO: Last in, First out</p> <p></p>"},{"location":"3-semester/AD1/07-data-structures/#operations","title":"Operations","text":"<pre><code>Push(S, x):\n    inserts an element x into the stack S\n\nPop(S):\n    deletes the element on top of the stack S.\n\nStack-Empty(S):\n    returns whether the stack S is empty.\n</code></pre>"},{"location":"3-semester/AD1/07-data-structures/#queue","title":"Queue","text":"<p>A real-life queue</p> <p>An element added to the queue foes to the \"end\" of the queue. (<code>enqueue</code>)</p> <p>The element which has been in the queue the longest can be removed from the queue. (<code>dequeue</code>)</p> <p>Elements are removed from a queue in the same order as they were inserted.</p> <p>FIFO: First in, First out.</p> <p></p>"},{"location":"3-semester/AD1/07-data-structures/#operations_1","title":"Operations","text":"<pre><code>Enqueue(Q, x):\n    inserts an element x into the queue Q\n\nDequeue(Q):\n    deletes the head element in the queue Q.\n</code></pre>"},{"location":"3-semester/AD1/07-data-structures/#linked-list","title":"Linked List","text":"<p>A sequence of elements</p> <p>Each element in the linked list is with:</p> <ul> <li>One key</li> <li>One ore more pointers</li> </ul> <p>There are different types depending on how the elements are linked.</p>"},{"location":"3-semester/AD1/07-data-structures/#singly-linked-list","title":"Singly linked list","text":"<p>Element:</p> <ul> <li>A key</li> <li>One pointer: \"next\", pointing the the successor of the element.</li> <li>The last element points to a \"NIL\".</li> </ul> <p>Head pointer:</p> <ul> <li>Pointer \"head\": pointing to the first element of the list.</li> </ul> <p></p> <p>Note:</p> <ul> <li>\"next\" are for elements (x.next)</li> <li>\"head\" is for whole list (L.head)</li> </ul>"},{"location":"3-semester/AD1/07-data-structures/#alternatively","title":"Alternatively:","text":""},{"location":"3-semester/AD1/07-data-structures/#doubly-linked-list","title":"Doubly linked list","text":"<p>Element:</p> <ul> <li>A key</li> <li>Two pointers: \"next\" and \"prev\"</li> </ul> <p>Still has \"head\".</p> <p></p>"},{"location":"3-semester/AD1/07-data-structures/#alternatively_1","title":"Alternatively","text":""},{"location":"3-semester/AD1/07-data-structures/#operations_2","title":"Operations","text":"<pre><code>Search(L, k):\n    Find the first element with a key k in the list L\n\nInsert(L, x):\n    Insert element x into list L\n\nDelete(L, x):\n    Delete the element x from list L\n</code></pre>"},{"location":"3-semester/AD1/07-data-structures/#priority-queue","title":"Priority Queue","text":"<p>A priority queue (PQ) is a container for maintaining a set A of elements, each with an associated value called key.</p>"},{"location":"3-semester/AD1/07-data-structures/#operations_3","title":"Operations","text":"<pre><code>Insert(A, x):\n    insert element x in set A\n\nMaximum(A):\n    returns the element of A with the largest key (i.e. highest priority)\n\nextract-Max(A):\n    returns and removes the element of A with  the largest key from A\n</code></pre>"},{"location":"3-semester/AD1/07-data-structures/#heap-implementation","title":"Heap Implementation","text":"<p>Use a max-heap.</p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/08a-hash-tables/","title":"Dictionaries","text":"<p>An element has a key part and a sattelite data part.</p> <p>Dictionaries store elements so that they can be located quickly using keys.</p> <p>Dictionary ADT</p> <pre><code>Search(S, k):\n    access operation that returns an element where x.key = k\n\nInsert(S, x):\n    a manipulation operation that adds element x to S.\n\nDelete(S, x):\n    a manipulation operation that removes element x from S. \n</code></pre>"},{"location":"3-semester/AD1/08a-hash-tables/#hash-tables","title":"Hash tables","text":"<p>Like an array, but come up with a Hash function to map the large range (eg. 0 to 9999999) into a small one which we can manage. (eg. 0 to 4)</p> <p>Eg. Take the original key, modulo the (relatively small) size of the array, and use that as an index.</p> <p>Example:</p> <p>(96358904, Bill) into a hashed array with, say, 5 slots:</p> <pre><code>hash(96358904) = 96358904 mod 5 = 4\nhash(96358902) = 96358902 mod 5 = 2\n</code></pre> <p></p> <p>Lookup:</p> <pre><code>Search(\"96358904\"), hash(96358904)=4, then \"Bill\"\nSearch(\"96358900\"), hash(96358900)=0, then \"\\\"\n</code></pre>"},{"location":"3-semester/AD1/08a-hash-tables/#collisions","title":"Collisions","text":"<p>When to elements has the same hashed key.</p>"},{"location":"3-semester/AD1/08a-hash-tables/#chaining","title":"Chaining","text":"<p>Each entry in the table is pointer to a linked list.</p> <p>Elements with same hashed key are placed into a linked list.</p> <p></p>"},{"location":"3-semester/AD1/08a-hash-tables/#linear-probing","title":"Linear Probing","text":"<p>If the current location is used, try the next table location.</p> <p>Lookups walk along the table until the key or an empty slot is found.</p> <p></p>"},{"location":"3-semester/AD1/08a-hash-tables/#open-addressing","title":"Open addressing","text":"<p>Step i from 0, 1, 2, ..., m-1</p> <p>Linear probing: $$ h(k,i)=(h'(k)+i)\\space mod\\space m $$ Quadratic probing:</p> <p>(c1 and c2 are constant) $$ h(k,i)=(h'(k)+c_1i+c_2i^2)\\space mod\\space m $$ Double hashing: $$ h(k,i)=h_1(k)+ih_2(k))\\space mod\\space m $$</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/","title":"Binary Search Tree","text":"<p>Binary tree T satisfiyng binary-search-tree property. (Like max-heap property).</p> <ul> <li> <p>Let x be a node in a binary search tree.</p> </li> <li> <p>If y is a node in the left subtree of x, then $$ y.key\\leq x.key $$</p> </li> <li> <p>If y is a node in the right subtree of x, then</p> </li> </ul>  y.key\\geq x.key  <p>Example:</p> <p></p> <p></p> <p></p> <p>Note: more balanced, the better!</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#represent-with-linked-list","title":"Represent with Linked List","text":"<p>Each node has 3 pointers.</p> <ul> <li>\"P\" points to parent.</li> <li>\"Left\" points to left child.</li> <li>\"Right\" points to right child.</li> </ul> <p>The tree has pointer \"Root\" pointing to the root of the tree.</p> <p></p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#tree-walks","title":"Tree walks","text":"<p>Process of visiting each node in a tree data structure exactly once.</p> <p>Keys in the BST can be printed using \"tree walks\".</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#inorder-tree-walk","title":"Inorder tree walk","text":"<p>The key of each node is visited (printed) between the keys in the left and right subtrees.</p> <pre><code>InorderTreeWalk(x)\n01  if (x != NIL) then\n02      InorderTreeWalk(x.left())\n03      print x.key()\n04      InorderTreeWalk(x.right())\n</code></pre> <p>DaC algorith.</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#example","title":"Example","text":""},{"location":"3-semester/AD1/08b-binary-search-tree/#preorder-tree-walk","title":"Preorder tree walk","text":"<p>Visits each node before visiting its children.</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#postorder-tree-walk","title":"Postorder tree walk","text":"<p>Visits each node after visiting its children.</p>"},{"location":"3-semester/AD1/08b-binary-search-tree/#example_1","title":"Example","text":""},{"location":"3-semester/AD1/09-dynamic-programming/","title":"Dynamic Programming","text":"<p>What if the sub-problems overlap?</p> <ul> <li>Sub-problems share sub-sub-problems.</li> </ul> <p>A DaC algorithm would do more work than necessary, because it needs to repeatedly solve the overlapped sub-sub-problems.</p> <p>A Dynamic Programming algorithm solves each sub-sub-problem only once and then saves its result (in array or hash table), thus avoiding the work of repeatedly solving the common sub-sub-problems.</p>"},{"location":"3-semester/AD1/09-dynamic-programming/#example-fibonacci-numbers","title":"Example - Fibonacci Numbers","text":"<p>A rabbit was born in the beginning.</p> <p>A rabbit starts producing offspring on the second generation after its birth and produces one child each generation.</p> <p>How many rabbits will there be after n generations?</p> <p></p>"},{"location":"3-semester/AD1/09-dynamic-programming/#straightforward-recursive","title":"Straightforward Recursive","text":"F(n)=F(n-1)+F(n-2)  <p>F(0)=0,\\space F(1)=1F(0)=0,\\space F(1)=1 </p> <p>0,1,1,2,3,5,8,13,21,34,...0,1,1,2,3,5,8,13,21,34,...</p> <pre><code>FibonacciR(n)\n01  if n &lt;= 1 then return n\n02  else return FibonacciR(n-1) + FibonacciR(n-2)\n</code></pre> <p>This is slow!</p> <p>Here's why:</p> <p></p> <p>The same value is calculated over and over!</p> <ul> <li>Sub-problems are overlapping \u2013 they share sub-sub-problems.</li> </ul>"},{"location":"3-semester/AD1/09-dynamic-programming/#solution","title":"Solution","text":"<p>Dynamic Programming!</p> <p>We can calculate F(n) in linear time, by remembering solutions to the solved sub-problems.</p> <p>Compute solution in a bottom-up fashion.</p> <pre><code>Fibonacci(n)\n01  F[0] = 0\n02  F[1] = 1\n03  for i = 2 to n do\n04      F[i] = F[i-1] + F[i-2]\n05  return F[n]\n</code></pre>"},{"location":"3-semester/AD1/09-dynamic-programming/#optimization-problems","title":"Optimization Problems","text":"<p>DP is typically applied to optimization problems.</p> <p>Optimization problems can have many possible solutions, each solution has a value, and we wish to find a solution with the optimal value (e.i. minimum or maximum).</p> <p>An algorithm should compute the optimal value plus, if needed an optimal solution.</p>"},{"location":"3-semester/AD1/09-dynamic-programming/#example-rod-cutting","title":"Example - Rod Cutting","text":"<p>Problem:</p> <ul> <li>A steel rod of length n should be cut and sold in pieces.</li> <li>Pieces sold only in integer sizes according to a price table P[1..n]P[1..n]</li> </ul> <p>Goal:</p> <ul> <li>Cut up the rod to maximize profit.</li> </ul> <p></p> <p></p> <p>r_nr_n: the maximum profit of cutton a rod with length n. $$ r_n=max(P[1]+r_{n-1},P[2]+r_{n-2},...,P[n-1]+r_1,P[n]+r_0) $$</p> <ul> <li> <p>Having a rod with length 1, i.e., P[1], and the maximum profit of the   remaining rod with length n-1, i.e., r_{n-2}r_{n-2}</p> </li> <li> <p>Having a rod with length 2, i.e., P[2], and the maximum profit of the   remaining rod with length n - 2, i.e., r_{n-2}r_{n-2}</p> </li> <li>\u2026</li> <li>Having a rod with length n, i.e., P[n], and the maximum profit of the   remaining rod with length 0, i.e., r_=0r_=0</li> </ul> <p>We say that the rod cutting problem exhibits optimal substructure.</p> <pre><code>Rod-Cut(P, n) //P: Price table as array, n: rod length as integer.\n01  if n = 0 then return 0\n02  q = -infinity\n03  for i=1 to n do\n04      q = max(q, P[i] + Rod-Cut(P, n-1))\n05  return q\n</code></pre> <p>Running time is Exponential!</p> <p>\u200b   See analysis on lecture 9 slides, slide 28-30</p>"},{"location":"3-semester/AD1/09-dynamic-programming/#memoization-top-down","title":"Memoization - Top-Down","text":"<p>Remember the solutions in an array or a hash-table.</p> <pre><code>Rod-Cut-M(P, n)\n01  for i = 1 to n do\n02      R[i] = -infinity\n03  return Rod-Cut-M-Aux(P, n, R)\n\nRod-Cut-M-Aux(P, n, R)\n01  if R[n] &gt;= 0 then return R[n]\n02  if n = 0 then q = 0\n03  else\n04      q  = -infinity\n05      for i = 0 to n do\n06          q = max(q, P[i]+Rod-Cut-M-Aux(P, n-1, R))\n07      R[n] = q\n08  return q\n</code></pre>"},{"location":"3-semester/AD1/09-dynamic-programming/#running-example","title":"Running Example","text":"<p>\u200b   See on lecture 9 slides, slide 35-46</p> <p>Run time is Quadratic.</p>"},{"location":"3-semester/AD1/10a-graph-theory/","title":"Graph Theory","text":"<p>Directed graph, G, is a pair (V,E)(V,E), where VV is a finite set and EE is a binary relation on VV.</p> <p></p> <p>The figure shows the directed graph G=(V,E)G=(V,E), where V= \\{1,2,3,4,5,6\\}V= \\{1,2,3,4,5,6\\}  and E=\\{(1,2), (2,2), (2,4), (2,5),(4,1),(4,5),(5,4),(6,3)\\}E=\\{(1,2), (2,2), (2,4), (2,5),(4,1),(4,5),(5,4),(6,3)\\}. </p> <p>The edge (2,2) is a self-loop.</p> <p>A \"point\" is called a vertex, (plural: vertices). A \"connection\" is called an edges/edges. (E is the edge set).</p> <p>An undirected graph is a graph where the edge set of E is unordered.</p> <p></p> <p>This figure shows the undirected graph G=(V,E)G=(V,E), where V=\\{1,2,3,4,5,6\\}V=\\{1,2,3,4,5,6\\} and E=\\{(1,2),(1,5),(2,5),(3,6)\\}E=\\{(1,2),(1,5),(2,5),(3,6)\\} </p> <p>In undirected graphs, self-loops are forbidden. (u,v) and (v,u) are considered the same edge.</p> <p>In a directed graph we say that (u,v) is incident from or leaves u, and is incident to or enters v. If the graph is undirected, (u,v) is incident on u and v.</p> <p>             Incident from 6. Incident to 3. Leaves 6 and enters 6. </p> <p>If (u,v) is an edge in a graph, v is adjacent to u</p> <p>The degree of a vertex in an undirected graph is the number of edges incident on it.</p> <p>A vertex with a degree of 0 is isolated like vertex 4 in the undirected graph example.</p> <p>In a directed graph the out-degree of a vertex is the number of edges leaving it. The in-degree is the number of edges entering it. The degree is out-degree plus in-degree.</p> <p>A path of length k from u to u' is a sequence from u to u' going through k vertices.</p> <p>Mathematically: </p> <p>\u200b   \\langle v_0, v_1,...,v_k\\rangle\\langle v_0, v_1,...,v_k\\rangle where u=v_0,  u'=v_ku=v_0,  u'=v_k and (v_{i-1},v_i)\\in E(v_{i-1},v_i)\\in E for i=1,2,...,ki=1,2,...,k</p> <p>The path contains the vertices v_0, v_1,...,v_kv_0, v_1,...,v_k and the edges (v_0,v_1),(v_1,v_2),...,(v_{k-1},v_k)(v_0,v_1),(v_1,v_2),...,(v_{k-1},v_k)</p> <p>A graph is sparse if |E||E| is much less than |V|^2|V|^2 </p> <p>\u200b   while it is dense if |E||E| is close to |V|^2|V|^2</p>"},{"location":"3-semester/AD1/10a-graph-theory/#representation-of-graphs","title":"Representation of graphs","text":"<p>There are two standard ways to represent a graph:</p> <ul> <li>A collection of adjacency lists</li> <li>An adjacency matrix</li> </ul> <p></p> <p>If a graph is sparse the adjacency-list representation is of choice.</p> <p>If a graph is dense, adjacency-matrix may be of choice.</p>"},{"location":"3-semester/AD1/10b-graph-algorithms/","title":"Searching a graph","text":"<p>Systematically  following its edges so as to visit its vertices.</p> <ul> <li>Can discover the structure of a graph.</li> <li>Many algorithms begin by searching their input graph to obtain the structure information.</li> <li>Searching a graph lies at the heart of the field of graph algorithms.</li> </ul>"},{"location":"3-semester/AD1/10b-graph-algorithms/#breadth-first-search-bfs","title":"Breadth-first search (BFS)","text":"<p>Discovers all vertices at a distance k from s before discovering any vertices at distance k+1.</p> <p>\u200b   \"Breadth First\"</p> <p>Input:</p> <ul> <li>A graph G=(V,E) and a source vertex s</li> </ul> <p>Aim:</p> <ul> <li>Systematically discovers every vertex that is reachable from s.</li> </ul> <p>Output:</p> <ul> <li>The distance from s to each reachable vertex.</li> <li>Distance = the smallest number of edges (unweighted graph)</li> <li>A Breadth-first tree with root s that contains all reachable vertices.</li> </ul> <p>Vertex attributes:</p> <ul> <li>Color:</li> <li>White: unexplored</li> <li>Gray: explored, but not all adjacent vertices has been explored.</li> <li>Black: explored + all adjacent explored.</li> <li>Distance:</li> <li>Distance to source s.</li> <li>Parent:</li> <li>Its parent in the breadth-first tree.</li> </ul>"},{"location":"3-semester/AD1/10b-graph-algorithms/#algorithm","title":"Algorithm","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#running-example","title":"Running Example","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#breadt-first-tree","title":"Breadt-first tree","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#running-time","title":"Running Time","text":"<p>\u200b   See analisys in lecture-10 slides, slide 26</p> <p>Running time: $$ O(|V|+|E|) $$</p>"},{"location":"3-semester/AD1/10b-graph-algorithms/#depth-first-search-dfs","title":"Depth-first search (DFS)","text":"<p>It searches \"deeper\" in the graph whenever possible.</p> <p>Input:</p> <ul> <li>A graph G=(V,E)</li> </ul> <p>Aim:</p> <ul> <li>Systematically visit every vertex in V.</li> </ul> <p>Output:</p> <ul> <li>A depth-first forest that is composed of several depth-first trees.</li> </ul> <p>Vertex attributes:</p> <ul> <li>Color (same as BFS):</li> <li>White: unexplored</li> <li>Gray: explored, but not all adjacent vertices has been explored.</li> <li>Black: explored + all adjacent explored.</li> <li>Timestamp:</li> <li>v.d: discovery time, ie. when v is first explored.</li> <li>v.f: finishing time, ie. when v finishes examining v's adjacency list.</li> <li>Parent:</li> <li>Its parent in the depth-first tree.</li> </ul>"},{"location":"3-semester/AD1/10b-graph-algorithms/#algorithm_1","title":"Algorithm","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#running-example_1","title":"Running Example","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#depth-first-forest","title":"Depth-first forest","text":""},{"location":"3-semester/AD1/10b-graph-algorithms/#running-time_1","title":"Running Time","text":"<p>Initializes all vertices (DFS: line 1-4): </p> <p>\u200b   \\Theta(|V|)</p> <p>DFS-Visit is called exactly once for each vertex, when its white (DFS: line 5-6):</p> <p>\u200b   \\Theta(|V|)\\Theta(|V|)</p> <p>For each vertex u, the loop executes |u.adjacent()|\u200b times (DFS-Visit: line 4-7).</p> <p>\u200b   \\Sigma_{u\\in V}(|u.adjacent()|=|E|)\\Sigma_{u\\in V}(|u.adjacent()|=|E|)</p> <p>Thus: $$ \\Theta(|V|+|E|) $$</p>"},{"location":"3-semester/AD1/10b-graph-algorithms/#bfs-vs-dfs","title":"BFS vs. DFS","text":"<p>BFS</p> <ul> <li>Search from one source</li> <li>Only visits vertices that are reachable from source.</li> <li>BFS tree.</li> <li>Often serves to find shortest paths and shortests path distances.</li> <li>O(|V|+|E|)O(|V|+|E|)</li> </ul> <p>DFS</p> <ul> <li>May search from multiple sources.</li> <li>Visit every vertex.</li> <li>DFS forest.</li> <li>Often as a subroutine in another algorithm, eg.:</li> <li>Classifying edges.</li> <li>Topological sort.</li> <li>Strongly connected components</li> <li>\\Theta(|V|+|E|)\\Theta(|V|+|E|)</li> </ul>"},{"location":"3-semester/AD1/10b-graph-algorithms/#edge-classification-based-on-dfs","title":"Edge Classification based on DFS","text":"<p>Tree edges:</p> <ul> <li>Edges that are in the DFS forest</li> <li>From the example (u,v), (v,y), (y,x), (w,z)</li> </ul> <p>Non Tree edges:</p> <ul> <li>Back edges</li> <li>From descendant to ancestor in DFS tree<ul> <li>(x,v)</li> </ul> </li> <li>Self loops<ul> <li>(z,z)</li> </ul> </li> <li>Forward edges</li> <li>From ancestor to descendant in a DFS tree<ul> <li>(u,x)</li> </ul> </li> <li>Cross edges</li> <li>Remaining edges, between trees or subtrees<ul> <li>(w,y)</li> </ul> </li> </ul> <p></p> <p>When exploring an edge (x,y), y's color tells something:</p> <ul> <li>If y is white - visit x, then y, edge (x, y) is a tree edge.</li> <li>If y is gray - visit y, later x, then y again, edge (x, y) is a back edge.</li> <li>If y is black, edge (x, y) is a forward or cross edge.</li> </ul> <p></p>"},{"location":"3-semester/AD1/10c-topological-sort/","title":"Directed Acyclic Graph (DAG)","text":"<p>A DAG is a directed graph with no cycles.</p> <p></p> <p>Applications:</p> <ul> <li>Indicate precedence relationships</li> <li>An edge e=(a, b) from a to b means that event a must happen before event b.</li> <li>Dependency Graphs</li> </ul> <p>Example - Professor gets dressed in the morning.</p> <p>The professor must put on certain garments before others</p> <p></p>"},{"location":"3-semester/AD1/10c-topological-sort/#how-to-check-dag","title":"How to check DAG","text":"<p>A directed graph is acyclic if and only if the graph has no back edges.</p> <p></p>"},{"location":"3-semester/AD1/10c-topological-sort/#topological-sort","title":"Topological Sort","text":"<p>CLRS page 612.</p> <p>Input:</p> <ul> <li>DAG G = (V, E)</li> </ul> <p>Aim:</p> <ul> <li>Introduce a linear ordering of all its vertices, such that for any edge (u, v) in the DAG, event u appears before event v in the ordering.</li> </ul> <p>Output:</p> <ul> <li>Topologically sorted DAG, ie. a linked list of vetices, showing an order.</li> </ul> <p>Reversely sort vertices according to the finishing times obtained from a DFS.</p> <ul> <li>If v.f &lt; u.f</li> </ul> <p></p> <ul> <li>Event u happens before event v</li> </ul>"},{"location":"3-semester/AD1/10c-topological-sort/#algorithm","title":"Algorithm","text":"<pre><code>Topological-Sort(G)\n01  call DFS(G) to compute finishing times v.f for each vertex v\n02  as each vertex is finished, insert it onto the front of a linked list\n03  return the linked list of vertices\n</code></pre>"},{"location":"3-semester/AD1/10c-topological-sort/#example","title":"Example","text":""},{"location":"3-semester/AD1/10c-topological-sort/#running-time","title":"Running Time","text":"<ul> <li>DFS takes \\Theta(|V|+|E|)\\Theta(|V|+|E|)</li> <li>It takes constant time \\Theta(1)\\Theta(1) to insert a vertex onto the front of a linked list.</li> <li>In total, |V| vertices. Thus, \\Theta(|V|)\\Theta(|V|)</li> <li>In total:</li> </ul>  \\Theta(|V|+|E|)   \\Theta(|V|+|E|)  <p>See Proof of correctness on lecture-10 slides, slide 47-48 </p>"},{"location":"3-semester/AD1/11a-strongly-connected-components/","title":"Strongly Connected Components","text":"<p>A strongly connected component of a directed graph G=(V, E) is a maximal set of vertices C\\subseteq V, such that for every pair of vertices u and v in C, they are reachable from each other.</p> <p></p> <p>Strongly connected components are: $$ {a,b,e},{c,d},{f,g},{h} $$</p>"},{"location":"3-semester/AD1/11a-strongly-connected-components/#dfs-and-transpose-of-a-graph","title":"DFS and Transpose of a graph","text":"<p>DFS often works as a subroutine in another algorithm</p> <ul> <li>Classifying edges</li> <li>Topological sort</li> <li>Strongly Connected Components</li> </ul> <p>Transpose of a graph:</p> <p>Given a graph G = (V, E)</p> <ul> <li>Its transpose graph is </li> </ul>  G^T=(V,E^T),where\\\\ E^T=\\{(u,v):(v,u)\\in E\\}   G^T=(V,E^T),where\\\\ E^T=\\{(u,v):(v,u)\\in E\\}  <ul> <li>Transpose graph G^TG^T has the same vertex set as G,    but has a different edge set from G, where directions of the edges are reversed. </li> </ul> <p>G and G^TG^T has exactly the same strongly connected components.</p> <ul> <li>Vertices u and v are reachable from each other in G   if and only if they are reachable from each other in G^TG^T</li> </ul> <p></p>"},{"location":"3-semester/AD1/11a-strongly-connected-components/#algorithm","title":"Algorithm","text":"<pre><code>Strongly-Connected-Components(G)\n01  call DFS(G) to compute finishing times u.f for each vertex u\n02  compute G^T\n03  call DFS(G^T), but in the main loop of DFS, consider the vertices\n        in order of decreasing u.f (as computed in line 1)\n04  output the vertices of each tree in the depth-first forest formed in line 3 as a \n        seperate strongly connected component\n</code></pre>"},{"location":"3-semester/AD1/11a-strongly-connected-components/#running-example","title":"Running Example","text":""},{"location":"3-semester/AD1/11b-minimum-spanning-tree/","title":"More Graph Concepts","text":"<p>Weighted Graph</p> <ul> <li>G = (V, E), with a weight function \\bold{w}:E\\rarr\\R</li> <li>Weight function w assigns a cost value to each edge in E.</li> <li>Eg. In a graph modeling a road netwok, the weight of an edge represents the length of a road.</li> <li>Eg. w(e)=10w(e)=10 or w(u,v)=10w(u,v)=10, given e=(u)e=(u)</li> </ul> <p>Path</p> <ul> <li>A sequence of vertices &lt;v_1,v_2,...,v_k&gt;&lt;v_1,v_2,...,v_k&gt;    such that vertex v_{i+1}v_{i+1} is adjacent to vertec v_iv_i for i=1 ... k-1i=1 ... k-1</li> <li>A sequence of edges &lt;(v_1,v_2),(v_2,v_3),...,(v_{k-1},v_k)&gt;&lt;(v_1,v_2),(v_2,v_3),...,(v_{k-1},v_k)&gt;</li> <li>A sequence of edges &lt;e_1, e_2, ...,e_{k-1}&gt;&lt;e_1, e_2, ...,e_{k-1}&gt;, where</li> <li>e_1=(v_1,v_2)e_1=(v_1,v_2)</li> <li>e_2=(v_2,v_3),...,e_2=(v_2,v_3),..., and</li> <li>e_{k-1}=(v_{k-1},v_k)e_{k-1}=(v_{k-1},v_k)</li> </ul> <p>Sub-Graph</p> <ul> <li>A subset of vertices and edges.</li> </ul> <p></p> <p>Connected Graph</p> <ul> <li>Any two vertices in the graph are connected by some path</li> </ul> <p></p> <p>Tree</p> <ul> <li>Connected undirected graph without cycles.</li> </ul>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#spanning-tree","title":"Spanning Tree","text":"<p>A spanning tree T of a connected, undirected graph G = (V, E) is a sub-graph of G, satisfying:</p> <ul> <li>T contains all vertices of G;</li> <li>T connnects any two vertices of G;</li> <li>T\\subseteq ET\\subseteq E and T is acyclic.</li> </ul> <p>T is a tree, since T is acyclic and connects any two vertices of the undirected graph G.</p> <p></p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#minimum-spanning-tree-mst","title":"Minimum Spanning Tree (MST)","text":"<p>There are more than one spanning tree.</p> <p>MST of a connected, undirected, weighted graph G is a spanning tree T:</p> <ul> <li>Satisfying all conditions of a spanning tree.</li> <li>Has the minimum value of w(T)=\\Sigma_{(u,v)\\in T}(w(u,v))w(T)=\\Sigma_{(u,v)\\in T}(w(u,v)),   among all possible spanning trees.</li> </ul> <p>Finding MST is an optimization problem.</p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#growing-mst","title":"Growing MST","text":"<p>Input</p> <ul> <li>Connected, undirected, weigthed graph G = (V, E)</li> <li>A weight function w:E\\rarr \\Rw:E\\rarr \\R</li> </ul> <p>Output</p> <ul> <li>An MST A, ie. a set of edges.</li> </ul> <p>Intuition - Greedy search:</p> <ul> <li>Initialize A = \u00f8, and A is a subset of some MST, ie. a tree.</li> <li>Add one edge (u, v) to A at a time, such that A \\cup\\{((u,v)\\}A \\cup\\{((u,v)\\} is a subset of some MST.</li> <li>Key part: How to determine an edge (u, v) to add?</li> <li>Edge (u,v)\\in E(u,v)\\in E but (u,v)\\notin A(u,v)\\notin A</li> <li>What else?</li> </ul> <pre><code>Generic-MST(G, w)\n01  A = \u00d8\n02  while A does not form a spanning tree\n03      find an edge (u,v) that is safe for A\n04      A = A U {(u,v)}\n05  return A\n</code></pre>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#prims-algorithm","title":"Prim's Algorithm","text":"<p>https://www.youtube.com/watch?v=YyLaRffCdk4</p> <p>A special case of the generic MST method.</p> <p>Input</p> <ul> <li>Connected, undirected, weighted graph G = (V, E)</li> <li>A weight function w:E\\rarr \\Rw:E\\rarr \\R</li> <li>A random vertex r to start with.</li> </ul> <p>Output</p> <ul> <li>MST where each vertex v has two attributes</li> <li>Parent, v.parent: v's parent in the MST</li> <li>Key, v.key: the least weight of any edge connecting v to a vertex in the MST.</li> </ul> <p>Intuition</p> <ul> <li>A vertex based algorithm</li> <li>The algorithm maintains a tree.</li> <li>Add one vertex to a tree at a time, until all are added -- MSP</li> <li>Safe edge: the least weight edge that connects a vertex v not in the tree, to a vertex in the tree, ie. greedy feature, -- add v.</li> </ul>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#pseudocode","title":"Pseudocode","text":""},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#running-example","title":"Running Example","text":"<p>See explanation in lecture-11 slides, slide 24-28!</p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#complexity","title":"Complexity","text":"<p>See analysis in lecture-11 slides, slide 31</p>  O(|E|*lg(|V|))   O(|E|*lg(|V|))"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#kruskal-algorithm","title":"Kruskal Algorithm","text":"<p>https://www.youtube.com/watch?v=5xosHRdxqHA</p> <p>A special case of the generic MST method.</p> <p>Input</p> <ul> <li>Connected, undirected, weighted graph G = (V, E)</li> <li>A weight function w:E\\rarr\\Rw:E\\rarr\\R</li> </ul> <p>Output</p> <ul> <li>MST</li> </ul> <p>Intuition</p> <ul> <li>An edge based algorithm</li> <li>The algorithm maintains a forest, where each vertex is treated as a distinct tree in the beginning.</li> <li>Add one edge from G to MST at a time.</li> <li>Safe edge: the least weight edge amon all edges in G that connects to distinct trees in the forest, ie. greedy feature.</li> </ul> <p>The algorithm keeps adding a sefe edge (u, v) to the MST, if (u, v) satisfies:</p> <ul> <li>C1: has the least weight among all edges in G</li> <li>C2: connects two different trees in the forest - (u, v) is not in MST.</li> </ul> <p>If u and v belong to the same tree in the forest, u and v are a part of a MST - adding (u, v) creates a cycle for MST.</p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#pseudocode_1","title":"Pseudocode","text":""},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#running-example_1","title":"Running Example","text":"<p>See explanation in lecture-11 slides, slide 36-41</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#generic-algorithm","title":"Generic Algorithm","text":"<p>A cut of an undirected graph G = (V, E) is a partition of vertices, denoted as (S, V-S), where S\\sub VS\\sub V</p> <p>An edge (u,v)\\in E(u,v)\\in E crosses the cut if </p> <ul> <li>u is in S and v is in V-S, or</li> <li>v is in S and u is in V-S</li> </ul> <p>Light edge is an edge crossing the cut an has the minimum weight of any edge crossing the cut.</p> <p></p> <p>Given a cut (S, V-S) as a partition of G = (V, E).</p> <p>Considering a set A of edges, we say the cut respects A if no edge in A crosses the cut.</p> <p></p> <pre><code>MST(G)\n01      A = \u00d8\n02      while A does not form a spanning tree do\n03.1        Make a cut (S, V-S) of G that respects A\n03.2        Take the light edge (u,v) crossing S to V-S\n04          A = A U {(u,v)}\n05      return A\n</code></pre> <p>3.1: </p> <p>If an edge belongs to A, ie. a part of MST, it does not cross S to V-S,  this makes sure edges in A are not safe edges.</p> <p>3.2:</p> <p>The light edge (u, v) is safe for A, satisfying:</p> <ul> <li>(u, v) crosses S to V-S: (u, v) does not belong to A</li> <li>(u, v) has the minimum weight of any edge crossing the cut: greedy.</li> </ul> <p>Essence:</p> <ul> <li>Find a possible cut.</li> <li>Take a light edge.</li> </ul>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#example","title":"Example","text":"<p>From the AD (DAT/SW) Exam 2015</p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#prims-vs-generic-algorithm","title":"Prim's vs Generic Algorithm","text":"<p>See more in lecture-11 slide 48</p>"},{"location":"3-semester/AD1/11b-minimum-spanning-tree/#kruskalss-vs-generic-algorithm","title":"Kruskals's vs Generic Algorithm","text":"<p>See more in lecture-11 slide 49-51</p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/","title":"The Shortests Path Problem","text":"<p>Lars plans to go from Aalborg to Aarhus and he wants to save fuel.</p> <ul> <li>Assuming fuel consumption is prorpotional to travel distance</li> </ul> <p>One possible solution is:</p> <ul> <li>Model road network as weighted graph</li> <li>Enumerate all paths from Aalborg to Aarhus</li> <li>Add upp the lengths of roads in each path and selected the paht with shortest sum of lengths</li> </ul> <p>This is verty ineffecient because it examines a lot of paths that are note worth considering.</p> <p>Weighted, directed graph G = (V, E) with a weight function w:E\\rarr \\R</p> <p>A path on G: </p> <p>\u200b   p=&lt;(v_0,v_1),(v_1,v_2),...,(v,_{k-1},v_k)&gt;p=&lt;(v_0,v_1),(v_1,v_2),...,(v,_{k-1},v_k)&gt;</p> <p>\u200b       w(v_0,v_1)\\space w(v_1,v_2)\\space\\space w(v,_{k-1},v_k)w(v_0,v_1)\\space w(v_1,v_2)\\space\\space w(v,_{k-1},v_k)</p> <p>Weight of a path is:</p> <p>\u200b   w(p)=\\Sigma^{k-1}_{i=0}w(v_i,v_{i+1})w(p)=\\Sigma^{k-1}_{i=0}w(v_i,v_{i+1})</p> <p>Given two vertices u and v in V,</p> <ul> <li>More than one path exists to go from u to v, eg. p_1,p_2,...,p_np_1,p_2,...,p_n</li> <li>Each path has a weight w(p_1),w(p_2),...,w(p_n)w(p_1),w(p_2),...,w(p_n)</li> </ul> <p>The shortests-path weight, denoted as \\delta(u, v)\\delta(u, v), from u to v:</p> <ul> <li> <p>min(w(p_1),w(p_2),...,w(p_n))min(w(p_1),w(p_2),...,w(p_n))</p> </li> <li> <p>defined as: </p> </li> </ul> <p></p> <p>The shortest path between u and v is a path p with the short-path weight w(p)=\\delta(u,v)w(p)=\\delta(u,v)</p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#problems","title":"Problems","text":"<p>Single-source</p> <p>Find a shortest path from a given source (vertex s) to each of the vertices that are reachable from s.</p> <p>Single-pair</p> <p>Given two vertices, find a shortest path between them.</p> <ul> <li>Solution to single-source also solves this.</li> </ul> <p>All-pairs</p> <p>Find shortest-paths for every pair of vertices.</p> <ul> <li>Running a single-source algorithm once from each vertex</li> <li>More efficient method: Not covered in AD1</li> </ul> <p>Shortest-paths for un-weighted graphs.</p> <ul> <li>BFS, lecture 10.</li> </ul>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#negative-weights","title":"Negative weights","text":"<p>If weights are non-negative, shortest paths are well-defined.</p> <p>Negative weights effect shortest-path weights?</p> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#cycles","title":"Cycles","text":"<p>A path &lt;v_0,v_1,...,v_i,...,v_j,...,v_k&gt;&lt;v_0,v_1,...,v_i,...,v_j,...,v_k&gt; forms a cycle, if v_i=v_jv_i=v_j</p> <p>Shortest paths have NO cycles.</p> <ul> <li>Negative-weight cycles</li> <li>No. Otherwise, shortest paths are not well-defined anymore.</li> <li>Positive-weight cycles</li> <li>No. Otherwise, we could get shorter paths by removing the cycles.</li> <li>0-weight cycles</li> <li>No. We can just repeatedly remove the 0-weight cycles to form another shortest path, until the path becomes cycle free.</li> </ul> <p>Any acyclic path in a graph G = (V, E) contains at most |V| distinct vertices and at most |V|-1 edges.</p> <ul> <li>This is used by Bellman-Ford algorithm</li> </ul>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#shortest-paths-tree","title":"Shortest Paths Tree","text":"<p>The result of shortest path algorithms.</p> <p>A shortest paths tree.</p> <ul> <li>The shortest paths tree is a tree with the source vertex s as the root</li> <li>It records a shortest path from the source vertex s to each vertex v that is reachable from s.</li> </ul> <p>Each vertex v</p> <ul> <li>v.parent() records the predecessor of v in its shortest path</li> <li>v.d() records a shortest-path weight from s to v.</li> </ul>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#relaxation-technique","title":"Relaxation Technique","text":"<p>For each vertex v in the graph, we maintain v.d():</p> <ul> <li>Estimate the weight of a shortest path from s to v.</li> <li>Initialize v.d() to \\infin\\infin in the beginning.</li> <li>Update, ie. decrease the value of v.d() during the search.</li> </ul> <p>Intuition</p> <ul> <li>Check whether a new path from s, via u, to v, can improve the existing shortest path from s to v.</li> <li>w(s,u)+w(u,v)w(s,u)+w(u,v) vs w(s,v)w(s,v)</li> <li>is u.d +w(u,v)&lt;v.du.d +w(u,v)&lt;v.d ?</li> </ul> <p></p> <pre><code>Relax(u,v,G)\n01  if v.d &gt; u.d + G.w(u,v) then\n02      v.d = u.d + G.w(u,v)\n03      v.parent = u\n</code></pre> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#dijkstras-algorithm","title":"Dijkstra's Algorithm","text":"<p>Works fro graphs with non-negative edge weights</p> <p>Input</p> <ul> <li>Directed, weighted graph G = (V, E)</li> <li>A weight function w:E\\rarr\\Rw:E\\rarr\\R</li> <li>A source vertex s.</li> </ul> <p>Output</p> <ul> <li>A set of vertices S, |S|=|V|</li> <li>Each vertex u\\in Su\\in S has a value for u.d() and for u.parent()</li> <li>If u is not reachable from s, u.d() = \\infin\\infin</li> </ul> <p>Intuition</p> <ul> <li>Maintain a set S of visited vertices, and each time</li> <li>1) select a vertex u that is the \"closest\"* from s, and add it to S</li> <li>2) relax all edges from u,      ie. check whether going through u can improve the shortest-path weight of u's neighbours.</li> </ul> <p>* \"Closest\" = Least shortest-path weights (a priority queue prioritized on u.d())</p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#pseudocode","title":"Pseudocode","text":"<p>A little different from book in syntax, see CLRS p. 658</p> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#running-example","title":"Running Example","text":"<p>Explained in Lecture-12 slide 18-21</p> <p></p> <p></p> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#running-time","title":"Running Time","text":"<p>Analysis in Lecture-12 slide 23-24</p> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#correctness","title":"Correctness","text":"<p>Analysis in Lecture-12 slide 25-28</p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#bellman-ford-algorithm","title":"Bellman-Ford Algorithm","text":"<p>Dijkstra's doesn't work when there are negative edges.</p> <ul> <li>Intuition - We cannot guarantee that the length of a path increases when more edges are included.</li> </ul> <p>Bellman-Ford alg. can handle a graph where edges have negative weights (but no negative-weight cycles)</p> <p>Input</p> <ul> <li>Directed, weighted graph G = (V, E)</li> <li>A weight function w:E\\rarr\\Rw:E\\rarr\\R</li> <li>A source vertex s.</li> </ul> <p>Output</p> <ul> <li>Boolean value:</li> <li>False = detects negative-weight cycles</li> <li> <p>True = returns the shortest path-tree</p> </li> <li> <p>If Boolean value = true, a set of vertices S, |S|=|V|</p> </li> <li>Each vertex u\\in Su\\in S has a value for u.d() and for u.parent()</li> <li>If u is not reachable from s, u.d() = \\infin\\infin</li> </ul>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#pseudocode_1","title":"Pseudocode","text":""},{"location":"3-semester/AD1/12-finding-shortest-paths/#running-example_1","title":"Running Example","text":"<p>Explained in Lecture-11 slide 30-34</p> <p></p> <p></p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#correctness_1","title":"Correctness","text":"<p>Based on Path Relaxation Property</p> <p>\u200b   Analysis in lecture-12 slide 35-37</p>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#shortest-path-in-dags","title":"Shortest Path in DAGs","text":"<ul> <li>Topologically sort the DAG</li> <li>Relax the edges of vertices according to the topologically sorted order of vertices.</li> </ul>"},{"location":"3-semester/AD1/12-finding-shortest-paths/#running-example_2","title":"Running Example","text":""},{"location":"3-semester/AD1/12-finding-shortest-paths/#correctness_2","title":"Correctness","text":"<p>Based on Path Relaxation Property</p> <p>\u200b   Analysis in lecture-12 slide 41 + 35-37</p>"},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/","title":"Big O Cheat Sheet","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#complexity","title":"Complexity","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#chart","title":"Chart","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#table","title":"Table","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#algorithms-and-data-structures","title":"Algorithms and Data structures","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#sorting-algorithms","title":"Sorting Algorithms","text":""},{"location":"3-semester/AD1/extra1-big-o-cheat-sheet/#data-structures","title":"Data Structures","text":""},{"location":"3-semester/AD1/extra2-standard-notation-and-common-functions/","title":"Standard Notation and Common Functions","text":"<p>See CLRS p. 53-</p>"},{"location":"3-semester/AD1/extra2-standard-notation-and-common-functions/#exponentials","title":"Exponentials","text":"<p>For all real a &gt; 0, m, and n, we have the following identities</p> <p></p>"},{"location":"3-semester/AD1/extra2-standard-notation-and-common-functions/#logarithms","title":"Logarithms","text":"<p>We shall be using the following notations:</p> <p></p> <p>An important notational convention we shall adopt is that logarithm functions will apply only to the next term in the formula,so that lg\\space n + k will mean lg(n)+klg(n)+k and not lg(n+k)lg(n+k). If we hold b&gt; 1b&gt; 1 constant, then for n&gt;0n&gt;0, the function log_b nlog_b n is strictly increasing.</p> <p></p>"},{"location":"3-semester/AD1/extra3-standard-knowledge/","title":"Standard Knowledge","text":""},{"location":"3-semester/AD1/extra3-standard-knowledge/#logarithm","title":"Logarithm","text":"<p>Log_{10}(200)=2.3 because 200=10^{2.3}200=10^{2.3}</p> <p>Log_{10}(10^x)=xLog_{10}(10^x)=x</p> <p>i-th Logarithm:</p> <p>What to raise i in to get the result.</p> <p>log_i(x)log_i(x): solve equation:</p> <p>\u200b   find y: x=i^yx=i^y</p>"},{"location":"3-semester/AD1/extra3-standard-knowledge/#others","title":"Others","text":"\\frac{a}{c}\\cdot\\frac{b}{d}=\\frac{ab}{cd}   \\frac{a}{c}\\cdot\\frac{b}{d}=\\frac{ab}{cd}   \\frac{a}{b}:\\frac{c}{d}=\\frac{a}{b}\\cdot\\frac{d}{c}   \\frac{a}{b}:\\frac{c}{d}=\\frac{a}{b}\\cdot\\frac{d}{c}"},{"location":"3-semester/DEB/","title":"DEB - DESIGN AND EVALUATION OF USER INTERFACES","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=27350</p>"},{"location":"3-semester/DEB/03-envisionment/","title":"Envisionment","text":"<ul> <li> <p>Making ideas visible</p> </li> <li> <p>Representing design products to ourselves and others</p> </li> <li> <p>Generation, communication and evaluation of ideas</p> </li> </ul> <p>Types of representations:</p> <p>Exploration</p> <ul> <li>e.g. sketches and wireframes</li> </ul> <p>Accuracy</p> <ul> <li>e.g. prototypes</li> </ul> <p>Needs to be accurate enough, but not confusing (main features must stand out)</p>"},{"location":"3-semester/DEB/03-envisionment/#basic-techniques","title":"Basic Techniques","text":""},{"location":"3-semester/DEB/03-envisionment/#sketch-and-wireframe-examples","title":"Sketch and Wireframe Examples","text":"<p>Two examples from the same example project</p>"},{"location":"3-semester/DEB/03-envisionment/#sketch","title":"Sketch","text":""},{"location":"3-semester/DEB/03-envisionment/#wireframe","title":"Wireframe","text":"<p>A wireframe is a step up from a sketch</p>"},{"location":"3-semester/DEB/03-envisionment/#navigation-maps","title":"Navigation maps","text":""},{"location":"3-semester/DEB/03-envisionment/#prototypes","title":"Prototypes","text":"<p>A prototype is something you can interact with.</p> <p>Sketch/wireframe provides a static view while a prototype provides an interactive view.</p> <p>There are two types of prototypes: </p> <p>Lo-fi prototypes and Hi-fi prototypes.</p>"},{"location":"3-semester/DEB/03-envisionment/#lo-fi-prototypes","title":"Lo-fi prototypes","text":"<p>AKA \u201cpaper prototypes\u201d</p> <p>More explorative.</p> <p>Quick to produce (throw-away)</p> <p>Broad emphasis on:</p> <ul> <li>Content</li> <li>Structure</li> <li>Key functions</li> <li>Navigation</li> </ul>"},{"location":"3-semester/DEB/03-envisionment/#hi-fi-prototypes","title":"Hi-fi prototypes","text":"<p>\"Plug in the power cord\".</p> <p>High level of detail (layout and graphics).</p> <p>Useful for evaluating specific design elements and features.</p> <p>Interactive.</p> <p>Used when design ideas are stabilizing.</p>"},{"location":"3-semester/DEB/03-envisionment/#hi-fi-vs-lo-fi","title":"Hi-fi vs Lo-fi","text":"<p>Lo-fi</p> <ul> <li>Cheap</li> <li>Lack of detail</li> <li>Not realistic</li> <li>Low level of validity when testing</li> </ul> <p>Hi-fi</p> <ul> <li>Expensive</li> <li>Realistic</li> <li>High level of validity when testing</li> <li>Testing is done at a later stage</li> <li>Clients believe they are real!</li> <li>Premature commitment</li> <li>Reluctance in making radical changes, because you as a designer has spend time on the prototype.</li> </ul> <p>Be careful with making prototypes too real. The clients can think that the system is done, and wonder why you need to spend more time. </p> <p>That's why the sketch example looks like a drawing. It is made in a tool, but made to look like a drawing, so that there is no doubt that it is not a finished product.</p>"},{"location":"3-semester/DEB/03-envisionment/#tools","title":"Tools","text":"<p>Exploration: Balsamiq</p> <p>Accuracy: Axure</p> <p>Power Point</p> <p>More tools: http://wiki.c2.com/?GuiPrototypingTools</p>"},{"location":"3-semester/DEB/04-physical-design/","title":"Physical Design","text":"<p>Literature:</p> <ul> <li>Benyon, D. (3rd edition): Chapter 4, section 4.5 + Chapter 9, sections 9.5 and 9.6 + Chapter 12, sections 12.1-12.3.</li> <li>Nielsen (1994): Enhancing the Explanatory Power of Usability Heuristics (PDF)</li> <li>Petrie (2012): What do users really care about?: a comparison of usability problems found by users and experts on highly interactive websites (PDF)</li> </ul> <p>Abstract vs. concrete design.</p> <p>Abstract (Conceptual design):</p> <p>Determining the following:</p> <ul> <li>Logic</li> <li>Functions</li> <li>Structure</li> <li>Content</li> </ul> <p>Concrete design:</p> <p>Physical realization of the same (logic, functions, ...)</p> <p>The UI: \"Everything in the system that people come in contact with\"</p> <p>Difference user interfaces: Command prompt and GUI (Graphical User Interface).</p>"},{"location":"3-semester/DEB/04-physical-design/#command-prompt","title":"Command Prompt","text":"<p>Some things can be done fast by expert users.</p>"},{"location":"3-semester/DEB/04-physical-design/#graphical-user-interface","title":"Graphical User Interface","text":"<p>Direct Manipulation</p> <p>Example: Windows File Manager</p> <ul> <li>Continuous representation of the object of interest</li> <li>Physical actions or labeled button presses instead of complex syntax</li> <li>Rapid incremental reversible operations whose impact on the object of interest is immediately visible</li> </ul> <p>User friendly for novice user.</p> <p>WIMP</p> <ul> <li>Windows</li> <li>Icons</li> <li>Menus</li> <li>Pointers</li> </ul>"},{"location":"3-semester/DEB/04-physical-design/#icons","title":"Icons","text":"<p>Holton's icon checklist</p> <ul> <li>Understandable</li> <li>Familiar</li> <li>Unambiguous</li> <li>Memorable</li> <li>Informative</li> <li>Few</li> <li>Distinct</li> <li>Attractive</li> <li>Legible (Easily readable)</li> <li>Compact</li> <li>Coherent</li> <li>Extensible</li> </ul>"},{"location":"3-semester/DEB/04-physical-design/#menus","title":"Menus","text":"<p>Different types of menus:</p> <ul> <li>Cascading</li> <li>Pop-up</li> <li>Contextual</li> </ul>"},{"location":"3-semester/DEB/04-physical-design/#cascading-menu","title":"Cascading Menu","text":"<p>It cascades/unfolds.</p> <p>Compacting the information visible to the user.</p>"},{"location":"3-semester/DEB/04-physical-design/#popup-menu","title":"Popup Menu","text":""},{"location":"3-semester/DEB/04-physical-design/#contextual-menu","title":"Contextual Menu","text":"<p>Typically right click on folder/file you want to access.</p> <p>Adapts based on the context.</p>"},{"location":"3-semester/DEB/04-physical-design/#widget-guidelines","title":"Widget Guidelines","text":""},{"location":"3-semester/DEB/04-physical-design/#radio-buttons","title":"Radio Buttons","text":"<p>You can only select one item.</p> <p>Mutual exclusiveness.</p>"},{"location":"3-semester/DEB/04-physical-design/#checkboxes","title":"Checkboxes","text":"<p>You can select more than one.</p>"},{"location":"3-semester/DEB/04-physical-design/#toolbars","title":"Toolbars","text":""},{"location":"3-semester/DEB/04-physical-design/#more-examples","title":"More examples:","text":"<ul> <li>Textbox</li> <li>Dropdowns</li> <li>Date</li> <li>Textarea</li> <li>Password</li> <li>Tel</li> <li>URL</li> <li>And many more</li> </ul>"},{"location":"3-semester/DEB/04-physical-design/#nielsens-heuristics","title":"Nielsen's Heuristics","text":"<ol> <li>Visibility of systems status</li> <li>Match between system and real world</li> <li>User control and freedom</li> <li>Consistency and standards </li> <li>Error prevention</li> <li>Recognition rather than recall</li> <li>Flexibility and efficiency of use</li> </ol>"},{"location":"3-semester/DEB/04-physical-design/#petrie-and-powers-heuristics","title":"Petrie and Powers' heuristics","text":"<p>Physical presentation:</p> <ol> <li>Make text and interactive elements large and clear enough</li> <li>Make page layout clear</li> <li>Avoid short time-outs and display timeouts</li> <li>Make key content and elements and changes to them salient[^salient]</li> </ol> <p>Content:</p> <ol> <li>Provide relevant and appropriate content</li> <li>Provide sufficient but not excessive content</li> <li>Provide clear terms, abbreviations, avoid jargon</li> </ol> <p>Information Architecture:</p> <ol> <li>Provide clear, well-organized information structures</li> </ol> <p>Interactivity:</p> <ol> <li>How and why? </li> <li>Clear labels and instructions</li> <li>Avoid duplication/excessive effort by users</li> <li>Make input formats clear and easy</li> <li>Provide feedback on user actions and system progress</li> <li>Make the sequence of interaction logical</li> <li>Provide a logical and complete set of options</li> <li>Follow conventions for interaction</li> <li>Provide the interactive functionality users will need and expect</li> <li>Indicate if links go to an external site or to another webpage</li> <li>Interactive and non-interactive elements should be clearly distinguished</li> <li>Group interactive elements clearly and logically</li> <li>Provide informative error messages and error recovery</li> </ol> <p>[^salient]: most noticeable or important. (Dansk: fremtr\u00e6dende)</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/","title":"Memory","text":""},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#working-memory","title":"Working memory","text":"<p>Central executive is part of working memory and part of the brain. Consists of two slave systems, and helps humans focus on/remember things they see or hear fairly detailed, but not for a long time</p> <p>Working memory is persistent for about 30 seconds. Dialog boxes are persistent until users take action, otherwise they might forget.</p> <ul> <li>Visuo-spatial sketchpad (visualization)</li> <li>Articulatory loop (audiotory)</li> <li>Called \"loop\" because humans will repeat things to remember them<ul> <li>For example phone numbers</li> </ul> </li> </ul>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#chunking","title":"Chunking","text":"<p>Division of a thing to remember, into smaller parts, which then helps remember more</p> <ul> <li>Phone numbers</li> <li>25687462 =&gt; 25 68 74 62</li> <li>Area codes are often separated from the rest of the number</li> </ul> <p>Reduce the memory load by chunking</p> <p></p> <p>Sub-items need to be strongly connected to the super category</p> <p>Another example is in the Word tool bar, that groups different actions together</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#theories-about-recollection","title":"Theories about recollection","text":"<p>How many things can a human recall, based on free memory, without any cues to help remember. Helps decide how many menu items to include in a UI.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#miller-1956-5-to-9-items","title":"Miller (1956)   5 to 9 items","text":""},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#cowan-2002-3-to-5-items","title":"Cowan (2002) 3 to 5 items","text":"<p>A menu with many items is not necessarily bad design. Humans can't remember that much, needs to be shown what they need, rather than let them recall. Can be described as a form of direct manipulation (constant overview of objects, reverse actions and see them).</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#principles","title":"Principles","text":"<p>For reducing the memory load</p> <ul> <li>Recognition rather than recall</li> <li>Match between system and the real world</li> <li>An icon with a design from the real world, will let users recognize what it does</li> <li>Linked to recognition rather than recall</li> </ul>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#attention","title":"Attention","text":"<p>What we focus upon. Focus can be directed to surroundings while interacting. Concentration of mental effort on sensory (things that are seen or heard) or mental (thoughts) events.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#the-stroop-effect","title":"The Stroop Effect","text":"<p>Shows how bad the human attention span is. </p> <p></p> <p>When asked to say the color of the font, and not the color that is written, it is easier when there is a correspondence. Requires a larger mental effort when missing correspondence. Attention is directed towards reading the word (mental stimuli) but the font color is seen.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#forms-of-attention","title":"Forms of attention","text":""},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#selective-attention","title":"Selective attention","text":"<p>Where attention is directed towards one element</p> <ul> <li>An example is sitting on the phone at a bus stop. It is selective attention, but can quickly become divided if bus arrives. Must realize how environment can affect attention when designing.</li> </ul>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#divided-attention","title":"Divided attention","text":"<p>When attention is shifted from one element to another</p> <ul> <li>An example is driving while being on the phone</li> <li>Another example is BT, shows lots of ads and articles, so difficult to be selective with attention</li> </ul>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#stress","title":"Stress","text":"<p>Stress will affect attention, and is described as external (noise, light vibration) and mental (anger, fear) stimuli affecting level of arousal.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#yerkes-dodson-law","title":"Yerkes-Dodson law","text":"<p>As the stress/arousal level increases, so will the performance, until a certain level. More stress can be handled with a simple task than with a complex task, before performance drops.</p> <p>An optimal level of stress exist, but will vary between users, typically because of skill.</p> <p>If a system is designed in a stressful environment, the performance level needs to be considered.</p> <p></p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#examples","title":"Examples","text":"<ul> <li>A news website with lots of ads </li> <li>Ambulances</li> <li>Other safety critical environments</li> <li>Flight cockpits</li> <li>Environments with lots of stimuli</li> </ul>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#mental-workload","title":"Mental workload","text":"<p>Describes how busy the user is and how difficult their task is.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#nasa-task-load-index","title":"NASA Task Load Index","text":"<p>Helps measure mental workload through questionnaire form</p> <p></p> <p>Result of a NASA TLX</p> <p></p> <p>Helps measure the perceived workload</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#visual-search","title":"Visual search","text":"<p>When having to locate an item in a visual scene. Easy to locate an item when using attention drawing elements, such as the item being larger or another color. Attention is grabbed.</p> <p>Humans do not use a particular strategy to search for items. They will often look at images however, so images can be \"dangerous\" to use, as they can stand out too much compared to text.</p>"},{"location":"3-semester/DEB/05-physical-design-memory-and-attention/#alerts-and-error-messages","title":"Alerts and error messages","text":"<p>If an error occurs or there is a change in the system state, the users attention needs to be grabbed. Can be done in two ways:</p> <ul> <li>Unobtrusive</li> <li>When an email is received and a small popup appears</li> <li>General Windows popups</li> <li>The message can be seen, but does not interfere with the users current task</li> <li>Obtrusive</li> <li>Master alerts in planes (will happen if an engine goes out, blinks and beeps). Grabs attention from flying, but is more important.</li> <li>Can't have too many obtrusive alerts as it will slow and/or hinder their work</li> </ul> <p>More detailed guidelines for error messages:</p> <ul> <li>Careful wording (direct, but not rude)</li> <li>Avoid threatening words (catastrophe etc)</li> <li>Do not use no double negation</li> <li>Be specific (e.g. \"enter your name\")</li> <li>No uppercase letters (Don't SHOUT at the user. Humans reads through shapes)</li> <li>Use attention-grabbing techniques with caution</li> </ul>"},{"location":"3-semester/DEB/06-perception-and-navigation/","title":"Perception and Navigation","text":""},{"location":"3-semester/DEB/06-perception-and-navigation/#perception","title":"Perception","text":"<p>Perceptual set: Our previous experiences that makes us experience depth and patterns in a particular way.</p> <p></p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#depth-perception","title":"Depth perception","text":"<p>Critical in the design of 3D applications</p> <p>How we understand depth:</p> <p>Primary cues</p> <ul> <li>Retinal disparity (two separate images)</li> <li>Stereopsis (image combining process)</li> <li>Accommodation (muscular process to create image focus)</li> <li>Convergence (muscular process for image focus on short distances)</li> </ul> <p>Secondary cues (2D plane, monocular)</p> <ul> <li> <p>Light and shade</p> </li> <li> <p>Linear perspective</p> </li> <li> <p>Height in horizontal plane</p> </li> <li> <p>Motion parallax</p> </li> <li> <p>Overlap</p> </li> </ul> <p></p> <p>Also makes use of light and shade</p> <ul> <li> <p>Relative size</p> </li> <li> <p>Texture gradient</p> </li> </ul>"},{"location":"3-semester/DEB/06-perception-and-navigation/#pattern-recognition","title":"Pattern recognition","text":"<p>Based on our perceptual set</p> <p>Gestalt laws of perception</p> <p>Psychology terms </p> <ul> <li> <p>Proximity</p> </li> <li> <p>\"Elements that are positioned close together are belonging together\"</p> <p></p> <p>Two separate groups of stars</p> </li> <li> <p>Continuity</p> </li> <li> <p>\"We tend to perceive smooth, continuous patterns rather than disjoint, interrupted ones.\"</p> </li> </ul> <p></p> <ul> <li> <p>Similarity</p> </li> <li> <p>\"Similar figures tend to be grouped together.\"</p> </li> </ul> <p></p> <p>Round vs diamond shapes -&gt; These have different properties</p> <p></p> <ul> <li>Closure</li> <li>\"Closed figures are perceived more easily than incomplete (or open) figures\"</li> <li>\"Images that are not complete that nevertheless provides a complete image\"</li> </ul> <p></p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#affordance","title":"Affordance","text":"<p>\"The affordance of the environment are what it offers animals, what it provides or furnishes, for good or ill\" - Gibson</p> <p>So, an affordance is a resource that the environment offers an animal and...</p> <p>...the animal must possess the capabilities to perceive and use the resource.</p> <p>\"It is perceived affordances that tell the user what actions can be performed on an object and, to some extent how to do them\" - Norman</p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#examples","title":"Examples","text":"<p>Salt and pepper shaker. We know through our perceptual set, that we use more salt than pepper in European countries, so the one with more holes is for salt.</p> <p></p> <p>There being only plates but no door handles provides the affordance, that we need to push the door. Through our perceptual set.</p> <p></p> <p>This is a juice presser. But that is not clear from the leftmost picture. The affordance of this product is unclear.</p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#navigation","title":"Navigation","text":"<p>Object identification</p> <ul> <li>Identifying categories and clusters of objects</li> </ul> <p>Wayfinding</p> <ul> <li>Working out how to reach a destination</li> </ul> <p>Exploration</p> <ul> <li> <p>Understanding what exists in an environment</p> </li> <li> <p>How objects are related</p> </li> </ul> <p>Three types of signs:</p> <ul> <li>Informational signs (object identification)</li> <li>Directional signs (wayfinding)</li> <li>Warning and reassurance signs (exploration)</li> </ul>"},{"location":"3-semester/DEB/06-perception-and-navigation/#informational-signs","title":"Informational signs","text":"<p>Orienting oneself (Passini 1994)</p> <p>Providing information on objects</p> <p>Aid in object identification and classification of objects</p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#directional-signs","title":"Directional signs","text":"<p>Choosing the correct route (Passini, 1994)</p> <p>Providing information on routes and route hierarchies</p> <p>Apple Guidelines:</p> <ul> <li>Provide one path for one destination</li> <li>Make the path logical</li> </ul> <p>We need to provide a clear visual hierarchy</p> <p></p>"},{"location":"3-semester/DEB/06-perception-and-navigation/#warning-and-reassurance-signs","title":"Warning and reassurance signs","text":"<p>Monitoring chosen route (Passini, 1994)</p> <p>Recognizing when the destination is reached (Passini, 1994)</p> <p>Providing feedback on actual location</p> <p>Providing information on possible actions within the environment</p> <p>Apple Guidelines:</p> <ul> <li>Provide markers of where you are</li> <li>Traceability</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/","title":"Evaluation - What is Usability and Usability Testing","text":"<p>Literature:</p> <ul> <li>Benyon - Designing Interactive Systems (chap. 4 section 4.3 + chap. 10)</li> <li>Rubin &amp; Chisnell - Handbook of Usability Testing (chap. 3) (PDF)</li> <li>Rubin &amp; Chisnell - Handbook of Usability Testing (chap. 5) (PDF)</li> <li>Nielsen &amp; Molich - Heuristic Evaluation of User Interfaces (PDF)</li> <li>Nielsen and Molic's heuristics (PDF)</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#usability","title":"Usability","text":""},{"location":"3-semester/DEB/07-evaluation/#iso-9241-definition","title":"ISO 9241 definition:","text":"<p>\"The effectiveness, efficiency and satisfaction with which specified users achieve specified goals in particular envirionments\"</p> <p>Effectiveness:</p> <ul> <li>The accuracyand completeness with which specified users can achieve specified goals in particular envirionments.</li> </ul> <p>\u200b How well the users can complete their tasks.</p> <p>Efficiency:</p> <ul> <li>The resource expended in relation to the accuracy and completeness of goals achieved.</li> </ul> <p>\u200b How much eg. time needed to solve their tasks.</p> <p>Satisfaction:</p> <ul> <li>The comfort and acceptability of the work system to its users and other people affected by its use.</li> </ul> <p>\u200b Subjective measure.</p>"},{"location":"3-semester/DEB/07-evaluation/#jacob-nielsen-definition","title":"Jacob Nielsen definition","text":"<p>Learnability:</p> <ul> <li>How easy is it for users to accomplish basic tasks the first time they encounter the design?</li> </ul> <p>Efficiency:</p> <ul> <li>Once users have learned the design, how quickly can they perform the tasks?</li> </ul> <p>Memorability:</p> <ul> <li>When users return to the design after a period of not using it, how easily can they reestablish proficiency?</li> </ul> <p>Errors:</p> <ul> <li>How many errors do users make, how severe are these errors, and how easily can they recover from the errors?</li> </ul> <p>Satisfaction:</p> <ul> <li>How pleasant is it to use the design?</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#usability-testing","title":"Usability Testing","text":"<p>Purpose</p> <ul> <li>Identifying usability problems in a system</li> <li>Starting point for refinements of design.</li> </ul> <p>Outcome</p> <ul> <li>A ranked list of usability problems</li> <li>Knowledge about what works well</li> </ul> <p>How do we evaluate usability?</p> <p>Inquiry</p> <ul> <li> <p>We try to understand users.</p> </li> <li> <p>Also part of doing PACT.</p> </li> </ul> <p>Testing</p> <ul> <li>Users test product designs.</li> </ul> <p>Inspection</p> <ul> <li>Testing of a design by an expert.</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#when-to-test","title":"When to test?","text":""},{"location":"3-semester/DEB/07-evaluation/#lab-vs-field-test","title":"Lab vs. Field Test","text":""},{"location":"3-semester/DEB/07-evaluation/#lab-test","title":"Lab Test","text":""},{"location":"3-semester/DEB/07-evaluation/#strengths","title":"Strengths","text":"<ul> <li>The least obtrusive way to collect data</li> <li>Allows communication \"behind the scenes\"</li> <li>Allows many observers</li> <li>High replicability and control</li> <li>Demand characteristics</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#weaknesses","title":"Weaknesses","text":"<ul> <li>Somewhat \"sterile\" environment</li> <li>Test participants may feel like \"lab monkeys\"</li> <li>Questionable realism (ecological validity)</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#testing","title":"Testing","text":"<p>Representative users interact with design.</p> <p>Task solving and/or \"thinking-aloud\".</p> <p>Produces a ranked list of usability problems.</p> <p>Pros</p> <ul> <li>Identifies problems very precisely</li> <li>Gives first-hand insight into use</li> </ul> <p>Cons</p> <ul> <li>Test situation can be unnatural</li> <li>Difficult and very time consuming</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#testing-process-participant-perspective","title":"Testing Process (Participant perspective)","text":""},{"location":"3-semester/DEB/07-evaluation/#testing-process-our-perspective","title":"Testing Process (Our Perspective)","text":""},{"location":"3-semester/DEB/07-evaluation/#activities","title":"Activities","text":""},{"location":"3-semester/DEB/07-evaluation/#planning","title":"Planning","text":""},{"location":"3-semester/DEB/07-evaluation/#test-participants","title":"Test Participants","text":"<p>Representative for the user group</p> <ul> <li>Demographics</li> <li>Experience</li> </ul> <p>Number of test-subjects</p> <ul> <li>Generalizability</li> <li>Quantitative conclusions</li> <li>Statistics</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#deciding-on-the-tasks","title":"Deciding on the Tasks","text":"<p>What are the basic tasks that representative users do with the system?</p> <p>Is the whole system part of the evaluation?</p> <p>Can we create a crystal clear task description?</p> <p>How long does it take to solve the tasks?</p> <p>Useful rules:</p> <ol> <li>Make the tasks realistic</li> <li>Make the tasks actionable</li> <li>Avoid clues and describing the steps</li> </ol> <p>Good Tasks:</p> <ul> <li>Represent real use of the system</li> <li>Describe the end result</li> <li>Motivate (why should they be solved?)</li> <li>Include relevant data (eg. names)</li> <li>Don't force the users to use their own logins for example.</li> <li>Group smaller sub-tasks together</li> </ul> <p>Typical bad tasks:</p> <ul> <li>Vague, unclear or general</li> <li>Provides too much help</li> <li>Contain jargon and unfamiliar terms</li> <li>Forces the user into a specified sequence</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#deciding-what-to-measure-and-how","title":"Deciding What to Measure and How","text":"<ul> <li>Are all the components of usability relevant?</li> <li>How will we collect data?</li> <li>What are we going to measure?</li> <li>Think aloud?</li> </ul>"},{"location":"3-semester/DEB/07-evaluation/#usability-metrics","title":"Usability Metrics","text":"<p>Objective metrics:</p> <ul> <li>Effectiveness</li> <li>How many tasks were completed</li> <li>Efficiency</li> <li>How fast were they completed</li> </ul> <p>Subjective (perceived) metrics:</p> <ul> <li>Interview data</li> <li>Questionnaires (for example SUS, USE questionnaires)</li> </ul> <p></p>"},{"location":"3-semester/DEB/07-evaluation/#heuristic-inspection","title":"Heuristic inspection","text":"<p>Experts inspects a design using a checklist (heuristic)</p> <p>Scenarios + relevant tasks can structure process.</p> <p>Produces a ranked list of usability problems.</p> <p>Pros</p> <ul> <li>Quick and easy to conduct</li> <li>No users required</li> <li>3-5 inspections finds 70% of all problems</li> </ul> <p>Cons</p> <ul> <li>High proportion of \"cosmetic\" problems</li> <li>\"False\" usability problems</li> </ul>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/","title":"After usability test","text":"<p>A usability test has been conducted, what to do now:</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#transcription-of-log-files","title":"Transcription of log files","text":"<p>Have to transcribe what the user does. Catches the user interaction in textual form. Provides an overview and shows problems with </p> <p>Can be done live, by a test logger, and then finished afterwards by looking at videos.</p> <p></p> <p>Above shows an example of a transcript. First column shows a timestamp, middle shows the transcription, and right column shows the exact problem, interpreted by who ever writes the transcript. No interpretation in the transcript</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#data-summary","title":"Data summary","text":"<p>Main outcome is list of problems, but also want a summary of user performance. Information like how long time tasks generally took, if all tasks were solved, how much stress etc, how many problems in each category, how many unique problems (unique problem is only experienced by a single user. Need to decide if they should be dealt with, as only one user encounters them)</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#data-analysis","title":"Data analysis","text":""},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#what-is-a-usability-problem","title":"What is a usability problem","text":"<p>When talking user-based evaluation, a usability problem is a problem experienced by a specific user while interacting with a specific system. Can be observed if:</p> <p></p> <p>Not always clear why the problem is. Often clear what the problem is, but not why the user has the problem</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#problematic-behavior-from-test-moderator","title":"Problematic behavior from test moderator","text":"<ul> <li>Don't tell the user to not click something, as they can get nervous about breaking the test</li> <li>Don't take control over mouse to remove notification</li> <li>Support rather than control. Remember to wait before taking control</li> <li>(Lecturer thinks non-condescending tone is very important, has two examples where the moderator doesn't sound condescending, but rather makes normal conversation with the test user. Just something to be aware of, if a question about speaking tone appears)</li> </ul>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#describing-usability-problems","title":"Describing usability problems","text":"<p>The problem list is the primary outcome of a evaluation. It is:</p> <p></p> <p>Produced by looking at the transcript. Example below shows a problem list, a typical layout</p> <p></p> <p>Might need more detail, if test done for others. Can be done providing extra document with extra details, describing the problems in more detail. Sometimes extra details can be for serious problems</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#categorizing-problems","title":"Categorizing problems","text":"<p>Users may experience different level of severity. When making the problem list, use most critical level</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#critical","title":"Critical","text":"<ul> <li>The user is unable to continue</li> <li>Feels the system behaves strongly irritating</li> <li>Critical difference between believed and actual state of system</li> </ul>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#critical-added-by-nielsen","title":"Critical (Added by Nielsen)","text":"<ul> <li>More than one user experiences one critical problem, independently of each other</li> </ul>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#serious","title":"Serious","text":""},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#cosmetic","title":"Cosmetic","text":"<p>Image above shows schema a decide on a problem category. Again, pick the most severe/critical category. Not set in stone, but guidelines</p>"},{"location":"3-semester/DEB/08-evaluation-identifying-problems/#documentation-report","title":"Documentation (report)","text":"<p>(This is an entry in the lecture, but not talked about, other than mentioned at the start)</p>"},{"location":"3-semester/DEB/09a-user-experience/","title":"User Experience","text":"<p>Literature:</p> <ul> <li>Bargas-Avila and Hornb\u00e6k - Old wine in new bottles or novel challenges? (PDF)</li> <li>Kjeldskov et al. - Instant Data Analysis (PDF)</li> </ul> <p>Recall the definition of Usability in Lecture 07.</p> <p>User Experience:</p> <p>From ISO 9241-210</p> <p>A person's perceptions and responses that result from the use or anticipated use of a product, system or service...</p> <p>This is a broader term than usability.</p> <p></p> <p>Emotion is a key aspect!</p>"},{"location":"3-semester/DEB/09a-user-experience/#how-is-ux-data-collected","title":"How is UX data collected?","text":""},{"location":"3-semester/DEB/09a-user-experience/#attrakdiff2","title":"AttrakDiff2","text":"<p>From Marc Hassenzahl et al.</p> <p></p>"},{"location":"3-semester/DEB/09a-user-experience/#lavie-and-tractinsky","title":"Lavie and Tractinsky","text":"<p>Purely aesthetics.</p>"},{"location":"3-semester/DEB/09a-user-experience/#pitfalls","title":"Pitfalls?","text":"<p>What does the participant remember most from the interaction?</p> <p>If he had a bad interaction in the end, is this what is reflected in the questionnaire?</p> <p>Or is it the mean of the whole interaction? </p>"},{"location":"3-semester/DEB/09a-user-experience/#emotions","title":"Emotions","text":"<p>What are emotions?</p> <p>James-Lange (1884):</p> <ul> <li>\"... the result of physical changes in autonomic and motor functions\"</li> <li>Sensory input creates bodily responses</li> <li>Awareness of bodily changes constitutes an emotion.</li> </ul> <p>Scherer (2005):</p> <ul> <li>Mobilization and synchronization of organismic subsystems</li> <li>A response to a cognitive evaluation of stimulus events</li> <li>Events are \"of major concerns for the organism\"</li> </ul> <p>Moods/Attitudes vs. Emotions (Scherer, 2005)</p> <ul> <li>Emotions are intense and short-lived (connected to specific events)</li> <li>Moods are of low intensity and may last for days</li> </ul> <p>6 Basic Emotions</p> <p></p> <p>Emotion Graph</p> <p></p>"},{"location":"3-semester/DEB/09a-user-experience/#how-can-we-measure-emotions","title":"How can we measure emotions?","text":""},{"location":"3-semester/DEB/09a-user-experience/#self-assessment-manikin-sam","title":"Self-Assessment-Manikin (SAM)","text":"<p>Studies show that when we evaluate emotions in retrospect, the major movements in emotions will dominate.</p> <ul> <li>If one really cool thing makes us happy, this will dominate the evaluation</li> </ul>"},{"location":"3-semester/DEB/09a-user-experience/#galvanic-skin-response-gsr","title":"Galvanic Skin Response (GSR)","text":"<p>Used during the interactions</p> <p></p> <p></p>"},{"location":"3-semester/DEB/09a-user-experience/#electromyography-emg","title":"Electromyography (EMG)","text":""},{"location":"3-semester/DEB/09a-user-experience/#facereader-software","title":"Facereader Software","text":""},{"location":"3-semester/DEB/09a-user-experience/#cued-recall-debrief","title":"Cued Recall Debrief","text":"<ul> <li>Use the graph data to pick points of interests.</li> <li>Show the user video clips of the POI's</li> <li>Ask them to reflect on what happens</li> </ul>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/","title":"Alternative Methods for Testing Usability","text":""},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#instant-data-analysis","title":"Instant Data Analysis","text":"<p>Main Difference: You do not analyze video data!</p> <p></p> <p>Analysis done immediately after the last session</p> <ul> <li>Brainstorm</li> <li>Tasks</li> <li>Logger's notes</li> </ul> <p>Presence during IDA:</p> <ul> <li>Test moderator</li> <li>Logger</li> <li>Facilitator</li> </ul> <p>Test moderator and data logger starts by brainstorming all the usability problems that they can remember from the sessions.</p> <p>The facilitator notes this down, and creates an overview of the problems. </p> <p>So that the moderator and logger can focus only on remembering the problems.</p>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#comparison","title":"Comparison","text":"<p>From the study (Kjeldskov et al. - Instant Data Analysis (PDF))</p> <p></p>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#overlap","title":"Overlap","text":"<p>White box is an unidentified problem, Black box is an identified problem. </p>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#time-spent","title":"Time Spent","text":"<p>IDA:        4 person hours</p> <p>VBA:    40 person hours</p>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#remote-usability-testing","title":"Remote Usability testing","text":""},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#remote-asynchronous","title":"Remote Asynchronous","text":"<ul> <li>Logging/Analytics</li> <li>You know what users do, but not why.</li> <li>Usability Questionnaire</li> </ul>"},{"location":"3-semester/DEB/09b-alternative-methods-for-testing-usability/#usability-problems","title":"Usability Problems","text":"<p>Definition:</p> <p>Usability problems are present when the system is:</p> <ul> <li>Unuseful: You cannot find the documents or functions you wneed to solve your tasks.</li> <li>Difficult to learn: It takes a long time to learn how to use the system.</li> <li>Difficult to remember: It takes a long time to find elements in the system, which you have used previously.</li> <li>Ineffective to use: It takes a long time to solve certain tasks with the system.</li> <li>Unsatisfying to use: The system does not feel comfortable to use, it is not joyful to work with it.</li> </ul> <p>This is basically an inverted edition of Jacob Nielsen's definition from lecture 07.</p>"},{"location":"3-semester/SU/","title":"SU - SYSTEMS DEVELOPMENT","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=27347</p>"},{"location":"3-semester/SU/1-classes-and-objects/","title":"Classes and Objects","text":"<p>Class:</p> <p>A description of a collection of objects sharing: structure, behavioral pattern, and attributes.</p> <p>Object:</p> <p>An entity with identity, state, and behavior.</p> <p>Relation:</p> <p>An object is created from the description of a class. An object belongs to a class (from which it was created). Each class contains a set of objects; we refer to them as the objects of the class.</p>"},{"location":"3-semester/SU/2-factor/","title":"System Definition","text":""},{"location":"3-semester/SU/2-factor/#factor","title":"FACTOR","text":"<p>See page 40-41 in OOAD</p>"},{"location":"3-semester/SU/2-factor/#f-functionality","title":"F - Functionality","text":"<p>The system functions that support the application-domain tasks.</p>"},{"location":"3-semester/SU/2-factor/#a-application-domain","title":"A - Application domain","text":"<p>Those parts of an organization that administrate, monitor, or control a problem domain.</p>"},{"location":"3-semester/SU/2-factor/#c-conditions","title":"C - Conditions","text":"<p>The conditions under which the system will be developed and used.</p>"},{"location":"3-semester/SU/2-factor/#t-technology","title":"T - Technology","text":"<p>Both the technology used to develop the system and the technology on which the system will run.</p>"},{"location":"3-semester/SU/2-factor/#o-objects","title":"O - Objects","text":"<p>The main objects in the problem domain.</p>"},{"location":"3-semester/SU/2-factor/#r-responsibility","title":"R - Responsibility","text":"<p>The system's overall responsibility in relation to its context.</p>"},{"location":"3-semester/SU/2-factor/#wiums","title":"Wiums","text":""},{"location":"3-semester/SU/2-factor/#system-definition_1","title":"System Definition","text":"<p>After analyzing the case study at Wiums Renseri, the problem with the current system is order management being done manually by hand. A modern system, that keeps track of order information, could reduce the number of human errors and potentially increase productivity. Modelling the company\u2019s desired situation and looking at existing solution had confirmed the possible solution being a computerized order management system. This results in the following FACTOR criterion.</p>"},{"location":"3-semester/SU/2-factor/#factor_1","title":"FACTOR","text":"<p>Functionality: Hold information about orders, customers and products. The system should be able to print tags for tracking orders. Assist the employees in administrating customers and payments. Support managers by generating sales statistics, and facilitate payments.</p> <p>Application domain: Employees such as managers, the receptionist and the people in the production are all part of the application domain, because they either monitor, administrate or control orders, by using the system. The credit card terminal will also interact with the system, by receiving transaction amount and confirming if a transaction is accepted. Therefore, it is also a part of the application domain.</p> <p>Conditions: The system should be developed in close cooperation with Wiums Renseri, to understand the appropriate steps of the process. The employees should have knowledge about the processes in Wiums Renseri, in order to understand the systems sequential steps.</p> <p>Technology: The system will be based on a modern computer with a monitor. A receipt printer and waterproof label printer should be supported by the system, as to make it possible to print receipts and tags for the textiles. Furthermore, scanners will be needed to scan the tags. A credit card terminal should help facilitate payments.</p> <p>Objects: The most important objects are products, orders and customers.</p> <p>Responsibility: Tool that assist in order administration, by maintaining information about products, orders and customers. Notifies customers of order completion, and passing relevant information to e-conomic.</p>"},{"location":"3-semester/SU/2-factor/#definition","title":"Definition","text":"<p>Using the FACTOR model the following system definition is made:</p> <p>A computerized system used to assist in order management, by allowing the employees to monitor and register new orders and keep track of payments and pricing of products, as well as tracking individual orders at certain stages of service. The system should also be able to print notes, tags and receipts for these orders, as well as handle customer notifications of completed orders and support integration with e-conomic. The system should primarily serve as a tool to improve the order management process, by maintaining information about orders, products and customers. Secondarily, it should serve as a tool to automate filling out invoices in e-conomic for business customers, as well as generating statistics from all sales. The system should be based on regular modern PCs and monitors, a receipt printer, a waterproof label printer, a credit card terminal and several scanners for the tags. The system should be developed in close cooperation with Wiums Renseri and it should be assumed that employees are experienced in the processes at Wiums Renseri.</p>"},{"location":"3-semester/SU/3-structure/","title":"Structure","text":"<p>A class with no objects is called abstract class</p>"},{"location":"3-semester/SU/3-structure/#structures-between-classes","title":"Structures between classes","text":""},{"location":"3-semester/SU/3-structure/#generalization-structure","title":"Generalization Structure","text":"<p>Generalization: A general class (the super class) describes properties common to a group of          specialized classes (the subclasses)</p> <p>Specialized Classes are subclasses</p> <p>Generalized classes are superclasses</p>"},{"location":"3-semester/SU/3-structure/#example","title":"Example","text":"<p>The classes \u201cTaxi\u201d and \u201cPrivate Car\u201d might be specializations of the general class \u201cPassenger Car\u201d which might be a specialization of the general class \u201cVehicle\u201d</p> <p>\u200b   Think programming!</p> <p></p>"},{"location":"3-semester/SU/3-structure/#cluster-structure","title":"Cluster Structure","text":"<p>Cluster: Collection of related classes</p>"},{"location":"3-semester/SU/3-structure/#example_1","title":"Example","text":"<p>From an automobile register</p> <p></p>"},{"location":"3-semester/SU/3-structure/#structures-between-objects","title":"Structures between objects","text":"<p>Two types: aggregation and association.</p>"},{"location":"3-semester/SU/3-structure/#aggregation-structure","title":"Aggregation Structure","text":"<p>Aggregation: A superior object (the whole) consists of a number of inferior objects (the parts)</p> <p>See the picture below, \u201cCar\u201d consists of \u201cEngine\u201d which consists of \u201cCylinder\u201d</p> <p></p> <p>An <code>Engine</code> consists of at least 2 <code>Cylinder</code>'s, this is marked by the 2...* and is called multiplicity</p>"},{"location":"3-semester/SU/3-structure/#association-structure","title":"Association Structure","text":"<p>Association: A meaningful relation between a number of objects</p> <p>For example, maybe a car is owned by one or more people, and a Person owns 0 or more cars. It It makes no sense to say that a person contains a car.</p> <p></p> <p>We can name the association, for example call this line \u201cownership\u201d (This is often because we a missing a class though)</p>"},{"location":"3-semester/SU/3-structure/#find-candidates-for-structure","title":"Find candidates for structure","text":""},{"location":"3-semester/SU/3-structure/#identify-generalizations","title":"Identify Generalizations","text":"<p>First approach; we take every pair and determine if one of the two is a generalization of the other</p> <p>Second approach; we determine if a relevant generalization exists for pairs of selected classes.</p> <p>Third approach; we take each of the selected classes and attempt to define a relevant generalization or specialization.</p>"},{"location":"3-semester/SU/3-structure/#identify-aggregations","title":"Identify Aggregations","text":"<p>To find candidates for aggregation, systematically examine selected classes individually in pairs.</p> <p>There are three typical applications of aggregation structure:</p> <ul> <li>Whole-Part; the whole is the sum of the parts</li> <li>Container-Content; the whole is a container for the parts</li> <li>Union-Member; the whole is an organized union of members</li> </ul> <p>The whole is considered to be superior to its parts. (Vertical placement in the class diagram)</p>"},{"location":"3-semester/SU/3-structure/#identify-associations","title":"Identify Associations","text":"<p>Look at remaining class pairs to see if the can be meaningfully related.</p>"},{"location":"3-semester/SU/3-structure/#identify-clusters","title":"Identify Clusters","text":"<p>To increase the diagrams clarity</p> <p>Can use other structures as a starting point for generating clusters.</p> <p>It is NOT allowed to place a class in 2 different clusters!</p>"},{"location":"3-semester/SU/4-usage/","title":"Usage","text":"<p>Actor: An abstraction of users or other systems that interact with the target system</p> <p>Use Case: A pattern for interaction between the system and actors in the application domain</p> <p>Involve the user,  by presenting use cases through prototypes.</p> <p>To illustrate relations between actors and use-cases you can use either action table or use case diagrams. UML recommends use-case diagrams, while the book prefers actor table (because of space).</p> <p>Actor table example for automatic payment system:</p> <p></p>"},{"location":"3-semester/SU/4-usage/#find-actors-and-use-cases","title":"Find Actors and Use Cases","text":"<p> Who will use the system?  How will it be used? </p> <p>If several roles appear the same to the system, consider consolidating them into one.</p>"},{"location":"3-semester/SU/4-usage/#actor-specifications","title":"Actor Specifications","text":"<p>The target system\u2019s actors described in specifications.</p> <p>Consists of 3 parts: goal, characteristics, and examples.</p> <p>Describes (as precisely as possible) the actor\u2019s role in relation to the target system.</p> <p>Example from automatic payment system</p> <p></p>"},{"location":"3-semester/SU/4-usage/#use-case-specification-statechart-diagram","title":"Use Case Specification | Statechart Diagram","text":"<p>Use case specification is more detailed than statechart diagram - Should not contain unnecessary details thought!</p> <p>Use case specification example from automatic payment system:</p> <p></p> <p>Statechart diagram example from automatic payment system:</p> <p></p>"},{"location":"4-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>PSS - Principles of Operating Systems and Concurrency</li> <li>SPO - Languages and Compilers</li> <li>SS - Syntax og Semantik</li> </ul> <p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=28797</p> <p></p>"},{"location":"4-semester/PSS/","title":"PSS - PRINCIPLES OF OPERATING SYSTEMS AND CONCURRENCY","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=28773</p>"},{"location":"4-semester/PSS/1-intro/","title":"Et program i hukommelsen","text":"<p>Datalaget: Konstante variable, globale variable</p> <p>Heap</p> <p>Stack</p> <p>Code</p> <p></p> <p>En process er et k\u00f8rende program med alt det tilh\u00f8rende data.</p>"},{"location":"4-semester/PSS/5-memory-management/","title":"Memory Management","text":"<p>Address space:</p> <p>Running program's (abstract) view of memory</p>"},{"location":"4-semester/PSS/exam/","title":"PSS - Exam","text":"<p>1 Processes and Threads 2 Scheduler 3 Memory Management 4 Paged Memory 5 Concurrency 6 Concurrency Problems 7 I/O, Device Drivers</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/","title":"1 - Processes and Threads","text":"<p>Keywords: Definition of process/thread, process-/thread-control block, 5-state process model, process creation, process image, process/thread switching, multithreading, implementation strategies for thread support, user-/kernel-mode.</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#litterature","title":"Litterature","text":"<p>OSTEP Chapters 3, 4, 5</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#learning-goals","title":"Learning Goals","text":"<p>After lecture 1 you can:</p> <ul> <li> Define and explain the concept of a process </li> <li> \u200bExplain what a process image is. </li> <li> Explain what a process control block is, what it is used for and why it is needed.</li> <li> Explain in general terms, how process creation, switching and termination works</li> <li> Define and discuss process states</li> <li> Define and explain the concept of a thread</li> <li> Discuss when, where and how (multi-)threads are usefull</li> <li> Explain what a thread control block is, what it is used for and why it is needed</li> <li>Discuss implementation strategies for thread support and explain the associated trade-offs</li> </ul>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#noter","title":"Noter","text":""},{"location":"4-semester/PSS/exam/1-processes-and-threads/#process","title":"Process","text":"<p>En process er k\u00f8rende program med alt tilh\u00f8rende data.</p> <p>Et program er bare data p\u00e5 disken.</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#process-image","title":"Process Image","text":"<p>Et process image er en samling af process relateret data. Det best\u00e5r af:</p> <ul> <li>Process control block (PCB)</li> <li>Program (code)</li> <li>Stack</li> <li>Heap (user data)</li> </ul>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#process-control-block-pcb","title":"Process Control Block (PCB)","text":"<p>PCB er en datastruktur der indeholder data om en process.</p> <p>Indeholder ting som:</p> <ul> <li>Identifier</li> <li>State (tilstand)</li> <li>Prioritet</li> <li>Program Counter (PC)</li> <li>Memory counter</li> <li> <p>I/O Status</p> </li> <li> <p>Context (gemte registre til hvis processen skal k\u00f8re igen)</p> </li> </ul> <p>XV6</p> <p>Implementering i xv6 kan findes i filen <code>proc.h</code></p> <p>En PCB bruges til at kunne skifte mellem processer.  </p> <p>Task listen, eller process tabellen i operativsystemet er en liste over PCB'er. Den har dermed al den information den skal bruge om de processer den skal skifte imellem.</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#process-creation-switching-and-termination","title":"Process creation, switching and termination","text":"<p>XV6</p> <p>Implementering i xv6 kan findes i filen <code>proc.c</code></p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#creation","title":"Creation","text":"<p>N\u00e5r en process bliver oprettet, l\u00e6ses programmet og program data ind i memory. </p> <ul> <li> <p>I simple operativsystemer, g\u00f8res dette eagerly, hvilket betyder at al data l\u00e6ses ind inden programmet starter.</p> </li> <li> <p>I mere moderne systemer g\u00f8res dette lazily, hvilket betyder at data l\u00e6ses ind n\u00e5r det skal bruges.</p> </li> </ul> <p>Herefter allokeres memory til stakken (runtime-stack) og eventuelt heap. </p> <ul> <li>Stakken bruges i C til lokale variable, funktionsparametre, return adresser.</li> <li>Heapen bruges i C til explicit requested, dynamisk allokeret memory, som ved <code>malloc()</code> kald. </li> </ul>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#switching","title":"Switching","text":"<p>N\u00e5r en process bliver scheduled, skifter dens tilstand fra ready til running. </p> <p>F\u00f8rst bliver PCB for den k\u00f8rende process oprettet, og information lagres.</p> <p>Derefter udpakkes PCB for den skiftede til process. Registre s\u00e6ttes, dette kaldes context switch.</p> <p>Den nye process k\u00f8res, via den nyindstillede PC (program counter)</p> <p>Ekstra info</p> <p>https://medium.com/@ppan.brian/context-switch-from-xv6-aedcb1246cd</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#process-state","title":"Process state","text":"<p>En process's tilstande bruges af scheduleren til at vide hvilke processer den kan k\u00f8re. OSTEP definerer f\u00f8lgende tilstande.</p> <ul> <li>Running: Processen k\u00f8rer lige nu p\u00e5 en processor, instruktioner udf\u00f8res.</li> <li>Ready: Processen er klar til at k\u00f8re, men af en eller anden grund, har OS valgt ikke at k\u00f8re den.</li> <li>Blocked: Processen er ikke klar til at k\u00f8re. Et eksempel kan v\u00e6re mens den venter p\u00e5 I/O.</li> </ul> <p>xv6 har tilmed: <code>EMBROYO</code> : den er oprettet, men ikke udfyldt med n\u00f8dvendig data endnu.  <code>ZOMBIE</code>: den er termineret, men endnu ikke opryttet af OS endnu. (Bruges af f.eks. parent processes, til at se return code)</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#5-state-process-model","title":"5-State Process Model","text":""},{"location":"4-semester/PSS/exam/1-processes-and-threads/#thread","title":"Thread","text":"<p>En tr\u00e5d (thread) er den mindste eksekverbare del af en process.</p> <p>En process kan have 1 eller flere tr\u00e5de.</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#multithreading","title":"Multithreading","text":"<p>Opsplitningen af en process i flere tr\u00e5de. </p> <p></p> <p>Multithreading kan eksempelvis v\u00e6re nyttigt ved GUI.</p> <ul> <li>Nogle tr\u00e5de arbejder p\u00e5 hovedarbejdet (baggrunden)</li> <li>Nogle tr\u00e5de arbejder p\u00e5 at opdatere GUI, s\u00e5 den virker mere responsiv.</li> </ul> <p>Eksempel: Der trykkes p\u00e5 en opdateringsknap med der opdatere en liste med data fra internettet. Ved single-thread, vil GUI'en \"holde stille\" og vente p\u00e5 al data. Ved multithreading, kan man hente data i en anden tr\u00e5d, og dermed er GUI stadig brugbar imens.</p> <ul> <li>Low cost creation, switching and termination</li> <li> <p>Interthread communication (memory sharing)</p> </li> <li> <p>Kan udnytte multi-processor/-core platforme.</p> </li> </ul> <p>Skaber bedre arkitektur / design.</p> <ul> <li>Modularitet</li> </ul> <p></p> <p>Thread-local data:</p> <ul> <li>thread-ID</li> <li>priority</li> <li>stack</li> </ul> <p>Process-local data:</p> <ul> <li>Address space, heap, open files</li> <li>process-ID</li> <li>parent, ownership, CPU reg (copy)</li> </ul> <p>Shared data:</p> <ul> <li>Program text</li> </ul>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#thread-control-block","title":"Thread Control Block","text":"<p>Ligesom process control block (PCB), men indeholder information om tr\u00e5den som thread-ID, som beskrevet ovenfor.</p>"},{"location":"4-semester/PSS/exam/1-processes-and-threads/#thread-support-implementation-strategies","title":"Thread Support Implementation Strategies","text":""},{"location":"4-semester/PSS/exam/1-processes-and-threads/#amdahls-law","title":"Amdahls Law","text":"<p>Potientel performance speedup: $$ Speedup=\\frac{1}{(1-f)+\\frac{f}{N}} $$ hvor</p> <p>\u200b   f er \"parallelisable fraction\" (hvor meget execution time der bliver paralleliseret) \u200b   NN er antallet af tilg\u00e6ngelige cores/CPUs</p> <p></p>"},{"location":"4-semester/PSS/exam/2-scheduler/","title":"2 - Scheduling","text":"<p>Keywords: Metrics for scheduling (turnaround time, response time), simple process model, scheduling policies (FIFO, SJF, STCF, Round Robin, MLFQ, lottery scheduler).</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#litterature","title":"Litterature","text":"<p>OSTEP Chapters 6, 7, 8, 9</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#learning-goals","title":"Learning Goals","text":"<p>After lecture 2 you:</p> <ul> <li> Can explain the notion of limited direct execution and how it relates to scheduling</li> <li> Will know the simplified process model</li> <li> Will know and can explain important metrics for measuring a scheduling policy:<ul> <li> Fairness</li> <li> Turnaround time</li> <li> Response time</li> </ul> </li> <li> Can explain important scheduling policies and their pros and cons:<ul> <li> FIFO (First In First Out)</li> <li> SJF (Shortest Job First)</li> <li> STCF (Shortest Time-to-Completion First)</li> <li> Round Robin</li> <li> MLFQ</li> <li> Lottery scheduling</li> </ul> </li> </ul>"},{"location":"4-semester/PSS/exam/2-scheduler/#noter","title":"Noter","text":""},{"location":"4-semester/PSS/exam/2-scheduler/#limited-direct-execution-lde","title":"Limited Direct Execution (LDE)","text":"<p>The direct execution part: Run the program directly on the CPU</p> <p></p> <p>Direct execution is fast, running directly on the CPU. </p> <p>How do allow a process to perform restricted operations without giving complete control?</p> <p>For at undg\u00e5 malicious processer, findes 2 modes. User- og kernel-mode.</p> <p>Restriktede operationer, kan kun laves i kernel mode. System kald, er kald som user-processer kan eksekvere, der kan eksekvere kode i kernel mode.</p> <p>For at eksekvere system kald, eksekvere programmer en trap instruktion.</p> <p>N\u00e5r systemet er f\u00e6rdig, eksekveres en return-from-trap instruktion, der returnerer til det kaldende bruger-program.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#trap","title":"Trap","text":"<p>N\u00e5r et trap eksekveres, gemmes kalderens registrer, s\u00e5 den kan returnere igen. x86 pusher PC, flags og andre registre til en kernel stack. Som s\u00e5 bliver popped igen n\u00e5r return-from-trap eksekveres.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#trap-table","title":"Trap Table","text":"<p>For at kernel ved hvad der m\u00e5 eksekveres under et trap, ops\u00e6ttes et trap-table under boot. </p> <p>Trap table fort\u00e6ller hardware hvilket kode der skal eksekveres under hvilke events (trap handlers).</p> <p>Et system-call number er assigned til hvert system kald. User programmet placerer dette nummer i et bestemt register, eller bestemt sted i stakken.</p> <p>OS tjekker dette nummers validitet og k\u00f8rer det tilsvarende kode. Denne indirekthed fungerer som besykttelse.</p> <p>xv6</p> <p>System call numbers i xv6 kan ses i <code>syscall.h</code>. De gemmes i %eax. Og kaldes ved at eksekvere trap med <code>T_SYSCALL</code>. </p>"},{"location":"4-semester/PSS/exam/2-scheduler/#switching-process-scheduling","title":"Switching Process (Scheduling)","text":"<p>2 method: cooperative approach og non-cooperative. </p>"},{"location":"4-semester/PSS/exam/2-scheduler/#cooperative-approach","title":"Cooperative Approach","text":"<p>Processer st\u00e5r selv for at overgive kontrollen til OS. Eksempelvis gennem system kald eller yield kald. Overgiver ogs\u00e5 kontrollen ved fejl, ex divide-by-zero. Generer trap.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#non-cooperative","title":"Non-Cooperative","text":"<p>Timer-interrupts: en timer k\u00f8rer i hardware og interrupter. Under interrupt, pauses den k\u00f8rende process, og OS's interrupt-handler k\u00f8rer. </p> <p>Hvilket kode der skal k\u00f8re (interrupt-handler) meddeles til hardware under boot. Timer startes under boot.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#context-switch","title":"Context Switch","text":"<p>Scheduler bestemmer om der skal skiftes process. Hvis der skiftes process udf\u00f8res context switch.</p> <p>Registre gemmes fra k\u00f8rende process (til kernel stack), og registre genoprettes fra soon-to-be-running process (fra kernel stack).</p> <p>N\u00e5r return-from-trap udf\u00f8res, returneres til process B.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#simplified-process-model","title":"Simplified Process Model","text":"<ol> <li>Each job runs for the same amount of time</li> <li>All jobs arrive at the same time</li> <li>Once started each job runs to completion</li> <li>All jobs only use the CPU (no I/O)</li> <li>The run-time of each job is known</li> </ol> <p>Terminologi: job==process\\ |\\ job == thread</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#scheduling-metrics","title":"Scheduling Metrics","text":"<p>Turnaround time: Tid fra arrival til f\u00e6rdigg\u00f8rrelse $$ T_{turnaround}=T_{complition}-T_{arrival} $$ Dette er en performance metric.</p> <p>Response time: Tid fra arrival til f\u00f8rste schedule $$ T_{response}=T_{firstrun}-T_{arrival} $$</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#first-in-first-out-fifo","title":"First In, First Out (FIFO)","text":"<p>AKA First Come, First Served (FCFS)</p> <ul> <li>Nem at implementere</li> </ul> <p></p> <p>Average turnaround time:</p> <p>\u200b   \\frac{10+20+30}{3}=20\\frac{10+20+30}{3}=20</p> <p>Men hvis vi relaxer assumtion 1:</p> <p></p> <p>Convoy effect: Korte jobs bliver sat i k\u00f8 bag store jobs.</p> <p>Average turnaround time h\u00f8j:</p> <p>\u200b   \\frac{100+110+120}{3}=110\\frac{100+110+120}{3}=110</p> <p>D\u00e5rlig response time</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#shortest-job-first-sjf","title":"Shortest Job First (SJF)","text":"<p>Average turnaround time:</p> <p>\u200b   \\frac{10+20+120}{3}=50\\frac{10+20+120}{3}=50</p> <p>Givet vores assumptions om at alle jobs ankommer p\u00e5 samme tid, kan SJF bevises til at v\u00e6re optimal scheduling algoritme.</p> <p>Men hvis vi relaxer assumption 2.</p> <p>Hvis A ankommer f\u00f8r B og C vil den f\u00e5 h\u00f8j turnaround time igen. </p> <p>\u200b   (103.33103.33)</p> <p>Skidt for response time</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#shortest-time-to-completion-first-stcf","title":"Shortest Time-to-Completion First (STCF)","text":"<p>AKA Preemptive Shortest Job First (PSJF)</p> <p>Vi relaxer assumption 3. </p> <p></p> <p>Giver os bedre average turnaround time: 5050</p> <p>Givet vores nuv\u00e6rende assumptions er STCF beviseligt optimal.</p> <p>Skidt for response time</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#round-robin-rr","title":"Round Robin (RR)","text":"<p>RR k\u00f8rer jobs for en time slice (ogs\u00e5 kaldt scheduling quantum)</p> <p>Time slices skal v\u00e6re dividerbar med timer-interrupt perioden.</p> <p></p> <p>Jo kortere time slice, jo bedre response time.</p> <p>MEN: Hvis time slice bliver s\u00e5 kort, at kosten ved context switching dominerer overall performance.</p> <p>Armortization: hvis noget har en fixed cost, s\u00e5 kald denne operation s\u00e5 f\u00e5 gange som muligt. </p> <p>Average turnaround time: 14, rimelig skidt.</p> <ul> <li>RR er en af de v\u00e6rste policies set fra Turnaround time</li> </ul> <p>Generalt, policies, som RR, som er fair (deler cpu ligeligt bland aktive processer i lille tidsscala) performer d\u00e5lrigt p\u00e5 metrics som turnaround time.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#multi-level-feedback-queue-mlfq","title":"Multi Level Feedback Queue (MLFQ)","text":"<p>Goal:</p> <p>Optimer turnaround time og minmer response time</p> <p>Hver process f\u00e5r en priorietet</p> <p>Hvert prioritet level har sin egen process k\u00f8 (queue)</p> <p>Basic rules:</p>  \\begin{equation} \\text{if } Pri(A)&gt;Pri(B) \\text{ run } A \\tag{Rule 1}\\label{rule1} \\end{equation}   \\begin{equation} \\text{if } Pri(A)&gt;Pri(B) \\text{ run } A \\tag{Rule 1}\\label{rule1} \\end{equation}   \\begin{equation} \\text{if } Pri(A)=Pri(B) \\text{ use RR for } A \\text{ and } B \\tag{Rule 2} \\end{equation}   \\begin{equation} \\text{if } Pri(A)=Pri(B) \\text{ use RR for } A \\text{ and } B \\tag{Rule 2} \\end{equation}  <p>Handler om hvordan scheduleren s\u00e6tter prioriteter.</p> <p>Et program der ofte giver afkald p\u00e5 CPU for at vente p\u00e5 I/O f\u00e5r h\u00f8j prioritet.</p> <p>Regler for prioritets\u00e6ndring</p> <p>Rule 3:     Nye processer starter p\u00e5 h\u00f8jeste prioritet</p> <p>Rule 4a:     Prioritet af process der bruger al sin time-slice bliver reduceret</p> <p>Rule 4b:     En process der slipper CPU f\u00f8r tid, bliver p\u00e5 samme prioritet</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#problemer","title":"Problemer","text":"<p>Starvation: Hvis der er for mange interaktive jobs, tager de al CPU-tid, og starverer de lange jobs.</p> <p>En smart bruger kan rewrite et program til at game the scheduler</p> <p>Et lang job kan \u00e6ndre sin behavior og blive interaktiv efter noget tid. Dette bliver ikke rewardet i nuv\u00e6rende system.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#ny-regel","title":"Ny regel","text":"<p>Rule 5:     Efter noget tid S, boostes alle jobs til \u00f8verste prioritet (k\u00f8)</p> <p>Rule 4 (samling af 4a og 4b):     Altid reducer prioriteten p\u00e5 et job, n\u00e5r den bar brugt alt tildelt (alloted) tid.</p> <p>S\u00e5 vi ender ud med:</p> <p></p>"},{"location":"4-semester/PSS/exam/2-scheduler/#proportional-share-lottery-scheduling","title":"Proportional Share (Lottery Scheduling)","text":"<p>AKA fair-share scheduler</p> <p>Princip: Et antal tickets er i spil. Efter hver time slice, holdes lotteri. Processen, der ejer den ticket der bliver trukket, bliver k\u00f8rt.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#ticket-mechanics","title":"Ticket Mechanics","text":"<p>Ticket currency: Lader brugeren allokere tickets mellem dens egen jobs. Currency converteres til rigtige tickets.</p> <p></p> <p>Ticket transfer: En process kan midlertidigt give sine tickets til en anden process.</p> <p>Ex en client/server struktur. Klienten kan give serveren sine tickets n\u00e5r den beder den om noget arbejde.</p> <p>Ticket inflation: En process kan midlertidigt h\u00e6ve eller s\u00e6nke dets antal tickets. </p> <p>Giver ikke mening i et kompetitativt milj\u00f8.</p>"},{"location":"4-semester/PSS/exam/2-scheduler/#unfairness-metric","title":"Unfairness Metric","text":"<p>UU, tiden det f\u00f8rste job er f\u00e6rdigt divideret med tiden det andet job er f\u00e6rdigt.</p> <p>Hvis job A er f\u00e6rdig efter 10 og job B efter 20:  $$ U=\\frac{10}{20}=0.5 $$ N\u00e5r jobs bliver f\u00e6rdigt n\u00e6sten sammentidigt vil UU n\u00e6rme sig 1. En perfectly fair scheduler har U=1U=1</p>"},{"location":"4-semester/PSS/exam/3-memory-management/","title":"3 - Memory Management","text":"<p>Keywords: Memory hierarchy, goals for memory management (transparency, efficiency, isolation), address space, challenges for memory management, features (relocation, protection, and sharing), virtual addresses vs. physical addresses, address translation, base and bound registers, simple allocation, static allocation (nonuniform), dynamic allocation, virtual memory, segmentation.</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#litterature","title":"Litterature","text":"<p>OSTEP Chapter 12, 13, (14), 15, 16, 17</p> <p>Kapitler med parenteser skimmes: (x)</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#learning-goals","title":"Learning Goals","text":"<p>After Lecture 5 you:</p> <ul> <li> ... will know and can discuss the three goals of memory management:<ul> <li> Transparency </li> <li> Efficiency </li> <li> Protection (isolation)</li> </ul> </li> <li> ... can explain what an address space is </li> <li> ... define and explain the notion of virtual memory </li> <li> ... perform simple address translation from virtual to physical </li> <li> ... can explain the need for and use of base/bound registers </li> <li> ... define and explain the use of segmentation</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#noter","title":"Noter","text":"<p>XV6</p> <p>XV6 memory management i <code>vm.c</code> <code>memlayout.h</code> <code>mmu.h</code> <code>kalloc.c</code></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#adress-space","title":"Adress Space","text":"<p>Addres space er en abstraktion af den fysiske hukommelse. S\u00e5 ser det ud fra hver process' synspunkt at de har det plads.</p> <p></p> <p>Dette kaldes virtualizing memory.</p> <p>Hvis eksempelvis process A vil l\u00e6se fra adresse 0 (virtual address), s\u00e5 vil OS i samarbejde med hardware overs\u00e6tte til den fysiske (virkelige) adresse.</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#mal-med-memory-management","title":"M\u00e5l med Memory Management","text":"<p>Transparency:</p> <p>OS skal implementere virtuel memory s\u00e5 det er usynligt for det k\u00f8rende program. (Programmet skal ikke vide at det er virtuel hukommelse)</p> <p>Efficiency:</p> <p>Virtualizeringen skal v\u00e6re s\u00e5 effektiv som muligt.</p> <ul> <li>Tid og plads</li> </ul> <p>Udnytter hardware support som TLB'er</p> <p>Protection:</p> <p>Beskyt processer fra hinanden, og OS fra processer.</p> <ul> <li>De skal ikke kunne skrive og l\u00e6se uden for deres egen adress space.</li> <li>Isolation processer er isoleret fra hinanden</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#adress-translation","title":"Adress Translation","text":"<p>AKA hardware-based address translation</p> <p>Hardware overs\u00e6tter hver memory adresse, virtuel \\rightarrow physical.</p> <p>OS manages memory.</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#antagelser","title":"Antagelser","text":"<ul> <li>Sammenh\u00e6ngende allokation (Contiguous allocation)</li> <li>Lille address space (mindre end fysisk hukommelse)</li> <li>Fixed st\u00f8rrelse address space</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#eksempel","title":"Eksempel","text":""},{"location":"4-semester/PSS/exam/3-memory-management/#base-and-bounds","title":"Base and Bounds","text":"<p>AKA dynamic relocation</p> <p>2 Hardware registre: base- og bounds- (ogs\u00e5 kaldt limit) register.</p> <ul> <li>Lader os placere adress space hvor vi vil i fysisk.</li> </ul> <p>Memory referancer overs\u00e6ttes nu med: $$ Address_{physical}=Address_{virtual}+base\\ \\textbf{address translation} $$ Teknikken kaldes ofte dynamic relocation.</p> <p>Bounds bruges til protection. Undg\u00e5 at process l\u00e6ser uden for address space.</p> <p>Delen af CPU der hj\u00e6lper med adress translation kaldes memory management unit (MMU).</p> <p>Eksempler:</p> <p></p> <p>Hardware Requirements</p> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#os-problemer","title":"OS Problemer","text":"<ul> <li> <p>OS har en free list, en liste over ledigt hukommelse.</p> </li> <li> <p>Under context-switch skal base og bounds registre gemmes og l\u00e6ses.</p> </li> </ul> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#segmentation","title":"Segmentation","text":"<p>Base og bounds par pr segment address space.</p> <p>Et segment er et sammenh\u00e6ngende portion address space.</p> <p>Logisk: code, stack og heap.</p> <p>Segmentation lader os placere dem forskellige steder i fysisk.</p> <p></p> <p></p> <p>Ubrugt address space kaldes sparce address space</p> <p>En referance til en adresse uden for segmentet -&gt; segmentation violation eller segmentation fault</p> <p>Vi kan bruge bits i virtuelle adresse til at pr\u00e6cisere segment (explicit approach)</p> <p></p> <pre><code>Segment = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SEG_SHIFT\nOffset  = VirtualAddress &amp; OFFSET_MASK\nif (Offset &gt;= Bounds[Segment])\nRaiseException(PROTECTION_FAULT)\nelse\nPhysAddr = Base[Segment] + Offset\nRegister = AccessMemory(PhysAddr)\n</code></pre> <pre><code>SEG_MASK    = 0x3000\nSEG_SHIFT   = 12\nOFFSET_MASK = 0xFFF\n</code></pre> <p>Implicit approach: Hardware bestemmer segment ved at se p\u00e5 hvor addressen blev dannet. (Eks. fra PC, s\u00e5 er addr. fra code segment)</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#the-stack","title":"The Stack","text":"<p>Stack vokser bagud. Vi tilf\u00f8jer bit til hardware der fort\u00e6ller om adresser vokser fremad.</p> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#sharing","title":"Sharing","text":"<p>Noget hukommelse kan deles mellem address spaces.</p> <ul> <li>code sharing.</li> </ul> <p>Vi tilf\u00f8jer protection bits til hukommelse.</p> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#fine-vs-coars-grained-segmentation","title":"Fine- vs Coars-grained Segmentation","text":"<p>Det vi har ovenover kaldes coarse-grained segmentation.</p> <p>Fine-grained segmentation: Mange sm\u00e5 segments. Kr\u00e6ver et segment table i memory.</p> <ul> <li>OS kan l\u00e6re hvordan de forskellige segments bruges. Og derved optimere.</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#os-support","title":"OS Support","text":"<p>Problem: external fragmentation: fysisk hukommelse bliver fyldt med sm\u00e5 huller af ubrugt plads, som er for sm\u00e5 til et segment.</p> <ul> <li>L\u00f8sning kan v\u00e6re at compact fysisk memory.</li> <li>Dyrt,  memory-intensivt at kopiere segments.</li> <li> <p>Kan g\u00f8re segment-growing requests sv\u00e6re at servere.</p> </li> <li> <p>Simplere l\u00f8sning: free-list management algoritme.</p> </li> <li>best-fit holder liste af frit lager, og giver den der passer bedst i st\u00f8rrelse.</li> <li>worst-fit</li> <li>first-fit</li> </ul> <p>Modsat internal fragmentation: Allokeret lager, er for stort og meget ubrugt.</p> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#free-space-management","title":"Free Space Management","text":"<p>Free-list</p> <p></p> <p>XV6</p> <p>Se <code>line 22 in kalloc.c</code></p> <p>Splitting:</p> <p>Request for 1 byte. Allocator finder free chunk, splitter den op. Returnerer den ene del, og anden del bliver i listen.</p> <p></p> <p>Coalescing:</p> <p>Der kaldes <code>free(10)</code>. List vil se ud som f\u00f8lger:</p> <p></p> <p>Vi samler frie segmenter der er sammenh\u00e6ngende:</p> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#header","title":"Header","text":"<p>Bruges til at holde styr p\u00e5 st\u00f8rrelsen p\u00e5 allokerede regioner.</p> <p></p> <p></p> <p>XV6</p> <p>kan ses i <code>umalloc.c</code></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#embed-free-list","title":"Embed Free List","text":"<p>Listen laves i det frie hukommelse</p> <pre><code>typedef struct __node_t {\nint              size;\nstruct __node_t *next;\n} node_t\n</code></pre> <p></p>"},{"location":"4-semester/PSS/exam/3-memory-management/#basic-strategies","title":"Basic Strategies","text":""},{"location":"4-semester/PSS/exam/3-memory-management/#best-fit","title":"Best Fit","text":"<ul> <li>Find de chunks der er s\u00e5 stor eller st\u00f8rre end det \u00f8nskede.</li> <li>Returner det mindste af dem.</li> </ul> <p>Kan koste meget performance n\u00e5r den skal s\u00f8ge efter den bedste frie blok.</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#worst-fit","title":"Worst Fit","text":"<ul> <li>Find den st\u00f8rste chunk og returner den \u00f8nskede st\u00f8rrelse.</li> <li>Behold resten p\u00e5 free-list</li> </ul> <p>Kan v\u00e6re dyr i performance. Studier viser at den performer d\u00e5rligt. </p> <p>Leder til excess fragmentation, mens den stadig har h\u00f8j overheads.</p>"},{"location":"4-semester/PSS/exam/3-memory-management/#first-fit","title":"First Fit","text":"<ul> <li>Finder den f\u00f8rste blok der er stor nok.</li> <li>Returnerer den \u00f8nskede st\u00f8rrelse.</li> </ul> <p>Hurtig metode. Fylder dog nogen gange starten op med sm\u00e5 objekter.</p> <ul> <li>Hvordan allocator manager free-listens r\u00e6kkef\u00f8lge betyder noget.</li> </ul> <p>En l\u00f8sning er address-based ordering</p> <ul> <li>G\u00f8r det nemmere at coalesce, og fragmentering er reduceret.</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#next-fit","title":"Next Fit","text":"<p>Ligesom first-fit, men algoritmen holder en pointer til der hvor den ledte sidst.</p> <ul> <li>Spreder s\u00f8gningen mere uniformt.</li> <li>H\u00f8j performance, som first-fit.</li> </ul>"},{"location":"4-semester/PSS/exam/3-memory-management/#buddy-allocation","title":"Buddy Allocation","text":""},{"location":"4-semester/PSS/exam/4-paged-memory/","title":"4 - Paged Memory","text":"<p>Keywords: Address types (physical, relative, virtual), address translation (page tables), virtual memory, swapping, paging, shared memory, memory use for OS, page replacement algorithms (OPT, LRU, FIFO, CLOCK).</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#litterature","title":"Litterature","text":"<p>OSTEP Chapter 18, 19, 20, 21, 22, (23), 24</p> <p>Kapitler med parenteser skimmes: (x)</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#learning-goals","title":"Learning Goals","text":"<p>After Paged Memory you can:</p> <ul> <li>... define and explain paging and how paged memory works</li> <li>... perform simple address translation from paged (virtual) memory to physical memory</li> <li>... explain how paged memory supports shared memory</li> <li>... explain organisation of page tables (direct, two-level)</li> <li>... define, explain, and discuss various page replacement algorithms and their pros and cons</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#noter","title":"Noter","text":""},{"location":"4-semester/PSS/exam/4-paged-memory/#paging","title":"Paging","text":"<p>Chopping up space into fixed size pieces.</p> <p>Simple example:</p> <p></p> <p>For at holde styr p\u00e5 virtual pages, OS holder en per-process data struktur kaldet page table.</p> <ul> <li>Holder address translations for hver virtual page</li> </ul> <p>Virtuel adresse splittes op i virtual page number (VPN) og offset</p> <p></p> <p>16 bit page. 2 bit vpn.</p> <p>Vi indexer nu page table.  Page 1 ligger i page frame 7 i ovenst\u00e5ende billede.</p> <p>Dette er physical frame number (PFN) aka physical page number (PPN) 7.</p> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#page-tables","title":"Page Tables","text":"<p>Page tables kan blive meget store. 32-bit adresse, 4KB pages.</p> <p>Virtuel adresse splittes til 20-bit VPN og 12-bit offset.</p> <p>20-bit VPN betyder 2^{20} translations. 4 bytes per page table entry (PTE) giver 4MB per page table!</p> <p>Derfor er page tables ikke i MMU (hardware memory management unit)</p> <ul> <li>Vi holder page tables i memory.</li> </ul> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#linear-page-table","title":"Linear Page Table","text":"<p>Simpelt array af page table entries (PTE). Indexes med VPN, for at finde PFN.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#page-table-entry","title":"Page table entry","text":"<p>En valid bit er normalt. Indikerer om translation er valid.</p> <ul> <li>Eksempel, stack og heap der vokser mod hinanden. Alt imellem er invalid.</li> <li>Access af invalid lager generer trap.</li> </ul> <p>Protection bits indikerer om page m\u00e5 l\u00e6ses fra, skrives til eller executes fra.</p> <p>Present bit indikerer om denne page er i fysisk memory eller p\u00e5 disk.</p> <ul> <li>swapped out</li> </ul> <p>Dirty bit indikerer om den er \u00e6ndret siden den blev bragt til hukommelse.</p> <p>Reference bit aka accessed bit: indikerer om en page har v\u00e6ret tilg\u00e5et</p> <ul> <li>buges i page replacement</li> </ul> <p></p> <p>(P) present bit, (R/W) read/write, (U/S) user/supervisor, (PWT, PCD, PAT, G) bruges i hardware caching system, (A) accessed, (D) dirty bit, (PFN).</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#translation","title":"Translation","text":"<p>Lad os sige at page-table base register indeholder den fysiske adresse p\u00e5 start lokationen for page table. Giver os:</p> <pre><code>VPN         = (VirtualAddress &amp; VPN_MASK) &gt;&gt; SHIFT\nPTEAddr     = PageTableBaseRegister + (VPN * sizeof(PTE))\n\nVPN_MASK    = 0x30\nSHIFT       = 4\n\n\noffset      = VirtualAddress &amp; OFFSET_MASK\nPhysAddr    = (PFN &lt;&lt; SHIFT) | offset\n</code></pre>"},{"location":"4-semester/PSS/exam/4-paged-memory/#translation-lookaside-buffer-tlb","title":"Translation Lookaside Buffer (TLB)","text":"<p>For at g\u00f8re translation hurtigere tilf\u00f8jes tanslation-lookaside buffer (TLB) til hardware (MMU).</p> <ul> <li>En hardware cache af popul\u00e6re v2p translations.</li> <li>Kunne kaldes address-translation cache</li> </ul> <p>Ved hver virtual memory referance, tjekkes TLB for at se om den indeholder translation'en.</p> <p>Hvis TLB indeholder translation, har vi TLB hit.</p> <ul> <li>Hvis ikke, har vi TLB miss</li> </ul> <p>Simpelt algoritme inds\u00e6tter translation i TLB ved TLB miss.</p> <p>Det er vigtigt at vi oftest f\u00e5r TLB hit.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#locality","title":"Locality","text":"<ul> <li>Spacial locality: access af elementer der ligger t\u00e6t p\u00e5 hinanden giver h\u00f8jere hit rate</li> <li>Temporal locality: hurtig re-referencing af elementeri tid giver h\u00f8jere hit rate.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#tlb-miss-handling","title":"TLB Miss Handling","text":"<p>Kan h\u00e5ndteres af Hardware eller OS.</p> <p>Eksempel p\u00e5 hardware-managed TLB er Intel x86. Bruger multi-level page table.</p> <ul> <li>Current page table bliver pointed p\u00e5 af CR3 register.</li> </ul> <p>Software-managed TLB: Hardware raiser exception, og trap handler h\u00e5ndtere TLB miss</p> <ul> <li>Return-from trap er anderledes end ved system call, da vi skal kalde den for\u00e5sagende instruktion. Denne gang med TLB hit.</li> <li>Man skal s\u00f8rge for at undg\u00e5 infinite loop, eksempelvis ved at holde TLB miss handlers i fysisk memory.</li> <li>Eller reservere entries i TLB for permanente translations.</li> <li>Software-managed l\u00f8sning giver flexibilitet og simplicitet</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#tlb-indhold","title":"TLB Indhold","text":"<p>Typisk TLB har 32, 64 eller 128 entries, og er fully associative.</p> <ul> <li>En translation kan v\u00e6re overalt i TLB</li> <li>Hele TLB s\u00f8ges i parallel.</li> </ul> <p>En entry kan se ud som: $$ \\text{VPN}\\ |\\ \\text{PFN}\\ |\\ \\text{other bits} $$ Other bits:</p> <ul> <li>valid bit: har entry en valid translation</li> <li>protection bit: hvordan kan page tilg\u00e5s (som i page table)</li> <li>address-space identifier, dirty bit osv.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#tlb-problemer","title":"TLB Problemer","text":"<p>TLB indeholder v2p translations kun gyldige for nuv\u00e6rende process.</p> <ul> <li>N\u00e5r der skiftes process skal hardware, OS eller begge sikre sig at den n\u00e6ste process ikke bruge forkeret translations.</li> </ul> <p>En mulig l\u00f8sning er at flush TLB ved context switch.</p> <ul> <li> <p>S\u00e6tter alle valid bits til 0</p> </li> <li> <p>Kan v\u00e6re kostbart, da der vil v\u00e6re TLB miss'es efter hver context switch.</p> </li> </ul> <p>Nogle systemer har address space identifer (ASID) felt i TLB.</p> <ul> <li>Kan t\u00e6nkes som process identifer (PID) men ofte f\u00e6rre bits</li> </ul> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#formindsk-page-tables","title":"Formindsk Page Tables","text":"<p>En l\u00f8sning er st\u00f8rre pages.</p> <p>32-bit addresser igen. Denne gang 16KB pages. Giver 18-bit VPN plus 14-bit offset. PTE (4 bytes) giver: 2^{18}2^{18} entries, derfor 1MB per page table.</p> <ul> <li>Leder til internal fragmentation</li> </ul> <p>Hybrid apporach</p> <p>Et page table per logisk segment (code, heap og stack).</p> <p>Vi bruger base til holde fysisk adresse p\u00e5 page table. Og bound til at holde slutningen p\u00e5 page table.</p> <p>Eksempel:</p> <p>32-bit adress space, 4KB pages, adress space splittet i 4 segments.</p> <p></p> <p>Registers skal skiftes ved context-switch.</p> <pre><code>SN              = (VirtualAddress &amp; SEG_MASK) &gt;&gt; SN_SHIFT\nVPN             = (VirtualAddress &amp; VPN_MASK) &gt;&gt; VPN_SHIFT\nAddressOfPTE    = Base[SN] + (VPN * sizeof(PTE))\n</code></pre> <p>Eksempel: Hvis code kun bruger f\u00f8rste 3 pages, vil code page table kun have 3 entries, og bounds er sat til 3.</p> <p>Fordele:</p> <ul> <li>Ubrugte pages mellem stack og heap fylder ikke i page table.</li> </ul> <p>Ulemper:</p> <ul> <li>Kr\u00e6ver at segmentation brgues.</li> <li>Giver external fragmentation</li> </ul> <p>Multi-Level Page Tables kan l\u00f8se problemet.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#multi-level-page-tables","title":"Multi-Level Page Tables","text":"<p>Sk\u00e6r page table op i page-sized stykker.</p> <ul> <li>Hver page table passer i en enkelt page.</li> </ul> <p>Hvis en hel page af PTE (page-table-entries) er invalid, allokeres ikke plads.</p> <p>Ellers bruges en ny struktur: page directory.</p> <p></p> <p>Page directory (i 2-level) indeholder et antal page directory entries (PDE).</p> <p>En PDE har som minium en valid bit og page frame number (PFN).</p> <ul> <li>Hvis PDE er valid, er mindst en af pages valid.</li> <li>Hvis PDE ikke er valid, er resten af PDE ikke defineret.</li> </ul> <p>Fordele:</p> <ul> <li>Allokerer kun page table space i proportion til antal adress space brugt.</li> <li>Hvis carefully constructed, passer hver portion i en page, hvilket g\u00f8re det nemmere at manage memory.</li> <li>Lader os placere page-table pages hvor vi vil i memory.</li> </ul> <p>Ulemper</p> <ul> <li>Performance cost: ved TLB miss, kr\u00e6ves 2 loads. 1 for page directory og 1 for PTE.</li> <li>time-space trade-off</li> <li>complexity: Mere complex at implementere.</li> </ul> <p>Eksempel med 256 entry page table</p> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#more-than-2-levels","title":"More Than 2 Levels","text":"<p>Hvad hvis page directory bliver for stor?</p> <p>Eksempel:</p> <p>30-bit virtual address space, 512 byte page. PTE 4 bytes.</p> <p>Giver:</p> <ul> <li> <p>21-bit VPN og 9-bit offset</p> </li> <li> <p>128 PTE's per page.</p> </li> <li>7 bits til index</li> </ul> <p></p> <p>14 bits PDI: 2^{14}2^{14} entries. Fylder 128 pages.</p> <p>Vi bygger endnu et niveau p\u00e5.</p> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#inverted-page-tables","title":"Inverted Page Tables","text":"<p>Her holder vi \u00e9t page table, der har en entry for hver fysisk page.</p> <p>Hver entry fort\u00e6ller os hvilken process der bruger denne page, og hvilken virtuel page der mapper til denne fysiske page.</p> <ul> <li>S\u00f8g gennem den struktur for at finde den korrekte.</li> <li>Bruger ofte hash-tables, da linear search er dyrt.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#swapping","title":"Swapping","text":"<p>Vi t\u00e6nker nu p\u00e5 at alle address spaces tilsammen kan v\u00e6re st\u00f8rre end fysisk memory.</p> <p>Vi bruger et ekstra level i memory hierarchy</p> <p>Et eksempel p\u00e5 memory hierarchy:</p> <p></p> <p>Vi bruger hard disk til at opbevare portioner af adress spaces, der ikke er i great demand.</p> <ul> <li>F\u00f8r i tiden brugt man, memory overlays, hvor programm\u00f8rer selv skulle flytte data ind og ud af memory.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#swap-space","title":"Swap Space","text":"<p>Vi reservere noget plads p\u00e5 disk, til at flytte pages frem og tilbage imellem. Vi kalder dette for swap space.</p> <ul> <li>Vi swapper pages ud af memory til det, og memory ind i memory fra det.</li> </ul> <p>Derfor skal OS huske disk address for en given page.</p> <p></p> <p>Hver page table entry (PTE) f\u00e5r en present bit.</p> <ul> <li>Siger om page er i fysisk memory.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#page-fault","title":"Page Fault","text":"<p>Accessing af en page der ikke er i fysisk kaldes page fault aka page miss.</p> <ul> <li>Kalder page-fault handler i OS</li> </ul> <p>Disk adresse kan stores i PTE.</p> <ul> <li>OS finder adresse, og requester disk fetch.</li> <li>Opdaterer page table (markerer present)</li> <li>Pr\u00f8ver instruktion igen.</li> </ul> <p>Dette kan generere TLB miss.</p> <ul> <li>Alternativt kan man opdatere TLB under page fault</li> </ul> <p>(Under I/O vil processen v\u00e6re i blocked state, og andre processer kan k\u00f8re)</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#hvad-hvis-memory-er-fyldt","title":"Hvad Hvis Memory Er Fyldt?","text":"<p>Hvis der ikke er plads til at page in en page, vil OS f\u00f8rst page ud en eller flere pages.</p> <p>Dette styres af page-replacement policy</p> <p>For at holde en lille smule memory frit, bruger de fleste OS: HW og LW</p> <ul> <li>Low watermark (LW): His der er f\u00e6rre end LW pages tilg\u00e6ngelige, kaldes en baggrundstr\u00e5d til at frig\u00f8re memory.</li> <li>High watermark (HW): Dette g\u00f8res indtil der er HW pages ledige.</li> </ul> <p>Denne baggrundstr\u00e5d kaldes ofte swap daemon eller page daemon.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#swapping-policies","title":"Swapping Policies","text":"<p>Vi kan kalde main memory for cache for virtual memory.</p> <p>Vores m\u00e5l er at minimere cache misses.</p> <ul> <li>Samme som at maximere cache hits</li> </ul> <p>Average memory access time (AMAT)</p>  \\begin{align*} AMAT &amp;= T_M+(P_{Miss}*T_D),\\\\\\\\ &amp;\\text{hvor } T_M : \\text{cost of accessing memory}\\\\ &amp;\\text{and } T_D : \\text{cost of accessing disk}\\\\ &amp;\\text{and } P_{Miss} :\\text{chance of cache miss } (0.0&lt;P_{Miss}&lt;1.0) \\end{align*}   \\begin{align*} AMAT &amp;= T_M+(P_{Miss}*T_D),\\\\\\\\ &amp;\\text{hvor } T_M : \\text{cost of accessing memory}\\\\ &amp;\\text{and } T_D : \\text{cost of accessing disk}\\\\ &amp;\\text{and } P_{Miss} :\\text{chance of cache miss } (0.0&lt;P_{Miss}&lt;1.0) \\end{align*}"},{"location":"4-semester/PSS/exam/4-paged-memory/#optimal-replacement-policy","title":"Optimal Replacement Policy","text":"<p>(Impossible to implement)</p> <ul> <li>Udskifter den page der vil bliver accessed l\u00e6ngst ude i fremtiden</li> </ul> <p>Bruges til at sammenligne med.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#fifo-first-in-first-out","title":"FIFO (First In First Out)","text":"<ul> <li>Simpelt at implementere</li> </ul> <p>Kan ikke bestemme vigtigheden af en page</p> <p></p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#random","title":"Random","text":"<ul> <li>Simpel at implementere</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#least-recently-used-lru","title":"Least-Recently-Used (LRU)","text":"<p>Bruger history. (frequency eller recency)</p> <p>Replaces the least-recently-used page.</p> <p>Som Least-Frequently-Used (LFU)</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#workload-eksempler","title":"Workload Eksempler","text":""},{"location":"4-semester/PSS/exam/4-paged-memory/#ingen-lokalitet","title":"Ingen lokalitet:","text":"<p>100 unikke pages, v\u00e6lger random. 10k gange.</p> <p></p> <ul> <li>Ingen lokalitet: Ligegyldigt hvilken policy.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#80-20-workload","title":"80-20 workload:","text":"<p>80% af referancer er til 20% af pages.</p> <p></p> <ul> <li>LRU er den bedste.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#looping-sequential-workload","title":"Looping Sequential Workload","text":"<p>Referencer til 50 pages i sekvens startende fra 0.</p> <p></p> <ul> <li>Random er den bedste op til n\u00e5r cache bliver 50 eller mere.</li> </ul> <p>Worst-case for b\u00e5de LRU og FIFO.</p> <p>Random har ingen \"wierd\" corner cases.</p>"},{"location":"4-semester/PSS/exam/4-paged-memory/#aproximating-lru","title":"Aproximating LRU","text":"<p>For at undg\u00e5 at kigge en hel liste igennem for at finde least-recently-used page, kan man aproximere LRU.</p> <ul> <li>Bruger en use bit aka reference bit. 1 per page.</li> <li>N\u00e5r en page bliver referenced s\u00e6ttes use bit til 1 af hardware.</li> </ul> <p>Clock algorithm</p> <ul> <li> <p>Forestil alle pages i en cirkul\u00e6r liste.</p> </li> <li> <p>En clock hand peger p\u00e5 en page.</p> </li> <li>N\u00e5r replacement sker tjekker OS om den pegede p\u00e5 page P har use bit 1 eller 0.</li> <li>Hvis use bit er 1, er det ikke en god replacement kandidat. Use bit s\u00e6ttes til 0 (cleared) og clock hand incrementes.</li> <li>Forts\u00e6tter til en page med use bit 0 findes.</li> </ul> <p></p> <p>Tilf\u00f8jelse: dirty bit.</p> <ul> <li>Man kan tilf\u00f8je dirty bit, som fort\u00e6ller om page er modified (dirty).</li> <li>Dette betyder at der skal skrives til disk hvilket er dyrt.</li> </ul>"},{"location":"4-semester/PSS/exam/4-paged-memory/#thrashing","title":"Thrashing","text":"<p>Hvis memory er oversubscribed, og memory demand er over fysisk memory, vil systemet konstant page, kaldet thrashing.</p>"},{"location":"4-semester/PSS/exam/5-concurrency/","title":"5 - Concurrency","text":"<p>Keywords: Multi-threading, implementation strategies for multi-threading (concurrency), concurrency vs. parallelism, inter-process communication, race conditions, mutual exclusion, ensuring mutual exclusion (algorithms, hardware supported, mutexes, semaphores, monitors).</p>"},{"location":"4-semester/PSS/exam/5-concurrency/#litterature","title":"Litterature","text":"<p>OSTEP Chapter 25, 26, (27), 28, (29), (30), 31, 32, (33), 34</p> <p>Kapitler med parenteser skimmes: (x)</p>"},{"location":"4-semester/PSS/exam/5-concurrency/#learning-goals","title":"Learning Goals","text":"<p>After this lecture, you</p> <ul> <li> ... can define what a race condition is</li> <li> ... can explain how mutual exclusion can be used to avoid race conditions</li> <li> ... can explain strategies for achieving and implementing mutual exclusion</li> <li>... can define the notions of mutex, semaphore, and monitor and explain how they work and where they are useful</li> <li> ... can explain how to synchronise two (or more) threads and why it may be necessary</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#noter","title":"Noter","text":""},{"location":"4-semester/PSS/exam/5-concurrency/#threads","title":"Threads","text":"<p>Threads kan ses som en abstrahering i processer.</p> <p>En tr\u00e5d er lige som en seperate process, botset fra at de deler adress space, og kan derfor access samme data.</p> <p>Hver tr\u00e5d har sit eget s\u00e6t registre</p> <p>Hvis 2 tr\u00e5de k\u00f8rer p\u00e5 samme CPU skal der laves context switch hvis CPU skal skifte tr\u00e5d.</p> <ul> <li>Address space forbliver det samme</li> </ul> <p>Ligesom ved processer har vi en datastruktur til at gemme informationen. Her en thread control block (TCB) i stedet for PCB.</p> <p>Hver tr\u00e5d har sin egen stack:</p> <ul> <li>thread-local storage</li> </ul> <p></p>"},{"location":"4-semester/PSS/exam/5-concurrency/#hvorfor-trade","title":"Hvorfor Tr\u00e5de?","text":"<p>Parallelism</p> <p>En opgave splittes op, og kan k\u00f8re p\u00e5 flere CPU'er. Parallelization.</p> <p>I/O</p> <p>For at undg\u00e5 at programmet er blocked pga. langsom I/O.</p> <p>Mange server-based applikationer bruger tr\u00e5de.</p> <ul> <li>(web servere, databaser osv.)</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#race-conditions","title":"Race Conditions","text":"<p>Hvis 2 tr\u00e5de arbejder p\u00e5 den samme variabel, kan der opst\u00e5 det der kaldes race condition eller data race.</p> <p></p> <p>Hvis begge henter variabel k ind p\u00e5 samme med mens den er 42.</p> <ul> <li>S\u00e5 t\u00e6ller de den begge op, og resultatet bliver 43, selvom det burde v\u00e6re 44.</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#definitioner","title":"Definitioner","text":"<p>Race condition:</p> <ul> <li>N\u00e5r resultatet af en beregning afh\u00e6nger af relative speed af de individuelle tr\u00e5de</li> <li>Med andre ord: Resultatet afh\u00e6nger af interleaving af tr\u00e5dene.</li> <li>Sv\u00e6re at debug</li> </ul> <p>Critical region (critical section):</p> <ul> <li>Program fragment s\u00e5rbar overfor race conditions</li> <li>\"Kritisk region\"</li> <li>Kritiske regioner skal eksekveres under mutual exclusion</li> </ul> <p>Mutual exclusion (mutex):</p> <ul> <li>N\u00e5r kun en tr\u00e5d (blandt mange) kan tilg\u00e5 en given resource eller execute en specifik del af program-text.</li> <li>\"gensidig udelukkelse\"</li> </ul> <p>Atomic</p> <ul> <li>Event eller sekvens af events som sker uafbrudt.</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#locks","title":"Locks","text":"<p>Critical region kode omgives a lock og unlock.</p> <pre><code>lock_t mutex;\n...\nlock(&amp;mutex);\nbalance = balance + 1;\nunlock(&amp;mutex);\n</code></pre> <p>Her er <code>mutex</code> lock variable (lock for short). Lock variablen holder lock'ens tilstand.</p> <p>En lock er enten available (unlocked/free)</p> <ul> <li>Ingen tr\u00e5de holder lock'en</li> </ul> <p>Eller aquired (locked/held)</p> <ul> <li>Pr\u00e6cis 1 tr\u00e5d holder lock'en</li> </ul> <p>Kald til <code>lock()</code> fors\u00f8ger at aquire l\u00e5sen. </p> <ul> <li> <p>Hvis ingen tr\u00e5de holder l\u00e5sen (l\u00e5sen er available), vil tr\u00e5den aquire l\u00e5sen, og eksekvere den critical region.</p> </li> <li> <p>Hvis l\u00e5sen er held, vil tr\u00e5den vente p\u00e5 at l\u00e5sen bliver available</p> </li> </ul> <p>Kald til <code>unlock()</code> vil g\u00f8re l\u00e5sen available igen, og hvis nogle tr\u00e5de venter p\u00e5 l\u00e5sen, vil de nu aquire l\u00e5sen, og eksekvere critical region.</p>"},{"location":"4-semester/PSS/exam/5-concurrency/#building-a-lock","title":"Building a Lock","text":"<p>M\u00e5l:</p> <ul> <li>Correctness: Provides mutual exclusion</li> <li>Fairness: F\u00e5r alle tr\u00e5de et fair fors\u00f8g p\u00e5 at aquire. (Er der nogle tr\u00e5de der starver, og dermed aldrig f\u00e5r fat i l\u00e5sen)</li> <li>Performance</li> </ul> <p>Tidlig l\u00f8sning for single-processor systemer var at disable interrupts under critical region</p> <pre><code>void lock()     {DisableInterrupts();}\nvoid unlock()   {EnableInterrupts();}\n</code></pre> <ul> <li>Simpelt at implementere</li> </ul> <p>Ulemper:</p> <ul> <li>Lader alle tr\u00e5de kalde priviligeret instruktion, kan abuses</li> <li>Virker ikke p\u00e5 multi-processor systemer. <ul> <li>Hvis 2 tr\u00e5de k\u00f8rer p\u00e5 2 forskellige processorer, er det ligegyldigt om interrupts er disabled</li> </ul> </li> <li>Kan g\u00f8re til at interrupts bliver tabt.<ul> <li>Eksempelvis hvis CPU misser at disk l\u00e6sning er f\u00e6rdig</li> </ul> </li> <li>Ineffektivt</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#lock-variables","title":"Lock Variables","text":"<ul> <li>VIRKER IKKE</li> <li>Race conditions</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#dekkers-algorithm","title":"Dekkers Algorithm","text":"<ul> <li>Ikke effektiv</li> <li>Compiler vil m\u00e5ske allokere nogle variable i registers (ikke delt mellem tr\u00e5de)</li> <li>Sv\u00e6r (umulig?) at scalere til mere end 2 tr\u00e5de.</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#spin-lock-med-test-and-set","title":"Spin Lock Med Test-And-Set","text":"<p>Hardware instruktion test-and-set (atomic exchange)</p> <p>G\u00f8r f\u00f8lgende atomically:</p> <pre><code>int TestAndSet(int *old_ptr, int new) {\nint old = *old_ptr; // fetch old value at old_ptr\n*old_ptr = new;     // store 'new' into old_ptr\nreturn old;         // return the old value\n}\n</code></pre> <pre><code>typedef struct __lock_t { int flag;\n} lock_t; void init(lock_t *lock) {\n// 0: lock is available, 1: lock is held \nlock-&gt;flag = 0;\n} void lock(lock_t *lock) {\nwhile (TestAndSet(&amp;lock-&gt;flag, 1) == 1) ; // spin-wait (do nothing)\n}\nvoid unlock(lock_t *lock) { lock-&gt;flag = 0;\n}\n</code></pre> <p>Spin-locks kr\u00e6ver preemptive scheduler (interrupter via timer).</p> <ul> <li>Ellers clogger de CPU</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#evaluering-af-spin-locks","title":"Evaluering af Spin Locks","text":"<p>Correctness:</p> <ul> <li>Ja, lader kun 1 tr\u00e5d eksekvere critical region af gangen.</li> </ul> <p>Fairness:</p> <ul> <li>Nej, ingen garanti for ikke at starve</li> </ul> <p>Perfomance</p> <ul> <li>Ikke s\u00e5 god p\u00e5 single CPU.<ul> <li>Hvis tr\u00e5d bliver afbrudt midt i critcal region</li> <li>S\u00e5 kan alle andre tr\u00e5de, ventende, st\u00e5 at spinne i en hel time slice</li> </ul> </li> <li>Rimelig god p\u00e5 multiple CPU, hvis antallet af CPUs ca. passer med antallet af tr\u00e5de</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#compare-and-swap","title":"Compare-And-Swap","text":"<p>Ny hardware instruktion, atomically:</p> <pre><code>int CompareAndSwap(int *ptr, int expected, int new) { int original = *ptr;\nif (original == expected) *ptr = new;\nreturn original; }\n</code></pre> <p>Implementering:</p> <pre><code>void lock(lock_t *lock) {\nwhile (CompareAndSwap(&amp;lock-&gt;flag, 0, 1) == 1) ; // spin\n}\n</code></pre>"},{"location":"4-semester/PSS/exam/5-concurrency/#fetch-and-add","title":"Fetch-And-Add","text":"<p>Hardware instruktion, atomically:</p> <pre><code>int FetchAndAdd(int *ptr) { int old = *ptr;\n*ptr = old + 1;\nreturn old;\n}\n</code></pre> <p></p> <ul> <li>Sikrer progress for alle tr\u00e5de. Laver en \"k\u00f8\".</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#undga-tidsspild-ved-spinning","title":"Undg\u00e5 Tidsspild Ved Spinning","text":"<p>Hvis der sker context-switch midt i en critical region, vil en tr\u00e5d der venter p\u00e5 lock, bare spinne uden at g\u00f8re noget, hele time slice.</p> <ul> <li>Kaldes busy wait. </li> </ul> <p>Mulig l\u00f8sning: yield.</p> <ul> <li>I stedt for at g\u00f8re ingenting, s\u00e5 kald <code>yield</code></li> <li>Stadig ikke helt god. 100 threads der venter:<ul> <li>RR scheduler, waster 99 cycles</li> <li>Stadig bedre end at wase 99 time slices</li> </ul> </li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#brug-af-queues-sleeping-instead-of-spinning","title":"Brug af Queues: Sleeping Instead of Spinning","text":""},{"location":"4-semester/PSS/exam/5-concurrency/#semaphores","title":"Semaphores","text":"<p>Semaphore: Et objekt med en integer v\u00e6rdi der kan manipuleres med 2 routiner.</p> <p>I POSIX er det:</p> <ul> <li><code>sem_wait()</code></li> <li><code>sem_post()</code></li> </ul> <p>Initialiseres med</p> <pre><code>#include &lt;semaphore.h&gt;\nsem_t s;\nsem_init(&amp;s, 0, 1); // initilizere den til 1, arg2 (0) betyder at den er delt mellem tr\u00e5de i den samme process\n</code></pre> <pre><code>int sem_wait(sem_t *s) {\n/* decrement the value of semaphore s by one \n       wait if value of semaphore s is negative */\n}\n\nint sem_post(sem_t *s) { /* increment the value of semaphore s by one \n       if there are one or more threads waiting, wake one */\n}\n</code></pre>"},{"location":"4-semester/PSS/exam/5-concurrency/#binary-semaphore-lock","title":"Binary Semaphore (Lock)","text":"<pre><code>sem_t m;\nsem_init(&amp;m, 0, 1); // initialize to 1;\n\nsem_wait(&amp;m);\n// critical section here\nsem_post(&amp;m);\n</code></pre>"},{"location":"4-semester/PSS/exam/5-concurrency/#semaphores-for-ordering","title":"Semaphores For Ordering","text":"<pre><code>sem_t s;\n\nvoid *child(void *arg) { printf(\"child\\n\");\nsem_post(&amp;s); // signal here: child is done\nreturn NULL;\n} int main(int argc, char *argv[]) {\nsem_init(&amp;s, 0, 0); printf(\"parent: begin\\n\"); pthread_t c;\nPthread_create(&amp;c, NULL, child, NULL); sem_wait(&amp;s); // wait here for child \nprintf(\"parent: end\\n\");\nreturn 0;\n}\n</code></pre>"},{"location":"4-semester/PSS/exam/5-concurrency/#the-producerconsumer-problem-bounded-buffer-problem","title":"The Producer/Consumer Problem (Bounded Buffer Problem)","text":"<ul> <li>En eller flere producer threads<ul> <li>Genererer data items, placerer dem i en buffer</li> </ul> </li> <li>En eller flere consumer threads<ul> <li>Tager items fra bufferen og consumer dem</li> </ul> </li> </ul> <ul> <li>Virker hvis MAX er 1</li> <li>Hvis MAX er eks 10, f\u00e5r vi race condition</li> </ul>"},{"location":"4-semester/PSS/exam/5-concurrency/#readerwriter-lock","title":"Reader/Writer Lock","text":""},{"location":"4-semester/PSS/exam/5-concurrency/#thread-throtting-with-semaphores","title":"Thread Throtting with Semaphores","text":"<p>Hvis vi vil kontrollere max antal tr\u00e5de, kan vi g\u00f8re det med semaphores.</p> <ul> <li>Kaldes throttling, en form for admission control</li> </ul> <p>Eksempelvis hvis en masse memory heavy arbejde, og der k\u00f8rer en masse tr\u00e5de p\u00e5 en gang, kan det v\u00e6re at fysisk memory overstiges.</p> <p>Vi kan initialisere en semaphore med antallet af max tr\u00e5de.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/","title":"6 - Concurrency Problems","text":"<p>Keywords: Definition of deadlock, mutual exclusion, resource allocation graph, Coffman\u2019s conditions, solution strategies (prevention, avoidance, detection and recovery), how to achieve deadlock prevention (breaking Coffman\u2019s conditions), safe states and deadlock avoidance, deadlock detection and recovery, livelock, priority inversion.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#litterature","title":"Litterature","text":"<p>OSTEP Chapter 25, 26, (27), 28, (29), (30), 31, 32, (33), 34</p> <p>Kapitler med parenteser skimmes: (x)</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#learning-goals","title":"Learning Goals","text":"<p>After today\u2019s lecture, you:</p> <ul> <li>... can define and explain the concept of deadlock</li> <li>... can define and explain Coffman\u2019s conditions for deadlock</li> <li>... can explain and use deadlock prevention strategies:<ul> <li>prevention</li> <li>avoidance</li> <li>detect-and-recover</li> </ul> </li> <li>... can define and explain the following concepts<ul> <li>livelock</li> <li>priority inversion</li> </ul> </li> <li>... can use the Dining Philosophers example to explain concurrency     issues</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#noter","title":"Noter","text":"<p>Concurrency bugs in modern applications</p> <p></p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#non-deadlock-bugs","title":"Non-Deadlock Bugs","text":"<p>97 % af non-deadlock bugs er en af f\u00f8lgende:</p> <ul> <li>Atomicity Violation</li> <li>Order Violation</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#atomicity-violation","title":"Atomicity Violation","text":"<p>Eksempel fra MySQL:</p> <pre><code>Thread 1::\nif (thd-&gt;proc_info) {\nfputs(thd-&gt;proc_info, ... );\n}\n\nThread 2::\nthd-&gt;proc_info = NULL\n</code></pre> <p>Koden i thread 1, har en atomicity assumption, den tror at kode line 2-3 sker i et hug. Men hvis den laver null-check f\u00f8rst, og s\u00e5 tr\u00e5d 2 s\u00e6tter den til null f\u00f8r linje 3 k\u00f8res, s\u00e5 er der fejl</p> <p>L\u00f8sning: Locks rundt om lines 2-4 + line 7</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#order-violation","title":"Order-Violation","text":"<pre><code>float T;\n</code></pre> <p>Koden i thread 2, tror at <code>T</code> er initialiseret.</p> <p>L\u00f8sning:</p> <p>Kan l\u00f8ses med en semaphore</p> <p></p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#deadlock","title":"Deadlock","text":"<p>Se The Dining Philosphers Eksempel</p> <p>Sker hvis lad os sige Tr\u00e5d 1 holder en lock <code>L1</code> og venter p\u00e5 <code>L2</code>.  Og Tr\u00e5d 2 holder <code>L2</code> og venter p\u00e5 <code>L1</code></p> <p></p> <p></p> <p></p> <p>Sker blandt andet pga store code bases og encapsulation</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#conditions-for-deadlock","title":"Conditions for Deadlock","text":"<p>Fire conditions skal holde f\u00f8r en deadlock kan ske:</p> <ul> <li>Mutual exclusion: Tr\u00e5de holder eksklusiv kontrol over en resource som de skal bruge. (eks. en lock)</li> <li>Hold-and-wait: Tr\u00e5de holder resourcer allokeret til dem, eks. aquired locks, mens de venter p\u00e5 flere resourcer (eks. locks de gerne vil aquire).</li> <li>No preemption: Resourcer (eks. locks) kan ikke blive forcefully removed fra tr\u00e5de der holder dem.</li> <li>Circular wait: Der eksistere en cirkular k\u00e6de af tr\u00e5de, s\u00e5 at hver tr\u00e5d holder en eller flere resourcer (eks. locks) som bliver requestet af den n\u00e6ste tr\u00e5d i k\u00e6den.</li> </ul> <p>Alle disse conditions skal overholdes f\u00f8r der kan ske en deadlock.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#prevention","title":"Prevention","text":""},{"location":"4-semester/PSS/exam/6-concurrency-problems/#circular-wait","title":"Circular Wait","text":"<p>Nok den mest praktiske prevention teknik. Undg\u00e5 circular wait.</p> <p>Den mest ligetil l\u00f8sning er total ordering.</p> <ul> <li>Hvis der kun er 2 locks i systemet, s\u00e5 s\u00f8rg for at eks <code>L1</code> altid aquires f\u00f8r <code>L2</code>.</li> <li>Kan v\u00e6re sv\u00e6rt i et system med mere end 2 locks.</li> </ul> <p>Partial ordering:</p> <ul> <li>En r\u00e6kkef\u00f8lge for forskellige locks.</li> </ul> <p>Kr\u00e6ver careful design. Er kun en convention, og en \"doven\" programm\u00f8r kan ignorere dem.</p> <p>Kr\u00e6ver dyb forst\u00e5else for kode basen.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#hold-and-wait","title":"Hold-and-wait","text":"<p>Kan undg\u00e5s ved at tage alle locks p\u00e5 en gang:</p> <pre><code>pthread_mutex_lock(prevention);     // begin aquisition\npthread_mutex_lock(L1);\npthread_mutex_lock(L2);\n...\npthread_mutex_unlock(prevention);   // end\n</code></pre> <p>Problematisk:</p> <ul> <li>Encapsulation arbejder imod os.<ul> <li>Kr\u00e6ver at vi ved hvilke locksder skal holdes, og at de skal aquires f\u00f8r tid.</li> </ul> </li> <li>Neds\u00e6tter concurrency, da alle locks skal aquires p\u00e5 en gang i stedet for n\u00e5r de rigtigt skal bruges</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#no-preemption","title":"No Preemption","text":"<p>Flere libraries tilbyder flexibelt s\u00e6t interfaces til at hj\u00e6lpe.</p> <p>Routinen: <code>pthread_mutex_trylock()</code> grabber enten lock'en hvis den er klar og returnerer sucess, eller returnerer error hvis l\u00e5sen holdes.</p> <p>Kan bruges til at lave en deadlock-free ordering-robust lock aquisition protocol:</p> <pre><code>top:\npthread_mutex_lock(L1);\nif (pthread_mutex_trylock(L2) != 0) { pthread_mutex_unlock(L1); goto top;\n}\n</code></pre> <p>Et nyt problem er dog skabt: livelock</p> <ul> <li>Det kan ske (dog usansynligt) at 2 tr\u00e5de begge pr\u00f8ver og fejler gentagne gange p\u00e5 at aquire begge locks.</li> <li>Begge tr\u00e5de k\u00f8rer gennem koden om og om igen (alts\u00e5 ingen deadlock), men der sker intet, derfor livelock.</li> <li>En l\u00f8sning p\u00e5 dette kan v\u00e6re at inf\u00f8re et random delay.</li> </ul> <p>Dog:</p> <ul> <li>Problem igen, encapsulation</li> <li>Hvis koden har aquired andre resources, skal den huske at release dem igen.</li> <li>Tilf\u00f8jer ikke preemption. men bruger trylock til at lade udvilkeren tr\u00e6kke sig ud af et lock ownership.</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#mutual-exclusion","title":"Mutual Exclusion","text":"<p>Undg\u00e5 behovet for mutual exclusion.</p> <p>Ide: design data strukturer uden locks. (lock-free and wait-free)</p> <ul> <li>Brug hardware instruktioner.</li> </ul> <p>Eksempel vi bruger compare-and-swap til at atomically increment en v\u00e6rdi.</p> <pre><code>void AtomicIncrement(int *value, int amount) { do {\nint old = *value; } while (CompareAndSwap(value, old, old + amount) == 0); }\n</code></pre> <p>Istedet for at aquire en lock, update og release lock, har vi en metode der bliver  ved med at pr\u00f8ve at opdatere value med compare-and-swap.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#deadlock-avoidance-via-scheduling","title":"Deadlock Avoidance via Scheduling","text":"<p>Lad os sige at vi har 2 CPU'er og 4 tr\u00e5de, samt 2 locks.</p> <p>Lad os sige at vi ved at de 2 locks aquires af tr\u00e5dene som vist i tabellen: </p> <p></p> <p>En smart scheduler kan nu vide at s\u00e5 l\u00e6nge at T1 og T2 ikke k\u00f8re p\u00e5 samme tid kan der ikke ske deadlock.</p> <p>Eksempel p\u00e5 schedule:</p> <p></p> <p>Andet eksempel:</p> <p></p> <p></p> <ul> <li>Static scheduling koster i performance</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#detect-and-recover","title":"Detect and Recover","text":"<p>Sidste generelle strategi er at lade deadlocks v\u00e6re \"tilladet\", og s\u00e5 take action hvis en deadlock bliver detected.</p> <ul> <li>Eksempel, hvis OS fryser, kan det genstartes.</li> </ul> <p>Mange databasesystemer k\u00f8rer deadlock detection.</p> <ul> <li>Bygger en resource graf, og tjekker for cycles.</li> <li>Hvis det findes skal systemet genstartes.</li> </ul>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#the-dining-philosophers","title":"The Dining Philosophers","text":"<ul> <li>5 filosoffer</li> <li>Mellem hver er en enkelt gaffel.</li> <li>En filosof kan enten t\u00e6nke eller spise<ul> <li>T\u00e6nke: ingen gaffel</li> <li>Spise: Kr\u00e6ver 2 gafler</li> </ul> </li> </ul> <p>Her er basic loop for hver philospher, hvor hver filosof har en thread idientifier <code>p</code> fra 0 til 4</p> <pre><code>while (1) { \n    think();\n    get_forks(p); \n    eat(); \n    put_forks(p);\n}\n</code></pre> <p>Udfordringen er at skrive routinerne <code>get_forks()</code> og <code>put_forks()</code> s\u00e5dan at:</p> <ul> <li>Der er ingen deadlock</li> <li>Ingen filosof starves</li> <li>H\u00f8j concurrency (s\u00e5 mange filosoffer som muligt spiser p\u00e5 samme tid)</li> </ul> <p>Vi bruger f\u00f8lgende helper funktioner:</p> <pre><code>int left(int p)     { return p; }\nint right(int p)    { return (p + 1) % 5; }\n</code></pre> <p>N\u00e5r en filisof vil have gaflen til venstre kaldes <code>left(p)</code> og samme for h\u00f8jre <code>right(p)</code>.</p> <p>Vi har ogs\u00e5 nogle semaphores, lad os sige vi har 5, en for hver fork: <code>sem_t forks[5]</code></p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#umiddelbare-lsning-forkert","title":"Umiddelbare L\u00f8sning (FORKERT)","text":"<pre><code>void get_forks(int p) {\nsem_wait(&amp;forks[left(p)]);\nsem_wait(&amp;forks[right(p)]);\n}\n\nvoid put_forks(int p) {\nsem_post(&amp;forks[left(p)]); sem_post(&amp;forks[right(p)]);\n}\n</code></pre> <p>==DETTE ER FORKERT==</p> <p>Det f\u00f8rer til deadlock.</p> <p>Hvis hver filosof tager deres gaffel til venstre f\u00f8r nogen n\u00e5r at tage deres gaffel til h\u00f8jre, vil de alle sammen v\u00e6re stuck ventende p\u00e5 at deres h\u00f8jre gaffel bliver ledig.</p>"},{"location":"4-semester/PSS/exam/6-concurrency-problems/#lsning-breaking-the-dependency","title":"L\u00f8sning: Breaking The Dependency","text":"<p>Vi \u00e6ndre p\u00e5 hvordan gafler bliver taget hos mindst en af filosofferne.</p> <pre><code>void get_forks(int p) { if (p == 4) {\nsem_wait(&amp;forks[right(p)]); sem_wait(&amp;forks[left(p)]);\n} else {\nsem_wait(&amp;forks[left(p)]); sem_wait(&amp;forks[right(p)]);\n} }\n</code></pre>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/","title":"7 - I/O and Device Drivers","text":"<p>Keywords: Types of I/O (programmed, interrupt-driven, DMA), implementation of I/O (as system calls), definition and implementation of system call, device drivers.</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#litterature","title":"Litterature","text":"<p>OSTEP Chapter 35, 36, 37, (38), (39), (40), [41], [42], [43], [44], [45]</p> <p>Kapitler med parenteser skimmes: (x) Kapitler med kantede paranteser er optional: [x]</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#noter","title":"Noter","text":""},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#system-arkitektur","title":"System Arkitektur","text":"<p>\"Klassisk\" diagram af et system:</p> <p></p> <p>Hvorfor har vi hierakisk struktur?</p> <ul> <li>Fysik<ul> <li>Jo hurtigere en bus er, jo kortere skal den v\u00e6re</li> </ul> </li> <li>Pris<ul> <li>Det er dyrt at lave high performance busses</li> </ul> </li> </ul> <p>Intel's Z270 Chipset:</p> <p></p> <ul> <li>CPU connecter med en I/O chip via Intel's proprietary DMI (Direct Media Interface)</li> <li>Resten af devices connecter til I/O chuppen via forskellige interconnects.<ul> <li>Harddrives via eSATA <ul> <li>ATA - AT Attachement</li> <li>SATA - Serial ATA</li> <li>eSATA - external SATA</li> </ul> </li> <li>USB (Universal Serial Bus) connections<ul> <li>Low performance devices</li> </ul> </li> <li>Higher performance devices gennem PCIe (Peripheral Component Interconnect Express)<ul> <li>Network</li> <li>NVMe storage devices</li> </ul> </li> </ul> </li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#en-canonical-device","title":"En Canonical Device","text":"<ul> <li>Interface som pr\u00e6senteres til systemet.</li> <li>Internal structure. </li> </ul> <p>Denne enhed best\u00e5r af 3 registre:</p> <ul> <li>status: l\u00e6ses for at se enhedens nuv\u00e6rende status</li> <li>command: fort\u00e6ller enheden hvilken opgave den skal udf\u00f8re</li> <li>data: til at videregive data til enheden, eller til at modtage data fra enheden.</li> </ul> <p>Typisk simpel interaktion som OS kan have med enheden:</p> <pre><code>While (STATUS == BUSY)\n    ; // wait until device is not busy\nWrite data to the DATA register\nWrite command to the COMMAND register\n    (starts device and executes the command)\nWhile (STATUS == BUSY)\n    ; // wait ontil devices is done with your request\n</code></pre> <ol> <li>OS venter p\u00e5 at enheden er klar ved at l\u00e6se STATUS (polling the device) (line 1-2)</li> <li>OS sender data til DATA (line 3)<ul> <li>N\u00e5r main CPU er involveret i data flytning kaldes det programmed I/O (PIO)</li> </ul> </li> <li>OS skriver kommando til COMMAND<ul> <li>Fort\u00e6ller implicit til enheden b\u00e5de at data er tilstede og at den skal begynde kommandoen</li> </ul> </li> <li>OS venter p\u00e5 enheden f\u00e6rdigg\u00f8rer arbejdet ved polling</li> </ol> <p>Simpel men ineffektiv protokol.</p> <p>CPU spilder tid ved polling.</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#lsning-interrupts","title":"L\u00f8sning: Interrupts","text":"<p>OS laver I/O request, putter processen i sleep, laver context switch.</p> <p>N\u00e5r I/O enheden er f\u00e6rdig, laver den et hardware interrupt.</p> <p>Interrupt handler aka interrupt service routine (ISR) tager over.</p> <ul> <li>Ikke altid den bedste l\u00f8sning. Hvis en enhed er meget hurtig, vil interrupts s\u00e6nke farten. Polling bedre.</li> </ul> <p>Hybrid:</p> <ul> <li>poll'er lidt i starten og bruger interrupts hvis ikke enheden er f\u00e6rdig.</li> </ul> <p>Networks</p> <ul> <li>Kan v\u00e6re skidt at bruge interrupts, hvis der kommer en masse packets der genererer interrupts.<ul> <li>OS kan g\u00e5 i livelock hvor det ikke laver andet end at behandle interrupts</li> </ul> </li> </ul> <p>Polling giver lidt mere kontrol</p> <p>Coalescing er en anden optimering.</p> <ul> <li>En device der skal interrupt, venter f\u00f8rst med at sende.</li> <li>Mens den venter, kan andre requests klares, og flere interrupts kan samles (coalesced).</li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#effektiv-data-overfrsel-med-dma","title":"Effektiv Data Overf\u00f8rsel Med DMA","text":"<p>Det kr\u00e6ver tid for CPU'en at overf\u00f8re data. (Markeret med gr\u00e5 'c' bokse)</p> <p></p> <p>En l\u00f8sning p\u00e5 dette problem er Direct Memory Access (DMA)</p> <p>En DMA engine, er en specifik enhed i systemet der orkestrerer overf\u00f8rseler mellem enheder og main memory uden meget CPU intervention.</p> <ul> <li>OS programmerer DMA engine ved at fort\u00e6lle den hvor dataen befinder sig, hvor meget data, og hvor det skal sendes hen.</li> </ul> <p></p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#device-interaction","title":"Device Interaction","text":"<p>2 forskellige m\u00e5der at kommunikere med enheder er udviklet over tid.</p> <ul> <li>Explicit I/O instructions.<ul> <li>Hardware instruktioner der specificere en m\u00e5de for OS at sende data til device registre.</li> <li>x86 har <code>in</code> og <code>out</code> instruktioner<ul> <li>Caller specificerer register med data og en specifik port.</li> </ul> </li> <li>Instruktioner er priviligerede.</li> </ul> </li> <li>Memory-mapped I/O<ul> <li>Hardware g\u00f8r device registre ledige som var de memory locations.</li> <li>OS kalder load eller store til adressen, og hardware router til enheden i stedet for main memory.</li> </ul> </li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#device-drivers","title":"Device Drivers","text":"<p>Abstraction</p> <p>Et stykke software i OS, device driver kender i detajler hvordan en enhed fungerer.</p> <p>Linux File System Stack:</p> <p></p> <ul> <li>Et file system, er ligeglad med hvilken disk den bruger.</li> <li>Raw interface er ogs\u00e5 stillet til r\u00e5dighed.<ul> <li>Lader specielle applikationer som file-system checker eller disk defragmentation tools l\u00e6se og skrive direkte.</li> </ul> </li> </ul> <p>Kan have ulemper: </p> <ul> <li>Hvis en device har specielle capabilities, men skal have en generic interface, g\u00e5r disse capabilities til spilde.</li> </ul> <p>Studier viser at over 70% af Linux OS code er device drives.</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#ide-disk","title":"IDE Disk","text":"<p>Interface:</p> <p></p> <p>4 registre:</p> <ul> <li>Control</li> <li>Command block</li> <li>Status</li> <li>Error</li> </ul> <p>Tilg\u00e5s ved at l\u00e6se de specifikke I/O adresser med <code>in</code> og <code>out</code> instruktionerne i x86.</p> <p>Basic protocol er som f\u00f8lger:</p> <ul> <li>Wait for drive to be ready: L\u00e6s Status Register until drevet er READY og ikke BUSY</li> <li>Skriv parametre til command registre: Skriv sector count, logical block address (LBA) p\u00e5 sektorerne der skal tilg\u00e5s, og drive number (master=0x00 eller slave=0x10) til command registre</li> <li>Start I/O: ved at issue read/write til command registre. </li> <li>Data transfer (ved writes): vent til drive status er READY og DRQ (drive request for data). Skriv data til data port.</li> <li>H\u00e5ndter interrupts</li> <li>Error handling: efter hver operation, l\u00e6s status register. Hvis ERROR bit er 1 l\u00e6s error register for detaljer.</li> </ul> <p>xv6</p> <p>IDE drive i xv6 findes i <code>ide.c</code></p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#hard-disk-drive","title":"Hard Disk Drive","text":"<p>Best\u00e5r af et stort antal sektorer (512-byte blocks)</p> <ul> <li>Som hver kan l\u00e6ses eller skrives</li> <li>Numereret fra 0 til n-1 p\u00e5 en disk med nn sektorer</li> <li>Kan ses som et array af sektorer</li> <li>0 til n-1n-1 er address space for drevet</li> </ul> <p>Multi-sektor operationer er mulige.</p> <ul> <li>Mange fil-systemer l\u00e6ser eller skriver 4KB af gangen.</li> <li>Eneste garanti er at 512-byte writes er atomic<ul> <li>Hvis der sker power loss, er det m\u00e5ske kun en del af en skrivning der f\u00e6rdigg\u00f8res (torn write)</li> </ul> </li> </ul> <p>Assumptions som klienter af disk dreve g\u00f8r sig (unwritten contract)</p> <ul> <li>Access af 2 blocks t\u00e6t p\u00e5 hinanden er hurtiger end 2 blocks langt fra hinanden</li> <li>Access af blocks i en sammenh\u00e6ngende chunk er hurtigst</li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#disk-geometri","title":"Disk Geometri","text":"<ul> <li>Vi har en platter en cirkul\u00e6r plade med en h\u00e5rd overflade<ul> <li>Hver platter har 2 sider (surface)</li> <li>En disk har en eller flere platters</li> <li>Ofte lavet af aluminium</li> <li>Coated med tyndt magnetisk lag</li> </ul> </li> <li>Platters er bundet sammen omkring spindle<ul> <li>Som er connected til en moter</li> <li>Spinner ofte mellem 7,200 og 15,000 RPM (rotations per minute)<ul> <li>10,000 RPM \\rightarrow\\rightarrow 1 rotation tager ca 6 ms</li> </ul> </li> </ul> </li> <li>Data er encoded p\u00e5 hver surface i  koncentriske cirkler af sektorer. (track)</li> <li>Disk head l\u00e6ser og skriver sektorer ved at l\u00e6se eller p\u00e5virke magnetic patterns <ul> <li>1 per surface</li> <li>Attached til en disk arm</li> </ul> </li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#simple-disk-drive","title":"Simple Disk Drive","text":"<p>Vi tager udgangspunkt i figur 37.2 ovenfor.</p> <p>Hvis vi laver request til block 0. S\u00e5 skal disken bare vente p\u00e5 at 0 roterer under disk head.</p> <ul> <li>Kaldes rotational delay aka rotation delay</li> </ul> <p>Moderne diske har flere millioner tracks. Eksempel med flere tracks:</p> <p></p> <p>Request til sektor 11. F\u00f8rst skal disk armen bev\u00e6ge sig til det korrekte track. Kaldet et seek.</p> <p>Seeks sammen med rotations er de dyreste disk operationer.</p> <p>Seek har flere faser:</p> <ul> <li>acceleration</li> <li>coasting</li> <li>deceleration</li> <li>settling: settling time er signifikant e.g., 0.5 til 2 ms<ul> <li>drev skal v\u00e6re sikker p\u00e5 at finde det rigtige track.</li> </ul> </li> </ul> <p>N\u00e5r sector 11 passerer under disk head kan sidste fase af I/O ske (transfer).</p> <p>Ofte bruges track skew</p> <p></p> <p>S\u00e5 n\u00e5r head repositioner armen, passer det bedre.</p> <p>Ydre tracks har ofte flere sektorer (pga geometri). Kaldes multi-zoned disk drives: Disk er organiseret i mange zoner.</p> <ul> <li>Hver zone har det samme antal sektorer per track. Ydre zoner har flere sektoerer end indre zoner.</li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#cache","title":"Cache","text":"<p>Ogs\u00e5 kaldet track buffer.</p> <p>Lille stykke memory, ofte omkring 8- eller 16 MB</p> <p>Disk skal v\u00e6lge ved writes, om den vil anerkende et write n\u00e5r den har puttet data i memory, eller f\u00f8rst n\u00e5r den har skrevet p\u00e5 disk?</p> <ul> <li>Write back:  n\u00e5r det er skrevet i memory (ogs\u00e5 kaldet immediate repporting)<ul> <li>Kan f\u00e5 drevet til at se hurtigere ud, men kan v\u00e6re farligt hvis filsystemet kr\u00e6ver at data skrives i en bestemt r\u00e6kkef\u00f8lge.</li> </ul> </li> <li>Write through: n\u00e5r der er skrevet til disk.</li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#io-time","title":"I/O Time","text":"<p>I/O Time: $$ T_{I/O}=T_{seek}+T_{rotation}+T_{transfer} $$ Rate of I/O: $$ R_{I/O}=\\frac{Size_{Transfer}}{T_{I/O}} $$</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#eksempler","title":"Eksempler","text":"<p>Random workload laver sm\u00e5 reads (eg 4KB) til random lokationer</p> <p>Sequential workload l\u00e6ser et stort antal sammenh\u00e6ngende sektorer</p> <p></p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#disk-scheduling","title":"Disk Scheduling","text":"<p>Da I/O er dyrt spiller OS en rolle i scheduling.</p> <ul> <li>Disk scheduler</li> </ul> <p>I/O \"job\"-tid er nogenlunde kendt i mods\u00e6tning til job-scheduling.</p> <p>Pr\u00f8ver at f\u00f8lge principle of SJF (shortest job first)</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#sstf-shortest-seek-time-first","title":"SSTF: Shortest Seek Time First","text":"<p>AKA shortest-seek-first (SSF).</p> <ul> <li>Rangerer k\u00f8en af I/O request baseret p\u00e5 track.</li> <li>V\u00e6lger den request p\u00e5 det n\u00e6rmeste track f\u00f8rst.</li> <li>Kender dog ikke geometrien af disk, ses som array af blocks.</li> </ul> <p>Kan derfor implementere nearest-block-first (NBF) i stedet for SSTF.</p> <p>Kan f\u00f8re til starvation, hvis der kommer str\u00f8m af requests til de indre track eksempelvis.</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#elevator-aka-scan-or-c-scan","title":"Elevator (AKA SCAN or C-SCAN)","text":"<p>Algoritmen bev\u00e6ger sig frem og tilbage over disken, og h\u00e5ndterer request i r\u00e6kkef\u00f8lge over tracks.</p> <ul> <li>Et enkelt pass over disken kaldes et sweep.</li> </ul> <p>Varianter:</p> <ul> <li>F-SCAN: fryser k\u00f8en n\u00e5r den sweeper.<ul> <li>Requests der kommer ind under sweep s\u00e6ttes i en sekund\u00e6r k\u00f8</li> <li>Undg\u00e5r at far-away requests bliver starved ved at delay sent-ankomne (men t\u00e6ttere p\u00e5) requests.</li> </ul> </li> <li>C-SCAN: Circular SCAN<ul> <li>I stedet for frem og til bage, k\u00f8re den i \"cirkel\".</li> <li>Mere fair over for de midterste tracks.</li> </ul> </li> </ul> <p>Hverken SCAN eller SSTF er den bedste scheduling technology, de adhere ikke til principle of SJF som de kunne.</p> <ul> <li>De ignorerer rotation.</li> </ul>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#sptf-shortest-positioning-time-first","title":"SPTF: Shortest Positioning Time First","text":"<p>Hvis det tager l\u00e6ngere tid at rotere, giver det mere mening at lave det lange seek, ex 8, s\u00e5 den ikke skal rotere s\u00e5 meget. </p> <p>P\u00e5 moderne drives er seek og rotation ca. ens. Derfor er SPTF brugbart og increaser performance.</p> <p>Sv\u00e6rt at implementere i OS, s\u00e5 ofte implementeret inde i drevet.</p>"},{"location":"4-semester/PSS/exam/7-io-and-device-drivers/#andre-scheduling-problemer","title":"Andre Scheduling Problemer","text":"<p>I/O Merging: Der kommer 3 request til 33, s\u00e5 8, s\u00e5 34. Scheduler burde her merge 33 og 34 indtil en two-block request.</p> <p>Hvor lang tid skal OS vente med at sende request?</p> <p>Naiv approach: work-conserving: send s\u00e5 snart der er en I/O.</p> <ul> <li>Harddisk arbejder hele tiden.</li> </ul> <p>Research om anticpatory disk scheduling viser at det kan betale sige at vente lidt. Kaldet non-work-conserving</p>"},{"location":"4-semester/PSS/exam/8-xv6/","title":"8 - XV6 Exercise of Choice","text":""},{"location":"4-semester/PSS/exam/8-xv6/#potential-xv6-exercises","title":"Potential XV6 Exercises:","text":""},{"location":"4-semester/PSS/exam/8-xv6/#processes-and-threads","title":"Processes and Threads","text":"<p>(5) Find the code implementing the shell</p> <ol> <li>Discuss how the shell works, e.g., make a flow diagram for a single shell command; how does one add \"commands\" to the shell?</li> <li>Find the code the implements directy change, i.e., the <code>cd</code> shell command; why does it have to be built directly into the shell?</li> <li>Discuss how scripting could be added to the shell</li> <li>Discuss if the shell is part of the operating system. Should it be?</li> </ol>"},{"location":"4-semester/PSS/exam/8-xv6/#scheduling","title":"Scheduling","text":"<p>(1) Find the code for the scheduler of XV6.</p> <ol> <li>Is the scheduler preemptive or cooperative? Is that a good or bad design decision?</li> <li>Explain how the scheduler works, in particular, how does XV6 choose the next process to run?</li> <li>Discuss the scheduling policy: what are the advantages and disadvantages, is it a good choice for a desktop OS? What does \"good choice\" mean?</li> <li>Discuss how to implement a different scheduler, e.g., a fixed priority scheduler that always picks the process with the highest priority.</li> </ol>"},{"location":"4-semester/PSS/exam/8-xv6/#memory-management","title":"Memory Management","text":"<p>(1) Find the code that defines the memory layout of XV6</p> <ol> <li>Explain the memory layout of XV6.</li> <li>Find and explain the code that sets up memory layout for processes in XV6, i.e., memory layout for users of XV6.</li> </ol> <p>(2) Find the code that handles the virtual memory of XV6</p> <ol> <li>Explain the format for virtual addresses used in XV6.</li> <li>Find and explain the code for converting between \"real\" and virtual addresses.</li> <li>Explain how segments are used in the kernel.</li> <li>Find and explain the implementation of XV6's page tables.</li> <li>How are page tables organised (how many levels)?</li> <li>How big (potentially) is a page table?</li> </ol>"},{"location":"4-semester/PSS/exam/8-xv6/#paged-memory","title":"Paged Memory","text":"<p>(1) Find the code that handles the virtual memory of XV6</p> <ol> <li>Explain the format for virtual addresses used in XV6.</li> <li>Find and explain the code for converting between \"real\" and virtual addresses.</li> <li>Explain how segments are used in the kernel.</li> <li>Find and explain the implementation of XV6's page tables.</li> <li>How are page tables organised (how many levels)?</li> <li>How big (potentially) is a page table?</li> </ol>"},{"location":"4-semester/SPO/","title":"SPO - LANGAUGES AND COMPILERS","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=28774</p>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/","title":"Compiler","text":"<p>Translates human-oriented programming languages into computer-oriented machine languages.</p> <p>A compiler allows virtually all computer users to ignore machine independent details of machine language.</p> <ul> <li>Making programs and programming expertise portable across wide variety of computers.</li> </ul> <p>Compiler Distinction</p> <p>Compilers may be distinguished by:</p> <ul> <li>By the kind of machine code they generate</li> <li>By the format of the target code they generate</li> </ul>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#machine-code-generated-by-compilers","title":"Machine Code Generated by Compilers","text":"<p>May generate any of three:</p> <ul> <li>Pure Machine Code</li> <li>Augmented Machine Code</li> <li>Virtual Machine Code</li> </ul>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#pure-machine-code","title":"Pure Machine Code","text":"<p>Code for a particular machines instruction set.</p> <p>Called pure code, because it only includes instructions part of that instruction set.</p> <p>Rare because most compilers rely on runtime libraries and OS's</p> <p>Most commonly used in compilers for system implementation languages, which are inteded for implementing OS's ore embedded applications.</p> <p>Can execute on bare hardware without dependence on any other software.</p>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#augmented-machine-code","title":"Augmented Machine Code","text":"<p>Augmented with OS routines and runtime language support routines.</p> <p>Requires that a particular OS be present.</p>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#virtual-machine-code","title":"Virtual Machine Code","text":"<p>Consists of entirely of virtual instructions.</p> <ul> <li>Increases portability</li> </ul> <p>An interpreter for the virtual machine (VM) is written for every target architecure.I</p> <p>Example: Java</p>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#bootstrapping-a-compiler","title":"Bootstrapping a Compiler","text":"<p>If a compiler accepts source language L. Any instance of this compiler can translate from L to VM instructions.</p> <p>If the compiler itself is written in L, the compiler can compile itself into the VM instructions.</p> <p></p>"},{"location":"4-semester/SPO/01-programming-languages-and-compilers/#language-criteria","title":"Language Criteria","text":"<p>Sebesta's Language Criteria</p> <p></p>"},{"location":"4-semester/SPO/02-tombstone-diagrams/","title":"Tombstone Diagrams","text":"<ul> <li>Diagrams consisting out of a set of \"puzzle pieces\", we use to reason about language processores and programs</li> <li>Differnt kinds of pieces</li> <li>Combination rules (not all diagrams are well formed)</li> </ul>"},{"location":"4-semester/SPO/02-tombstone-diagrams/#combination-rules","title":"Combination Rules","text":""},{"location":"4-semester/SPO/02-tombstone-diagrams/#example","title":"Example","text":""},{"location":"4-semester/SPO/02-tombstone-diagrams/#cross-compilation","title":"Cross Compilation","text":"<p>A cross compiler is a compiler that runs on one machine (host machine), but emits code for another machine (target machine).</p> <p></p> <p>This is what happens when compiling an app for android on a x86 machine for example.</p>"},{"location":"4-semester/SPO/02-tombstone-diagrams/#two-stage-compilation","title":"Two Stage Compilation","text":"<p>Two-stage translator: a composition of two translators. The output of the first translator is provided as input for the second translator.</p> <p></p> <p>Generate C code from Java, compile the C code with C-compiler.</p> <p></p>"},{"location":"4-semester/SPO/02-tombstone-diagrams/#interpreters","title":"Interpreters","text":"<p>Interpreter: A language processor implemented in software.</p> <p>Terminology: abstract (virtual) machine versus real machine.</p> <p>Example: The Java Virtual Machine</p> <p></p>"},{"location":"4-semester/SPO/02-tombstone-diagrams/#compiler-vs-interpreter","title":"Compiler vs Interpreter","text":"<p>Compilers offer advantages when:</p> <ul> <li>Programs are deployed in a production setting</li> <li>Programs are repetative</li> <li>The instructions of the programming language are complex</li> </ul> <p>Interpreters are better choice when:</p> <ul> <li>In development/testing/debugging stage</li> <li>Programs are run once and then discarded</li> <li>The instructions of the language are simple</li> <li>The execution speed is overshadowed by other factors.</li> </ul>"},{"location":"4-semester/SPO/02-tombstone-diagrams/#portable-compilers","title":"Portable Compilers","text":"<p>Example:</p> <p></p> <p>It is easier to port Kit 2.</p>"},{"location":"4-semester/SPO/03a-the-phases-of-a-compiler/","title":"The \"Phases\" of a Compiler","text":""},{"location":"4-semester/SPO/03a-the-phases-of-a-compiler/#syntax-analysis","title":"Syntax Analysis","text":"<p>Syntax</p> <ul> <li>Lexical analysis<ul> <li>Regular expressions</li> </ul> </li> <li>Parsing<ul> <li>Context Free Grammar</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/03a-the-phases-of-a-compiler/#contextual-analysis","title":"Contextual analysis","text":"<p>Contextual constraints</p> <ul> <li>Scope checking<ul> <li>Scope rules (static semantics)</li> </ul> </li> <li>Type checking<ul> <li>Type rules (static semantics)</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/03a-the-phases-of-a-compiler/#code-generations","title":"Code Generations","text":"<p>Semantics (dynamic semantics)</p>"},{"location":"4-semester/SPO/03a-the-phases-of-a-compiler/#organization-of-a-compiler","title":"Organization of a Compiler","text":"<p>Scanner</p> <ul> <li>Source program -&gt; tokens<ul> <li>Part of Syntax analysis</li> </ul> </li> </ul> <p>Parser</p> <ul> <li>tokens -&gt; abstract syntax tree (AST)<ul> <li>Part of Syntax analysis</li> </ul> </li> </ul> <p>Symbol table</p> <ul> <li>Created from AST<ul> <li>Part of Contextual analysis</li> </ul> </li> </ul> <p>Semantic analysis: AST decoration</p> <ul> <li>Part of code generation</li> </ul>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/","title":"The Language 'ac'","text":"<p>ac: adding calculator</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#informal-definition","title":"Informal Definition","text":"<p>Types:</p> <ul> <li><code>integer</code></li> <li><code>float</code>: 5 fractional digits after the decimal point.</li> <li>Automatic type conversion from <code>int</code> to <code>float</code></li> </ul> <p>Keywords</p> <ul> <li><code>f: float</code></li> <li><code>i: integer</code></li> <li><code>p: print</code></li> </ul> <p>Variables</p> <ul> <li>23 names from lowercase Roman alph. except the 3 reserved keywords.</li> </ul> <p>Flat scope</p> <ul> <li>Names are visible in the program when they are declared</li> </ul> <p>Target of translation: dc (desk calculator)</p> <ul> <li>Reverse Polish Notation (RPN)</li> </ul>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#example-program","title":"Example Program","text":"<p>Example ac program:</p> <p><pre><code>f b         // declare var b as float\ni a         // declare var a as int\na = 5       // assign a the value 5\nb = a + 3.2 // assign b teh result of calculation a + 3.2\np b         // print content of b\n$           // end of input\n</code></pre> Corresponding dc program:</p> <pre><code>5\nsa\nla\n3.2\n+\nsb\nlb\np\n</code></pre>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#formal-definition","title":"Formal Definition","text":"<ul> <li>Syntax specification: context-free grammar (CFG)</li> <li>Token specification: Regular Expressions</li> </ul> <p>No formal definition of Type Rules or Runtime semantics (in Fisher et. Al.)</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#context-free-grammar-cfg","title":"Context Free Grammar (CFG)","text":"<ul> <li> <p>A set of productions or rewriting rules</p> </li> <li> <p>Eg.: </p> </li> </ul> <pre><code>Stmt  -&gt;  id assign Val Expr\n|   print id\n\n// A statement (Stmt) can either be line 1 or line 2\n</code></pre> <ul> <li> <p>Two kinds of symbols:</p> </li> <li> <p>Terminals - Cannot be rewritten</p> <ul> <li>Eg. id, assign, print</li> <li>Start symbol: Prog</li> <li>Empty or null string: \\lambda (some references use \\varepsilon\\varepsilon for empty string)</li> <li>End of input stream or file: $</li> </ul> </li> <li>Nonterminals<ul> <li>Eg. Val, Expr</li> </ul> </li> </ul> <p>Note: nonterminals begin with uppercase in Fisher et. al.</p> <p></p> <p>LHS - left-hand side (<code>Prog</code>)</p> <p>RHS - right-hand side (<code>Dcls Stmts $</code>)</p> <ul> <li> <p>We begin with the start-symbol usually the LHS of the first rule.</p> </li> <li> <p>We proceed by replacing it with the RHS of some production for that symbol</p> </li> <li>We continue choosing some nonterminal symbol in out derived string of symbols, finding a production for that nonterminal, replacing it with the string of symbols on the production's RHS.</li> <li>We continue until no nonterminal remain.</li> </ul> <p>Any string of terminals produced in this manner is considered syntactically valid.</p> <p>\u200b   Any other string has a syntax error</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#syntax-specification-with-cfg-for-ac","title":"Syntax Specification with CFG for 'ac'","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#example-derivation-of-an-ac-program","title":"Example Derivation of an 'ac' program","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#parse-tree","title":"Parse Tree","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#token-specification","title":"Token Specification","text":"<p>Using Regular Expressions</p> <p></p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#phases-of-an-ac-compiler","title":"Phases of an ac compiler","text":"<ul> <li>Scanning</li> <li>The scanner reads a src ac program as a text file and produces a stream of tokens</li> <li>Parsing</li> <li>Determine if the stream of tokens conforms to the language's grammar spec. And creates an abstract syntax tree (AST).<ul> <li>For ac, recursive descent is used</li> </ul> </li> <li>Symbol Table</li> <li>The AST is traversed to create a symbol table, associating type and other contextual information with variables used in an 'ac' program.</li> <li>Semantic Analysis</li> <li>The AST is traversed to perform Semantic Analysis.</li> <li>In 'ac' its fairly minimal, in most languages, multiple passes over the AST may be required.</li> <li>Often decorates or transforms portions of the AST.<ul> <li>The actual meaning of those portions become clear</li> </ul> </li> <li>Translation</li> <li>The AST is traversed to generate a Translation of the original program.</li> </ul>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#scanning","title":"Scanning","text":"<p>Translating stream of chars into a stream of tokens.</p> <p>Each token found by the scanner has the following two components:</p> <ul> <li>A token's type explain s the token's membership in the terminal alphabet. All instances of a given terminal have the same token type.</li> <li>A token's semantic value provides additional information about the token.</li> </ul> <p>For terminals such as <code>plus</code> no semantic info is required (only one token (+) can correspond to it).</p> <p>Other, such as <code>id</code> and <code>num</code> require semantic info, so the compiler can record which identifier or number has been scanned.</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#scanner-pseudocode","title":"Scanner pseudocode","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#parsing","title":"Parsing","text":"<p>Responsible for determining if the stream of tokens provided by the scanner conforms to the language's grammar spec.</p> <p>The parsing technique used for the ac compiler is called Recursive descent.</p> <ul> <li>Mutually recursive parsing routines that in effect descent through a derivation tree.</li> </ul> <p>We look at recursive descent parsing procedures for <code>Stmt</code> and <code>Stmts</code></p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#pseudocode-for-stmt-and-stmts","title":"Pseudocode for Stmt and Stmts","text":"<p>First it examines the next input token to predict which production to apply.</p> <p>Ex. <code>Stmt</code> offers two productions:</p> <pre><code>Stmt    -&gt;  id assign Val Expr\nStmt    -&gt;  print id\n</code></pre> <p>This is done at marker 1 and 6 in figure 2.7.</p> <p>If 'id' is the next input token, then the parse must proceed with a rule that generates 'id' as its first terminal.</p> <ul> <li>We say that the predict set for <code>Stmt -&gt; id assign Val Expr</code> is {id}</li> </ul> <p>The predict set for <code>Stmt -&gt; print id</code> is {print}</p> <p></p> <p></p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#semantic-analysis","title":"Semantic Analysis","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#code-generation","title":"Code Generation","text":"<ul> <li>Assumes that program has been thoroughly checked and is well formed (scope and type rules)</li> <li>Takes semantics of both the source and target language into account</li> <li>Transforms source program into target code</li> </ul>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#tree-traversal","title":"Tree Traversal","text":"<ul> <li>\"Traditional\" OO approach</li> <li>Visitor Approach<ul> <li>GOF</li> <li>Using static overloading</li> <li>Reflective</li> </ul> </li> <li>\"Functional\" approach</li> <li>Active patterns in Scala (or F#)</li> </ul>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#traditional","title":"Traditional","text":"<p>Method for each phase in every node</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#visitor","title":"Visitor","text":""},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#gof","title":"GOF","text":"<pre><code>@Override\nvoid visitAssigning(Assigning n) {\n// TODO Auto-generated method stub\nn.child1.accept(this);\nemit(\" s\");\nemit(n.id);\nemit(\" 0 k \");\n}\n</code></pre>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#static-overloading","title":"Static Overloading","text":"<pre><code>@Override\nvoid visit(Assigning n) {\n// TODO Auto-generated method stub\nn.child1.accept(this);\nemit(\" s\");\nemit(n.id);\nemit(\" 0 k \");\n}\n</code></pre>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#reflective","title":"Reflective","text":"<p>Using double dispatch</p> <p>Visitor decides the best class / method to use</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#functional","title":"Functional","text":"<p>If-else chain or switch</p>"},{"location":"4-semester/SPO/03b-the-ac-language-and-compiler/#scala-active-patterns","title":"Scala Active Patterns","text":""},{"location":"4-semester/SPO/04-language-specification/","title":"Language Specification","text":"<p>A communication device between people who need to have a common understanding of the PL.</p> <p>What to specify?</p> <ul> <li>What is a well formed program</li> <li>Syntax</li> <li>Contextual constraints (static semantics)<ul> <li>sope rules</li> <li>type rules</li> </ul> </li> <li>What is the meaning of (well formed) programs.</li> <li>Semantics (runtime semantics)</li> </ul> <p>How to specify?</p> <ul> <li>Formal specification</li> <li>Some kind of precisely defined formalism</li> <li>Informal specification</li> <li> <p>Description in eg. English</p> </li> <li> <p>Usually a mix of both (eg. Java spec.)</p> </li> <li>Syntax -&gt; Formal spec. using RE and CFG</li> <li>Contextual constraints and semantics -&gt; informal</li> <li> <p>Formal semantics has been retrofitted.</p> </li> <li> <p>Trend towards more formality (C#, Fortress)</p> </li> </ul>"},{"location":"4-semester/SPO/04-language-specification/#terminology","title":"Terminology","text":"<p>A sentence is a string of characters over some alphabet</p> <p>A language is a set of sentences</p> <p>A lexeme is the lowest level syntactic unit of a language (eg. <code>*</code>, <code>sum</code>, <code>begin</code>)</p> <p>A token is a category of lexemes (eg. identifier)</p> <p>Generators</p> <ul> <li>A device that generates sentences of a language</li> <li>One can determine if syntax of particular sentence is syntactically correct, by comparing it to the structure of the generator.</li> </ul> <p>Recognizers</p> <ul> <li>A recognition device reads input strings over the alphabet of the language and decides whether the input strings belong to the language</li> <li>Ex: syntax analysis part of a compiler</li> </ul>"},{"location":"4-semester/SPO/04-language-specification/#syntax-analysis","title":"Syntax Analysis","text":"<p>Portion of a language processor nearly always consists of two parts.</p> <ul> <li>A low-level part called a lexical analyzer.</li> <li>Finite automaton based on regular grammar.</li> <li>A high-level part called syntax analyzer, or parser.</li> <li>Push-down automaton based on a CFG or BNF</li> </ul>"},{"location":"4-semester/SPO/04-language-specification/#context-free-grammars-and-bnf","title":"Context-Free Grammars and BNF","text":"<p>CFG Developed by Noam Chomsky in mid-1950's</p> <p>Language generators, meant to describe syntax of natural languages.</p> <ul> <li>A finite set of terminal symbols (tokens)</li> <li>A finite set of non-terminal symbols</li> <li>A start symbol</li> <li>A finite set of production rules</li> </ul> <p>CFG's are written in BNF notation.</p> <p>A production rule in BNF is written as:</p> <p>\u200b   N::=\\alpha </p> <p>where N is a non terminal and \\alpha\\alpha a sequence of terminals and non-terminals</p> <p>\u200b   N::=\\alpha|\\beta|..N::=\\alpha|\\beta|..</p> <p>is an abbreviation for several rules with N as LHS</p>"},{"location":"4-semester/SPO/04-language-specification/#example","title":"Example","text":""},{"location":"4-semester/SPO/04-language-specification/#bnf-fundamentals","title":"BNF Fundamentals","text":"<ul> <li>Abstractions are used to represent classes of syntactic structures</li> <li> <p>They act like syntactic variables (also called non-terminal symbols)</p> </li> <li> <p>Terminals are lexemes or tokens</p> </li> <li> <p>A rule has a LHS, which is nonterminal and a RHS which is a string of terminals and/or nonterminals</p> </li> <li> <p>Nonterminals are often enclosed in angle brackets</p> </li> <li> <p>Grammar: a finite non-empty set of rules</p> </li> <li> <p>A start symbol is a special element of nonterminals of a grammar.</p> </li> <li> <p>An abstraction (or nonterminal symbol) can have more than one RHS</p> </li> </ul> <p></p> <ul> <li>Alternative rules are written with <code>|</code></li> </ul> <p></p> <ul> <li>Syntactic list are described using recursion</li> </ul> <p></p> <ul> <li>A derivation is a repeated application of rules, starting with the start symbol and ending with a sentence (all terminal symbols)</li> </ul>"},{"location":"4-semester/SPO/04-language-specification/#example_1","title":"Example","text":""},{"location":"4-semester/SPO/04-language-specification/#example-derivation","title":"Example derivation","text":""},{"location":"4-semester/SPO/04-language-specification/#derivations","title":"Derivations","text":"<ul> <li>Every string of symbols in a derivation is a sentential form</li> <li>A sentence is a sentential form that has only terminal symbols</li> <li>A leftmost derivation is one in which the leftmost nonterminal in each sentential form is the one that is expanded</li> <li>A rightmost derivation is one in which the rightmost nonterminal in each sentential form is the one that is expanded</li> <li>A derivation may be neither leftmost nor rightmost</li> </ul>"},{"location":"4-semester/SPO/04-language-specification/#ambiguity-in-grammars","title":"Ambiguity in Grammars","text":"<p>A grammar is ambiguous if and only if it generates a sentential form that has two or more distinct parse trees.</p>"},{"location":"4-semester/SPO/04-language-specification/#example_2","title":"Example","text":""},{"location":"4-semester/SPO/04-language-specification/#fix-the-example","title":"Fix the example","text":"<p>If we use the parse tree to indicate precedence levels of the operators, we cannot have ambiguity.</p> <p></p> <p></p>"},{"location":"4-semester/SPO/04-language-specification/#associativity-of-operators","title":"Associativity of Operators","text":"<p>Operator associativity can also be indicated by a grammar.</p> <p></p> <p></p>"},{"location":"4-semester/SPO/04-language-specification/#extended-bnf","title":"Extended BNF","text":"<ul> <li>Optional parts are placed in brackets []</li> </ul> <pre><code>&lt;proc_call&gt; -&gt; ident [(&lt;expr_list&gt;)]\n</code></pre> <ul> <li>Alternative parts of RHS are placed inside parenthethes and seperated via vertical bars</li> </ul> <pre><code>&lt;term&gt; -&gt; &lt;term&gt; (+|-) const\n</code></pre> <ul> <li>Repetitions (0 or more) are placed inside braces {}</li> </ul> <pre><code>&lt;ident&gt; -&gt; letter {letter|digit}\n</code></pre>"},{"location":"4-semester/SPO/04-language-specification/#bnf-vs-ebnf","title":"BNF vs EBNF","text":"<p>BNF</p> <p></p> <p>EBNF</p> <p></p>"},{"location":"4-semester/SPO/04-language-specification/#important","title":"Important","text":"<ul> <li>Syntax is the visible part of a programming language</li> <li>Programming language designers can waste a lot of time discussing unimportant details of syntax</li> <li>The language paradigm is the next most visible part</li> <li>The choice of paradigm, and therefor language, depends on how humans best think about the problem</li> <li>There are no right models of computations - just different models of computation, some more suited for cerain classes of problems than others.</li> <li>The most invisible part is the language semantics</li> <li>Clear semantics usually leads to simple and efficient implementations.</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/","title":"Context Free Grammar (CFG)","text":"<ul> <li>A finite set of terminal symbols</li> <li>A finite set of non-terminal symbols</li> <li>A start symbol</li> <li>A finite set of production rules</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#how-to-design-a-grammar","title":"How to Design a Grammar","text":"<p>Lets write a CFG for C-style function prototypes.</p> <p>Examples</p> <ul> <li><code>void myf1(int x, double y);</code></li> <li><code>int myf2();</code></li> <li><code>int myf3(double z);</code></li> <li><code>double myf4(int, int w, int);</code></li> <li><code>void myf5(void);</code></li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#one-possible-grammar","title":"One Possible Grammar","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#examples","title":"Examples","text":"<pre><code>void ident(int ident, double ident);\nint ident();\nint ident(double ident);\ndouble ident(int, int ident, int);\nvoid ident(void);\n</code></pre>"},{"location":"4-semester/SPO/05a-context-free-grammars/#another-possible-grammar","title":"Another Possible Grammar","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#examples_1","title":"Examples","text":"<pre><code>void ident(int ident, double ident);\nint ident();\nint ident(double ident);\nint ident(int, int ident, int);\nvoid ident(void);\n</code></pre>"},{"location":"4-semester/SPO/05a-context-free-grammars/#definition","title":"Definition","text":"<p>Components:  G=(N,\\Sigma,P,S)</p> <ul> <li>A finite terminal alphabet \\Sigma\\Sigma</li> <li>The set of tokens produced by the scanner</li> <li>A finite nonterminal alphabet N</li> <li>variables of the grammar</li> <li>A start symbol S </li> <li>S \\in NS \\in N that initiates all derivations (also called goal symbol)</li> <li>A finite set of productions P:</li> <li>P:A \\rightarrow X_1...X_m, \\space \\text{where} \\space A \\in N, X_i \\in N \\cup \\Sigma, 1\\leq i \\leq m \\space \\text{and} \\space m \\geq 0P:A \\rightarrow X_1...X_m, \\space \\text{where} \\space A \\in N, X_i \\in N \\cup \\Sigma, 1\\leq i \\leq m \\space \\text{and} \\space m \\geq 0</li> <li>(also called rewriting rules)</li> </ul> <p>Vocabulary V=N\\cup \\SigmaV=N\\cup \\Sigma</p> <ul> <li>N \\cap \\Sigma = \\phiN \\cap \\Sigma = \\phi</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#notation","title":"Notation","text":"<p>The book Fisher et. al. uses the following notation:</p> Names Beginning With Represent Symbols In Examples Uppercase N A, B, C, Prefix Lowercase and punctuation \\Sigma\\Sigma a, b, c, if, then, (, ; \\mathcal{X,Y}\\mathcal{X,Y} N \\cup \\SigmaN \\cup \\Sigma \\mathcal{X}_i,\\mathcal{Y}_3\\mathcal{X}_i,\\mathcal{Y}_3 Other Greek letters (N\\cup\\Sigma)^*(N\\cup\\Sigma)^* \\alpha, \\gamma\\alpha, \\gamma <p>A production rule is written:</p> <p>\u200b   A \\rightarrow \\alphaA \\rightarrow \\alpha or A \\rightarrow \\mathcal{X_1...X_m}A \\rightarrow \\mathcal{X_1...X_m} depending on the RHS.</p> <p>A production rule with multiple RHS is written with <code>|</code></p>  \\begin{align*} A \\rightarrow \\alpha \\\\ |\\space\\space \\beta \\\\ ... \\space \\space \\\\ |\\space\\space \\beta \\end{align*}   \\begin{align*} A \\rightarrow \\alpha \\\\ |\\space\\space \\beta \\\\ ... \\space \\space \\\\ |\\space\\space \\beta \\end{align*}  <p>Derivation:</p> <p>\u200b   \\alpha A \\beta \\Rightarrow \\alpha \\gamma\\beta\\alpha A \\beta \\Rightarrow \\alpha \\gamma\\beta is one step of derivation if A\\rightarrow \\gammaA\\rightarrow \\gamma is a production rule.</p> <p>\u200b   \\Rightarrow^+\\Rightarrow^+ derives in one or more steps.</p> <p>\u200b   \\Rightarrow^*\\Rightarrow^* derives in zero or more steps.</p> <p>Sentential form:</p> <p>\u200b   S\\Rightarrow^*\\beta:\\betaS\\Rightarrow^*\\beta:\\beta is a sentential form of the CFG</p> <p>\u200b   SF(G):SF(G): the set of sentential forms of G</p> <p>thus:</p> <p>\u200b   L(G)=\\{w\\in\\Sigma^* \\mid S\\Rightarrow^+w\\}L(G)=\\{w\\in\\Sigma^* \\mid S\\Rightarrow^+w\\}</p> <p>\u200b       also</p> <p>\u200b   L(G)=SF(G)\\cap\\Sigma^*L(G)=SF(G)\\cap\\Sigma^*</p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#derivation","title":"Derivation","text":"<p>Two conventions for rewriting nonterminals in a systematic order:</p> <ul> <li>Leftmost derivation (expands from left to right)</li> <li>Rightmost derivation (expands from right to left)</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#leftmost-derivation","title":"Leftmost Derivation","text":"<p>A derivation that always chooses the leftmost possible nonterminal at each step.</p> <p>Denoted with \\Rightarrow_{lm}\\Rightarrow_{lm}</p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#example","title":"Example","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#derivation_1","title":"Derivation","text":"<p><code>f ( v + v )</code></p> <p></p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#rightmost-derivation","title":"Rightmost Derivation","text":"<p>The rightmost possible terminal is always expanded</p> <p>Denoted with \\Rightarrow_{rm}\\Rightarrow_{rm}</p> <p></p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#parse-trees","title":"Parse Trees","text":"<p>A graphical representation of a derivation</p> <ul> <li>Root: start symbol S</li> <li>Each node: either grammar symbol or \\lambda\\lambda or \\varepsilon\\varepsilon </li> <li>Interior nodes: nonterminals</li> <li>An interior node and its children: production</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#example_1","title":"Example","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#bnf-form","title":"BNF Form","text":"<p>Backus-Naur Form (BNF)</p> <ul> <li>Formal grammar for expressing CFG</li> </ul>"},{"location":"4-semester/SPO/05a-context-free-grammars/#extended-bnf-ebnf","title":"Extended BNF (EBNF)","text":"<p>An extended form of BNF.</p> <p>Three additional postfix operators +, ?, and * are introduced.</p> <ul> <li>R+ indicates the occurrence of one or more Rs to express repetition</li> <li>R~opt~ is sometimes used.</li> <li>R? indicates the occurrence of zero or one Rs to express optionality</li> <li>[R] is sometimes used.</li> <li>R* indicates the ocurrence of zero or more Rs to express repetition</li> <li>{R} is sometimes used.</li> </ul> <p>EBNF can be rewritten to BNF</p> <p>Example:</p> <pre><code>expression -&gt; term (+ term)*\n</code></pre> <p>Rewritten to:</p> <pre><code>    expression  -&gt;  term term_tmp\n    term_tmp    -&gt;  + term term_tmp\n                |   \u03bb\n</code></pre>"},{"location":"4-semester/SPO/05a-context-free-grammars/#algorithm-to-rewrite","title":"Algorithm to rewrite","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#properties-of-grammars","title":"Properties of grammars","text":"<p>A non-terminal N is left-recursive if starting with at sentential form N, we can produce another sentential form starting with N</p> <pre><code>    expression  -&gt;  expression \u2018+\u2019 factor | factor\n</code></pre> <p>Right-recursion also exists, is less important</p> <pre><code>    expression  -&gt;  term '+' expression\n</code></pre> <p>A non-terminal N is nullable, if starting with a sentential form N, we can produce an empty sentential form.</p> <pre><code>    expression  -&gt;  \u03bb\n</code></pre> <p>A non-terminal is useless, if it can never produce a string of terminal symbols.</p> <pre><code>    expression  -&gt;  + expression\n                |   - expression\n</code></pre>"},{"location":"4-semester/SPO/05a-context-free-grammars/#grammar-transformations","title":"Grammar Transformations","text":"<p>We can rewrite the rules without changing the output of the rules.</p> <p>This can create less readable code grammars.</p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#left-factorization","title":"Left factorization","text":"<p>Example:</p> <p></p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#elimintaion-of-left-recursion","title":"Elimintaion of Left Recursion","text":"<p>Example:</p> <p></p>"},{"location":"4-semester/SPO/05a-context-free-grammars/#substitution","title":"Substitution","text":""},{"location":"4-semester/SPO/05a-context-free-grammars/#dangling-else-problem","title":"Dangling Else Problem","text":"<p>We have this rule:</p> <pre><code>single-Command\n    ::=     if Expression   then single-Command\n    |       if Expression   then single-Command\n                            else single-Command\n</code></pre> <p>This parse tree? </p> <p></p> <p>Or this parse tree?</p> <p></p> <p>Rewrite the grammar:</p> <pre><code>sC  ::=     if E then sC endif\n    |       if E then sC else sC endif\n</code></pre> <p>or</p> <pre><code>sC  ::=     CsC \n    |       OsC\nCsC ::=     if E then CsC else CsC \nCsC ::= \u2026 \nOsC ::=     if E then sC \n    |       if E then CsC else OsC\n</code></pre>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/","title":"From Tokens to Parse Trees","text":"<p>The process of finding the structure in the flat stream of tokens is called parsing, and the module that performs this task is called parser.</p> <p>Two well-known ways to parse.</p> <ol> <li>top-down</li> <li>Left-scan, Leftmost derivation (LL)<ul> <li>Constructs the parse tree in pre-order</li> </ul> </li> <li>bottom-up</li> <li>Left-scan, Rightmost derivation in reverse (LR)<ul> <li>Constructs the parse tree in post-order</li> </ul> </li> </ol>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#example-parsing-of-micro-english","title":"Example Parsing of Micro-English:","text":""},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#top-down-parsers","title":"Top-down Parsers","text":"<p>Tree is grown from the root (top)</p> <p></p> <p>Corresponds to a left derivation</p> <p></p>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#bottom-up-parser","title":"Bottom-up parser","text":"<p>Tree grows from the leaves (bottom) up to the root (top).</p> <p>Just read right derivations backwards. (Rightmost derivation in reverse)</p> <p></p>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#top-down-vs-bottom-up-parsing","title":"Top-Down vs. Bottom-Up parsing","text":""},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#hierachy","title":"Hierachy","text":""},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#formal-definition-of-ll1","title":"Formal Definition of LL(1)","text":"<p>Properties of the grammar that determines if it is LL(1) or not:</p> <p>A grammar G is LL(1) if for each set of productions M::=X_1|X_2|...|X_n:</p> <ol> <li>\\text{first}[X_1], \\text{first}[X_2],...,\\text{first}[X_n]\\text{first}[X_1], \\text{first}[X_2],...,\\text{first}[X_n] are all pairwise disjoint</li> <li>If X_i\\Rightarrow^*\\lambdaX_i\\Rightarrow^*\\lambda then \\text{first}[X_j]\\cap \\text{follow}[X]=\u00d8\\text{first}[X_j]\\cap \\text{follow}[X]=\u00d8, for 1\\leq j\\leq n. i\\neq j1\\leq j\\leq n. i\\neq j</li> </ol> <p>If G is \\lambda\\lambda-free then (1) is sufficient</p> <ul> <li>An LL(1) grammar is a grammar which can be parsed with a top-down parser with a lookahead of one token.</li> </ul>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#first-sets","title":"First Sets","text":"<p>The set of all terminal symbols that can begin a sentential form derivable from the string \\alpha\\alpha</p> <p>\u200b   First(\\alpha)=\\{a\\in\\Sigma \\mid \\alpha \\Rightarrow^*a\\beta\\}First(\\alpha)=\\{a\\in\\Sigma \\mid \\alpha \\Rightarrow^*a\\beta\\}</p> <p>We never include \\lambda\\lambda in First(\\alpha\\alpha) even if \\alpha \\Rightarrow \\lambda\\alpha \\Rightarrow \\lambda</p>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#example","title":"Example","text":"<pre><code>First(Tail)     = { + }\nFirst(Prefix)   = { f }\nFirst(E)        = { v, f, ( }\n</code></pre>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#algorithm-for-computing-first-set","title":"Algorithm for Computing First-Set","text":""},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#follow-sets","title":"Follow Sets","text":"<p>The set of terminals that can follow a nonterminal A in some sentential form.</p> <p>\u200b   For A\\in NA\\in N</p> <p>\u200b       Follow(A)=\\{b\\in \\Sigma \\mid S\\Rightarrow^+ \\alpha A b \\beta\\}Follow(A)=\\{b\\in \\Sigma \\mid S\\Rightarrow^+ \\alpha A b \\beta\\}</p> <p>The right context associated with A</p>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#example_1","title":"Example","text":"<p>Using the same example as in First Sets</p> <pre><code>Follow(Tail)    = { ) }\nFollow(Prefix)  = { ( }\nFollow(E)       = { $, ) }\n</code></pre>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#algorithm-for-computing-followa","title":"Algorithm for Computing Follow(A)","text":""},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#provable-facts-about-ll1-grammars","title":"Provable Facts About LL(1) Grammars","text":"<ul> <li>No left-recursive grammar is LL(1)</li> <li>No ambiguous grammar is LL(1)</li> <li>Some languages have no LL(1) grammar</li> <li>A \\lambda\\lambda-free grammar, where each alternative X_jX_j for N::=X_jN::=X_j begins with a distinct terminal, is a simple LL(1) grammar</li> </ul>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#lr-grammars","title":"LR Grammars","text":"<p>A Grammar is an LR Grammar if it can be parsed by a LR parsing algorithm.</p> <p>Harder to implement LR than LL parsers.</p> <ul> <li>Tools exists though (JavaCUP, Yacc, C#CUP, SableCC)</li> </ul> <p>Can recognize LR(0), LR(1), SLR, LALR grammars.</p> <ul> <li> <p>Bigger class of grammars than LL</p> </li> <li> <p>Can handle left recursion!</p> </li> <li> <p>Usually more convenient because less need to rewrite grammar</p> </li> </ul> <p>Most commonly used for automatic tools today (LALR in particular)</p>"},{"location":"4-semester/SPO/05b-from-tokens-to-parse-trees/#tools-for-designing-cfgs","title":"Tools for designing CFG's","text":"<ul> <li>kfG Edit</li> <li>Contex Free Grammar tool (Grammophone)</li> <li>ACLA</li> </ul> <p>Udvid</p> <p>Kig p\u00e5 predictset! Side 176 i Fisher et. al. PDF</p>"},{"location":"4-semester/SPO/06-lexical-analysis/","title":"Lexical Analysis","text":"<p>We are looking at the scanner</p> <p></p> <p>Lexemes are \"words\" in the input, for example keywords, operators, identifiers, literals, etc.</p> <p>Tokens: a data structure for lexemes and additional information. </p> <p>Example ac source program:</p> <pre><code>f b\ni a\na = 5\nb = a + 3.2\np b\n</code></pre> <p></p> <p>Turned into tokens by the scanner.</p> <p>We may choose to contain different amount and types of operation of different types of lexemes.</p> <p></p> <p>This can be done to reduce the amount of memory used.</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#lexical-elements","title":"Lexical Elements","text":"<p>You need to decide what to use</p> <p>Warning</p> <p>slide 8</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#lexemes","title":"Lexemes","text":"<p>The Lexem structure can be more detailed and subtle than one might expext.</p> <p>Rule of thumb</p> <p>If the lexem structure is complex then examine the language for design flaws!!</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#simple-grammar-for-identifiers","title":"Simple Grammar for Identifiers","text":"<p>Can be transformed to a regular expression:</p> <pre><code>[a-z]([a-z]|[0-9])*\n</code></pre>"},{"location":"4-semester/SPO/06-lexical-analysis/#regular-expressions","title":"Regular Expressions","text":"Regular Expression Meaning \\varepsilon The empty string t Generates only the string t X Y Generates any string xy such that x is generated by X and y is generated by Y X | Y Generates any string which generated either by X or by Y X* The concatenation of zero or more strings generated by X (X) Parentheses are used for grouping P+ positive-closure, strings consisting of one or more strings in P catenated together <p>A meta-character is any punctuation char or regular expression operator. A meta-character must be quoted when used as an ordinary char to avoid ambiguity. </p>"},{"location":"4-semester/SPO/06-lexical-analysis/#regular-grammars","title":"Regular Grammars","text":"<p>Warning</p> <p>slide 15</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#the-ac-language","title":"The ac Language","text":"<p>Remember the ac language</p> <p>Warning</p> <p>slide 17-19</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#implement-scanner-based-on-re-by-hand","title":"Implement Scanner Based on RE by Hand","text":"<p>Warning</p> <p>slide 25</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#developing-a-scanner","title":"Developing a Scanner","text":"<p>Lexical grammar of Mini-Triangle</p> <p>Warning</p> <p>slide 26-</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#developing-a-scanner-by-hand","title":"Developing a Scanner by Hand","text":"<ul> <li>Hard and error prone.</li> <li>Can be automated</li> <li>Programming scanner generator is an example of declarative programming</li> <li>What to scan, not how to scan</li> <li>Most compilers are developed using a generated scanner</li> </ul> <p>Slide 35 - Finite Automata and implementation of Scanners</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#generating-scanners","title":"Generating Scanners","text":"<p>Based on:</p> <ul> <li>Regular Expressions</li> <li>To describe the tokens to be recognized</li> <li>Finite State Machines</li> <li>An execution model to which RE's are \"compiled\"</li> </ul> <p>Regular Expressions can be recognized by a finite state machine (FA)</p> <p>Finite State Automaton</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#converting-a-re-into-an-ndfa-epsilon","title":"Converting a RE Into an NDFA-epsilon","text":""},{"location":"4-semester/SPO/06-lexical-analysis/#implementing-a-dfa","title":"Implementing a DFA","text":"<p>Slide 46-47</p> <p>Algorithm on slide 48</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#implementing-a-scanner-as-a-dfa","title":"Implementing a Scanner as a DFA","text":"<p>Slide 49</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#jlex-lexical-analyzer-generator-for-java","title":"JLex Lexical Analyzer Generator for Java","text":"<p>Slide 51-52</p>"},{"location":"4-semester/SPO/06-lexical-analysis/#jlex-regular-expressions","title":"JLex Regular Expressions","text":"<p>Slide 53-55-</p> <p>...</p>"},{"location":"4-semester/SPO/exam/","title":"SPO - Exam","text":""},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/","title":"Language Design and Control Structures","text":"<ul> <li>Language Design Criteria</li> <li>Evaluation of expressions</li> <li>Explicit sequence control vs. structured sequence control</li> <li>Loop constructs</li> <li>Subprograms</li> <li>Parameter mechanisms</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#design-criteria","title":"Design Criteria","text":""},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#orthogonality","title":"Orthogonality","text":"<p>\u201cThe number of independent primitive concepts has been minimized in order that the language be easy to describe, to learn, and to implement. On the other hand, these concepts have been applied \u201corthogonally\u201d in order to maximize the expressive power of the language while trying to avoid deleterious superfluities\u201d </p> <p>-Adriaan van Wijngaarden et al., Revised Report on the Algorithmic Language ALGOL 68, section 0.1.2, Orthogonal design</p> <p>\u201cA precise definition is difficult to produce, but languages that are called orthogonal tend to have a small number of core concepts and a set of ways of uniformly combining these concepts. The semantics of the combinations are uniform; no special restrictions exist for specific instances of combinations.\u201d</p> <p>-David Schmidt</p>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#lack-of-orthogonality","title":"Lack of Orthogonality","text":"<p>Examples of exceptions from C:</p> <ul> <li>Structures (but not arrays) may be returned from a function.</li> <li>An array can be returned if it is inside a structure.</li> <li>A member of a structure can be any data type<ul> <li>(except void, or the structure of the same type).</li> </ul> </li> <li>An array element can be any data type (except void)</li> <li>Everything is passed by value (except arrays)</li> <li>Void can be used as a type in a structure, but a variable of this type cannot be declared in a function</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#sequence-control","title":"Sequence Control","text":"<p>Implicit and explicit sequence control</p> <ul> <li>Expressions<ul> <li>Precedence rules</li> <li>Associativity</li> </ul> </li> <li>Statements<ul> <li>Sequence</li> <li>Conditionals</li> <li>Loop Constructs</li> <li>Unstructured vs structured sequence control</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#expressions","title":"Expressions","text":"<ul> <li>Operator evaluation order</li> <li>Operand evaluation order</li> </ul> <p>Operators</p> <ul> <li>Most operators are infix or prefix</li> <li>Order of evaluation determined by operator precedence and associativity</li> </ul> <p>The following grammar is ambiguous</p> <p></p> <p>The grammar can express operator precedence:</p> <p></p> <p>In LL(1)</p> <p></p> <p>Gives us:</p> <p></p> <p>Association can be expressed with grammar also:</p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#statements","title":"Statements","text":"<ul> <li>Sequential</li> <li>Conditional</li> <li>Looping Construct</li> </ul> <p>Must have all three to provide full power of a Computing Machine!</p>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#sequential","title":"Sequential","text":"<ul> <li>Skip</li> <li>Assignments<ul> <li>Most languages treats assignments as a basic operation</li> <li>Some languages have derived assignment operators such as:<ul> <li><code>+=</code> and <code>*=</code> in C</li> </ul> </li> </ul> </li> <li>I/O<ul> <li>Some languages treat I/O as basic operations</li> <li>Others treat I/O as functions/methods</li> </ul> </li> <li>Sequencing<ul> <li><code>C;C</code></li> </ul> </li> <li>Blocks<ul> <li><code>begin...end</code>, <code>{...}</code>, <code>let...in...end</code></li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#conditional","title":"Conditional","text":"<ul> <li>Single-way<ul> <li><code>IF...THEN...</code></li> <li>Controlled by boolean expression</li> </ul> </li> <li>Two-way<ul> <li><code>IF...THEN...ELSE...</code></li> <li>Controlled by boolean expression</li> <li><code>IF...THEN</code> is usually treated as degenerate of <code>IF...THEN...ELSE...</code></li> </ul> </li> <li>Multi-way<ul> <li><code>SWITCH</code></li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#loops","title":"Loops","text":"<ul> <li>Counter-controlled iterators<ul> <li><code>For-loops</code></li> </ul> </li> <li>Logical-iterators</li> <li>Iterations based on data structures</li> <li>Recursion</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#for-loops","title":"For-loops","text":"<p>Controlled by loop variable of scalar type with bounds and increment size.</p>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#logic-test","title":"Logic-Test","text":"<ul> <li>While-loops<ul> <li>Test performed before entry</li> </ul> </li> <li><code>repeat...until</code> and <code>do...while</code><ul> <li>Test performed at end</li> <li>Always executed at least once</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#subprograms","title":"Subprograms","text":"<ol> <li>A subprogram has a single entry point</li> <li>The caller is suspended during execution of the called subprogram</li> <li>Control always returns to the caller when the called subprogram's execution terminates</li> </ol> <p>Functions vs Procedures</p> <ul> <li>Procedures provide user-defined statements<ul> <li>Abstractions over statements</li> </ul> </li> <li>Functions provide user-defined operators<ul> <li>Abstraction over expressions</li> </ul> </li> <li>Methods used for both functions and procedures</li> </ul> <p>Specification:</p> <ul> <li>Name</li> <li>Signature<ul> <li>Number and types of input arguments, number and types of output results</li> </ul> </li> <li>Actions<ul> <li>Direct function relating input values to output values</li> <li>Side effects on global state and subprogram internal state</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#local-referencing-envirionments","title":"Local Referencing Envirionments","text":"<p>Local variables can be stack-dynamic</p> <ul> <li>Support for recursion</li> <li>Storage for locals is shared among some subprograms</li> </ul> <p>But</p> <ul> <li>Allocation/de-allocation, initialization time</li> <li>Indirect addressing</li> <li>Subprograms cannot be history sensitive</li> </ul> <p>Local variables can be static</p> <ul> <li>Advantages and disadvantages are the opposite of those for stack-dynamic local variables</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#actualformal-parameter-correspondence","title":"Actual/Formal Parameter Correspondence","text":"<ul> <li> <p>Positional</p> <ul> <li>Binding is by position</li> <li>First actual is bound to first formal, and so forth</li> <li>Safe and effective</li> </ul> </li> <li> <p>Keyword</p> <ul> <li>Name of the formal to which the actual is to be bound, is specified with actual.</li> <li>Parameters can appear in any order, avoiding parameter correspondence errors</li> <li>BUT: User must know the formal parameters's names</li> </ul> </li> </ul> <p>In some languages, formal parameters can have default values.</p> <p>Some languages allow variable number of parameters</p> <p>Attributes of variables are used to exchange information</p> <ul> <li>Name - Call-by-name</li> <li>Memory location - Call-by-reference</li> <li>Value<ul> <li>Call-by-value (one way, from actual to formal parameter)</li> <li>Call-by-value-result (two ways between actual and formal parameter)</li> <li>Call-by-result (one way, from formal to actual parameter)<ul> <li><code>out</code> in C#</li> </ul> </li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#design-considerations","title":"Design Considerations","text":"<ol> <li>Efficiency</li> <li>One-way or two-way</li> </ol> <p>These are in conflict</p> <ul> <li>Good programming \\rightarrow Limited access to variables, meaning one-way whenever possible</li> <li>Efficiency \\rightarrow\\rightarrow Pass by reference is fastest way to pass structures of significant size</li> <li>Functions should not allow reference parameters </li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#subprograms-as-parameter","title":"Subprograms as Parameter","text":"<p>First class functions</p> <p>Lamdas</p> <ul> <li>C and C++: functions cannot be passed as parameters but pointers to functions can be passed and their types include the types of the parameters, so parameters can be type checked</li> <li>Ada does not allow subprogram parameters; an alternative is provided via Ada\u2019s generic facility</li> <li>Java until Java 8 did not allow method names to be passed as parameters</li> <li>C# supports functions a parameters through delegates <ul> <li>Delegates can now be anonymous or lambda expression</li> <li>We talk about first class functions</li> </ul> </li> <li>Functional languages supports functions as first class functions</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#tennents-language-design-principles","title":"Tennent's Language Design Principles","text":"<p>The Principle of Abstraction</p> <ul> <li>All major syntactic categories should have abstractions defined over them.     For example, functions are abstractions over expressions.</li> </ul> <p>The Principle of Correspondence</p> <ul> <li>Declarations \\approx\\approx Parameters</li> </ul> <p>The Principle of Data Type Completeness</p> <ul> <li>All data types should be first class without arbitrary restriction on their use</li> </ul> <p>- Originally defined by R.D.Tennent</p>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#abstraction","title":"Abstraction","text":"<p>Nearly all programming languages support process (or command) abstractions with subprograms (procedures)</p> <p>Many programming languages support expression abstraction with functions.</p> <p>Nearly all programming languages designed since 1980 have supported data abstraction</p> <ul> <li>Abstract data types</li> <li>Objects</li> <li>Modules</li> </ul>"},{"location":"4-semester/SPO/exam/1-language-design-and-control-structures/#correspondence","title":"Correspondence","text":""},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/","title":"Structure of the Compiler","text":"<ul> <li>Describe the phases of the compiler and give an overall description of what the purpose of each phase is and how the phases interface</li> <li>Single pass vs. multi pass compiler<ul> <li>Issues in language design</li> <li>Issues in code generation</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#phases-of-a-compiler","title":"Phases of a Compiler","text":"<p>The different phases can be seen as different transformation steps to transform source code into object code.</p> <p>The different phases correspond roughly to the different parts of the language specification:</p> <ul> <li> <p>Syntax analysis \\Leftrightarrow Syntax</p> <ul> <li> <p>Lexical Analysis \\Leftrightarrow\\Leftrightarrow Regular Expressions</p> </li> <li> <p>Parsing \\Leftrightarrow\\Leftrightarrow Context Free Grammar</p> </li> </ul> </li> <li> <p>Contextual Analysis \\Leftrightarrow\\Leftrightarrow Contextual Constraints</p> <ul> <li> <p>Scope Checking \\Leftrightarrow\\Leftrightarrow  Scope rules (static semantics)</p> </li> <li> <p>Type Checking \\Leftrightarrow\\Leftrightarrow Type rules (static semantics)</p> </li> </ul> </li> <li> <p>Code Generation \\Leftrightarrow\\Leftrightarrow Semantics (dynamic semantics)</p> </li> </ul>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#organization-of-the-compiler","title":"Organization of the Compiler","text":"<p>N\u00e6sten alle moderne compilere er syntax-directed.</p> <ul> <li>Compileringsprocessen er drevet af den syntaktiske struktur.</li> </ul> <p>De fleste compilere laver et AST (abstract syntax tree).</p>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#scanner","title":"Scanner","text":"<p>Scanneren l\u00e6ser input texten, karakter efter karakter.</p> <ul> <li>Grupperer karakterer i tokens<ul> <li>Som eks. identifiers, integers, reserved words, delimiters.</li> </ul> </li> <li>Eliminerer un\u00f8dvendig information som comments.</li> </ul> <p>Laver en stream a tokens.</p> <p>Drevet af regular expressions</p>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#parser","title":"Parser","text":"<p>Parseren er baseret p\u00e5 en formel syntax specifikation, s\u00e5 som CFG'er.</p> <ul> <li>L\u00e6ser tokens og grupperer dem i phrases if\u00f8lge syntax specifikationen.</li> <li>Typisk drevet af tabeller lavet fra en CFG af en parser generator</li> </ul> <p>Parseren verificerer korrekt syntax.</p> <ul> <li>Hvis en fejl findes laver den en fejlmeddelelse</li> </ul> <p>Parsers genererer ofte et AST.</p>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#type-checker","title":"Type Checker","text":"<p>Tjekker static semantics for hver AST node.</p> <ul> <li>The construct is legal and meaningful</li> <li>Variabler er deklareret, typer er korrekte osv.</li> </ul> <p>Type checker decorates AST noden ved at tilf\u00f8je type information.</p> <p>Hvis en semantisk fejl findes, laves en fejlmeddelelse.</p>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#translator","title":"Translator","text":"<p>Hvis en AST node er semantisk korrekt, kan den translates til IR kode.</p> <p>I simple ikke-optimerende compilere, kan translatoren generere target code uden at bruge explicit IR.</p> <ul> <li>G\u00f8r retargeting mere besv\u00e6rligt.</li> </ul>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#symbol-tables","title":"Symbol Tables","text":"<p>En symbol table er en mekanisme der bruges til at associere information med identifiers delt mellem compiler-phases.</p> <ul> <li>Bruges gennem type checking, men kan ogs\u00e5 bruges i andre faser.</li> </ul>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#optimizer","title":"Optimizer","text":"<p>IR kode analyseres og laves til funktionel identisk men optimeret kode af optimizeren.</p> <ul> <li>Kan v\u00e6re kompleks og indeholde flere underfaser.</li> </ul> <p>De fleste compilere lader dig slukke for optimizer.</p> <p>Kan ogs\u00e5 g\u00f8res efter code generation.</p> <ul> <li>Eksempel: peep-hole optimization.<ul> <li>Unders\u00f8ger kode f\u00e5 instruktioner af gangen.</li> <li>Kan optimere ting som:<ul> <li>Eleminering af gange med 1 eller addition med 0.</li> <li>Lad af v\u00e6rdi til register n\u00e5r v\u00e6rdi er i andet register.</li> <li>Sekvens af instruktioner til single instruktion med samme effekt.</li> </ul> </li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#code-generator","title":"Code Generator","text":"<p>Mapper IR code til target code.</p> <ul> <li>Kr\u00e6ver maskin specifik information</li> <li>Laver maskinspecifik optimering</li> </ul> <p>Er normalt hand-coded da de er meget specifikke og komplekse.</p>"},{"location":"4-semester/SPO/exam/2-structure-of-the-compiler/#example","title":"Example","text":"<p>Example</p> <p>As an example see the notes on the ac language and compiler</p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/","title":"Lexical Analysis","text":"<ul> <li>Describe the role of the lexical analysis phase</li> <li>Describe how a scanner can be implemented by hand or auto-generated</li> <li>Describe regular expressions and finite automata</li> </ul>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#the-scanner","title":"The Scanner","text":"<p>The scanner is sometimes called lexical analyzer or lexer.</p> <p></p> <p>Lexemes are \"words\" in the input, for example keywords, operators, identifiers, literals, etc.</p> <p>Tokens: a data structure for lexemes and additional information. </p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#lexical-elements","title":"Lexical Elements","text":"<ul> <li>Character set<ul> <li>ASCII vs Unicode</li> </ul> </li> <li>Identifiers</li> <li>Operators<ul> <li>+, -, /, *, ...</li> </ul> </li> <li>Keywords<ul> <li><code>if, then, while</code></li> </ul> </li> <li>Noise words</li> <li> <p>Elementary data</p> <ul> <li>Numbers (integers, floats)</li> <li>Strings</li> <li>Symbols</li> </ul> </li> <li> <p>Delimiters</p> <ul> <li><code>begin...end</code> vs <code>{...}</code></li> </ul> </li> <li> <p>Comments</p> <ul> <li><code>/*...*/</code> vs <code>#</code> vs <code>!</code> vs <code>//</code></li> </ul> </li> <li>Whitespace</li> <li>Layout</li> </ul>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#lexemes","title":"Lexemes","text":"<p>Can be detailed and subtle</p> <ul> <li>String constants:<ul> <li>Escape sequence: <code>\\\", \\n, ...</code></li> <li>Null strings</li> </ul> </li> <li>Rational constants:<ul> <li>0.1, 10.01</li> <li>$.1,\\ 10.,\\ $ vs 1..101..10</li> </ul> </li> </ul> <p>Rule of Thumb</p> <p>If the lexem structure is complex then examine the language for design flaws!!</p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#regular-expressions","title":"Regular Expressions","text":"<p>Tokens can be \"scanned\" with regular expressions.</p> Regular Expression Meaning \\varepsilon\\varepsilon The empty string t Generates only the string t X Y Generates any string xy such that x is generated by X and y is generated by Y X | Y Generates any string which generated either by X or by Y X* The concatenation of zero or more strings generated by X (X) Parentheses are used for grouping P+ positive-closure, strings consisting of one or more strings in P catenated together <p>A meta-character is any punctuation char or regular expression operator. A meta-character must be quoted when used as an ordinary char to avoid ambiguity. </p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#identifier-grammar-to-re","title":"Identifier Grammar to RE","text":"<p>Elimination of Left Recursion</p> <pre><code>N   ::= X | N Y     =&gt;      N   ::= X Y*\n</code></pre> <p>Left factorization:</p> <pre><code>X Y | X Z           =&gt;      X ( Y | Z )\n</code></pre>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#regular-grammars","title":"Regular Grammars","text":"<p>A grammar is regular if by substituting every nonterminal (except the root one) with its righthand side, you can reduce it down to a single production for the root, with only terminals and operators on the righthand side.</p> <p>This grammar is regular:</p> <pre><code>Identifier  ::= Letter\n            |   Identifier Letter\n            |   Identifier Digit\n</code></pre> <p>Because it can be reduced to:</p> <pre><code>Identifier  ::= Letter (Letter | Digit)*\n</code></pre> <p>Or rather</p> <pre><code>(a|b|c|...|z)((a|b|c|...|z) | (0|1|2|...|9))*\n</code></pre> <p>Called a regular expression often reduced to:</p> <pre><code>[a-z]([a-z]|[0-9])*\n</code></pre>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#implementing","title":"Implementing","text":"<p>A DFA can be implemented with a transition table:</p> <p></p> <p></p> <p>Can be coded in one of two forms:</p> <ol> <li>Table-driven<ul> <li>The table is explicitly represented in a runtime table, interpreted by the program</li> <li>Often used by scanner generators</li> <li>Token independent</li> </ul> </li> <li>Explicit control<ul> <li>The table appears implicitly through the control logic of the program.</li> </ul> </li> </ol>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#pseudocode","title":"Pseudocode","text":"<p>The DFA from above implemented:</p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#table-driven","title":"Table-driven","text":""},{"location":"4-semester/SPO/exam/3-lexical-analysis/#explicit-control","title":"Explicit Control","text":""},{"location":"4-semester/SPO/exam/3-lexical-analysis/#transducers","title":"Transducers","text":"<p>It is smart to associate a semantic value with the token, such as the value of an integer constant. An FA that does this is called a transducer.</p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#scanner-generator","title":"Scanner Generator","text":"<p>The scanner is often generated by a tool, such as Lex</p> <p></p> <p>The tokens are specified in a scanner specification that is fed to the generator tool.</p>"},{"location":"4-semester/SPO/exam/3-lexical-analysis/#performance-considerations","title":"Performance Considerations","text":""},{"location":"4-semester/SPO/exam/4-parsing/","title":"Parsing","text":"<ul> <li>Describe the purpose of the parser</li> <li>Discuss top down vs. bottom up parsing</li> <li>Explain necessary conditions for construction of recursive descent parsers</li> <li>Discuss the construction of an RD parser from a grammar</li> <li>Discuss bottom up / LR parsing</li> </ul> <p>To Read:</p> <ul> <li> Sebesta Chapter 4.4-</li> <li> Fischer Chapter 5, 6</li> </ul>"},{"location":"4-semester/SPO/exam/4-parsing/#context-free-grammar","title":"Context Free Grammar","text":"<p>See Context Free Grammars</p>"},{"location":"4-semester/SPO/exam/4-parsing/#parsers","title":"Parsers","text":"<p>See From Tokens to Parse Trees</p>"},{"location":"4-semester/SPO/exam/4-parsing/#recursive-descent-parsing-top-down","title":"Recursive Descent Parsing (Top-Down)","text":"<p>LL(1) grammars can be parsed with a Recursive Descent Parser.</p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/4-parsing/#algorithm-to-convert-ebnf-to-rd-parser","title":"Algorithm to Convert EBNF to RD Parser","text":"<ol> <li>Express grammar in EBNF</li> <li>Grammar Transformations<ul> <li>Left factorizations and Left recursion elemination</li> </ul> </li> <li>Create a parser class with<ul> <li>Private variable <code>currentToken</code></li> <li>Methods to call the scanner <code>accept</code> and <code>acceptIt</code></li> </ul> </li> <li>Implement private parsing methods<ul> <li>Add private <code>parseN</code> method for each non-terminal N</li> <li>public <code>parse</code> method that<ul> <li>gets the first token from the scanner</li> <li>calls <code>parseS</code> (SS is the start symbol of the grammar)</li> </ul> </li> </ul> </li> </ol>"},{"location":"4-semester/SPO/exam/4-parsing/#bottom-up-parsers","title":"Bottom-Up Parsers","text":"<p>LR grammars.</p> <ul> <li>LR(0): Simplest algorithm<ul> <li>Theoretically important but rather weak (not practical)</li> </ul> </li> <li>SLR: An improved version of LR(0)<ul> <li>More practical but still rather weak</li> </ul> </li> <li>LR(1) : LR(0) algorithm with extra lookahead token<ul> <li>Very powerful algorithm. Not used often because of large memory requirements (big parsing tables)</li> <li>Note: LR(0) and LR(1) use 1 lookahead token when operating<ul> <li>0 res. 1 refer to token used in table construction</li> </ul> </li> </ul> </li> <li>LR(k) for k&gt;0k&gt;0, k tokens are used for operation and table</li> <li>LALR: \"Watered down\" version of LR(1)<ul> <li>Still very powerful, but much smaller parsing tables</li> <li>Most commonly used algorithm today</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/4-parsing/#terminology","title":"Terminology","text":"<ul> <li> <p>\\alpha\\alpha is a right sentential form if S \\Rightarrow^*_{rm} \\alphaS \\Rightarrow^*_{rm} \\alpha with \\alpha=\\beta x\\alpha=\\beta x where xx is a string of terminals</p> </li> <li> <p>A handle of a right sentential form \\gamma \\ (=\\alpha \\beta w)\\gamma \\ (=\\alpha \\beta w) is a production A \\rightarrow \\betaA \\rightarrow \\beta and a position in \\gamma\\gamma where \\beta\\beta may be found and replaced by AA to produce the previous right-sentential form in a rightmost derivation of \\gamma:\\gamma:</p>  S \\Rightarrow^*_{rm} \\alpha A w \\Rightarrow_{rm} \\alpha \\beta w   S \\Rightarrow^*_{rm} \\alpha A w \\Rightarrow_{rm} \\alpha \\beta w  <ul> <li>A handle is a production we can reverse without getting stuck</li> <li>If the handle is A \\rightarrow \\betaA \\rightarrow \\beta, we will also call \\beta\\beta the handle.</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/4-parsing/#handles-and-reductions","title":"Handles and Reductions","text":""},{"location":"4-semester/SPO/exam/4-parsing/#shift-reduce","title":"Shift-Reduce","text":""},{"location":"4-semester/SPO/exam/4-parsing/#resembles-knitting","title":"Resembles Knitting","text":""},{"location":"4-semester/SPO/exam/4-parsing/#algorithm","title":"Algorithm","text":"<p>All bottom up parsers have similar algorithm</p> <ul> <li>A loop with these parts<ul> <li>Try to find the leftmost node of the parse tree which has not yet been constructed, but all of whose children have been constructed.<ul> <li>This sequence of children is called a handle</li> <li>The sequence of children is built by pushing, also called shifting, elements on a stack</li> </ul> </li> <li>Construct a new parse tree node<ul> <li>Called reducing</li> </ul> </li> </ul> </li> </ul> <p>The difference between different algorithms is only in the way they find the handle.</p> <p></p>"},{"location":"4-semester/SPO/exam/4-parsing/#parse-table","title":"Parse Table","text":"<ul> <li>For every state and every terminal<ul> <li>Either shift x<ul> <li>Put next input-symbol on the stack and go to state x</li> </ul> </li> <li>or reduce production<ul> <li>On the stack we now have symbols to go backwards in the production - afterwards do a goto</li> </ul> </li> </ul> </li> <li>For every state and every non-terminal<ul> <li>Goto x<ul> <li>Tells us, in which state to be in after a reduce-operation</li> </ul> </li> </ul> </li> <li>Empty cells in the table indicate an error</li> </ul>"},{"location":"4-semester/SPO/exam/4-parsing/#lr0-dfa","title":"LR(0)-DFA","text":"<p>To get parse table: Build DFA and encode it in a table.</p> <ul> <li>Every state is a set of items</li> <li>Transitions are labeled by symbols </li> <li>States must be closed</li> <li>New states are constructed from states and transitions</li> </ul> <p>Item:</p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/5-semantic-analysis/","title":"Semantic Analysis","text":"<ul> <li>Describe the purpose of the Semantic Analysis phase</li> <li>Discuss Identification and type checking</li> <li>Discuss scopes/block structure and implication for implementation of identification-/symbol tables</li> <li>Discuss implementation of semantic analysis</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/","title":"Runtime Organization","text":"<ul> <li>Data representation (direct vs. indirect)</li> <li>Storage allocation strategies: static vs. stack dynamic</li> <li>Activation records (sometimes called frames)</li> <li>Routines and Parameter passing</li> </ul>  \\newcommand{\\bits}{\\text{ bits}} \\newcommand{\\bit}{\\text{ bit}} \\newcommand{\\size}[1]{\\text{size}[\\mathtt{#1}]}"},{"location":"4-semester/SPO/exam/6-runtime-organization/#data-representation","title":"Data Representation","text":"<p>Data representation: how to represent values of the source language on the target machine.</p> <p></p> <p>Important properties of a representation schema</p> <ul> <li>Non-confusion<ul> <li>Different values of a given type should have different representations</li> </ul> </li> <li>Uniqueness<ul> <li>Each value should always have the same representation</li> </ul> </li> </ul> <p>Important issues</p> <ul> <li>Constant-size representation<ul> <li>The representation of all values of a given type should occupy the same amount of space</li> </ul> </li> <li>Direct vs indirect representation</li> </ul> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#indirect-representation","title":"Indirect Representation","text":"<p>Why chose indirect representation?</p> <ul> <li>Make the representation \"constant size\" even if representation requires different amounts of memory for different values.</li> </ul> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#indirect-vs-direct","title":"Indirect vs Direct","text":"<ul> <li>Direct representations are often preferable for efficiency<ul> <li>More efficient access (no need to follow pointers)</li> <li>More efficient \"storage class\" (e.g stack- rather than heap allocation)</li> </ul> </li> <li>For types with widely varying size of representations, it is almost a must to use indirect. </li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#notation","title":"Notation","text":"<p>If TT is a type then:</p> <ul> <li>\\#[T]\\#[T] is the cardinality of the type (the number of possible values)</li> <li>\\text{size}[T]\\text{size}[T] is the size of the representation (in number of bits/bytes)</li> </ul> <p>In general: if \\#[T]=n\\#[T]=n then \\text{size}[T]=\\log_2n \\text{ bits}\\text{size}[T]=\\log_2n \\text{ bits}</p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#primitive-types","title":"Primitive Types","text":"<p>Types that cannot be decomposed into simpler types. For example:</p> <ul> <li><code>integer</code>,<code>boolean</code>, <code>char</code> etc.</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#boolean","title":"Boolean","text":"<p>2 values: <code>true</code> and <code>false</code></p> <p>\\Rightarrow \\#[\\mathtt{boolean}]=2\\Rightarrow \\#[\\mathtt{boolean}]=2</p> <p>\\Rightarrow \\text{size}[\\mathtt{boolean}]=1 \\text{ bit}\\Rightarrow \\text{size}[\\mathtt{boolean}]=1 \\text{ bit}</p> <p>Possible representations</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#integer","title":"Integer","text":"<p>Typically uses one word (16, 32 or 64 bits).</p> <p>\\Rightarrow \\#[\\mathtt{integer}]=\\leq 2^{16}=65536\\Rightarrow \\#[\\mathtt{integer}]=\\leq 2^{16}=65536</p> <p>\\Rightarrow \\text{size}[\\mathtt{boolean}]=word\\ (=16 \\bits)\\Rightarrow \\text{size}[\\mathtt{boolean}]=word\\ (=16 \\bits)</p> <p>Modern processors use two's complement representation of integers:</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#composite-types","title":"Composite  Types","text":"<ul> <li>Records</li> <li>Arrays</li> <li>Variant Records or Disjoint Unions</li> <li>Pointers or References</li> <li>(Objects)</li> <li>Functions</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#records","title":"Records","text":"<p>Example: Triangle Record Representations</p> <pre><code>type Date = record\ny : Integer,\nm : Integer,\nd : Integer\nend;\ntype Details = record\nfemale  : Boolean,\ndob     : Date,\nstatus  : Char\nend;\nvar today   : Date;\nvar my      : Details\n</code></pre> <p></p> <p></p> <p>\\Rightarrow \\text{size}[\\mathtt{Date}]= 3*\\size{integer}=3\\ words\\Rightarrow \\text{size}[\\mathtt{Date}]= 3*\\size{integer}=3\\ words </p> <p>\\text{address}[\\mathtt{today.y}]=\\text{address}[\\mathtt{today}]+0\\\\ \\text{address}[\\mathtt{today.m}]=\\text{address}[\\mathtt{today}]+1\\\\ \\text{address}[\\mathtt{today.d}]=\\text{address}[\\mathtt{today}]+2\\text{address}[\\mathtt{today.y}]=\\text{address}[\\mathtt{today}]+0\\\\ \\text{address}[\\mathtt{today.m}]=\\text{address}[\\mathtt{today}]+1\\\\ \\text{address}[\\mathtt{today.d}]=\\text{address}[\\mathtt{today}]+2</p> <p>\\text{address}[\\mathtt{my.dob.m}]=\\text{address}[\\mathtt{my.dob}]+1=\\text{address}[\\mathtt{my}]+2\\text{address}[\\mathtt{my.dob.m}]=\\text{address}[\\mathtt{my.dob}]+1=\\text{address}[\\mathtt{my}]+2</p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#disjoint-unions","title":"Disjoint Unions","text":"<p>Example: Pascal variant records</p> <pre><code>type Number = record\ncase discrete: Boolean of\ntrue: (i: Integer);\nfalse: (r: Real)\nend;\nvar num: Number\n</code></pre> <p></p> <p>Assuming \\size{Integer}=\\size{Boolean}=1\\size{Integer}=\\size{Boolean}=1 and \\size{Real}=2\\size{Real}=2 then</p> <p>\\size{Number}=\\size{Boolean}+ \\max{(\\size{Integer}, \\size{Real})}=1+\\max{(1,2)}=3\\size{Number}=\\size{Boolean}+ \\max{(\\size{Integer}, \\size{Real})}=1+\\max{(1,2)}=3</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#arrays","title":"Arrays","text":"<p>Two kinds of arrays</p> <ul> <li>Static arrays: size is known at compile time</li> <li>Dynamic arrays: Number of elements is computed at run-time and sometimes may vary at run-time (Flex-arrays)</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#static-arrays","title":"Static Arrays","text":"<pre><code>type Name = array 6 of Char;\nvar me: Name;\nvar names: array 2 of Name\n</code></pre> <pre><code>type Coding = record\nChar c, Integer n\nend\nvar code: array 3 of Coding\n</code></pre>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#dynamic-arrays","title":"Dynamic Arrays","text":"<p>Example: Java arrays</p> <pre><code>char[] buffer;\nbuffer = new char[buffersize];\n...\nfor (int i = 0; i &lt; buffer.length; i++) // can ask for size at run time\nbuffer[i]= '';\n</code></pre> <pre><code>char[] buffer;\nbuffer = new char[7];\n</code></pre> <p>Possible representation:</p> <p></p> <p>Another possible representation:</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#where-to-put-data","title":"Where to Put Data","text":"<p>3 methods</p> <ul> <li>Static allocation</li> <li>Stack allocation</li> <li>Heap allocation</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#static-allocation","title":"Static Allocation","text":"<p>Originally all data were global. All memory allocation was static.</p> <p>Data was placed at a fixed memory address during compilation, for the entire execution of a program.</p> <p>Static allocation can waste memory space.</p> <ul> <li>Fortran introduced <code>equivalent</code> statement that forces 2 variables to share memory location</li> </ul> <p>In modern languages, static allocation is used for global variables and literals (constants) that are fixed in size and accessible throughout program execution.</p> <p>Also used for static and extern variables in C/C++ and for static fields in C# and Java classes.</p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#stack-allocation","title":"Stack Allocation","text":"<p>Recursive languages require dynamic memory allocation. Each time a recursive method is called, a new copy of local variables (frame) is pushed on a runtime stack. The number of allocations is unknown at compile-time.</p> <p>A frame (or activation record) contains space for all of the local variables in the method. When the method returns, its frame is popped and the space reclaimed. Thus, only the methods that are actually executing are allocated memory space in the runtime stack. This is called stack allocation.</p> <p></p> <p>Frame for procedure <code>p</code>:</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#stack-storage-allocation","title":"Stack Storage Allocation","text":"<p>Allocation of local variables</p> <p>Example: When do the variables \"exist\"?:</p> <p></p> <p></p> <ol> <li>Procedure activation behaves like a stack (LIFO)</li> <li>Local variables \"live\" as long as the procedure they are declared in.</li> <li>1+2\\Rightarrow1+2\\Rightarrow Allocation of locals on the \"call stack\" us a good model</li> </ol>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#recursion","title":"Recursion","text":"<pre><code>int fact(int n) {\nif (n &gt; 1)  return n * fact (n-1);\nelse        return 1;\n}\n</code></pre>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#dynamic-link","title":"Dynamic Link","text":"<p>Stack frames may vary in size and because the stack may contain more than just frames (e.g. registers saved across calls), dynamic link is used to point to the preceding frame:</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#nested-functionsprocedures","title":"Nested Functions/Procedures","text":"<pre><code>int p(int a) {\nint q(int b) {\nif (b &lt; 0) q (-b) else return a + b;\n}\nreturn q(-10);\n}\n</code></pre> <p>Functions can nest in languages like Pascal, ML and Python. How to keep track of static block structure as above? </p> <p>A static link points to the frame of the method that statically encloses the current method:</p> <p></p> <p>An alternative is the use of a display. We maintain a set of registers which comprise the display:</p> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#blocks","title":"Blocks","text":"<pre><code>void p(int a) {\nint b;\nif (a &gt; 0)  { float c, d;   }\nelse        { int e[10];    }\n}\n</code></pre> <p>We can view blocks as parameter-less procedures, and use procedure-level-frames to implement blocks.</p> <ul> <li>But because the then and else parts of the if statement above are mutually exclusive, variables in block 1 and 2 can overlay.</li> <li>This is called block-level frame as contrasted with procedure level frame</li> </ul> <p></p>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#high-order-functions","title":"High-order Functions","text":"<p>Functions as values (first-class)</p> <ul> <li>Pass as arguments</li> <li>Return as values</li> <li>Stored into data structures</li> </ul> <p>Implementation:</p> <ul> <li>A code pointer (a code address + an environment pointer)<ul> <li>Called a closure</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#routines","title":"Routines","text":"<p>The assembly language equivalent of procedures</p> <p>Not directly supported by language constructs, but modeled in terms of how to use the low-level machine to emulate procedures.</p> <p>Behavior to emulate:</p> <ul> <li>Calling a routine and returning to the caller after completion</li> <li>Passing arguments to a called routine</li> <li>Returning a result from a routine</li> <li>Local and non-local variables</li> </ul> <p>Transferring control to and from routine:</p> <ul> <li>Most low-level processors have <code>CALL</code> and <code>RETURN</code> for transferring control from caller to callee and back.</li> </ul> <p>Transmitting arguments and return values:</p> <ul> <li>Caller and callee must agree on a method to transfer argument and return values.<ul> <li>Called routine protocol</li> <li>There are many possible ways.</li> <li>Often dictated by the operating system.</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#routine-protocol-examples","title":"Routine Protocol Examples","text":""},{"location":"4-semester/SPO/exam/6-runtime-organization/#example-1","title":"Example 1","text":"<p>Passing arguments:</p> <ul> <li>First argument in R1, second in R2, etc.</li> </ul> <p>Passing return value:</p> <ul> <li>Return result (if any) in R0</li> </ul> <p>This is simplistic</p> <ul> <li>What if more arguments than registers</li> <li>What if argument is larger than a register</li> </ul>"},{"location":"4-semester/SPO/exam/6-runtime-organization/#example-2","title":"Example 2","text":"<p>Passing arguments:</p> <ul> <li>Pass argument on top of stack</li> </ul> <p>Passing of return value:</p> <ul> <li>Leave return value on stack top</li> </ul> <p>Puts no boundary on number of arguments, or size of arguments.</p> <p></p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/","title":"Heap Allocation and Garbage Collection","text":"<ul> <li>Why may we need heap allocation?</li> <li>Garbage collection strategies<ul> <li>Types of GCs</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#heap-allocation","title":"Heap Allocation","text":"<ul> <li> <p>Memory allocation under explicit programmatic control</p> <ul> <li>C <code>malloc</code>, C++ / Pascal / Java / C# <code>new</code>-operation</li> </ul> </li> <li> <p>Memory allocation implicit in language constructs</p> <ul> <li>Lisp, Scheme, Haskell, SML, ... most functional languages.</li> <li>Autoboxing/unboxing in Java 1.5 and C#</li> </ul> </li> <li>Deallocation under explicit programmatic control<ul> <li>C, C++, Pascal (<code>free</code>, <code>delete</code>, <code>dispose</code> operations)</li> </ul> </li> <li>Deallocation implicit<ul> <li>Java, C#, Lisp, Scheme, Haskell, SML, ...</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#garbage","title":"Garbage","text":"<pre><code>int *p, *q;\n...\np = malloc(sizeof(int));\np = q;\n</code></pre> <p>Created space becomes garbage.</p> <pre><code>for (int i = 0; i &lt; 10000; i++) {\nSomeClass obj = new SomeClass(i);\nSystem.out.println(obj);\n}\n</code></pre> <p>Creates 10 000 objects which becomes garbage just after the print.</p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#problems-with-explicit-heap-management","title":"Problems with Explicit Heap Management","text":""},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#dangling-pointer","title":"Dangling Pointer","text":"<pre><code>int *p, *q;\n...\np = malloc(sizeof(int))\nq = p;\nfree(p);\n</code></pre> <p>Dangling pointer in <code>q</code> now.</p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#hard-to-recognize","title":"Hard to Recognize","text":"<pre><code>float myArray[100];\n\np = myArray;\n*(p+i) = ...    //equivalent to myArray[i]\n</code></pre>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#stacks-and-dynamic-allocations-are-incompatible","title":"Stacks and Dynamic Allocations are Incompatible","text":"<p>We can't do dynamic allocation within the stack.</p> <p></p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#where-to-put-the-heap","title":"Where to put the Heap?","text":"<ul> <li>It may grow and shrink during runtime.</li> <li>It is not LIFO like the stack</li> <li>We will typically have both heap- and stack allocated memory coexisting.</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#implicit-memory-management","title":"Implicit Memory Management","text":"<p>A current trend of modern programming language development is to give only implicit means of memory management to the programmer.</p> <ul> <li>The constant increase of hardware memory justifies the policy of automatic memory management</li> <li>The explicit memory management distracts the programmer from his primary tasks</li> <li>The philosophy of high-level languages conforms to the implicit memory management.</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#garbage-collection","title":"Garbage Collection","text":"<ol> <li> <p>Garbage collection provides the \"illusion of infinite memory\"!</p> </li> <li> <p>A garbage collector predicts the future!</p> </li> </ol> <p>Types of garbage collectors</p> <ul> <li>The \"Classic\" algorithms<ul> <li>Reference counting</li> <li>Mark and Sweep</li> </ul> </li> <li>Copying garbage collection</li> <li>Generational garbage collection</li> <li>Incremental Tracing garbage collection</li> </ul> <p>Direct Garbage Collectors: a record is associated with each node in the heap. The record for node N indicates how many other nodes or roots points to NN.</p> <p>Indirect/Tracing Garbage Collectors: usually invoked when a user's request for memory fails. The garbage collector visits all live nodes, and returns all other memory to the free list. If sufficient memory has been recovered from this process, the user's request for memory is satisfied.</p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#terminology","title":"Terminology","text":"<ul> <li>Roots<ul> <li>Values that a program can manipulate directly (values held in registers, on the program stack, and global variables)</li> </ul> </li> <li>Node/Cell/Object<ul> <li>An individually allocated piece of data in the heap</li> </ul> </li> <li>Children Nodes<ul> <li>The list of pointers that a given node contains</li> </ul> </li> <li>Live Node<ul> <li>A node whose address is held in a root or is the child of a live node</li> </ul> </li> <li>Garbage<ul> <li>Nodes that are not live, but are not free either.</li> </ul> </li> <li>Garbage Collection<ul> <li>The task of recovering (freeing) garbage nodes</li> </ul> </li> <li>Mutator<ul> <li>The program running alongside the garbage collection system</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#reference-counting","title":"Reference Counting","text":"<ul> <li>Every cell has a reference count field, containing the number of pointers to that cell from roots or heap cells.</li> <li>Initially all cells in the heap are placed in the free list</li> <li>When a cell is allocated from the free list, its reference count is set to 1</li> <li>When a pointer is set to reference a cell, the cells reference count is incremented by 1.<ul> <li>If a pointer to the cells is deleted, its reference count is decremented by 1.</li> </ul> </li> <li>When a cell's reference count reaches 0, its pointers to its children are deleted and it is returned to the free list</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#advantages-and-disadvantages","title":"Advantages and Disadvantages","text":"<p>Advantages:</p> <ul> <li>GC overhead is distributed</li> <li>Locality of reference is no worse than mutator</li> <li>Free memory is returned to free list quickly</li> </ul> <p>Disadvantages:</p> <ul> <li>High time cost (every time a pointer is changed, reference count must be updated)<ul> <li>In place of a single assignment <code>x.f = p</code>:<ul> <li></li> </ul> </li> </ul> </li> <li>Storage overhead for reference counter can be high</li> <li>If the reference counter overflows, the object becomes permanent</li> <li>Unable to reclaim cyclic data structures</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#free-memory-management","title":"Free Memory Management","text":"<p>The Heap is not LIFO like the stack, how to manage free space in the \"middle\" of the heap?</p> <p></p> <p>We can use a free list</p> <p></p> <p>Which we can store in the free memory itself since it is not used by anything else</p> <p></p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#mark-sweep","title":"Mark-Sweep","text":"<ul> <li>The first tracing garbage collection algorithm</li> <li>Garbage cells are allowed to build up until heap space is exhausted (a user program requests a memory allocation, but there is insufficient free space on the heap)</li> <li>At this point, the mark-sweep algorithm is invoked, and garbage cells are returned to the free list</li> <li>Performed in two phases:<ul> <li>Mark: identifies all live cells by setting a mark bit. Live cells are cells reachable from a root</li> <li>Sweep: returns garbage cells to the free list</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#pseudo-code","title":"Pseudo Code","text":"<pre><code>void garbageCollect() {\n    mark all heap variables as free\n    foreach frame in stack \n        scan(frame)\n    foreach heapvar marked as free\n        add heapvar to freelist\n}\nvoid scan(region) {\n    foreach pointer p in region{\n        if p points to region marked as free then{\n            mark region at p as reachable\n            scan(region at p)\n        }\n    }\n}\n</code></pre>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#advantages-and-disadvantages_1","title":"Advantages and Disadvantages","text":"<p>Advantages:</p> <ul> <li>Cyclic data structures can be recovered</li> <li>Tends to be faster than reference counting</li> </ul> <p>Disadvantages:</p> <ul> <li>Computation must be halted while GC is being performed</li> <li>Every live cell must be visited in the mark phase, and every cell in the heap must be visited in the sweep phase.</li> <li>GC becomes more frequent as residency of a program increases</li> <li>May fragment memory</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#mark-sweep-compact","title":"Mark-Sweep-Compact","text":"<p>Advantages:</p> <ul> <li>The contiguous free area eliminates fragmentation problem     Allocating objects of various sizes is simple</li> <li>The garbage space is \"squeezed out\", without disturbing the original ordering of objects. This improves locality.</li> </ul> <p>Disadvantages:</p> <ul> <li>Requires several passes over the data.     \"Sliding compactors\" takes two, three or more passes over the live objects.<ul> <li>One pass computes the new location</li> <li>Subsequent passes update the pointers to refer to new locations, and actually move the objects</li> </ul> </li> </ul> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#copying-garbage-collection","title":"Copying Garbage Collection","text":"<p>Cheney's Algorithm</p> <ul> <li> <p>Like mark-compact, copying garbage collection, but does not really \"collect\" garbage.</p> </li> <li> <p>The heap is subdivided into two contiguous subspaces</p> <ul> <li>FromSpace and ToSpace</li> </ul> </li> <li>During normal program execution, only one of these semispaces is in use.</li> <li>When the garbage collector is called, all the live data are copied from the current semispace (FromSpace) to the other semispace (ToSpace), so that objects need only be traversed once.</li> <li>The work needed is proportional to the amount of live data (all of which must be copied).</li> </ul> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#advantages-and-disadvantages_2","title":"Advantages and Disadvantages","text":"<p>Advantages:</p> <ul> <li>Allocation is extremely cheap.</li> <li>Excellent asymptotic complexity.</li> <li>Fragmentation is eliminated.</li> <li>Only one pass through the data is required.</li> </ul> <p>Disadvantages: </p> <ul> <li>The use of two semi-spaces doubles memory requirement</li> <li>Poor locality. Using virtual memory will cause excessive paging.</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#generational-garbage-collection","title":"Generational Garbage Collection","text":"<p>Attempts to address weaknesses of simple tracing collectors such as mark-sweep and copying collectors</p> <ul> <li>All active data must be marked or copied</li> <li>For copying collectors, each page of the heap is touched every two collection cycles, even though the user program is only using half the heap, leading to poor cache behavior and page faults</li> <li>Long-lived objects are handled inefficiently</li> </ul> <p>Generational garbage collection is based on the generational hypothesis:</p> <p>Most objects die young</p> <p>As such, concentrate GC efforts on objects likely to be garbage: young objects</p>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#advantages-and-disadvantages_3","title":"Advantages and Disadvantages","text":"<p>Advantages:</p> <ul> <li>Keeps youngest generation's size small</li> <li>Helps address mistakes made by the promotion policy by creating more intermediate generations that still get garbage collected fairly frequently.</li> </ul> <p>Disadvantages:</p> <ul> <li>Collections for intermediate generations may be disruptive.</li> <li>Tends to increase number of inter-generational pointers, increasing the size of the root set for younger generations.</li> </ul> <p>Performs poorly if any of the main assumptions are false:</p> <ul> <li>That objects tend to die young.</li> <li>That there are relatively few pointers from old objects to young ones.</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#incremental-tracing-collectors","title":"Incremental Tracing Collectors","text":"<p>Program (Mutator) and Garbage Collector run concurrently.</p> <ul> <li>Can think of system as similar to two threads. One performs collection, and the other represents the regular program in execution.</li> </ul> <p>Can be used in systems with real-time requirements. For example, process control systems.</p> <ul> <li>Allow mutator to do its job without destroying collector\u2019s possibilities for keeping track of modifications of the object graph, and at the same time</li> <li>Allowing collector to do its job without interfering with mutator</li> </ul>"},{"location":"4-semester/SPO/exam/7-heap-allocation-and-gc/#summary","title":"Summary","text":""},{"location":"4-semester/SPO/exam/8-code-generation/","title":"Code Generation","text":"<ul> <li>Describe the purpose of the code generator</li> <li>Discuss Intermediate representations</li> <li>Describe issues in code generation</li> <li>Code templates and implementations</li> <li>Back patching</li> <li>Implementation of functions/procedures/methods</li> <li>Register Allocation and Code Scheduling</li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#the-code-generation-phase","title":"The Code Generation Phase","text":""},{"location":"4-semester/SPO/exam/8-code-generation/#intermediate-representations","title":"Intermediate Representations","text":"<ul> <li>\"Neutral\" architecture</li> <li>Easy to translate to native code</li> <li>Can abstract away complicated runtime issues<ul> <li>Stack Frame Management</li> <li>Memory Management</li> <li>Register Allocation</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#challenges","title":"Challenges","text":"<ul> <li> <p>IL must be precisely defined</p> </li> <li> <p>Translators and processors must be crafted for an IL</p> </li> <li> <p>Connections must be made between levels so feedback from intermediate steps can be related to the source program</p> </li> <li>Efficiency </li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#st-vs-st","title":"S*T vs S+T","text":""},{"location":"4-semester/SPO/exam/8-code-generation/#jvm","title":"JVM","text":"<p>Easy conversion between java types and JVM types</p> <p></p> <p>The JVM is an abstract machine.</p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#class-files","title":"Class Files","text":"<p>Binary encodings of the data and instructions in a Java program</p> <p>Contains:</p> <ul> <li>Table of constants</li> <li>Tables describing the class<ul> <li>Name, superclass, interfaces, attributes, constructors</li> </ul> </li> <li>Tables describing fields and methods<ul> <li>Name, type/signature</li> <li>attributes (private, public, etc)</li> </ul> </li> <li>Code for methods</li> </ul> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#internal-architecure","title":"Internal Architecure","text":""},{"location":"4-semester/SPO/exam/8-code-generation/#runtime-data-areas","title":"Runtime Data Areas","text":"<p>Supports multi-threading.</p> <ul> <li>Two kinds of runtime data areas<ol> <li>Shared between all threads</li> <li>Private to a single thread</li> </ol> </li> </ul> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#stack-machine","title":"Stack Machine","text":"<p>JVM is a stack machine.</p> <pre><code>(a * b) + (1 - (c * 2))\n</code></pre> <p>On the stack machine:</p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#interpreter","title":"Interpreter","text":"<p>The core of a JVM interpreter is basically this:</p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#instruction-set","title":"Instruction-set","text":"<p>Typed instructions</p> <pre><code>iload   integer load\nlload   long load\nfload   float load\ndload   double load\naload   reference-type load\n</code></pre> <p>Different operands:</p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#code-generation-visitor","title":"Code Generation Visitor","text":"<p>TopVisitor</p> <ul> <li>Starts at root of AST</li> <li>Handles class/method declarations</li> <li>Calls others for specific needs</li> </ul> <p>MethodBodyVisitor</p> <ul> <li>Generates most of the actual code</li> <li>Calls others for specific needs</li> </ul> <p>Signature Visitor</p> <ul> <li>Handles AST subtrees for method definition or invocation<ul> <li>Method name, parameter types, return type</li> </ul> </li> <li>Used by MethodBodyVisitor for invocations</li> </ul> <p>LHSVisitor</p> <ul> <li>Generates code for LHS of assignments</li> <li>May call other visitors if LHS contains subexpressions<ul> <li>Java example: <code>a[x+y] = ...</code></li> <li>Remember that LHS of assignment use the address of a variable, whereas the RHS uses the value</li> </ul> </li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#code-emmision","title":"Code Emmision","text":"<pre><code>MethodBodyVisitor.visit(Plus){\nvisit(E1);\nvisit(E2);\nemit(\"iadd\\n\");\n}\n</code></pre>"},{"location":"4-semester/SPO/exam/8-code-generation/#postludes","title":"Postludes","text":"<p>Sometimes a single emission isn't enough</p> <p>Assignments:</p> <ul> <li>Visit LHS to find storage location and type</li> <li>Visit RHS to compute value</li> <li>Re-visit LHS to emit storage operations</li> </ul> <p>Inefficient!</p> <p>Better:</p> <ul> <li>LHS visitor builds storage operation</li> <li>Saves in a Postlude</li> <li>Parent requests postlude emission</li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#class-declarations","title":"Class Declarations","text":""},{"location":"4-semester/SPO/exam/8-code-generation/#code-templates","title":"Code Templates","text":"<p>If-then-else:</p> <p></p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#template-invariants","title":"Template Invariants","text":"<ul> <li>A statement and a void expression leaves the stack height unchanged</li> <li>A non-void expression increases the stack height by one</li> </ul> <p>This is a local property of each template</p> <ul> <li>The generated code must be verifiable</li> </ul> <p>This is not a local property, since the verifier performs a global static analysis</p>"},{"location":"4-semester/SPO/exam/8-code-generation/#instruction-selection","title":"Instruction Selection","text":"<p>We define patterns for instructions.</p> <p></p> <p>We can now match pattern to find the best instruction to use.</p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#register-allocation","title":"Register Allocation","text":"<p>Compiler generating code for register machine needs to pay attention to register allocation, since it is a limited resource.</p> <p>Routine protocol</p> <ul> <li>Allocate arg1 in R1, arg2 in R2, ... and result in R0</li> <li>But what if there are more args than regs?</li> </ul> <p>On MIPS all calculations takes place in registers</p> <ul> <li>Reduces traffic between memory and regs</li> </ul>"},{"location":"4-semester/SPO/exam/8-code-generation/#register-needs","title":"Register Needs","text":""},{"location":"4-semester/SPO/exam/8-code-generation/#code-scheduling","title":"Code Scheduling","text":"<p>Modern computers are pipelined</p> <ul> <li>Instructions are processed in stages</li> <li>Instructions take different time to execute</li> <li>If result from previous instruction is needed but not yet ready, then we have a stalled pipeline</li> <li>Delayed load<ul> <li>Load from memory takes 2, 10 or 100 cycles</li> </ul> </li> <li>Also FP instructions takes time</li> </ul> <p></p> <p></p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#register-allocation-and-code-scheduling","title":"Register Allocation and Code Scheduling","text":"<p>Register allocations algorithms try to minimize number of regs used</p> <ul> <li>May conflict with pipeline architecture<ul> <li>Using more regs than strictly necessary may avoid pipeline stalls</li> </ul> </li> </ul> <p>Solution:</p> <ul> <li>Integrated register allocator and code scheduler</li> </ul> <p>As long as registers are available, they are used.</p> <p>When registers grow scarce, the algorithm switches emphasis and begins to schedule code to free registers.</p> <p></p>"},{"location":"4-semester/SPO/exam/8-code-generation/#peephole-optimizations","title":"Peephole Optimizations","text":""},{"location":"4-semester/SS/","title":"SS - SYNTAX OG SEMANTIK","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=28781</p>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/","title":"Eksamen Fremgangsm\u00e5de","text":""},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#konvertering-af-nfa-til-dfa","title":"Konvertering af NFA til DFA","text":"<ul> <li>Husk at \\varepsilon transitioner er \"gratis\"<ul> <li>De m\u00e5 dog ikke tages \"alene\", de skal l\u00e6ses sammen med et andet symbol. Dette symbol kan godt g\u00e5 til samme tilstand, og s\u00e5 kan  \\varepsilon\\varepsilon g\u00e5 videre.</li> </ul> </li> </ul>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#pushdown-automater","title":"Pushdown Automater","text":"<ul> <li>Brug epsilon-transitioner til at komme videre (\\varepsilon, \\varepsilon \\to \\varepsilon\\varepsilon, \\varepsilon \\to \\varepsilon)</li> </ul>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#eksempel","title":"Eksempel","text":"L_1=\\{a^ib^jc^k\\mid i,j,k \\geq 0;\\ k=i+j\\}   L_1=\\{a^ib^jc^k\\mid i,j,k \\geq 0;\\ k=i+j\\}"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#fra-cfg-til-pushdown","title":"Fra CFG til Pushdown","text":""},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#pumping-lemma-for-regulre-sprog","title":"Pumping Lemma for Regul\u00e6re Sprog","text":"<ul> <li> <p>Antag at LL er et regul\u00e6rt sprog, s\u00e5 ville Pumping Lemma v\u00e6re overholdt. (Se formelsamling s. 5)</p> </li> <li> <p>V\u00e6lg en streng s\\in Ls\\in L der er defineret ud fra pp og kan \"pumpes op\" s\u00e5 s\\notin Ls\\notin L</p> </li> <li>Skriv:</li> </ul> <p>\" Jeg v\u00e6lger s=s= \"valgte streng\" og viser at ingen opsplitninger af ss vil kunne overholde alle tre betingelser i pumping lemma for regul\u00e6re sprog samtidigt. </p> <p>Hvis (3) skal g\u00e6lde s\u00e5, m\u00e5 xyxy best\u00e5 af \"...\" og dermed y=x^ky=x^k for k\\geq 0k\\geq 0.</p> <p>Hvis (2) ogs\u00e5 skal g\u00e6lde m\u00e5 yy ikke v\u00e6re den tomme streng.</p> <p>Men s\u00e5 overtr\u00e6des (1), for vi har at xy^iz \\notin Lxy^iz \\notin L hvis i=i= \"...\", da \"...\". \"</p>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#semantik","title":"Semantik","text":"<ul> <li>Husk at numeraler skal g\u00f8res til tal ved \\mathcal{N}[\\![n]\\!]\\mathcal{N}[\\![n]\\!]<ul> <li>Eksempel: \\langle \\text{cutoff}(x, n), s \\rangle \u2192 s[x \\mapsto v] \\quad \\text{hvor } v = \\mathcal{N}[\\![n]\\!] \\quad \\text{hvis } s(x) &gt; \\mathcal{N}[\\![n]\\!]\\langle \\text{cutoff}(x, n), s \\rangle \u2192 s[x \\mapsto v] \\quad \\text{hvor } v = \\mathcal{N}[\\![n]\\!] \\quad \\text{hvis } s(x) &gt; \\mathcal{N}[\\![n]\\!]</li> </ul> </li> <li>Sl\u00e5 op i tilstand s med s(x)s(x)</li> <li>Husk at stregen over ikke altid bruges</li> </ul>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#se-fejl","title":"Se Fejl","text":"<ul> <li>Tjek at start og sluttilstande er korrekte</li> <li>Tjek efter s \\vdashs \\vdash</li> </ul>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#small-step-semantik","title":"Small-Step Semantik","text":"<ul> <li>Brug de predefinerede kommandoer (s. 7 i formelsamling)</li> </ul>"},{"location":"4-semester/SS/0-eksamen-fremgangsm%C3%A5der/#variabelbindinger","title":"Variabelbindinger","text":"<p>Hvis du sl\u00e5r op i Env_pEnv_p og f\u00e5r variabelenvironment med, er der tale om statisk variabelbinding.</p> <p>Det samme g\u00e6lder for procedurebindinger.</p> <p>Hvis du sl\u00e5r op, f\u00e5r du en gammel krop - Mads-Bo, 2019</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/","title":"Grundl\u00e6ggende Sprogteori","text":"<p>Et sprog er en m\u00e6ndge af strenge.</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#alfabet","title":"Alfabet","text":"<p>Definition: </p> <p>En endelig m\u00e6ngde af tegn.</p> <p>Notation:</p> <p>Skrives \\Sigma</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#eksempler","title":"Eksempler","text":"<p>\u200b   A=\\{a,b,c,d,...,\u00e6,\u00f8,\u00e5\\}A=\\{a,b,c,d,...,\u00e6,\u00f8,\u00e5\\}   (danske alfabet)</p> <p>\u200b   B=\\{0,1\\}B=\\{0,1\\}                     (bin\u00e6re alfabet)</p> <p>\u200b   ASCII-tegnene</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#streng","title":"Streng","text":"<p>Definition:</p> <p>Givet et alfabet \\Sigma\\Sigma, er en streng over \\Sigma\\Sigma er en endelig f\u00f8lge af tegn fra \\Sigma\u200b\\Sigma\u200b </p> <p>Notation:</p> <p>L\u00e6ngden af en streng s betegnes |s||s|</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#eksempler_1","title":"Eksempler:","text":"<p>Streng over A</p> <p>\u200b   |abe|=3\u200b|abe|=3\u200b</p> <p>\u200b   |kpst|=4|kpst|=4</p> <p>Streng over B</p> <p>\u200b   |01001|=5\u200b|01001|=5\u200b</p> <p>\u200b   |100|=3|100|=3</p> <p>En lille streng:</p> <p>\u200b   \\varepsilon\u200b\\varepsilon\u200b  (den tomme streng)</p> <p>\u200b   |\\varepsilon|=0|\\varepsilon|=0 </p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#sprog","title":"Sprog","text":"<p>Definition:</p> <p>Givet et alfabet \\Sigma\\Sigma, er et sprog over \\Sigma\\Sigma en endelig m\u00e6ngde af strenge over \\Sigma\\Sigma </p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#eksempler_2","title":"Eksempler","text":"<p>Alfabet A:</p> <p>\u200b   L_1=\\{a,aa,bba\\}L_1=\\{a,aa,bba\\}</p> <p>\u200b   L_2=\\{a,aa,aaa,...\\}L_2=\\{a,aa,aaa,...\\}</p> <p>\u200b   L_3=\u00d8L_3=\u00d8     (det tomme sprog)</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#sigmasigma-sigma-stjerne","title":"\\Sigma^*\\Sigma^* - Sigma-stjerne","text":"<p>Definition:</p> <p>Lad \\Sigma\\Sigma v\u00e6re et alfabet.</p> <p>\\Sigma^*\u200b\\Sigma^*\u200b er sproget best\u00e5ende af alle strenge over \\Sigma\u200b\\Sigma\u200b</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#eksempel","title":"Eksempel","text":"<p>\\Sigma=\\{0,1\\}\\Sigma=\\{0,1\\}</p> <p>\\Sigma^*=\\{\\varepsilon,0,1,00,01,10,11,000,001,... \\}\u200b\\Sigma^*=\\{\\varepsilon,0,1,00,01,10,11,000,001,... \\}\u200b</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#konkatination","title":"Konkatination","text":"<p>Definition:</p> <p>Lad u og v v\u00e6re strenge over \\Sigma\\Sigma</p> <p>\u200b   (u\\in\\Sigma^*,v\\in\\Sigma^*u\\in\\Sigma^*,v\\in\\Sigma^*)</p> <p>S\u00e5 er u\\circ vu\\circ v    (skrives tit uvuv)  strengen best\u00e5ende af symbolerne i u efterfulgt af symbolerne i v</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#eksempler_3","title":"Eksempler","text":"<p>u=abcu=abc</p> <p>v=hatv=hat</p> <p>uv=abchatuv=abchat</p> <p>--</p> <p>u=kat\u200bu=kat\u200b</p> <p>v=\\varepsilonv=\\varepsilon</p> <p>uv=katuv=kat</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#husk","title":"Husk!","text":"<p>Et sprog er bare en m\u00e6ngde af strenge.</p> <p>S\u00e5 vi kan bruge alle de s\u00e6dvanlige m\u00e6ngdeoperation, s\u00e5 l\u00e6nge de igen giver os et sprog.</p> <p>L_1\\cup L_2 :\\{x|x\\in L_1\\lor x \\in L_2\\}L_1\\cup L_2 :\\{x|x\\in L_1\\lor x \\in L_2\\}</p> <p>L_1 \\cap L_2 : \\{x|x\\in L_1 \\land x\\in L_2\\}L_1 \\cap L_2 : \\{x|x\\in L_1 \\land x\\in L_2\\}</p> <p>L_1 -L_2: \\{x|x \\in L_1 \\land x \\notin L_2 \\}L_1 -L_2: \\{x|x \\in L_1 \\land x \\notin L_2 \\}</p> <p>Men f.eks.:</p> <p>L_1 \\times L_2L_1 \\times L_2 giver ingen mening</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#regulre-sprog","title":"Regul\u00e6re Sprog","text":"<p>L er regul\u00e6rt hvis \\exists \\space \\text{DFA} \\space A:L=L(A)\\exists \\space \\text{DFA} \\space A:L=L(A)</p> <p>\u200b   L er regul\u00e6rt hvis der findes en DFA der l\u00e6ser L</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#regulre-operationer","title":"Regul\u00e6re Operationer","text":"<p>Foreningsm\u00e6ngde:</p> <p>\u200b   L_1 \\cup L_2 = \\{w \\mid w \\in L_1 \\text{eller} \\space w \\in L_2\\}L_1 \\cup L_2 = \\{w \\mid w \\in L_1 \\text{eller} \\space w \\in L_2\\}</p> <p>Konkatination:</p> <p>\u200b   L_1 \\circ L_2 = \\{w \\mid \\exists u, \\exists v:u \\in L_1, v \\in L_2, w=uv\\}L_1 \\circ L_2 = \\{w \\mid \\exists u, \\exists v:u \\in L_1, v \\in L_2, w=uv\\} </p> <p>L-stjerne (Kleene-stjerne):</p> <p>\u200b   {L_1}^* = \\{x_1...x_k \\mid k \\geq 0, x_i \\in L_1 \\space \\text{for} \\space 0 \\leq i \\leq k\\}\u200b{L_1}^* = \\{x_1...x_k \\mid k \\geq 0, x_i \\in L_1 \\space \\text{for} \\space 0 \\leq i \\leq k\\}\u200b</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#lukket-under-foreningsmngden","title":"Lukket Under Foreningsm\u00e6ngden","text":"<p>S\u00e6tning:</p> <p>Hvis L_1L_1 og L_2L_2 er regul\u00e6re sprog, s\u00e5 er L_1 \\cup L_2L_1 \\cup L_2 ogs\u00e5 et regul\u00e6rt sprog.</p>"},{"location":"4-semester/SS/01a-regul%C3%A6re-sprog/#produktkonstruktionen","title":"Produktkonstruktionen","text":""},{"location":"4-semester/SS/01b-endelige-automater/","title":"Endelige automater","text":"<p>Man ledte efter en model ag neuroner i hjernen.</p> <p>I datalogi anvendes endelige automater:</p> <ul> <li>I den fase af en compiler kaldet 'Leksikalske analyser' (lexer)</li> <li>I specifikation af systemer.</li> </ul> <p>Endelige automater er simple algoritmer til sproggendkendelse.</p> <p>\"Givet w, har vi w\\in L?\"</p> <p></p> <p>Tilstand er markeret af en cirkel.</p> <p>Transition er markeret med en pil.</p> <p>Accepttilstand er markeret med en ekstra cirkel.</p> <p>Definition:</p> <p>En endelig automat (DFA) er en 5-tupel</p> <p>\u200b   (Q,\\Sigma,q_0,\\delta,F)(Q,\\Sigma,q_0,\\delta,F)</p> <p>QQ     endelig m\u00e6ngde af tilf\u00e6lde</p> <p>\\Sigma\\Sigma    input alfabet</p> <p>q_0q_0   starttilstand q_0\\in Qq_0\\in Q</p> <p>\\delta\\delta    overf\u00f8ringsfunktion</p> <p>FF     m\u00e6ngden af accepttilstande F\\subseteq QF\\subseteq Q</p>"},{"location":"4-semester/SS/01b-endelige-automater/#overfringsfunktion","title":"Overf\u00f8ringsfunktion","text":"<p>\\delta(q,a)=q_1\\delta(q,a)=q_1</p> <p>\\delta:Q\\times \\Sigma \\rightarrow Q\\delta:Q\\times \\Sigma \\rightarrow Q</p>"},{"location":"4-semester/SS/01b-endelige-automater/#eksempel","title":"Eksempel","text":"<p>Q=\\{q_0,q_1\\}Q=\\{q_0,q_1\\}</p> <p>\\Sigma =\\{0,1\\}\\Sigma =\\{0,1\\}</p> <p>q_0=q_0q_0=q_0</p> <p>F=\\{q_0\\}F=\\{q_0\\}</p> \\delta\\delta 0 1 q_0q_0 q_0q_0 q_1q_1 q_1q_1 q_1q_1 q_1q_1"},{"location":"4-semester/SS/01b-endelige-automater/#andet","title":"Andet","text":"<p>Et lille v\u00e6rkt\u00f8j til at tegne endelige automater:</p> <p>http://madebyevan.com/fsm/</p>"},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/","title":"Nondeterministiske Endelige Automater","text":"<p>En NFA M accepterer et input w hvis M ved at l\u00e6se w KAN havne i en accepttilstand til sidst.</p> <p>Note</p> <p>Hvis en NFA ingen steder har at g\u00e5, \"crasher\" den, og l\u00e6ser dermed ikke strengen.</p>"},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#definition","title":"Definition","text":"<p>En nonderterministisk endelig automat (NFA) er en 5-tupel. $$ (Q,\\Sigma,\\delta,q_0,F) $$ Q:    endelig m\u00e6ngde af tilstande</p> <p>\\Sigma\\Sigma:   input alfabet</p> <p>\\delta\\delta:   overf\u00f8ringsfunktion</p> <p>q_0q_0:  starttilstand q_0 \\in Qq_0 \\in Q</p> <p>FF:    m\u00e6ngde af accepttilstande F \\subseteq QF \\subseteq Q</p> <p>Transitioner beskriver m\u00e6ngden af mulige efterf\u00f8lgertilstande for ethvert tegn.</p> <p></p> <p>\\delta(q_1,a)=\u00d8\\delta(q_1,a)=\u00d8</p> <p>\\delta(q_2,a)=\\{q_1,q_2\\}\\delta(q_2,a)=\\{q_1,q_2\\}</p> <p>\\delta(q_1,\\varepsilon)=\\{q_2\\}\\delta(q_1,\\varepsilon)=\\{q_2\\}</p> <p>\\delta(q_2, \\varepsilon)=\u00d8\\delta(q_2, \\varepsilon)=\u00d8  $$ \\delta:Q\\times\\Sigma_\\varepsilon \\rightarrow \\mathcal{P}(Q) $$ \u200b   - m\u00e6ngden af alle delm\u00e6ngder af Q</p>"},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#kvivalens-mellem-dfa-og-nfa","title":"\u00c6kvivalens mellem DFA og NFA","text":"<p>NFA'er og DFA'er er \u00e6kvivalente:</p> <p>For enhver NFA N kan vi konstruere en DFA M s\u00e5: L(N)=L(M)L(N)=L(M)</p> <p>Eksempel 1:</p> <p></p> <p>Eksempel 2:</p> <p></p>"},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#lukning-under-de-regulre-operationer","title":"Lukning Under de Regul\u00e6re Operationer","text":""},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#foreningsmngden","title":"Foreningsm\u00e6ngden","text":""},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#konkatination","title":"Konkatination","text":""},{"location":"4-semester/SS/02-nondeterministiske-endelige-automater/#stjerneoperationen","title":"Stjerneoperationen","text":""},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/","title":"Regul\u00e6re Udtryk","text":"<p>Regul\u00e6re udtryk og NFA'er er \u00e6kvivalente.</p> <p>Man taler om regul\u00e6re udtryk over et alfabet.</p> <p>Basis-udtryk</p> Regul\u00e6rt udtryk R Sproget betegnet af R, L(R) a [a\\in \\Sigma] {a} \u00d8 {} \\varepsilon\\varepsilon {\\varepsilon\\varepsilon} <p>Sammensatte udtryk</p> Regul\u00e6rt udtryk R Sproget betegnet af R, L(R) (R_1\\cup R_2)(R_1\\cup R_2) L(R_1) \\cup L(R_2)L(R_1) \\cup L(R_2) (R_1 \\circ R_2)(R_1 \\circ R_2) L(R_1) \\circ L(R_2)L(R_1) \\circ L(R_2) R^*R^* L(R)^*L(R)^*"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#regulre-udtryk-er-kvivalente-med-nfaer","title":"Regul\u00e6re Udtryk er \u00c6kvivalente med NFA'er","text":"<p>Eksempel: $$ (aa \\space \\cup \\space b)^* $$ Kan tegnes som NFA:</p> <p> \u03b5 \u03b5 \u03b5 a \u03b5 a \u03b5 b \u03b5 </p> <p>Og som vi s\u00e5 i Lektion 2, s\u00e5 kan en NFA skrives om til en DFA.</p>"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#generaliseret-nfa-gnfa","title":"Generaliseret NFA (GNFA)","text":"<p>Definition:</p> <p>En GNFA er en 5-tupel</p> <p>\u200b   (Q, \\Sigma,q_{start},q_{accept},\\delta)(Q, \\Sigma,q_{start},q_{accept},\\delta)</p> <p>Q:           m\u00e6ngde af tilstande</p> <p>\\Sigma\\Sigma:           input alfabet</p> <p>q_{start}q_{start}:     starttilstand q_{start} \\in Qq_{start} \\in Q</p> <p>q_{accept}q_{accept}:   accepttilstand q_{accept} \\in Qq_{accept} \\in Q</p> <p>\\delta\\delta:            Skal over en \"bordskik\"</p> <p>Bordskik:</p> <ul> <li>\u00c9n transition mellem hvert par af  tilstande, dog</li> <li>Ingen transitioner fra q_{accept}q_{accept}</li> <li>Ingen transition til q_{start}q_{start}</li> <li>Regul\u00e6re udtryk p\u00e5 transitionerne.</li> </ul>"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#eksempel","title":"Eksempel","text":""},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#konstruer-regulrt-udtryk-ud-fra-gnfa","title":"Konstruer Regul\u00e6rt Udtryk ud fra GNFA","text":"<p>Fjern tilstande i G \u00e9n efter \u00e9n og opdater.</p> <p>Til sidst har vi 2 tilstande med et regul\u00e6rt udtryk mellem.</p>"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#fjerne-tilstande","title":"Fjerne tilstande","text":"<ul> <li>M\u00e5 ikke v\u00e6re q_{start}q_{start} eller q_{accept}q_{accept}</li> <li>Kald den tilstand vi fjerne q_{rip}q_{rip}</li> </ul>"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#opdatere-transitioner","title":"Opdatere transitioner","text":"<p>F\u00f8r og efter</p> <p> q_i q_j q_rip q_i q_j R\u2081 R\u2083 R\u2084 R\u2082 R\u2084 U R\u2081R\u2082*R\u2083 </p> <ul> <li>For hvert par q_i,q_j \\neq q_{rip}q_i,q_j \\neq q_{rip} lav denne opdatering</li> </ul>"},{"location":"4-semester/SS/03-regul%C3%A6re-udtryk/#algoritme","title":"Algoritme","text":"<p>\\text{CONVERT}(G)=\\text{CONVERT}(G)=</p> <ol> <li> <p>Lad m\u00e6ngden af tilstande i GG v\u00e6re Q_GQ_G.</p> <p>Hvis Q_G =\\{q_{start}, q_{accept}\\}Q_G =\\{q_{start}, q_{accept}\\} s\u00e5 stop.</p> <p>Returner RR, hvor:</p> </li> </ol> <p></p> <ol> <li> <p>Ellers v\u00e6lg q_{rip} \\notin \\{q_{start}, q_{accept}\\}q_{rip} \\notin \\{q_{start}, q_{accept}\\}</p> </li> <li> <p>For hvert par (q_i, q_j)(q_i, q_j) opdat\u00e9r transitioner som vist ovenfor.</p> <p>Kald ny GNFA for G'G'.</p> <p>Q_{G'}=Q_G \\smallsetminus \\{q_{rip}\\}Q_{G'}=Q_G \\smallsetminus \\{q_{rip}\\}</p> </li> <li> <p>\\text{CONVERT}(G')\\text{CONVERT}(G')</p> </li> </ol>"},{"location":"4-semester/SS/04-pumping-lemma/","title":"Pumping Lemma","text":"<p>DFA'er kan ikke t\u00e6lle!</p> <p>Hvordan beviser man at et sprog L ikke er regul\u00e6rt?</p> <p>En mulig strategi: Pumping Lemma</p>"},{"location":"4-semester/SS/04-pumping-lemma/#primtal","title":"Primtal","text":"<p>Hvordan viser jeg at et naturligt tal ikke er et primtal?</p> <p>S\u00e6tning:</p> <p>Hvis p er et primtal og p&gt;2 s\u00e5 er p et ulige tal. $$ 2174354654664 $$ Dette ender p\u00e5 4, er dermed et lige tal, og er derfor ikke et primtal.</p>"},{"location":"4-semester/SS/04-pumping-lemma/#pumping-lemma-for-regulre-sprog","title":"Pumping Lemma for regul\u00e6re sprog","text":"<p>Hvis L er et regul\u00e6rt sprog, s\u00e5 findes der et tal p&gt;0p&gt;0 s\u00e5ledes at enhver s\\in Ls\\in L hvor |s| \\geq p|s| \\geq p kan splittes op som s=xyzs=xyz der opfylder:</p> <ol> <li>xy^iz \\in L \\space\\text{for alle}\\space i \\geq0xy^iz \\in L \\space\\text{for alle}\\space i \\geq0</li> <li>|y|&gt;0|y|&gt;0           (y er ikke tom)</li> <li>|xy|\\leq p|xy|\\leq p         (x og y findes blandt de p f\u00f8rste tegn)</li> </ol>"},{"location":"4-semester/SS/04-pumping-lemma/#eksempel-1","title":"Eksempel 1","text":"<p>https://www.youtube.com/watch?v=FJq3NkqyYac&amp;list=PLA8H0-CuqhGFb1yAl_z3XNCZXPrI21dal&amp;index=4</p> <p>Udvid</p> <p>udvid noterne med eksemplet fra videoen.</p>"},{"location":"4-semester/SS/04-pumping-lemma/#eksempel-2","title":"Eksempel 2","text":"<p>https://www.youtube.com/watch?v=i8JPnM3rFrM&amp;index=5&amp;list=PLA8H0-CuqhGFb1yAl_z3XNCZXPrI21dal</p> <p>Udvid</p> <p>udvid noterne med eksemplet fra videoen.</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/","title":"Kontekstfrie Grammatikker","text":"Beskrive Genkende Regul\u00e6re sprog Regul\u00e6re udtryk Endelige automater - NFA og DFA (\u00e6kv.) Kontekstfrie sprog Kontekstfrie grammatikker Pushdown-automater- NDPDA og DPDA (ikke \u00e6kv.)"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#kontekstfri-grammatik-cfg","title":"Kontekstfri Grammatik - CFG","text":"<p>Definition:</p> <p>En kontekstfri grammatik er en 4-tupel $$ (V,\\Sigma,R,S) $$</p> Symbol Betydning V Endelig m\u00e6ngde af variable (aka. nonterminaler) \\Sigma Endelig m\u00e6ngde af terminaler R Endelig m\u00e6ngde af regler S Startvariabel S\\in VS\\in V (aka. startsymbol) <p>Regler i R er p\u00e5 formen: $$ A \\longrightarrow w, \\quad w \\in (V\\cup\\Sigma)^* $$</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#eksempel","title":"Eksempel","text":"<p>Sprog: $$ L={a^nb^n | n \\geq0} $$ CFG: $$ \\text{S} \\longrightarrow \\varepsilon \\ |\\  \\text{aSb} $$</p> <p>\u200b   svarer til:</p>  \\begin{align*} \\text{S} &amp;\\longrightarrow \\varepsilon \\\\ \\text{S} &amp;\\longrightarrow \\text{aSb} \\end{align*}   \\begin{align*} \\text{S} &amp;\\longrightarrow \\varepsilon \\\\ \\text{S} &amp;\\longrightarrow \\text{aSb} \\end{align*}"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#byggelse-af-en-streng","title":"Byggelse af en streng","text":"<p>Strengen aaabbb</p>  \\begin{align*} \\text{S} &amp;\\Rightarrow \\text{aSb} \\\\ &amp; \\Rightarrow \\text{aaSbb} \\\\ &amp; \\Rightarrow \\text{aaaSbbb} \\\\ &amp; \\Rightarrow \\text{aaabbb} \\end{align*}   \\begin{align*} \\text{S} &amp;\\Rightarrow \\text{aSb} \\\\ &amp; \\Rightarrow \\text{aaSbb} \\\\ &amp; \\Rightarrow \\text{aaaSbbb} \\\\ &amp; \\Rightarrow \\text{aaabbb} \\end{align*}"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#derivition","title":"Derivition","text":"<p>Definition:</p> <p>Lad G v\u00e6re en CFG hvor G=(V,\\Sigma,R,S)G=(V,\\Sigma,R,S)  og lad u,v \\in (V\\cup\\Sigma)^*u,v \\in (V\\cup\\Sigma)^*</p> <p>Hvis</p>  \\begin{align*} u&amp;=u_1Au_2 \\quad og \\quad A\\longrightarrow w \\\\ og \\quad v &amp;=u_1wu_2  \\end{align*}   \\begin{align*} u&amp;=u_1Au_2 \\quad og \\quad A\\longrightarrow w \\\\ og \\quad v &amp;=u_1wu_2  \\end{align*}  <p>s\u00e5 skriver vi</p>  u \\Rightarrow v   u \\Rightarrow v  <p>\u200b   u deriverer i et skridt til v $$ u \\Rightarrow^* v $$</p> <p>\u200b   u deriverer i 0 eller flere et skridt til v</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#eksempel_1","title":"Eksempel","text":"<p>Sprog</p>  L_2=\\{w \\in \\{a,b\\}^* \\ | \\ \\text{w er et palindrom}\\}   L_2=\\{w \\in \\{a,b\\}^* \\ | \\ \\text{w er et palindrom}\\}  <p>\u200b   Eksempler: $$ aaa \\in L_2 \\quad abba \\in L_2 \\quad ab \\notin L_2 $$ Regler: $$ S \\longrightarrow \\varepsilon \\ | \\ a \\ | \\ b \\ | \\ aSa \\ | \\ bSb $$ Derivation af abba $$ S \\Rightarrow aSa \\Rightarrow abSba \\Rightarrow abba $$</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#kontekstfrie-sprog","title":"Kontekstfrie sprog","text":"<p>Definition:</p> <p>Lad G=(V,\\Sigma,R,S)G=(V,\\Sigma,R,S)  v\u00e6re en CFG</p> <p>Sproget defineret af G er</p>  L(G)=\\{w\\in\\Sigma^* \\ | \\ S \\Rightarrow^*w\\}   L(G)=\\{w\\in\\Sigma^* \\ | \\ S \\Rightarrow^*w\\}  <p>Et sprog L kalder vi kontekstfrit hvis der findes en CFG G s\u00e5 L=L(G)L=L(G)</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#kontekstfrie-sprog-vs-regulre-sprog","title":"Kontekstfrie sprog vs Regul\u00e6re sprog","text":"<p>S\u00e6tning</p> <p>Hvis M er en DFA, kan vi konstruere en CFG G s\u00e5 L(G)=L(M)L(G)=L(M)</p> <p>Eksempel:</p> <p>\u200b   M:</p> <p></p> <p>Ide i konstruktion: Til hver tilstand svarer en variabel i vores CFG</p>  \\begin{align*} A_1 &amp;\\longrightarrow aA_1 \\ | \\ bA_2 \\ | \\ b\\\\  A_2 &amp;\\longrightarrow vA_2 \\ | \\ aA_1 \\ | \\ b \\ | \\ \\varepsilon \\end{align*}   \\begin{align*} A_1 &amp;\\longrightarrow aA_1 \\ | \\ bA_2 \\ | \\ b\\\\  A_2 &amp;\\longrightarrow vA_2 \\ | \\ aA_1 \\ | \\ b \\ | \\ \\varepsilon \\end{align*}  <p>Generelt:</p> <p>Hvis \\delta(q,a)=q'\\delta(q,a)=q' lav reglen:</p> <p>\u200b   A_q\\longrightarrow aA_{q'}A_q\\longrightarrow aA_{q'}    Hvis q'\\in F: \\quad A_q\\longrightarrow aq'\\in F: \\quad A_q\\longrightarrow a \u200b                   Hvis q\\in F : \\quad A_q\\longrightarrow \\varepsilonq\\in F : \\quad A_q\\longrightarrow \\varepsilon</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#verdenskort-venn-diagram","title":"Verdenskort (Venn diagram)","text":""},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#derivitionstrer-parsetrer","title":"Derivitionstr\u00e6er / Parsetr\u00e6er","text":"<p>Et parsetr\u00e6 er en tr\u00e6repr\u00e6sentation af en derivition.</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#eksempel_2","title":"Eksempel","text":"<p>Aritmetiske udtryk</p>  V=\\{E\\},\\Sigma=\\{+,*,a\\} \\\\ E \\longrightarrow E+E \\ | \\ E*E \\ | \\ a   V=\\{E\\},\\Sigma=\\{+,*,a\\} \\\\ E \\longrightarrow E+E \\ | \\ E*E \\ | \\ a  <p>\"a+a*a\"</p>  E\\Rightarrow E+E \\Rightarrow a+E \\Rightarrow a+E*E \\Rightarrow a+a*E \\Rightarrow a+a*a   E\\Rightarrow E+E \\Rightarrow a+E \\Rightarrow a+E*E \\Rightarrow a+a*E \\Rightarrow a+a*a"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#parsetr","title":"Parsetr\u00e6","text":""},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#men","title":"MEN","text":"<p>Kan ogs\u00e5 deriveres p\u00e5 en anden m\u00e5de:</p>  E\\Rightarrow E*E \\Rightarrow E+E*E \\Rightarrow a+E*E \\Rightarrow a+a*E \\Rightarrow a+a*a   E\\Rightarrow E*E \\Rightarrow E+E*E \\Rightarrow a+E*E \\Rightarrow a+a*E \\Rightarrow a+a*a  <p></p> <p>Grammatikken er tvetydig (ambigous).</p> <p>Begge derivitioner er venstrederivitioner, 2 forskellige venstrederivitioner.</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#tvetydighed","title":"Tvetydighed","text":"<p>Definition:</p> <p>En CFG G er tvetydig hvis der findes en w\\in L(G)w\\in L(G) s\u00e5 S\\Rightarrow^*wS\\Rightarrow^*w med to (eller flere) forskellige venstrederivitioner</p> <p>S\u00e6tning:</p> <p>En CFG G er tvetydig hvis og kun hvis der findes en w\\in L(G)w\\in L(G) som har mindst to forskellige parsetr\u00e6er.</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#indbygget-tvetydighed","title":"Indbygget Tvetydighed","text":"<p>Der findes kontekstfrie sprog L s\u00e5 enhver CFG G s\u00e5 L(G)=LL(G)=L vil v\u00e6re tvetydig.</p> <p>Den slags sprog kaldes indbygget tvetydig</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#bestem-tvetydighed","title":"Bestem Tvetydighed","text":"<p>S\u00e6tning</p> <p>Der findes ikke nogen algoritme, der altid kan fort\u00e6lle os om en CFG er tvetydig.</p> <p>(umulighedsresultat)</p>"},{"location":"4-semester/SS/05-kontekstfrie-grammatikker/#chomsky-normalform-cnf","title":"Chomsky Normalform (CNF)","text":"<p>Definition</p> <p>En CFG er p\u00e5 Chomsky-Normalform (CNF) hvis reglerne overholder:</p> <ul> <li>Eneste tilladte \\varepsilon\\varepsilon-regel er S\\longrightarrow\\varepsilonS\\longrightarrow\\varepsilon</li> <li>Alle andre regler er p\u00e5 formerne:<ul> <li>A\\longrightarrow BCA\\longrightarrow BC</li> <li>A\\longrightarrow aA\\longrightarrow a</li> </ul> </li> <li>S fremkommer ikke p\u00e5 nogen h\u00f8jreside</li> </ul> <p>En CFG p\u00e5 CNF vil altid g\u00f8re at parstr\u00e6er for strenge \"n\u00e6sten bin\u00e6re tr\u00e6er\"</p> <p>Eksempel:</p> <p></p> <p>S\u00e6tning:</p> <p>For enhver CFG G kan vi konstruere en CFG G' p\u00e5 CNF s\u00e5 L(G')=L(G)L(G')=L(G)</p> <p>Bevis (Algoritme):</p> <p>Eksempel:</p>  \\begin{align*} S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon \\end{align*}   \\begin{align*} S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon \\end{align*}  <p>1) (ny startvariabel)</p> <p>Lav ny startvariabel S_1S_1 og regel:</p> <p>$$ S_1 \\longrightarrow S $$ Eksempel:</p>  \\begin{align*} S_1 &amp;\\longrightarrow S \\\\ S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon \\end{align*}   \\begin{align*} S_1 &amp;\\longrightarrow S \\\\ S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon \\end{align*}  <p>2) (fix \\epsilon\\epsilon-regler)</p> <p>Fjern reglerne A \\longrightarrow \\varepsilonA \\longrightarrow \\varepsilon en ad gangen (epsilonregler) og</p> <p>Tilf\u00f8j nye regler hvor 0 eller flere forekomster af A er blevet fjernet.</p> <p>Eksempel:</p>  \\begin{align*} S_1 &amp;\\longrightarrow S \\\\ S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon\\\\ &amp;\\Downarrow \\\\ S_1 &amp;\\longrightarrow S \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab\\\\ \\end{align*}   \\begin{align*} S_1 &amp;\\longrightarrow S \\\\ S &amp;\\longrightarrow aSSb \\ | \\ \\varepsilon\\\\ &amp;\\Downarrow \\\\ S_1 &amp;\\longrightarrow S \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab\\\\ \\end{align*}  <p>Vi fjerner at S kan blive til epsilon. Dette betyder at alle steder hvor der st\u00e5r et S, skal vi kunne skrive epsilon $$ S \\longrightarrow aSSb \\ | \\ aS \\varepsilon b \\ | \\ a \\varepsilon \\varepsilon b\\ $$ 3) (forl\u00e6ngelse af for korte regler)</p> <p>For hver regel der sender \u00e9n variabel over i \u00e9n anden variabel (A\\longrightarrow BA\\longrightarrow B): fjern reglen og erstat med A\\longrightarrow wA\\longrightarrow w for hver regel B\\longrightarrow wB\\longrightarrow w (der skriver B om til w)</p> <p>Eksempel:</p>  \\begin{align*} S_1 &amp;\\longrightarrow S \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab\\\\ &amp;\\Downarrow \\\\ S_1 &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\end{align*}   \\begin{align*} S_1 &amp;\\longrightarrow S \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab\\\\ &amp;\\Downarrow \\\\ S_1 &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\end{align*}  <p>4) (forkortelse af for lange regler)</p> <p>For hver regel A\\longrightarrow u_1u_2...u_k,\\quad k&gt;2A\\longrightarrow u_1u_2...u_k,\\quad k&gt;2 (u_iu_i kan v\u00e6re variabler eller terminaler), lav nye regler og nye variabler.</p>  \\begin{align*} A &amp;\\longrightarrow u_1W_1 \\\\ W_1 &amp;\\longrightarrow u_2W_2 \\\\ &amp;\\quad \\vdots \\\\ W_{k-2} &amp;\\longrightarrow u_{k-1}u_k \\end{align*}   \\begin{align*} A &amp;\\longrightarrow u_1W_1 \\\\ W_1 &amp;\\longrightarrow u_2W_2 \\\\ &amp;\\quad \\vdots \\\\ W_{k-2} &amp;\\longrightarrow u_{k-1}u_k \\end{align*}  <p>Eksempel:</p>  \\begin{align*} S_1 &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\\\ &amp;\\;\\Downarrow \\\\ S_1 &amp;\\longrightarrow aU_1 \\ | \\ aU_3 \\ | \\ ab \\ | \\ \\varepsilon \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow Sb \\\\ U_3 &amp;\\longrightarrow Sb \\\\ S &amp;\\longrightarrow aU_4 \\ | \\ aU_6 \\ | \\ ab \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow Sb \\\\ U_6 &amp;\\longrightarrow Sb \\\\ \\end{align*}   \\begin{align*} S_1 &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\ | \\ \\varepsilon\\\\ S &amp;\\longrightarrow aSSb \\ | \\ aSb \\ | \\ ab \\\\ &amp;\\;\\Downarrow \\\\ S_1 &amp;\\longrightarrow aU_1 \\ | \\ aU_3 \\ | \\ ab \\ | \\ \\varepsilon \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow Sb \\\\ U_3 &amp;\\longrightarrow Sb \\\\ S &amp;\\longrightarrow aU_4 \\ | \\ aU_6 \\ | \\ ab \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow Sb \\\\ U_6 &amp;\\longrightarrow Sb \\\\ \\end{align*}  <p>5)</p> <p>For hver terminal a som ikke er alene p\u00e5 en h\u00f8jreside: lav ny regel U_aU_a</p>  U_a\\longrightarrow a   U_a\\longrightarrow a  <p>Eksempel:</p>  \\begin{align*} S_1 &amp;\\longrightarrow aU_1 \\ | \\ aU_3 \\ | \\ ab \\ | \\ \\varepsilon \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow Sb \\\\ U_3 &amp;\\longrightarrow Sb \\\\ S &amp;\\longrightarrow aU_4 \\ | \\ aU_6 \\ | \\ ab \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow Sb \\\\ U_6 &amp;\\longrightarrow Sb \\\\ &amp;\\;\\Downarrow \\\\ S_1 &amp;\\longrightarrow U_aU_1 \\ | \\ U_aU_3 \\ | \\ U_AU_b \\ | \\ \\varepsilon \\\\ U_a &amp;\\longrightarrow a \\\\ U_b &amp;\\longrightarrow b \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow SU_b \\\\ U_3 &amp;\\longrightarrow SU_b \\\\ S &amp;\\longrightarrow U_aU_4 \\ | \\ U_aU_6 \\ | \\ U_aU_b \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow SU_b \\\\ U_6 &amp;\\longrightarrow SU_b \\\\ \\end{align*}   \\begin{align*} S_1 &amp;\\longrightarrow aU_1 \\ | \\ aU_3 \\ | \\ ab \\ | \\ \\varepsilon \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow Sb \\\\ U_3 &amp;\\longrightarrow Sb \\\\ S &amp;\\longrightarrow aU_4 \\ | \\ aU_6 \\ | \\ ab \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow Sb \\\\ U_6 &amp;\\longrightarrow Sb \\\\ &amp;\\;\\Downarrow \\\\ S_1 &amp;\\longrightarrow U_aU_1 \\ | \\ U_aU_3 \\ | \\ U_AU_b \\ | \\ \\varepsilon \\\\ U_a &amp;\\longrightarrow a \\\\ U_b &amp;\\longrightarrow b \\\\ U_1 &amp;\\longrightarrow SU_2 \\\\ U_2 &amp;\\longrightarrow SU_b \\\\ U_3 &amp;\\longrightarrow SU_b \\\\ S &amp;\\longrightarrow U_aU_4 \\ | \\ U_aU_6 \\ | \\ U_aU_b \\ \\\\ U_4 &amp;\\longrightarrow SU_5 \\\\ U_5 &amp;\\longrightarrow SU_b \\\\ U_6 &amp;\\longrightarrow SU_b \\\\ \\end{align*}"},{"location":"4-semester/SS/06-pushdown-automater/","title":"Pushdown Automater","text":"<p>PDA = en automat med en stak</p> <p>Udvid noter</p> <p>inds\u00e6t information om overf\u00f8ringsfunktion fra SS6 afsnit 2 https://www.youtube.com/watch?v=KUZwifJbGxE&amp;list=PLA8H0-CuqhGGH6lTKmcgzzmK7kkwX75rF&amp;index=2</p> <p>Definition</p> <p>En pushdown-automat (PDA) er en 6-tupel $$ (Q,\\Sigma, \\Gamma, q_0, \\delta, F) $$</p> Symbol Betydning Q M\u00e6ngde af tilstande \\Sigma Input alfabet \\Gamma\\Gamma Stak alfabet q_0q_0 Starttilstand q_0 \\in Qq_0 \\in Q \\delta\\delta Overf\u00f8rselsfunktion F Accepttilstande F\\subseteq QF\\subseteq Q  \\delta:\\quad Q \\times \\Sigma_{\\varepsilon} \\times \\Gamma_{\\varepsilon} \\longrightarrow \\mathcal{P}(Q \\times \\Gamma_{\\varepsilon})   \\delta:\\quad Q \\times \\Sigma_{\\varepsilon} \\times \\Gamma_{\\varepsilon} \\longrightarrow \\mathcal{P}(Q \\times \\Gamma_{\\varepsilon})"},{"location":"4-semester/SS/06-pushdown-automater/#pda-som-en-orienteret-graf","title":"PDA Som en Orienteret Graf","text":"<p>Betyder:</p> <p>N\u00e5r PDA'en er i tilstand q og ser a som n\u00e6ste input tegn og x er \u00f8verst p\u00e5 stakken, s\u00e5 skift til tilstand r og erstat x med y. $$ (r,y)\\in\\delta(q,a,x) $$</p>"},{"location":"4-semester/SS/06-pushdown-automater/#eksempel","title":"Eksempel","text":"L=\\{a^nb^n\\ | \\ n\\geq 0\\}   L=\\{a^nb^n\\ | \\ n\\geq 0\\}  <p>$ bruges som bundmark\u00f8r i stakken.</p> <p>Inputstreng: aabb</p> <p>Stakindhold:</p> <p></p>"},{"location":"4-semester/SS/06-pushdown-automater/#sprog-accepteret-af-pda","title":"Sprog Accepteret af PDA","text":"<p>Lad M=(Q,\\Sigma, \\Gamma, q_0, \\delta, F)M=(Q,\\Sigma, \\Gamma, q_0, \\delta, F) v\u00e6re en PDA</p> <p>Lad w\\in\\Sigma^*w\\in\\Sigma^*, hvor w=u_1...u_kw=u_1...u_k, hvor u_i\\in\\Sigma_{\\varepsilon} \\quad (1\\leq i\\leq k)u_i\\in\\Sigma_{\\varepsilon} \\quad (1\\leq i\\leq k)</p> <p>M accepterer w hvis:</p> <ol> <li> <p>Der findes en f\u00f8lge af tilstande r_0...r_kr_0...r_k</p> </li> <li> <p>Der findes en f\u00f8lge af stakindhold s_0...s_ks_0...s_k</p> <p>(s_i\\in\\Gamma^* \\ \\text{for} \\ 0\\leq i \\leq k)(s_i\\in\\Gamma^* \\ \\text{for} \\ 0\\leq i \\leq k)</p> <p>Der g\u00e6lder om (1) og (2) at:</p> <ul> <li>r_0=q_0,\\quad s_0=\\varepsilonr_0=q_0,\\quad s_0=\\varepsilon</li> <li>\\text{for alle}\\ 0\\leq i \\leq k\\text{for alle}\\ 0\\leq i \\leq k g\u00e6lder:</li> </ul>  \\begin{align*}  &amp;&amp; s_i &amp;=a_iS_i' \\\\ (r_{i+1}&amp;,a_{i+1}) \\in \\delta(r_i,u_{i+1},a_i) &amp; s_{i+1} &amp;=a_{i+1}S_i' \\end{align*}   \\begin{align*}  &amp;&amp; s_i &amp;=a_iS_i' \\\\ (r_{i+1}&amp;,a_{i+1}) \\in \\delta(r_i,u_{i+1},a_i) &amp; s_{i+1} &amp;=a_{i+1}S_i' \\end{align*}  <ul> <li>r_k\\in Fr_k\\in F</li> </ul> </li> </ol>"},{"location":"4-semester/SS/06-pushdown-automater/#eksempel-2-3","title":"Eksempel 2-3","text":"<p>Udvid noter</p> <p>inds\u00e6t eksempler fra SS6 afsnit 4 [https://www.youtube.com/watch?v=eBgtVhYUf50&amp;list=PLA8H0-CuqhGGH6lTKmcgzzmK7kkwX75rF&amp;index=4]</p>"},{"location":"4-semester/SS/06-pushdown-automater/#lav-pushdown-automat-ud-fra-cfg","title":"Lav Pushdown Automat ud fra CFG","text":"<ol> <li>Placer markersymbol $, og startvariablen p\u00e5 stakken.</li> <li>Gentag forevigt:<ol> <li>Hvis toppen af stakken er en variabel A, nondeterministisk v\u00e6lg en af reglerne for A og substituer A med strengen p\u00e5 h\u00f8jre side af reglen.</li> <li>Hvis toppen af stakken er en terminal a, l\u00e6s n\u00e6ste symbol fra input og sammenlign med a. Hvis de matcher, gentag. Hvis de ikke matcher, afvis p\u00e5 denne gren.</li> <li>Hvis toppen af stakken er $, g\u00e5 ind i accept tilstand.</li> </ol> </li> </ol>"},{"location":"4-semester/SS/07-pumping-lemma-for-kontekstfrie-sprog/","title":"Pumping Lemma for Kontekstfrie Sprog","text":"<p>S\u00e6tning </p> <p>Hvis L er et kontekstfrit sprog, s\u00e5 findes der et p&gt;0 s\u00e5ledes at for alle s\\in Ls\\in L hvor |s|\\geq p|s|\\geq p, findes der en opsplitning s=uvxyzs=uvxyz s\u00e5ledes at:</p> <ol> <li>uv^ixy^iz\\in Luv^ixy^iz\\in L for alle i\\geq0i\\geq0</li> <li>|vy|&gt;0|vy|&gt;0<ul> <li>v og y er ikke begge tomme</li> </ul> </li> <li>|vxy|\\le p|vxy|\\le p<ul> <li>v og y skal findes inden for et vindue p\u00e5 p tegn</li> </ul> </li> </ol> <p>Anvendelse</p> <p>Vise at L ikke er kontekstfrit (modstridsbevis):</p> <ul> <li>Antag L var kontekstfrit, s\u00e5 var der et p&gt;0\u200bp&gt;0\u200b s\u00e5 alle s\\in L\u200bs\\in L\u200b hvor |s|\\geq p\u200b|s|\\geq p\u200b har en opsplitning s\u00e5 (1), (2) og (3) er overholdt.</li> <li>Men s\u00e5 finder vi en s\\in L, \\quad |s|\\geq p\u200bs\\in L, \\quad |s|\\geq p\u200b, s\u00e5 ingen opsplitning kan overholde (1), (2) og (3)</li> </ul>"},{"location":"4-semester/SS/07-pumping-lemma-for-kontekstfrie-sprog/#eksempel","title":"Eksempel","text":"<p>L=\\{a^nb^nc^n\\ | \\ n \\geq 0\\}L=\\{a^nb^nc^n\\ | \\ n \\geq 0\\}     (Kongeeksemplet p\u00e5 et ikke kontekstfrit sprog)</p> <p>Antag at L var kontekstfrit. S\u00e5 var der et p&gt;0p&gt;0 s\u00e5 for alle s\\in Ls\\in L hvor |s|\\geq p|s|\\geq p findes en opsplitning s\u00e5 (1), (2) og (3) er overholdt.</p> <p>MEN, s\u00e5 finder vi en s\\in L, \\quad |s|\\geq ps\\in L, \\quad |s|\\geq p, s\u00e5 ingen opsplitning kan overholde (1), (2) og (3)</p> <p>\u200b   V\u00e6lg s=a^pb^pc^ps=a^pb^pc^p,     klart at |s|=3p\\geq p|s|=3p\\geq p</p> <p>Unders\u00f8g nu alle mulige opsplitninger. $$ \\underbrace{a...a}_p\\ \\underbrace{b...b}_p \\ \\underbrace{c...c}_p $$ Hvor kan v og y ligge henne? </p> <ul> <li>v eller y indeholder flere slags tegn.<ul> <li>S\u00e5 bliver (1) overtr\u00e5dt; uv^ixy^i z\u200buv^ixy^i z\u200b har tegn i forkert r\u00e6kkef\u00f8lge</li> </ul> </li> <li>v best\u00e5r af a'er.<ul> <li>Men hvis (3) skal g\u00e6lde, s\u00e5 m\u00e5 y best\u00e5 af a'er eller af b'er. Og s\u00e5 bliver (1) overtr\u00e5dt:<ul> <li>uv^ixy^i zuv^ixy^i z har for f\u00e5 c'er</li> </ul> </li> </ul> </li> <li>v best\u00e5r af b'er. <ul> <li>Men s\u00e5 skal y best\u00e5 af b'er eller af c'er, hvis (3) skal overholdes. Men s\u00e5 vil der v\u00e6re for f\u00e5 a'er.</li> </ul> </li> <li>v best\u00e5r af c'er.<ul> <li>S\u00e5 skal y ogs\u00e5 kun best\u00e5 af c'er. S\u00e5 vil der v\u00e6re for mange c'er</li> </ul> </li> </ul> <p>Ingen opsplitning er gyldig, DVS: L er ikke kontekstfrit. </p>"},{"location":"4-semester/SS/15-rekursive-definitioner/","title":"Rekursive Definitioner","text":"<ul> <li>En rekursiv definition giver anledning til en h\u00f8jresidefunktion f</li> <li>Definitionen har en \"l\u00f8sning\" hvis ff har et fikspunkt</li> </ul> <p>$$ L_S={a}\\ L_S\\ {b} \\cup {c} \\cup L_s $$ Lav en h\u00f8jresidefunktion:</p>  f(X)=\\{a\\}\\ X\\ \\{b\\} \\cup \\{c\\} \\cup X   f(X)=\\{a\\}\\ X\\ \\{b\\} \\cup \\{c\\} \\cup X  <p>ff er en funktion over sprog - Eks:</p>  \\begin{align*} f(\\{aa,b\\}) \\\\ &amp;= \\{a\\}\\{aa,b\\}\\{b\\} \\cup \\{c\\} \\cup \\{aa,b\\} \\\\ &amp;= \\{aaab,abb\\} \\cup\\{c\\} \\cup \\{aa,b\\} \\\\ &amp;= \\{aaab,abb,c,aa,b\\} \\end{align*}   \\begin{align*} f(\\{aa,b\\}) \\\\ &amp;= \\{a\\}\\{aa,b\\}\\{b\\} \\cup \\{c\\} \\cup \\{aa,b\\} \\\\ &amp;= \\{aaab,abb\\} \\cup\\{c\\} \\cup \\{aa,b\\} \\\\ &amp;= \\{aaab,abb,c,aa,b\\} \\end{align*}  <p>Vi vil gerne have et L_sL_s s\u00e5 f(L_s)=L_sf(L_s)=L_s</p> <p>\u200b   L_sL_s er et fikspunkt for funktionen ff</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#fikspunkt","title":"Fikspunkt","text":"<p>Lad f:A\\to Af:A\\to A</p> <p>xx er et fikspunkt for ff hvis f(x)=xf(x)=x</p> <p>Jagten p\u00e5 en \"l\u00f8sning\" til en rekursiv definition er faktisk jagten p\u00e5 et fikspunkt for h\u00f8jresidefunktionen.</p> <p>F\u00f8lge af tiln\u00e6rmelser:</p>  \\begin{align*} f^0(\\varnothing) &amp;= \\varnothing \\\\ f^1(\\varnothing) &amp;= \\{a\\} \\varnothing \\{b\\} \\cup \\{c\\} \\cup \\varnothing &amp;&amp;= \\{c\\} \\\\ f^2(\\varnothing) &amp;= f(f(\\varnothing)) &amp;&amp;= \\{acb,c\\} \\\\ f^3(\\varnothing) &amp;= f(f^2(\\varnothing)) &amp;&amp;= \\{aacbb, acb,c\\} \\\\ f^4(\\varnothing) &amp;= f(f^3(\\varnothing)) &amp;&amp;= \\{aaacbbb, aacbb, acb,c\\} \\\\ f^n(\\varnothing) &amp;&amp;&amp;= \\{a^icb^i\\ |\\ 0 \\leq i &lt; n\\} \\\\ \\end{align*}   \\begin{align*} f^0(\\varnothing) &amp;= \\varnothing \\\\ f^1(\\varnothing) &amp;= \\{a\\} \\varnothing \\{b\\} \\cup \\{c\\} \\cup \\varnothing &amp;&amp;= \\{c\\} \\\\ f^2(\\varnothing) &amp;= f(f(\\varnothing)) &amp;&amp;= \\{acb,c\\} \\\\ f^3(\\varnothing) &amp;= f(f^2(\\varnothing)) &amp;&amp;= \\{aacbb, acb,c\\} \\\\ f^4(\\varnothing) &amp;= f(f^3(\\varnothing)) &amp;&amp;= \\{aaacbbb, aacbb, acb,c\\} \\\\ f^n(\\varnothing) &amp;&amp;&amp;= \\{a^icb^i\\ |\\ 0 \\leq i &lt; n\\} \\\\ \\end{align*}  <p>Gr\u00e6nsev\u00e6rdien for f\u00f8lgen: \\{a^icb^i\\ |\\ i \\geq 0\\}\\{a^icb^i\\ |\\ i \\geq 0\\}</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#partiel-ordning","title":"Partiel Ordning","text":"<p>Lad DD v\u00e6re en m\u00e6ngde og \\sqsubseteq\\sqsubseteq v\u00e6re en bin\u00e6r relation over DD, (dvs. relaterer par af elementer).</p> <p>(D,\\sqsubseteq)(D,\\sqsubseteq) er en partiel ordning hvis:</p>  \\begin{align*} &amp;(1) &amp;&amp;\\text{For alle }d \\in D : &amp;&amp;d \\sqsubseteq d \\\\ &amp;(2) &amp;&amp;\\text{For alle }d_1d_2 \\in D : &amp;&amp;\\text{hvis } d_1  \\sqsubseteq d_2 \\text{ og } d_2  \\sqsubseteq d_1 \\text{ s\u00e5 } d_1=d_2 \\\\ &amp;(3) &amp;&amp;\\text{For alle } d_1,d_2,d_3 \\in D: &amp;&amp;\\text{hvis } d_1 \\sqsubseteq d_2 \\text{ og } d_2 \\sqsubseteq d_3 \\text{ s\u00e5 } d_1 \\sqsubseteq d_3 \\end{align*}   \\begin{align*} &amp;(1) &amp;&amp;\\text{For alle }d \\in D : &amp;&amp;d \\sqsubseteq d \\\\ &amp;(2) &amp;&amp;\\text{For alle }d_1d_2 \\in D : &amp;&amp;\\text{hvis } d_1  \\sqsubseteq d_2 \\text{ og } d_2  \\sqsubseteq d_1 \\text{ s\u00e5 } d_1=d_2 \\\\ &amp;(3) &amp;&amp;\\text{For alle } d_1,d_2,d_3 \\in D: &amp;&amp;\\text{hvis } d_1 \\sqsubseteq d_2 \\text{ og } d_2 \\sqsubseteq d_3 \\text{ s\u00e5 } d_1 \\sqsubseteq d_3 \\end{align*}  <p>En partiel ordning er alts\u00e5 bare en  ordnet m\u00e6ngde der opf\u00f8rer sig ligesom \\N\\N (de naturlige tal) ordnet under \\leq\\leq</p> <p>(\\N, \\leq)(\\N, \\leq) er en partiel ordning</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#eksempel","title":"Eksempel","text":"<p>Lad SS v\u00e6re en m\u00e6ngde.</p> <p>(\\mathcal{P}(S),\\subseteq)(\\mathcal{P}(S),\\subseteq) er en partiel ordning.</p> <p>\u200b   S=\\{1,2,3\\}S=\\{1,2,3\\}</p> <p></p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#vre-grnse","title":"\u00d8vre Gr\u00e6nse","text":"<p>Lad (D, \\sqsubseteq)(D, \\sqsubseteq) v\u00e6re en po (partiel ordning), og lad Y\\subseteq DY\\subseteq D</p> <p>Lad x\\in Dx\\in D.   xx er en \u00f8vre gr\u00e6nse for yy hvis:</p> <p>\u200b   for alle y \\in Y:y \\sqsubseteq xy \\in Y:y \\sqsubseteq x</p> <p>Hvis x er det mindste s\u00e5danne, kalder vi x for den mindste \u00f8vre gr\u00e6nse for y.</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#eksempel_1","title":"Eksempel","text":"<p>D=\\{1,2,3,4,5,6\\}D=\\{1,2,3,4,5,6\\}</p> <p>\\sqsubseteq\\sqsubseteq defineres ved x \\sqsubseteq yx \\sqsubseteq y hvis x \\leq yx \\leq y</p> <p>\u200b   (D, \\sqsubseteq)(D, \\sqsubseteq) er en po.</p> <p>Lad Y=\\{1,2,3\\}Y=\\{1,2,3\\}</p> <p>\u200b   4 er en \u00f8vre gr\u00e6nse for YY.</p> <p>\u200b   3 er den mindste \u00f8vre gr\u00e6nse for YY.</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#notation","title":"Notation","text":"<p>Hvis xx er den mindste \u00f8vre gr\u00e6nse for yy kalder vi xx for \\lim{Y}\\lim{Y}</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#kde","title":"K\u00e6de","text":"<p>Lad (D, \\sqsubseteq)(D, \\sqsubseteq) v\u00e6re en po.</p> <p>En k\u00e6de i DD er en voksende f\u00f8lge af elementer i DD</p> <p>\u200b   Y=\\{y_0,y_1,...\\}Y=\\{y_0,y_1,...\\}</p> <p>hvor</p> <p>\u200b   y_0 \\sqsubseteq y_1 \\sqsubseteq y_2 \\ ...y_0 \\sqsubseteq y_1 \\sqsubseteq y_2 \\ ...</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#fuldstndig-partiel-ordning-domne","title":"Fuldst\u00e6ndig Partiel Ordning (Dom\u00e6ne)","text":"<p>Lad (D,\\sqsubseteq)(D,\\sqsubseteq) v\u00e6re en po. Den kaldes fuldst\u00e6ndig partial ordning (fpo) hvis det g\u00e6lder at:</p> <ol> <li>For enhver k\u00e6de i D,YD,Y, har vi at \\lim{Y}\\lim{Y} findes     (enhver voksende f\u00f8lge har en mindste \u00f8vre gr\u00e6nse)</li> <li>Der findes et mindste element, \\perp\\perp s\u00e5: \\perp \\sqsubseteq x\\perp \\sqsubseteq x for alle x \\in Dx \\in D     (\\perp\\perp er mindst af alle)</li> </ol>"},{"location":"4-semester/SS/15-rekursive-definitioner/#monoton","title":"Monoton","text":"<p>Lad (D,\\sqsubseteq)(D,\\sqsubseteq) v\u00e6re en po og f:D\\to Df:D\\to D v\u00e6re en funktion.</p> <p>ff er monoton hvis:</p> <p>\u200b   for alle x,y \\in Dx,y \\in D : hvis x \\sqsubseteq yx \\sqsubseteq y s\u00e5 f(x) \\sqsubseteq f(y)f(x) \\sqsubseteq f(y) \u200b       (voksende mht. \\sqsubseteq\\sqsubseteq)</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#kontinuert-funktion","title":"Kontinuert Funktion","text":"<p>Lad (D, \\sqsubseteq)(D, \\sqsubseteq) v\u00e6re en fpo.</p> <p>f: D \\to Df: D \\to D er monoton.</p> <p>ff er kontinuert hvis for enhver k\u00e6de Y= \\{y_0,y_1,...\\}Y= \\{y_0,y_1,...\\} har vi at</p> <p>\u200b   f(\\lim{Y})= \\lim{f(y_0)}f(\\lim{Y})= \\lim{f(y_0)}  \u200b       (ff bevarer gr\u00e6nsev\u00e6rdi; ff kan flyttes ind under \\lim\\lim)</p>"},{"location":"4-semester/SS/15-rekursive-definitioner/#eksistens-af-mindste-fikspunkt-for-funktion","title":"Eksistens af Mindste Fikspunkt for Funktion","text":"<p>Lad (D, \\sqsubseteq)(D, \\sqsubseteq) v\u00e6re en fpo, og lad f:D \\to Df:D \\to D v\u00e6re kontinuert.</p> <p>S\u00e5 har ff et mindste fikspunkt (mht \\sqsubseteq\\sqsubseteq) som er givet ved:</p>  \\begin{align*} x^* &amp;= \\lim_{i \\geq 0}{\\{f^0(\\perp), f^1(\\perp), f^2(\\perp),\\ ...\\}} \\\\ &amp;= \\lim{\\{f^i(\\perp)\\ |\\ i \\geq 0\\}} \\end{align*}   \\begin{align*} x^* &amp;= \\lim_{i \\geq 0}{\\{f^0(\\perp), f^1(\\perp), f^2(\\perp),\\ ...\\}} \\\\ &amp;= \\lim{\\{f^i(\\perp)\\ |\\ i \\geq 0\\}} \\end{align*}"},{"location":"5-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>CC - Beregnelighed og Kompleksitet</li> <li>MI - Machine Intelligence</li> <li>SOE - Software Engineering</li> </ul> <p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=31415</p> <p></p>"},{"location":"5-semester/CC/","title":"CC - Beregnelighed og Kompleksitet","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=31439</p> <p></p>"},{"location":"5-semester/CC/01-turing-maskiner/","title":"Turing Maskiner","text":"\\newcommand{\\TM}{(Q,\\Gamma, \\Sigma, \\delta, q_0, q_{accept}, q_{reject})}"},{"location":"5-semester/CC/01-turing-maskiner/#turing-maskiner","title":"Turing Maskiner","text":""},{"location":"5-semester/CC/01-turing-maskiner/#turing-maskine","title":"Turing Maskine","text":"<p>Definition</p> <p>En 7-tuppel \\TM\\TM</p> <ul> <li>QQ endelig m\u00e6ngde af tilstande</li> <li>\\Gamma\\Gamma b\u00e5nd-alfabet</li> <li>\\Sigma\\Sigma input alfabet (\\Sigma \\subseteq \\Gamma\\Sigma \\subseteq \\Gamma)</li> <li>\\delta\\delta overf\u00f8ringsfuntion</li> <li>q_0q_0 starttilstand (q_0 \\in Qq_0 \\in Q)</li> <li>q_{accept}q_{accept} accepttilstand (q_{accept} \\in Qq_{accept} \\in Q)</li> <li>q_{reject}q_{reject} forkasttilstand (q_{reject} \\in Qq_{reject} \\in Q)</li> </ul> <p>q_{accept} \\neq q_{reject}q_{accept} \\neq q_{reject} $$ \\delta: (Q \\setminus {q_{accept},q_{reject}}) \\times \\Gamma \\to Q \\times \\Gamma \\times {L,R} $$</p> <p>LL: Venstre     RR: H\u00f8jre</p> <p>Example</p> <p>Se eksempel Lektion 1, Video 2</p> <p></p>"},{"location":"5-semester/CC/01-turing-maskiner/#konfiguration","title":"Konfiguration","text":"<p>Definition</p> <p>Givet en TMTM M = \\TMM = \\TM</p> <p>er en konfiguration en streng $$ uqav, $$ hvor uu er del af b\u00e5nd til venstre for hoved (u\\in\\Gamma^*)(u\\in\\Gamma^*), og q\\in Qq\\in Q, og aa indhold af det felt MM ser nu (a \\in \\Gamma)(a \\in \\Gamma), og vv ikke-tomme del af b\u00e5nd til h\u00f8jre for hoved (v \\in \\Gamma^*)(v \\in \\Gamma^*)</p>"},{"location":"5-semester/CC/01-turing-maskiner/#beregning","title":"Beregning","text":"<p>Definition</p> <p></p>"},{"location":"5-semester/CC/01-turing-maskiner/#standsende-beregning","title":"Standsende Beregning","text":"<p>En turing maskine kan g\u00e5 i en uendelig l\u00f8kke!</p>"},{"location":"5-semester/CC/01-turing-maskiner/#accept-af-streng","title":"Accept af Streng","text":"<p>Definition</p> <p>En TMTM MM accepterer input ww, hvis:</p> <ul> <li>MM har en accepterende beregning p\u00e5 input ww</li> </ul> <p>En TMTM MM afviser input ww hvis:</p> <ul> <li>MM har en afvisende beregning p\u00e5 input ww</li> </ul> <p>Bem\u00e6rk: At MM ikke accepterer ww er ikke det samme som at MM afviser ww, da en TMTM kan g\u00e5 i en uendelig l\u00f8kke!</p>"},{"location":"5-semester/CC/01-turing-maskiner/#turing-genkendelig-sprog","title":"Turing Genkendelig Sprog","text":"<p>Med andre ord:</p> <p></p>"},{"location":"5-semester/CC/01-turing-maskiner/#afgrbart","title":"Afg\u00f8rbart","text":"<p>Note</p> <p>Inds\u00e6t fra afsnit 4 og frem</p>"},{"location":"5-semester/CC/02-church-turing-tesen/","title":"Church-Turing-Tesen","text":"\\newcommand{\\TM}{(Q,\\Gamma, \\Sigma, \\delta, q_0, q_{accept}, q_{reject})}"},{"location":"5-semester/CC/02-church-turing-tesen/#chuch-turing-tesen","title":"Chuch-Turing-Tesen","text":""},{"location":"5-semester/CC/02-church-turing-tesen/#lringsmal","title":"L\u00e6ringsm\u00e5l","text":"<ul> <li>Forst\u00e5 \u00e6kvivalensen mellem de udvidede turing-maskin-modeller og den oprindelige Turing-maskin-model</li> <li>Forst\u00e5 Church-Turing-tesen og hvad dens foruds\u00e6tninger er.</li> <li>Forst\u00e5 at der er en dualitet mellem beslutningsproblemer og medlemskab af sprog</li> <li>Andvende dualiteten mellem beslutningsproblemer og sprog til at overs\u00e6tte instanser af det ene begreb til instanser af det andet.</li> <li>Forst\u00e5 strengbeskrivelses-notation og dens rolle og kunne anvende den til at overs\u00e6tte beslutningsproblemer til sprog.</li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#flere-band","title":"Flere B\u00e5nd?","text":"<p>Overf\u00f8ringsfunktion: $$ \\delta: Q \\times \\Gamma^k \\longrightarrow Q \\times (\\Gamma \\times {L,R})^k $$</p>"},{"location":"5-semester/CC/02-church-turing-tesen/#simulering-af-en-k-bands-tm-med-et-band","title":"Simulering af en k-b\u00e5nds TM med \u00e9t B\u00e5nd","text":"<p>Prikkerne markerer l\u00e6sehovedets placering</p>  \\Gamma_{\\text{ny}} = \\Gamma \\cup \\{\\dot{a} \\mid a \\in \\Gamma\\} \\cup \\{\\#\\}   \\Gamma_{\\text{ny}} = \\Gamma \\cup \\{\\dot{a} \\mid a \\in \\Gamma\\} \\cup \\{\\#\\}  <p>Simulering af et skridt:</p> <ol> <li>Scan den ikke-blanke del af b\u00e5ndet, og find ud af hvad prikkerne peger p\u00e5 (Husk det vhja. tilstand)</li> <li>Flytte prikker og erstat tegn s\u00e5dan som k-b\u00e5nds-maskinen ville kr\u00e6ve det.<ul> <li>Skub indhold mod h\u00f8jre, om n\u00f8dvendigt</li> </ul> </li> </ol>"},{"location":"5-semester/CC/02-church-turing-tesen/#stning","title":"S\u00e6tning","text":"<p>Hvis et sprog LL kan genkendes af en k-b\u00e5nds-TM, kan LL ogs\u00e5 genkendes af en 1-b\u00e5nds-TM.</p> <ul> <li>Flere b\u00e5nd betyder ikke noget for regnekraft!</li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#nondeterminisme","title":"Nondeterminisme","text":"DFA \\sim NFA\\\\ DPDA \\nsim PDA\\\\ \\scriptstyle (DPDA \\to PDA)\\\\ \\scriptstyle (DPDA \\nleftarrow PDA)\\\\   DFA \\sim NFA\\\\ DPDA \\nsim PDA\\\\ \\scriptstyle (DPDA \\to PDA)\\\\ \\scriptstyle (DPDA \\nleftarrow PDA)\\\\   TM \\sim NTM   TM \\sim NTM  <p>Overf\u00f8ringsfunktion for NTM: $$ \\delta : Q \\times \\Gamma \\longrightarrow \\mathcal{P}(Q \\times \\Gamma) $$</p>"},{"location":"5-semester/CC/02-church-turing-tesen/#eksempel","title":"Eksempel","text":"<p> $$ \\delta(q_8, a)={(q_9,b,R),(q_7, a,R)} $$ </p>"},{"location":"5-semester/CC/02-church-turing-tesen/#accept","title":"Accept","text":"<p>Definition</p> <p>En NTM MM accepterer en streng, hvis der i beregningstr\u00e6et for strengen forekommer en konfiguration hvis tilstand er q_{accept}q_{accept}</p>"},{"location":"5-semester/CC/02-church-turing-tesen/#simulering-af-ntm","title":"Simulering af NTM","text":"<p>Sker ved at gennemvandre beregningstr\u00e6et og lede efter en accepterende konfiguration</p> <p>Problem: NTM'er kan g\u00e5 i uendelig l\u00f8kke, s\u00e5 grene i tr\u00e6et KAN v\u00e6re uendeligt lange!</p> <p>L\u00f8sning:</p> <p>Id\u00e9: Brug breddes\u00f8gning</p> <p></p> <p></p> <p>P\u00e5 input ww</p> <ol> <li>Kopier ww over p\u00e5 b\u00e5nd 1</li> <li>For k=0,1,2,...k=0,1,2,... <ol> <li>Kopier input fra b\u00e5nd 1 til b\u00e5nd 2</li> <li>Generer n\u00e6ste indexf\u00f8lge af l\u00e6ngde kk</li> <li>Simuler en beregning p\u00e5 b\u00e5nd 2 svarende til indexf\u00f8lgen p\u00e5 b\u00e5nd 3</li> <li>Hvis beregningen bes\u00f8ger q_{accept}q_{accept}: accepter!</li> </ol> </li> </ol>"},{"location":"5-semester/CC/02-church-turing-tesen/#stning_1","title":"S\u00e6tning","text":"<p>Hvis LL kan genkendes af en NTM, kan LL genkendes af en TM!</p> <ul> <li>Vigtigt af flere grunde: <ul> <li>Nondeterminisme giver ikke \u00f8get regnekraft</li> <li>Vi m\u00e5 godt g\u00f8re brug af nondeterminisme!</li> </ul> </li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#enumerator","title":"Enumerator","text":"<p>TM'er som sproggenkendere:</p>  L_{input}(M)=\\{ w \\in \\Sigma^* \\mid M\\ \\text{accepterer}\\ w \\}0   L_{input}(M)=\\{ w \\in \\Sigma^* \\mid M\\ \\text{accepterer}\\ w \\}0  <p>TM'er som sproggeneratorer (enumerator):</p>  L_{output}(M)=\\{ w \\in \\Gamma^* \\mid M\\ \\text{udskriver}\\ w\\ \\text{p\u00e5 tomt input} \\}   L_{output}(M)=\\{ w \\in \\Gamma^* \\mid M\\ \\text{udskriver}\\ w\\ \\text{p\u00e5 tomt input} \\}"},{"location":"5-semester/CC/02-church-turing-tesen/#stning_2","title":"S\u00e6tning","text":"<p>LL er et genkendeligt</p> <p>\u200b   \\Updownarrow\\Updownarrow</p> <p>\\exists\\exists enumerator EE s\u00e5 EE outputter LL (L_{output}(E)=LL_{output}(E)=L)</p> <p>Se bevis i Lektion 2, afsnit 4</p>"},{"location":"5-semester/CC/02-church-turing-tesen/#andre-modeller-for-beregnelighed","title":"Andre Modeller for Beregnelighed","text":"<p>Alle modeller for beregnelighed vi kender i dag, er h\u00f8jest lige s\u00e5 st\u00e6rke som Turing Maskiner.</p> <ul> <li>Inklusive programmeringssprog</li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#church-turing-tesen","title":"Church-Turing-tesen","text":"<p>Enhver model for beregnelighed vil v\u00e6re h\u00f8jest lige s\u00e5 st\u00e6rk som TM-modellen, hvis ellers den er rimelig.</p> <ul> <li>Kan ikke bevises (ikke en matematisk s\u00e6tning)<ul> <li>Kan potentielt modbevises.</li> </ul> </li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#konsekvenser","title":"Konsekvenser","text":"<ul> <li>Alle varianter af TM'er er nyttige, n\u00e5r vi skal vise at et sprog er genkendeligt</li> <li>Pseudokode er nok til at beskrive en TM's adf\u00e6rd</li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#beslutningsproblemer-og-sprog","title":"Beslutningsproblemer og Sprog","text":"<p>Beslutningsproblemer:</p> <ul> <li>Ja-nej-sp\u00f8rgsm\u00e5l<ul> <li>Eksempler:</li> <li>Givet en graf G, er G sammenh\u00e6ngende?</li> <li>Givet et tal n, er n et primtal?</li> <li>Givet en TM M og et input w, vil M acceptere w?</li> </ul> </li> </ul> <p>De understregede elementer er parametre / input i problemet.</p> <p>Sprog \\leftrightarrow\\leftrightarrow Beslutningsproblem</p> <p>Et hvert beslutningsproblem kan formuleres som et sprog. Og til hvert sprog er der et beslutningsproblem: </p> <ul> <li>Givet ww, er w\\in Lw\\in L?</li> </ul>"},{"location":"5-semester/CC/02-church-turing-tesen/#eksempel_1","title":"Eksempel","text":"<p>\"Givet GG, er GG da en sammenh\u00e6ngende graf?\"</p> <p></p> <p>&lt;G&gt;&lt;G&gt;: Strengrepr\u00e6sentationen af GG</p> <p>Problem svarer til: $$ CONN={\\ \\mid G\\ \\text{er en sammenh\u00e6ngende graf}} $$ <p>Alts\u00e5</p> <p>Et beslutningsproblem kan afg\u00f8res med en algoritme hvis, det tilsvarende sprog er afg\u00f8rbart!</p>"},{"location":"5-semester/CC/03-acceptproblemet-for-tm/","title":"Acceptproblemet for Turing-maskiner","text":"<p>Theorem 4.11</p> <p>A_{TM} er uafg\u00f8rbart</p> <p>Theorem 4.2.2</p> <p>Et sprog LL er afg\u00f8rbart hvis og kun hvis LL er genkendeligt og \\overline L\\overline L er genkendeligt.</p> <p>\u200b   Alts\u00e5: Et sprog er afg\u00f8rbart pr\u00e6cis n\u00e5r b\u00e5de det og dets komplement er genkendeligt.</p> <p>Corollary 4.23</p> <p>\\overline {A_{TM}}\\overline {A_{TM}} er ikke genkendeligt</p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/","title":"Er der Flere Problemer end Algoritmer? Og er Problemer Besl\u00e6gtede?","text":"<p>L\u00e6ringsm\u00e5l</p> <ul> <li> <p>Forst\u00e5 begreberne \"samme st\u00f8rrelse\" for m\u00e6ngder og de begreber, der er n\u00f8dvendige for at definere det (herunder bjektioner)</p> </li> <li> <p>Forst\u00e5 og kunne anvende teknikken til diagonalisering</p> </li> <li> <p>Forst\u00e5 hvordan diagonaliseringsteknikken og beviset for uafg\u00f8rbarhed er relateret</p> </li> <li> <p>Forst\u00e5 s\u00e6tningen om uafg\u00f8rbarhed for HALT_{TM} og dens bevis ved reduktion</p> <p></p> </li> </ul>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#mngdens-strrelse","title":"M\u00e6ngdens St\u00f8rrelse","text":"<p>Enentydig (1-1)</p> <p>Lad A,BA,B v\u00e6re m\u00e6ngder og f:A\\to Bf:A\\to B</p> <p>ff er 1-1 eller enentydig hvis: $$ \\forall a_1,a_2\\in A: f(a_1)\\neq f(a_2) $$ hvis a_1 \\neq a_2a_1 \\neq a_2</p> <p>(Alts\u00e5 hvis 2 forskellige v\u00e6rdier, giver 2 forskellige outputs i funktionen)</p> <p>P\u00e5</p> <p>Lad A,BA,B v\u00e6re m\u00e6ngder og f:A\\to Bf:A\\to B</p> <p>ff er p\u00e5 hvis: $$ \\forall b \\in B : \\exists a \\in A: f(a) = b $$</p> <p>Bijektion</p> <p>Lad A,BA,B v\u00e6re m\u00e6ngder og f:A\\to Bf:A\\to B</p> <p>ff er en bijektion hvis ff er 1-1 og p\u00e5.</p> <p>Samme St\u00f8rrelse</p> <p>Lad A,BA,B v\u00e6re m\u00e6ngder.</p> <p>Vi siger at AA og BB har samme st\u00f8rrelse (kardinalitet) hvis: $$ \\exists f: A\\to B, \\text{s\u00e5 } f \\text{ er en bijektion} $$ </p> <p>T\u00e6llelig M\u00e6ngde</p> <p>Lad AA v\u00e6re en m\u00e6ngde.</p> <p>AA er t\u00e6llelig hvis AA har samme st\u00f8rrelse som de naturlige tal (\\N\\N).</p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#tllelige-mngder","title":"T\u00e6llelige M\u00e6ngder","text":""},{"location":"5-semester/CC/04-more-problems-than-algorithms/#positive-rationelle-tal","title":"Positive Rationelle Tal","text":"<p>\\Q_+\\Q_+ er en t\u00e6llelig m\u00e6ngde! (Positive rationelle tal)</p> <p></p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#alle-strenge-over-sigma","title":"Alle Strenge over Sigma","text":"<p>\\Sigma^*\\Sigma^* er en t\u00e6llelig m\u00e6ngde!</p> <p></p> <ul> <li>Konsekvens: <ul> <li>Der er kun t\u00e6lleligt uendeligt mange TM'er<ul> <li>Da hver TM MM beskrives med en strengkonstruktion \\langle M\\rangle\\langle M\\rangle</li> </ul> </li> </ul> </li> </ul>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#overtllelige-mngder","title":"Overt\u00e6llelige M\u00e6ngder","text":"<p>Lad AA v\u00e6re en uendelig m\u00e6ngde.</p> <p>Hvis AA ikke er t\u00e6llelig, kalder vi AA for overt\u00e6llelig.</p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#positive-reelle-tal","title":"Positive Reelle Tal","text":"<p>\\R_+\\R_+ er overt\u00e6llelig.</p> <p>Bevis: Numberphile - Diagonalisering.</p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#potensmngden-af-alle-strenge","title":"Potensm\u00e6ngden af alle Strenge","text":"<p>\\mathcal{P}(\\Sigma^*)\\mathcal{P}(\\Sigma^*) er en overt\u00e6llelig m\u00e6ngde.</p> <p>Bevis ved diagonalisering:</p> <p>Observation: Ethvert sprog svarer til en uendelig 0-1-f\u00f8lge (og omvendt)</p> <p></p> <p></p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#uafgrbare-sprog","title":"Uafg\u00f8rbare Sprog","text":""},{"location":"5-semester/CC/04-more-problems-than-algorithms/#halt","title":"HALT","text":"<p>Theorem 5.1</p> <p>HALT_{TM}HALT_{TM} er uafg\u00f8rbart.</p>"},{"location":"5-semester/CC/04-more-problems-than-algorithms/#bevis","title":"Bevis","text":"<p>Lad os antage af TM RR afg\u00f8r HALT_{TM}HALT_{TM}, s\u00e5 kan vi konstruerer TM SS til at afg\u00f8re A_{TM}A_{TM}:</p> <p>S=S= \"P\u00e5 input \\langle M, w\\rangle\\langle M, w\\rangle\":</p> <ol> <li>K\u00f8r TM RR p\u00e5 input \\langle M, w\\rangle\\langle M, w\\rangle</li> <li>Hvis RR afviser, afvis</li> <li>Hvis RR accepterer, simuler MM p\u00e5 ww indtil den halter</li> <li>Hvis MM har accepteret, accepter, ellers afvis</li> </ol> <p>Ergo: Hvis RR afg\u00f8r HALT_{TM}HALT_{TM}, s\u00e5 afg\u00f8r SS, A_{TM}A_{TM}. Men da A_{TM}A_{TM} er uafg\u00f8rbart, da m\u00e5 HALT_{TM}HALT_{TM} ogs\u00e5 v\u00e6re uafg\u00f8rbart. \\square\\square</p>"},{"location":"5-semester/CC/05-beregningshistorier/","title":"Uafg\u00f8rbare Problemer om Beregningshistorier","text":""},{"location":"5-semester/CC/05-beregningshistorier/#konfigurationer","title":"Konfigurationer","text":"<p>En TM M accepter input ww hvis der findes en f\u00f8lge af konfigurationer $$ C_1,\\dots,C_k $$ s\u00e5</p> <ul> <li>C_1=q_0wC_1=q_0w                                                       (q_0q_0 er MM's starttilstand')</li> <li>C_i\\to C_{i+1}C_i\\to C_{i+1}                                                     (for 1 \\leq i \\leq k-11 \\leq i \\leq k-1)</li> <li>C_kC_k er en accepterende konfiguration       (indeholder q_{accept}q_{accept})</li> </ul>"},{"location":"5-semester/CC/05-beregningshistorier/#linert-begrnsede-automater-lba","title":"Line\u00e6rt Begr\u00e6nsede Automater (LBA)","text":"<p>En Line\u00e6rt begr\u00e6nset automat (LBA) er en TM der aldrig anvender flere b\u00e5ndceller end dem input st\u00e5r p\u00e5.</p> <ol> <li>Klassen af sprog som kan genkendes med LBA'er er pr\u00e6cis de kontekst-sensitive sprog<ul> <li>Defineret med CSG'er, hvor regler er p\u00e5 formen<ul> <li>uAv\\to u\\alpha vuAv\\to u\\alpha v</li> </ul> </li> </ul> </li> <li>Klassen af sprog som kan genkendes af LBA'er er pr\u00e6cis de sprog som kan genkendes af algoritmer med line\u00e6r pladskompleksitet.</li> </ol>"},{"location":"5-semester/CC/05-beregningshistorier/#acceptproblemet-for-lbaer","title":"Acceptproblemet for LBA'er","text":"<p>\"Givet en LBA MM og input ww, vil MM acceptere ww?\"</p>  A_{LBA}=\\left\\{\\langle M,w\\rangle \\mid M \\text{ er en LBA, der accepterer } w \\right\\}   A_{LBA}=\\left\\{\\langle M,w\\rangle \\mid M \\text{ er en LBA, der accepterer } w \\right\\}  <p>S\u00e6tning</p> <p>A_{LBA}A_{LBA} er afg\u00f8rbart!</p>"},{"location":"5-semester/CC/05-beregningshistorier/#bevis","title":"Bevis","text":""},{"location":"5-semester/CC/05-beregningshistorier/#tomhedsproblemet-for-lbaer","title":"Tomhedsproblemet for LBA'er","text":"<p>\"Givet en LBA MM, g\u00e6lder det at L(M)=\\emptyL(M)=\\empty\"</p>  E_{LBA}=\\{\\langle M\\rangle\\mid M \\text{ er en LBA, } L(M)=\\empty\\}   E_{LBA}=\\{\\langle M\\rangle\\mid M \\text{ er en LBA, } L(M)=\\empty\\}  <p>S\u00e6tning</p> <p>E_{LBA}E_{LBA} er uafg\u00f8rbart</p>"},{"location":"5-semester/CC/05-beregningshistorier/#totalitetsproblemet-for-cfger","title":"Totalitetsproblemet for CFG'er","text":"<p>\"Givet en CFG GG, g\u00e6lder det at L(G)=\\Sigma^*L(G)=\\Sigma^*?\"</p>  ALL_{CFG}=\\{ \\langle G\\rangle \\mid G \\text{ er en CFG, } L(G)=\\Sigma^*\\}   ALL_{CFG}=\\{ \\langle G\\rangle \\mid G \\text{ er en CFG, } L(G)=\\Sigma^*\\}  <p>S\u00e6tning</p> <p>ALL_{CFG}ALL_{CFG} er uafg\u00f8rbart!</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/","title":"Posts Korrospondanceproblem ; Teorien for Reduktioner","text":""},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#posts-korrespondanceproblem","title":"Posts Korrespondanceproblem","text":"<p>En samling af Post-brikker over alfabetet \\Sigma er en endelig m\u00e6ngde af par:</p>  P=\\left\\{ \\left[\\frac{t_1}{b_1}\\right],\\dots,\\left[\\frac{t_k}{b_k}\\right]\\right\\}   P=\\left\\{ \\left[\\frac{t_1}{b_1}\\right],\\dots,\\left[\\frac{t_k}{b_k}\\right]\\right\\}  <p>hvor \\quad t_i,b_i\\in \\Sigma^*, \\quad (1\\leq i \\leq k)\\quad t_i,b_i\\in \\Sigma^*, \\quad (1\\leq i \\leq k)</p> <p>En match for PP er en f\u00f8lge af indekser i_1,\\dots,i_ni_1,\\dots,i_n s\u00e5 t_{i_1},\\dots,t_{i_n} = b_{i_1},\\dots,b_{i_n}t_{i_1},\\dots,t_{i_n} = b_{i_1},\\dots,b_{i_n}</p> <p>\u200b   (Samme indeks m\u00e5 bruges 0 eller flere gange)</p> <p>Eksempel:</p> <p></p> <p></p> <p>Generalt: Hvis PP har \u00e9n match, s\u00e5 har PP uendeligt mange matches.</p> <p>Da brikker m\u00e5 bruges 0 eller flere gange er der et uendeligt stort s\u00f8gerum.</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#problemet","title":"Problemet","text":"<p>Givet en samling Post-brikker PP, har PP en match?</p>  PCP= \\biggl\\{ &lt;P&gt;\\ \\mathrel{\\Big|}  \\begin{array}{} P \\text{ er en samling Post-brikker. }\\\\ P \\text{ har en match} \\end{array} \\biggr\\}   PCP= \\biggl\\{ &lt;P&gt;\\ \\mathrel{\\Big|}  \\begin{array}{} P \\text{ er en samling Post-brikker. }\\\\ P \\text{ har en match} \\end{array} \\biggr\\}  <p>PCPPCP er uafg\u00f8rbart.</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#bevis","title":"Bevis","text":"<p>Reduktion.</p> <p>To skridt:</p> <ul> <li>A_{TM} \\leadsto MPCP (\\textcolor{red}{**})A_{TM} \\leadsto MPCP (\\textcolor{red}{**})</li> </ul>  MPCP= \\biggl\\{ &lt;P&gt;\\ \\mathrel{\\Big|}  \\begin{array}{} P \\text{ er en samling Post-brikker. }\\\\ P \\text{ har en match, der starter med brik 1} \\end{array} \\biggr\\}   MPCP= \\biggl\\{ &lt;P&gt;\\ \\mathrel{\\Big|}  \\begin{array}{} P \\text{ er en samling Post-brikker. }\\\\ P \\text{ har en match, der starter med brik 1} \\end{array} \\biggr\\}  <ul> <li>MPCP \\leadsto PCP (\\textcolor{red}{*})MPCP \\leadsto PCP (\\textcolor{red}{*}) </li> </ul> <p></p> <p>Bevis del 1</p> <p>Bevis del 2</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#reduktion","title":"Reduktion","text":"<p>Overs\u00e6ttelse mellem sprog</p> <ul> <li>Skal v\u00e6re trofast</li> <li>Skal v\u00e6re beregnbar</li> </ul> <p>Beregnbar </p> <p>Lad f: \\Sigma^* \\to \\Sigma^*f: \\Sigma^* \\to \\Sigma^*</p> <p>ff er en beregnbar hvis der findes en TM M_fM_f</p> <p>s\u00e5 at n\u00e5r f(x)=yf(x)=y, s\u00e5 vil M_fM_f med input x standse med y p\u00e5 b\u00e5ndet.</p> <p>Trofast</p> <p>Lad A, BA, B v\u00e6re sprog over alfabet \\Sigma\\Sigma</p> <p>\u200b   f: \\Sigma^* \\to \\Sigma^*f: \\Sigma^* \\to \\Sigma^*</p> <p>er trofast hvis for alle x\\in\\Sigma^*x\\in\\Sigma^*</p> <p>\u200b   x \\in A\\Longleftrightarrow f(x)\\in Bx \\in A\\Longleftrightarrow f(x)\\in B</p> <p></p> <p>Reduktion</p> <p>Lad A, BA, B v\u00e6re sprog over alfabet \\Sigma\\Sigma</p> <p>Vi siger at AA reducerer til BB,      A\\leq_m BA\\leq_m B,</p> <p>hvis der findes en f: \\Sigma^* \\to \\Sigma^*f: \\Sigma^* \\to \\Sigma^* som er beregnbar og trofast mht. AA og BB</p> <p>T\u00e6nk p\u00e5 \\leq_m\\leq_m som \"ikke sv\u00e6rerer end\"</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#afgrbarhed","title":"Afg\u00f8rbarhed","text":"<p>S\u00e6tning</p> <p>Hvis A \\leq_m BA \\leq_m B og BB er afg\u00f8rbart, s\u00e5 er AA ogs\u00e5 afg\u00f8rbart.</p> <p></p> <p></p> <p>Korollar</p> <p>Hvis A \\leq_m BA \\leq_m B og AA er uafg\u00f8rbar, s\u00e5 er BB ogs\u00e5 uafg\u00f8rbar</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#genkendelighed","title":"Genkendelighed","text":"<p>S\u00e6tning</p> <p>Hvis A \\leq_m BA \\leq_m B og BB er genkendeligt, s\u00e5 er AA ogs\u00e5 genkendeligt.</p> <p></p> <p>Korollar</p> <p>Hvis A\\leq_m BA\\leq_m B og AA er u-genkendeligt, ss\u00e5 er BB heller ikke genkendeligt</p>"},{"location":"5-semester/CC/06-posts-korrespondanceproblem/#komplement","title":"Komplement","text":"<p>S\u00e6tning</p> <p>Hvis A\\leq_m BA\\leq_m B, s\u00e5 $ \\overline A \\leq_m \\overline B$</p> <p></p>"},{"location":"5-semester/CC/07-rice/","title":"Rice's S\u00e6tning","text":"\\newcommand{\\egsk}{\\mathscr{S}}\\nonumber"},{"location":"5-semester/CC/07-rice/#egenskab","title":"Egenskab","text":"<p>Definition</p> <p>En egenskab er en klasse af genkendelige sprog.</p> <p>En egenskab \\egsk\\egsk er ikke-triviel hvis der er genkendelige sprog L_1,L_2L_1,L_2 s\u00e5</p> <p>\u200b   L_1 \\in \\egskL_1 \\in \\egsk men L_2 \\notin \\egskL_2 \\notin \\egsk</p> <p>Der findes kun to trivielle egenskaber:</p> <ul> <li>\\egsk_{ALT}\\egsk_{ALT}</li> <li>\\egsk_{INTET}=\\{\\}\\egsk_{INTET}=\\{\\}</li> </ul>"},{"location":"5-semester/CC/07-rice/#sprog","title":"Sprog","text":"<p>Givet en egenskab \\egsk\\egsk, definerer vi:</p>  \\egsk_{TM}=\\left\\{ &lt;M&gt; \\mid M \\text{ er en TM},\\ L(M)\\in\\egsk  \\right\\}   \\egsk_{TM}=\\left\\{ &lt;M&gt; \\mid M \\text{ er en TM},\\ L(M)\\in\\egsk  \\right\\}  <p></p>"},{"location":"5-semester/CC/07-rice/#rices-stning_1","title":"Rice's S\u00e6tning","text":""},{"location":"5-semester/CC/07-rice/#stning","title":"S\u00e6tning","text":"<p>Hvis \\egsk\\egsk er en ikke-triviel egenskab, s\u00e5 er \\egsk_{TM}\\egsk_{TM} uafg\u00f8rbart.</p>"},{"location":"5-semester/CC/07-rice/#bevis","title":"Bevis","text":"<p>Reduktion</p>  A_{TM} \\leq_m \\egsk_{TM}\\\\   A_{TM} \\leq_m \\egsk_{TM}\\\\   \\langle M,w \\rangle \\leadsto \\langle M' \\rangle   \\langle M,w \\rangle \\leadsto \\langle M' \\rangle  <p>s\u00e5 $$ M \\text{ accepterer } w \\Leftrightarrow L(M')\\in \\egsk $$ Antag at \\empty \\notin \\egsk\\empty \\notin \\egsk</p> <p>Det er nok, da:</p>  \\begin{align} \\egsk_{TM}&amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\in \\egsk \\} &amp;&amp;\\text{ er afg\u00f8rbart}\\\\ &amp;\\Updownarrow\\nonumber\\\\ \\overline\\egsk_{TM}&amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\notin \\egsk \\}&amp;&amp;\\text{ er afg\u00f8rbart}\\\\ &amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\in \\overline\\egsk \\} \\end{align}   \\begin{align} \\egsk_{TM}&amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\in \\egsk \\} &amp;&amp;\\text{ er afg\u00f8rbart}\\\\ &amp;\\Updownarrow\\nonumber\\\\ \\overline\\egsk_{TM}&amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\notin \\egsk \\}&amp;&amp;\\text{ er afg\u00f8rbart}\\\\ &amp;=\\{\\langle M \\rangle\\mid M \\text{ er en TM, } L(M)\\in \\overline\\egsk \\} \\end{align}  <p>Vi har at \\empty \\notin \\egsk\\empty \\notin \\egsk</p> <p>Der m\u00e5 ogs\u00e5 v\u00e6re et L \\in \\egskL \\in \\egsk (da \\egsk\\egsk er ikke-triviel), hvor LL er genkendeligt</p> <p>S\u00e5 er der en TM M_LM_L som genkender LL</p> <p>Vi bygger, givet \\langle M,w\\rangle\\langle M,w\\rangle, en M'M' s\u00e5</p> <ul> <li>MM acc. ww \\Rightarrow\\Rightarrow L(M')=L \\in \\egskL(M')=L \\in \\egsk</li> <li>M acc. ikke ww \\Rightarrow\\Rightarrow L(M')= \\empty \\notin \\egskL(M')= \\empty \\notin \\egsk</li> </ul> <p>M'=M'= \" </p> <p>P\u00e5 input x. </p> <ol> <li>Simuler MM p\u00e5 ww.</li> <li>Hvis M acc. ww, s\u00e5<ul> <li>simuler M_LM_L p\u00e5 xx og svar hvad M_LM_L svarede.</li> </ul> </li> <li>Ellers afvis</li> </ol> <p>\"</p> <p>M acc. w \\Rightarrow\\Rightarrow De x'er som M_LM_L acc., bliver accepteret \\Rightarrow\\Rightarrow L(M')=L\\quad \\in \\egskL(M')=L\\quad \\in \\egsk</p> <p>M acc. ikke w \\Rightarrow\\Rightarrow Intet x bliver acceptereret \\Rightarrow\\Rightarrow L(M')=\\empty\\quad \\notin \\egskL(M')=\\empty\\quad \\notin \\egsk</p>"},{"location":"5-semester/CC/07-rice/#korollar","title":"Korollar","text":"<ul> <li>E_{TM}E_{TM} er uafg\u00f8rbart</li> <li>REGULAR_{TM}REGULAR_{TM} er uafg\u00f8rbart</li> <li>ENDELIG_{TM}ENDELIG_{TM} er uafg\u00f8rbart</li> </ul>"},{"location":"5-semester/CC/07-rice/#bevis_1","title":"Bevis","text":""},{"location":"5-semester/CC/07-rice/#opskrift","title":"Opskrift","text":"<ol> <li>Er der tale om et problem om TM'er?</li> <li>Beslutningsproblem \\to\\to sprogudgave</li> <li>Sprogudgave \\to\\to Egenskab      (hvilken sprogklasse \\egsk\\egsk er der tale om?) [er det overhovedet tilf\u00e6ldet?]</li> <li>Er \\egsk\\egsk en klasse af genkendelige sprog?</li> <li>(Hvis ja) Find et genkendeligt sprog L_1 \\in \\egskL_1 \\in \\egsk og et genkendeligt L_2 \\notin \\egskL_2 \\notin \\egsk,     for s\u00e5 ved vi at \\egsk\\egsk er ikke-triviel</li> </ol>"},{"location":"5-semester/CC/09-tidskompleksitet/","title":"Tidskompleksitet","text":"<p>Definition (worst-case)</p> <p>Lad M v\u00e6re en TM, der standser for ethvert input.</p> <p>Tidskompleksiteten af MM er en funktion $$ t_M:\\N\\to\\N $$</p> <p>s\u00e5 </p> <p>\u200b   t_M(n)=kt_M(n)=k </p> <p>\u200b   hvis MM p\u00e5 et vilk\u00e5rligt input af l\u00e6ngde n h\u00f8jst bruger k skridt.</p> <p>Sammelign v\u00e6kstrater med O-notation</p>"},{"location":"5-semester/CC/09-tidskompleksitet/#kompleksitetsklasser","title":"Kompleksitetsklasser","text":"<p>Kompleksitetsklasse</p> <p>==</p> <p>famillie af sprog, der alle kan afg\u00f8res med afg\u00f8rer med bestemt tidskompleksitet.</p> <p>Definition</p> <p>Lad f: \\N \\to \\R_+f: \\N \\to \\R_+</p> <p>S\u00e5 er TIME(f(n))TIME(f(n)) familien af sprog givet ved:</p>  TIME(f(n))=\\left\\{ L\\ \\mid \\begin{array}\\  L \\text{ kan afg\u00f8res af en TM M, }\\\\ \\text{der har tidskompleksitet } O(f(n) \\end{array} \\right\\}   TIME(f(n))=\\left\\{ L\\ \\mid \\begin{array}\\  L \\text{ kan afg\u00f8res af en TM M, }\\\\ \\text{der har tidskompleksitet } O(f(n) \\end{array} \\right\\}"},{"location":"5-semester/CC/09-tidskompleksitet/#antallet-af-band-pa-tm","title":"Antallet af B\u00e5nd p\u00e5 TM","text":"<p>Hvad betyder antallet af b\u00e5nd p\u00e5 en TM for tidskompleksiteten?</p> <p>S\u00e6tning</p> <p>Lad M v\u00e6re en k-b\u00e5nds-TM med tidskompleksiteten t(n)\\geq nt(n)\\geq n.</p> <p>S\u00e5 kan vi simulere M p\u00e5 en 1-b\u00e5nds TM med tidskompleksitet t^2(n)t^2(n) (kvadratisk langsommere)</p> <p>\u200b   Afh\u00e6ngig ikke af antal b\u00e5nd!</p>"},{"location":"5-semester/CC/09-tidskompleksitet/#tidskompleksitet-i-nondeterminisme","title":"Tidskompleksitet i Nondeterminisme","text":"<p>Definition</p> <p>Lad MM v\u00e6re en NTM der altid standser for ethvert input.</p> <p>MM har tidskompleksitet t: \\N\\to\\Nt: \\N\\to\\N hvis det for enhver beregning p\u00e5 et vilk\u00e5rligt input af l\u00e6ngde n g\u00e6lder at MM h\u00f8jst bruger t(n)t(n)</p> <p>S\u00e6tning</p> <p>Lad MM v\u00e6re en NTM med tidskompleksitet t(n)t(n).</p> <p>S\u00e5 kan MM simuleres af en DTM med tidskompleksitet 2^{O(t(n))}2^{O(t(n))} (eksponentielt meget v\u00e6rre)</p>"},{"location":"5-semester/CC/09-tidskompleksitet/#tidsklassen-p","title":"Tidsklassen P","text":"<p>Definition</p>  P=\\bigcup_{k\\geq 0} TIME(n^k)\\\\   P=\\bigcup_{k\\geq 0} TIME(n^k)\\\\   P=\\{L\\mid L \\text{ kan afg\u00f8res af en DTM med tidskompleksitet } O(n^k), k\\geq0\\}   P=\\{L\\mid L \\text{ kan afg\u00f8res af en DTM med tidskompleksitet } O(n^k), k\\geq0\\}  <p>PATH \\in PPATH \\in P</p>"},{"location":"5-semester/CC/09-tidskompleksitet/#kontekstfrie-sprog","title":"Kontekstfrie Sprog","text":"<p>S\u00e6tning</p> <p>Alle kontekstfrie sprog er i PP</p> <p>Bevis</p> <p>En snedig algoritme, der givet en CFG G p\u00e5 Chomsky-normalform kan afg\u00f8re om et w\\in L(G)w\\in L(G)</p> <p>Tidskompleksitet er O(n^3),\\quad (n=|w|)O(n^3),\\quad (n=|w|)</p> <p>Kaldes CYK-algoritmen</p> <ul> <li>Eksempel p\u00e5 dynamisk programmering</li> </ul>"},{"location":"5-semester/CC/09-tidskompleksitet/#bevis","title":"Bevis","text":"w=w_1,\\dots,w_n\\quad(|w|=n) \\nonumber   w=w_1,\\dots,w_n\\quad(|w|=n) \\nonumber"},{"location":"5-semester/CC/10-np-fuldstaendighed/","title":"NP og NP-fuldst\u00e6ndighed","text":""},{"location":"5-semester/CC/10-np-fuldstaendighed/#verifikator","title":"Verifikator","text":"<p>Lad A v\u00e6re et sprog.</p> <p>En verifikator VV for sproget AA er en TM som opfylder at $$ A={w \\mid V \\text{ accepterer } \\langle w,c\\rangle} $$ hvor cc er et certifikat (bud p\u00e5 l\u00f8sning / vidne til medlemskab)</p> <p>En verifikator er polinomiel hvis den har polinomiel tidskompleksitet mht. |w||w|</p> <ul> <li>cc kan kun have st\u00f8rrelser der er polinomiel i |w||w|</li> </ul> <p></p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#hampath-eksempel","title":"HAMPATH Eksempel","text":"<p>Definition</p> <p>Givet en orienteret graf GG, er en sti i GG en Hamilton-sti, hvis stien bes\u00f8ger hver knude i GG pr\u00e6cis en gang.</p> <p>Problem</p> <p>\"Givet orienteret graf GG, startknude ss, slutknude tt, findes der da en Hamilton-sti i GG fra ss til tt?\"</p>  HAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}   HAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}  <p>Det er nemt (hurtigt) at tjekke om et bud p\u00e5 en Hamilton-sti faktisk er en s\u00e5dan.</p> <p>Eksempel:</p> <p></p> <p>Men er det nemt at finde ud af om en GG har en Hamilton-sti?</p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#verifikator-for-hampath","title":"Verifikator for HAMPATH","text":""},{"location":"5-semester/CC/10-np-fuldstaendighed/#composite-eksempel","title":"COMPOSITE Eksempel","text":"<p>Et n\\in \\Nn\\in \\N er sammensat hvis</p> <p>\\exists p,q \\in \\N\\exists p,q \\in \\N s\u00e5 p,q&gt;1p,q&gt;1 og p\\cdot q=np\\cdot q=n</p> <p>\"Givet n\\in \\Nn\\in \\N er n sammensat?\"</p>  COMPOSITE=\\{\\langle n \\rangle \\mid n\\in \\N, n \\text{ sammensat}\\}   COMPOSITE=\\{\\langle n \\rangle \\mid n\\in \\N, n \\text{ sammensat}\\}"},{"location":"5-semester/CC/10-np-fuldstaendighed/#verifikator-for-composite","title":"Verifikator for COMPOSITE","text":"<p>Hvad er certifikat for COMPOSITECOMPOSITE?</p> <p>\u200b   Et vidne for at n\\in COMPOSITEn\\in COMPOSITE, dvs. p,qp,q</p> <p>Verifikator: \"</p> <p>\u200b   Givet \\langle n, \\langle p,q \\rangle\\rangle\\langle n, \\langle p,q \\rangle\\rangle</p> <ol> <li>Hvis p&lt;np&lt;n og q &lt; nq &lt; n s\u00e5     s\u00e5     hvis p\\cdot q = np\\cdot q = n accepter ellers afvis</li> <li></li> </ol> <p>\"</p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#np","title":"NP","text":"<p>Definition $$ NP = {L \\mid L \\text{ har en polynomiel verifikator}} $$ (sprog hvor det er nemt at tjekke om et bud p\u00e5 et vidne for medlemskab er korrekt, men ikke n\u00f8dvendigvis nemt at tjekke for medlemskab)</p> <p>nemt: lav (polynomiel tidskompleksitet)</p> <p>$$ NP = \\bigcup_{k\\geq 0} NTIME(n^k) $$ NPNP er klassen af sprog der kan afg\u00f8res i nondererminiistisk polynomiel tid.</p> <p>S\u00e6tning $$ \\begin{align} \\forall L:\\quad  &amp;L \\text{ har en polynomiel verifikator}\\nonumber\\ &amp;\\Updownarrow\\nonumber\\ &amp;L \\text{ kan afg\u00f8res i nondet. polynomiel tid}\\nonumber \\end{align} $$</p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#ntime","title":"NTIME","text":"<p>Lad f: \\N \\to \\Nf: \\N \\to \\N</p>  NTIME(f(n)) = \\{ L\\mid L \\text{ kan afg\u00f8res af en NTM med tidskompleksitet } O(f(n))\\}   NTIME(f(n)) = \\{ L\\mid L \\text{ kan afg\u00f8res af en NTM med tidskompleksitet } O(f(n))\\}  <p>Bem\u00e6rk:</p> <p>TIME(f(n))\\subseteq NTIME(f(n))TIME(f(n))\\subseteq NTIME(f(n))</p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#bevis-for-stning-6","title":"Bevis for S\u00e6tning (6)","text":"<p>\\Downarrow\\Downarrow)</p> <p>Antag at LL har en polynomiel verifikator VV:</p> <p></p> <p>VV har pol. tidskompleksitet mht. ww dvs O(n^k)O(n^k)    (s\u00e5 |c||c| kan h\u00f8jst v\u00e6re O(n^k)O(n^k))</p> <p>Vi vil lave en nondet. polynomiel afg\u00f8rer NN:</p> <p></p> <p>\\Uparrow\\Uparrow)</p> <p>Antag at LL kan afg\u00f8res i nondet. polynomiel tid med afg\u00f8rer NN.</p> <p>Vi vil lave en polynomiel verifikator VV for LL.</p> <p>Certifikat skal v\u00e6re et bud p\u00e5 en accepterende sti i beregningstr\u00e5et (dvs. en f\u00f8lge af konfigurationer)</p> <p>Verifikator VV:</p> <p></p> <p>\\square\\square</p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#p-np","title":"P NP","text":"<p>Da TIME(f(n)) \\subseteq NTIME(f(n))TIME(f(n)) \\subseteq NTIME(f(n)) har vi</p>  P \\subseteq NP   P \\subseteq NP"},{"location":"5-semester/CC/10-np-fuldstaendighed/#reduktion","title":"Reduktion","text":"<p>F\u00f8r:</p> <ul> <li>\\leq_m \\approx\\leq_m \\approx er ikke sv\u00e6rere end</li> </ul> <p>Nu:</p> <ul> <li>\\leq_p \\approx\\leq_p \\approx er ikke sv\u00e6rere end (nu med tidskompleksitet)</li> </ul> <p>Definition</p> <p>Lad A, BA, B v\u00e6re sprog over \\Sigma^*\\Sigma^* </p> <p>A \\leq_p BA \\leq_p B (AA polynomial reducerer til BB), hvis \\exists f: \\Sigma^*\\to\\Sigma^*\\exists f: \\Sigma^*\\to\\Sigma^* s\u00e5</p> <ul> <li> <p>\\forall w \\quad w\\in A \\Leftrightarrow f(w)\\in B\\forall w \\quad w\\in A \\Leftrightarrow f(w)\\in B (ff er trofast)</p> <p>og ff er beregnbar i polynomiel tid</p> </li> </ul> <p>S\u00e6tning</p> <p>Hvis A \\leq_p BA \\leq_p B og B \\in PB \\in P, s\u00e5 A\\in PA\\in P </p>"},{"location":"5-semester/CC/10-np-fuldstaendighed/#np-fuldstndighed","title":"NP Fuldst\u00e6ndighed","text":"<p>Definition</p> <p>Et sprog LL kaldes NP-fuldst\u00e6ndigt hvis</p> <ol> <li>L\\in NPL\\in NP</li> <li>\\forall L' \\in NP.\\quad L'\\leq_p L\\forall L' \\in NP.\\quad L'\\leq_p L</li> </ol> <p>Hvis L_1, L_2L_1, L_2 er NP-fuldst\u00e6ndige, har vi</p> <ul> <li>L_1\\in NP,\\quad L_2\\in NPL_1\\in NP,\\quad L_2\\in NP</li> <li>\\forall L' \\in NP. \\quad L'\\leq_p L_1, \\quad L' \\leq_p L_2\\forall L' \\in NP. \\quad L'\\leq_p L_1, \\quad L' \\leq_p L_2</li> </ul> <p>S\u00e5:</p> <ul> <li>L_1 \\leq_p L_2 \\quad L_2 \\leq_p L_1L_1 \\leq_p L_2 \\quad L_2 \\leq_p L_1</li> </ul>"},{"location":"5-semester/CC/12-np-complete-sprog/","title":"Flere NP-fuldst\u00e6ndige Sprog","text":"<p>Lemma</p> <p>\\leq_p er transitiv</p> <p>Hvis L_1 \\leq_p L_2L_1 \\leq_p L_2 og L_2\\leq_p L_3L_2\\leq_p L_3</p> <p>s\u00e5 L_1 \\leq_p L_3L_1 \\leq_p L_3</p>"},{"location":"5-semester/CC/13-pladskompleksitet/","title":"Pladskompleksitet","text":"<p>Definition</p> <p>Deterministisk</p> <p>En DTM har pladskompleksitet f(n), hvor f: \\N \\to \\Nf: \\N \\to \\N hvis enhver beregning p\u00e5 et input af l\u00e6ngde nn h\u00f8jst bruger f(n)f(n) felter p\u00e5 b\u00e5ndet</p> <p>(for alle input af l\u00e6ngden nn)</p> <p>Definition </p> <p>Nondeterministisk</p> <p>En NTM har pladskompleksitet f(n)f(n), hvor f: \\N \\to \\Nf: \\N \\to \\N hvis enhver beregning p\u00e5 et input af l\u00e6ngde nn h\u00f8jst bruger f(n)f(n) felter p\u00e5 b\u00e5ndet</p> <p>(for ethvert input af l\u00e6ngden nn og enhver mulig beregning p\u00e5 et s\u00e5dant input)</p>"},{"location":"5-semester/CC/13-pladskompleksitet/#pladskompleksitetsklasser","title":"Pladskompleksitetsklasser","text":"<p>Definition</p> <p>Lad f:\\N\\to\\Nf:\\N\\to\\N</p>  \\begin{align} SPACE(f(n))&amp;=\\{L \\mid L \\text{ kan afg\u00f8res af en DTM med pladskompleksitet } O(f(n))\\}\\\\ NSPACE(f(n))&amp;=\\{L \\mid L \\text{ kan afg\u00f8res af en NTM med pladskompleksitet } O(f(n))\\} \\end{align}   \\begin{align} SPACE(f(n))&amp;=\\{L \\mid L \\text{ kan afg\u00f8res af en DTM med pladskompleksitet } O(f(n))\\}\\\\ NSPACE(f(n))&amp;=\\{L \\mid L \\text{ kan afg\u00f8res af en NTM med pladskompleksitet } O(f(n))\\} \\end{align}  <p>Klart at </p>  SPACE(f(n))\\subseteq NSPACE(f(n))   SPACE(f(n))\\subseteq NSPACE(f(n))"},{"location":"5-semester/CC/13-pladskompleksitet/#eksempler","title":"Eksempler","text":""},{"location":"5-semester/CC/13-pladskompleksitet/#sat","title":"SAT","text":"<p>SAT\\in SPACE(n)SAT\\in SPACE(n)</p> <p>Afg\u00f8rer</p> <p></p>"},{"location":"5-semester/CC/13-pladskompleksitet/#sammenhng-mellem-tids-og-pladskompleksitet","title":"Sammenh\u00e6ng Mellem Tids- og Pladskompleksitet","text":"<p>S\u00e6tning</p> <p>Hvis en TM har pladskompleksitet O(f(n))O(f(n)), s\u00e5 har den tidskompleksitet 2^{O(f(n))}2^{O(f(n))}</p> <p>Bevis</p> <p></p> <p></p>"},{"location":"5-semester/CC/13-pladskompleksitet/#exptime","title":"EXPTIME","text":"EXPTIME=\\bigcup TIME(2^{n^k})   EXPTIME=\\bigcup TIME(2^{n^k})  <p>S\u00e6tning</p> <p>Hvis L \\in SPACE(n^k)L \\in SPACE(n^k)</p> <p>s\u00e5 L\\in TIME(2^{n^k})L\\in TIME(2^{n^k}), dvs L\\in EXPTIMEL\\in EXPTIME</p> <p>Alts\u00e5 hvis LL kan afg\u00f8res i polynomiel plads, kan LL afg\u00f8res i eksponentiel tid.</p>"},{"location":"5-semester/CC/13-pladskompleksitet/#pspace","title":"PSPACE","text":"\\begin{align} PSPACE&amp;=\\bigcup_{k\\geq0} SPACE(n^k)\\\\ NPSPACE &amp;= \\bigcup_{k\\geq0} NSPACE(n^k) \\end{align}   \\begin{align} PSPACE&amp;=\\bigcup_{k\\geq0} SPACE(n^k)\\\\ NPSPACE &amp;= \\bigcup_{k\\geq0} NSPACE(n^k) \\end{align}  <p>Klart at</p> <p>$$ PSPACE\\subseteq NPSPAC $$ Det vides at</p>  PSPACE = NPSPAC   PSPACE = NPSPAC"},{"location":"5-semester/CC/13-pladskompleksitet/#verdenskort","title":"Verdenskort","text":""},{"location":"5-semester/CC/99-sprog-i-pensum/","title":"Sprogproblemer","text":""},{"location":"5-semester/CC/99-sprog-i-pensum/#afgrbare-sprog","title":"Afg\u00f8rbare Sprog","text":"A_{DFA}=\\{\\langle B, w\\rangle \\mid B \\text{ er en DFA der accepterer } w\\}  <ul> <li>A_{DFA}A_{DFA} er afg\u00f8rbart</li> </ul>  E_{DFA} = \\{\\langle A\\rangle \\mid A \\text{ er en DFA og } L(A) = \\empty\\}   E_{DFA} = \\{\\langle A\\rangle \\mid A \\text{ er en DFA og } L(A) = \\empty\\}  <ul> <li>E_{DFA}E_{DFA} er afg\u00f8rbart</li> </ul>  A_{CFG}=\\{\\langle G, w\\rangle \\mid G \\text{ er en CFG der genererer } w\\}   A_{CFG}=\\{\\langle G, w\\rangle \\mid G \\text{ er en CFG der genererer } w\\}  <ul> <li>A_{CFG}A_{CFG} er afg\u00f8rbart</li> </ul>"},{"location":"5-semester/CC/99-sprog-i-pensum/#uafgrbare-sprog","title":"Uafg\u00f8rbare Sprog","text":"A_{TM}=\\{\\langle M,w \\rangle \\mid M \\text{ er en TM der accepterer } w\\}   A_{TM}=\\{\\langle M,w \\rangle \\mid M \\text{ er en TM der accepterer } w\\}  <ul> <li>A_{TM}A_{TM} er uafg\u00f8rbart<ul> <li>Genkendeligt</li> <li>Ikke ko-genkendeligt</li> </ul> </li> </ul>  HALT_{TM} = \\{\\langle M, w\\rangle \\mid M \\text{ er en TM der standser p\u00e5 input } w\\}   HALT_{TM} = \\{\\langle M, w\\rangle \\mid M \\text{ er en TM der standser p\u00e5 input } w\\}  <ul> <li>HALT_{TM}HALT_{TM} er uafg\u00f8rbart<ul> <li>Genkendeligt</li> <li>Ikke ko-genkendeligt</li> </ul> </li> </ul>  E_{TM} = \\{\\langle M\\rangle \\mid M \\text{ er en TM og } L(M) = \\empty\\}   E_{TM} = \\{\\langle M\\rangle \\mid M \\text{ er en TM og } L(M) = \\empty\\}  <ul> <li>E_{TM}E_{TM} er uafg\u00f8rbart</li> </ul>  EQ_{TM}=\\{\\langle M_1, M_2\\rangle \\mid {M_1, M_2 \\text{ er TMs og } L(M_1)=L(M_2)}\\}   EQ_{TM}=\\{\\langle M_1, M_2\\rangle \\mid {M_1, M_2 \\text{ er TMs og } L(M_1)=L(M_2)}\\}  <ul> <li>EQ_{TM}EQ_{TM} er uafg\u00f8rbart<ul> <li>Ikke genkendeligt</li> <li>Ikke ko-genkendeligt</li> </ul> </li> </ul>"},{"location":"5-semester/CC/99-sprog-i-pensum/#sprog-i-np","title":"Sprog i NP","text":"SAT=\\{\\langle \\phi \\rangle \\mid \\phi \\text{ er en opfyldelig Boolsk formel }\\}   SAT=\\{\\langle \\phi \\rangle \\mid \\phi \\text{ er en opfyldelig Boolsk formel }\\}  <ul> <li>SATSAT er afg\u00f8rbart</li> <li>SAT\\in NPSAT\\in NP</li> </ul>  HAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}   HAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}  <ul> <li>HAMPATHHAMPATH er afg\u00f8rbart</li> </ul>  COMPOSITE=\\{\\langle n \\rangle \\mid n\\in \\N, n \\text{ sammensat}\\}   COMPOSITE=\\{\\langle n \\rangle \\mid n\\in \\N, n \\text{ sammensat}\\}  <ul> <li>COMPOSITECOMPOSITE er afg\u00f8rbart</li> </ul>  3SAT = \\{\\langle \\phi \\rangle\\mid \\phi \\text{ er en opfyldelig 3CNF-formel}\\}   3SAT = \\{\\langle \\phi \\rangle\\mid \\phi \\text{ er en opfyldelig 3CNF-formel}\\}  <ul> <li>3SAT3SAT er afg\u00f8rbart</li> <li>3SAT3SAT er NP-fuldst\u00e6ndig</li> </ul>  VERTEX-COVER=\\{ \\langle G,k\\rangle\\mid G \\text{ er en ikke-orienteret graf med en k-knudeoverd\u00e6kning} \\}   VERTEX-COVER=\\{ \\langle G,k\\rangle\\mid G \\text{ er en ikke-orienteret graf med en k-knudeoverd\u00e6kning} \\}  <ul> <li>Afg\u00f8rbart</li> <li>NP-fuldst\u00e6ndigt</li> </ul>  UHAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en ikke-orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}   UHAMPATH=\\{\\langle G,s,t\\rangle \\mid G \\text{ er en ikke-orienteret graf med en Hamilton-sti fra knude } s \\text{ til } t\\}  <ul> <li>Afg\u00f8rbart</li> <li>NP-fuldst\u00e6ndigt</li> </ul>  SUBSET-SUM=\\left\\{\\langle S, k\\rangle\\ \\left|\\ \\begin{array}{} S \\text{ er en endelig m\u00e6ngde } S\\subseteq \\N,\\\\ \\text{ og der findes } S'\\subseteq S \\text{ s\u00e5 } \\sum_{x\\in S'} x=k,\\quad k\\in \\N \\end{array} \\right. \\right\\}   SUBSET-SUM=\\left\\{\\langle S, k\\rangle\\ \\left|\\ \\begin{array}{} S \\text{ er en endelig m\u00e6ngde } S\\subseteq \\N,\\\\ \\text{ og der findes } S'\\subseteq S \\text{ s\u00e5 } \\sum_{x\\in S'} x=k,\\quad k\\in \\N \\end{array} \\right. \\right\\}  <ul> <li>Afg\u00f8rbart</li> <li>NP-fuldst\u00e6ndigt</li> </ul>"},{"location":"5-semester/MI/","title":"MI - Machine Intelligence","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=31435</p> <p></p>"},{"location":"5-semester/MI/09-04-introduction/","title":"Introduction","text":"<p>Mondays 08:15-12:</p> <ul> <li>Exercises 8:15-10:00 (in the lecture room), lecture 10:15-12:00</li> <li></li> </ul> <p>Wednesdays 08:15-12:00 Extended Exercise sessions (group rooms)</p> <p>Written exam</p> <ul> <li>You can bring everything except computers</li> </ul>"},{"location":"5-semester/MI/09-04-introduction/#the-book","title":"The Book","text":"<p>Online Version</p> <p>A foundational book</p> <ul> <li>Gives a basic understanding of the field</li> </ul>"},{"location":"5-semester/MI/09-04-introduction/#topics","title":"Topics","text":"<ul> <li>Introduction</li> <li>Problem solving as search</li> <li>Constrained satisfaction problems</li> <li>Logic-based knowledge representation</li> <li>Representing domains endowed with uncertainty</li> <li>Bayesian networks</li> <li>Machine Learning</li> <li>Planning</li> <li>Reinforced Learning</li> <li>Multi-agent systems</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/","title":"Problem Solving as Search","text":"<p>Extra knowledge beyond the search space is called heuristic knowledge</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#problem-description","title":"Problem Description","text":"<p>We consider problems where an agent</p> <ul> <li>has a state-based representation of its environment</li> <li>can observe with certainty which state it is in</li> <li>has a certain goal it wants to achieve</li> <li>can execute actions that have definite effects (no uncertainty)</li> </ul> <p>Agent needs to find a sequence of actions leading to a goal state</p> <ul> <li>A state in which its goal is achieved</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#example","title":"Example","text":"<p>Problem: re-arange tiles into goal configuration</p> <p></p> <ul> <li> <p>362.880 states (9!)</p> </li> <li> <p>Actions: move_ up/down/left/right</p> </li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#state-space-problem","title":"State-Space Problem","text":"<p>Consists of:</p> <ul> <li>A set of states</li> <li>A subset of start states</li> <li>A set of actions (not all available at all states)</li> <li>An action function that for a given state ss and action aa      returns the state reached when executing aa in ss</li> <li>A goal test that for any state ss returns the boolean value goal(s)goal(s) (true if ss is a goal state)</li> <li>(Optional) A cost function on actions</li> <li>(Optional) A value function on goal states</li> </ul> <p>A Solution consists of:</p> <ul> <li>For any given start state, a sequence of actions that lead to a goal state </li> <li>(optional) a sequence of actions with minimal cost </li> <li>(optional) a sequence of actions leading to a goal state with maximal value</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#graphs","title":"Graphs","text":"<p>Se AD1 - Graph Theory</p> <p>Se PM, 3.3.1: Formalizing Graph Searching</p> <p></p> <p>A directed graph consists of</p> <ul> <li>A set of nodes</li> <li>A set of arcs (ordered in pairs of nodes)</li> </ul> <p>Further terminology:</p> <ul> <li>n_2n_2 is a neighbor of n_4n_4 (not the other way round!)</li> <li>n_3, n_4, n_2, n_5n_3, n_4, n_2, n_5 is a path from n_3n_3 to n_5n_5</li> <li>n_2, n_5, n_4, n_2n_2, n_5, n_4, n_2 is a path that is a cycle</li> <li>a graph is acyclic if it has no cycles</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#example-1","title":"Example 1","text":"<ul> <li>Nodes: states</li> <li>Arcs: possible state-transitions from actions (can be labeled with actions)</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#example-2","title":"Example 2","text":""},{"location":"5-semester/MI/09-09-problem-solving-as-search/#graph-search","title":"Graph Search","text":"<p>A state-space problem can be solved by searching in the state-space graph  for paths from start states to a goal state</p> <ul> <li>Does not require the whole graph at once<ul> <li>Search may only locally generate neighbors of currently visited node</li> </ul> </li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#from-graph-to-search-tree","title":"From Graph to Search Tree","text":"<ul> <li>Search tree represents how we can navigate the state-space graph</li> </ul> <ul> <li>Red nodes are nodes that we can explore from where we are now (frontier or fringe)</li> </ul> <p>Generic Search Algorithm</p> <p></p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#depth-first-search","title":"Depth-first Search","text":"<p>AD1 - Depth-First Search</p> <p></p> <p>Properties</p> <ul> <li>Space used is linear in the length of the current path</li> <li>May not terminate if state-space graph has cycles</li> <li>With a forward branching factor bounded by b and depth n, the worst-case time complexity of a finite tree is b^nb^n</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#breadth-first-search","title":"Breadth-First Search","text":"<p>AD1 - Breadth-First Search</p> <p></p> <p>Properties</p> <ul> <li>Will always find a solution if one exists</li> <li> <p>Size of frontier always increases during search up to order of magnitude of total size of search tree</p> </li> <li> <p>Can be adapted to find a minimum cost path</p> </li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#problem-with-cost-function","title":"Problem With Cost Function","text":"<ul> <li>Assume that for each action at each state we have an associated cost</li> <li>The cost of a solution is the sum of the costs of all actions on the path from start to goal</li> <li>A minimum cost solution is a solution with minimal cost</li> </ul> <p>Example</p> <p></p> <p>Breadth-first finds the shortests, but not the cheapest solution</p> <p>Depth-first may find either, depending on order of neighbor enumeration</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#lowest-cost-first-search","title":"Lowest-Cost-First Search","text":"<p>Simple modification of generic.</p> <ul> <li>With each path in frontier store the cost of path</li> <li>Modify one line of code<ul> <li>select and remove path &lt;n_0,\\dots,n_k&gt;&lt;n_0,\\dots,n_k&gt; $\\color{red}\\text{with minimal cost} $ from Frontier</li> </ul> </li> </ul> <p>Properties</p> <ul> <li>If all actions have non-zero cost, and solution exists, a minimal cost solution will be found</li> <li>Space requirement depends on cost structure, but usually similar to breadth-first</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#iterative-deepening-search","title":"Iterative Deepening Search","text":"<p>Goal:</p> <ul> <li>Termination guarantee of breadth-first seach</li> <li>Space efficiency of depth-first search</li> </ul> <p>Algorithm</p> <p>Set a kk-value, do depth-first search till kk layers deep.</p> <p>Increase kk, repeat</p> <p></p> <p>Properties:</p> <ul> <li>Has desired termination and space efficiency properties</li> <li>Duplicates computations (depth-bounded search kk repeats computations of depth-bounded search k-1k-1). <ul> <li>Not as problematic as it looks: constant overhead of (b/(b-1)b/(b-1))</li> </ul> </li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#uninformed-search","title":"Uninformed Search","text":"<p>3.5 Uninformed Search Strategies</p> <ul> <li>Depth-first, Breadth-first and Iterative deepening are uninformed search strategies:<ul> <li>They do not assume/use any knowledge of the search space exept the pure graph structure.</li> </ul> </li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#informed-search","title":"Informed Search","text":"<p>Actual Cost</p> <p>Given a cost function on actions, can define for any node n in the search tree:</p> <ul> <li>opt(n) = cost of optimal path from n to a goal state<ul> <li>Infinite if no path to goal exists</li> </ul> </li> <li>opt function can usually not be computed</li> <li>opt(n) only depends on the state at node n</li> </ul> <p>Heuristic Function</p> <p>A heuristic function h(n)h(n) takes a node nn and returns a non-negative real number.</p> <ul> <li>This number is an estimate of the cost of the least-cost path from node nn to a goal node<ul> <li>h(n)\\leq opt(n)h(n)\\leq opt(n)</li> </ul> </li> </ul> <p>h(n)h(n) is an admissible heuristic if h(n)h(n) is always less than or equal to the actual cost.</p> <p>An example could be that h(n)h(n) could be the cost if we could move through walls.</p> <p>Simple use of heuristic function is heuristic depth-first search.</p> <ul> <li>Selects the locally best path, but explores all paths from that before it selects another path.</li> <li>Often used, but suffers the problems of depth-first search.</li> </ul> <p>Another use is greedy best-first search</p> <ul> <li>Always select a path on the frontier with the lowest heuristic value.</li> <li>Sometimes work well, but sometimes uses paths that looks promising in the beginning.</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#example_1","title":"Example","text":"<p>\"Consider the graph shown in Figure 3.9, drawn to scale, where the cost of an arc is its length. The aim is to find the shortest path from ss to gg. Suppose the Euclidean straight line distance to the goal gg is used as the heuristic function. A heuristic depth-first search will select the node below ss and will never terminate. Similarly, because all of the nodes below ss look good, a greedy best-first search will cycle between them, never trying an alternate route from gg.\"</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#a-search","title":"A* Search","text":"<p>3.6.1 A* Search</p> <p>Uses both path cost (as lowest-cost-first), and heuristic information (as greedy best-first search).</p> <ul> <li>For each path on the frontier, A* uses an estimate of the total path cost from the start node to a goal node constrained to follow that path initially.</li> <li>Uses cost(p)cost(p), the cost of the path found</li> <li>As well as h(p)h(p), the estimated cost from the end of pp to the goal.</li> </ul> <p>For any path pp on the frontier, define: $$ f(p)=cost(p)+h(p) $$ This is an estimate of the total path cost to follow path pp then go to a goal node.</p> <ul> <li>If nn is the node at the end of path pp, this can be depicted as:</li> </ul>  \\underbrace{\\underbrace{\\text{start}\\ \\underrightarrow{\\text{actual}}}_{cost(p)} \\ n\\ \\underbrace{\\underrightarrow{\\text{estimate}} \\ \\text{goal}}_{h(p)}}_{f(p)}   \\underbrace{\\underbrace{\\text{start}\\ \\underrightarrow{\\text{actual}}}_{cost(p)} \\ n\\ \\underbrace{\\underrightarrow{\\text{estimate}} \\ \\text{goal}}_{h(p)}}_{f(p)}  <p>If h(n)h(n) is an admissible heuristic, and so never overestimates the cost from node nn to a goal node, then f(p)f(p) does not overestimate the path cost of going from the start node to a goal node via pp</p> <p>A^*A^* is implemented using the Generic search algorithm, treating the frontier as a priority queue ordered by f(p)f(p)</p> <p>Example 3.15</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#admissible","title":"Admissible","text":"<p>A search algorithm is admissible if, whenever a solution exists, it returns an optimal solution.</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#a-admissiblity","title":"A* Admissiblity","text":"<p>Proposition 3.1</p> <p>If there is a solution, A*A* using heuristic function hh always returns an optimal solution if:</p> <ul> <li>The branching factor is finite (each node has a bounded number of neighbors)</li> <li>All arc costs are greater than some \\epsilon &gt; 0\\epsilon &gt; 0</li> <li>hh is an admissible heuristic, meaning that h(n)h(n) is less than or equal to the actual cost of the lowest-cost path from node nn to a goal node.</li> </ul> <p>See link for proof.</p>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#dynamic-programming","title":"Dynamic Programming","text":"<p>For statically stored graphs, build a table of dist(n) the actual distance of the shortest path from node n to a goal.</p> <p>This can be built backwards from the goal:</p>  \\begin{align*} dist(n)=\\left\\{ \\begin{array} \\ 0  &amp;\\text{if } is\\_goal(n) \\\\ \\min_{\\langle n,m\\rangle\\in A}(|\\langle n,m\\rangle|+dist(m)) &amp; \\text{otherwise} \\end{array} \\right. \\end{align*}   \\begin{align*} dist(n)=\\left\\{ \\begin{array} \\ 0  &amp;\\text{if } is\\_goal(n) \\\\ \\min_{\\langle n,m\\rangle\\in A}(|\\langle n,m\\rangle|+dist(m)) &amp; \\text{otherwise} \\end{array} \\right. \\end{align*}  <p>Example</p> <p></p> <p></p> <p>Two main problems:</p> <ul> <li>You need enough space to store the graph</li> <li>The dist function needs to be recomputed for each goal</li> </ul>"},{"location":"5-semester/MI/09-09-problem-solving-as-search/#pruning-the-search-space","title":"Pruning the Search Space","text":"<p>3.7.1 Cycle Pruning</p> <ul> <li>A seacher can prune a path that ends in a node already on the path, without removing an optimal solution</li> <li>Using depth-first methods, with the graph explicitly stored, this can be done in constant time.</li> <li>For other methods, the cost ins linear in path length</li> </ul> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/","title":"Constraints Satisfaction Problems","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#features-and-variables","title":"Features and Variables","text":"<p>Describing the world (environment) by features:</p> <p></p> <p>A possible world for a set of variables is an assignment of a value to each variable.</p> <p>Example (Cooking):</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#constraint-satisfaction-problems","title":"Constraint Satisfaction Problems","text":"<p>A constraint is a condition on the values of variables in a possible world.</p> <p>Can be specified with:</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#extensional-constraint-specification","title":"Extensional Constraint Specification","text":"<p>Explicitly list all allowed (or disallowed) combination of values:</p> <p></p> <p>Not on the list of allowed possible worlds:</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#intensional-constraint-specification","title":"Intensional Constraint Specification","text":"<p>Use logical expressions:</p>  \\begin{align*} Teacher\\_AD=Teacher\\_MI \\to Time\\_AD \\neq Time\\_MI\\\\ Time\\_AD = Time\\_MI \\to Room\\_AD \\neq Room\\_MI \\end{align*}  <ul> <li>If teacher for AD and MI is the same, then the time of AD cannot be the same as time of MI.</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#example-sudoku","title":"Example: Sudoku","text":"<p>Constraints:</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#definition","title":"Definition","text":"<p>A Constraint Satisfaction Problem (CSP) is given by</p> <ul> <li>a set of variables</li> <li>a set of constraints (usually intensional)</li> </ul> <p>A solution to a CSP consists of a possible world that satisfies all the constraints (also called a model of the constraints)</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#csp-as-state-space-problem","title":"CSP as State Space Problem","text":"<p>A CSP can be represented as a state space problem:</p> <ul> <li>States are all partial assignments of values to variables that are consistent with the constraints</li> <li>For a state ss: select some variable VV not assigned a value in ss, and let the neighbors of ss be all states that assign a value to VV (if any exist)</li> <li>The start state is the state that does not assign any values</li> <li>A goal state is a state that assigns values to all variables</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#solving-the-csp","title":"Solving the CSP","text":"<ul> <li> <p>A solution to the state space problem is a path with a goal state at the end:</p> <ul> <li>A solution to the CSP problem</li> </ul> </li> <li> <p>To solve the state space problem need only be able to:</p> <ul> <li>enumerate all partial assignments that assign a value to one or more variable than ss</li> <li>check whether a partial assignment is consistent with the constraints</li> </ul> <p>(That is sufficient to implement the get_neighbors and goal functions needed in the generic search algorithm)</p> </li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#example","title":"Example","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#consistency-algorithms","title":"Consistency Algorithms","text":"<p>Idea</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#constraint-network","title":"Constraint Network","text":"<p>The constraint network for a CSP consists of:</p> <ul> <li>1 (oval) node for each variable XX</li> <li>1 (rectangular) node for each constraint cc</li> <li>An (undirected) arc \\langle X,c \\rangle\\langle X,c \\rangle between every constraint and every variable involved in the constraint</li> </ul> <p>With each variable node XX is associated a (reduced) domain D_XD_X:</p> <ul> <li>Initially the domain of the variable</li> <li>Reduced by successively deleting values that cannot be part of a solution</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#arc-consistency","title":"Arc Consistency","text":"<p>An arc \\langle X,c \\rangle\\langle X,c \\rangle is arc consistent, if</p> <ul> <li>For all x\\in D_Xx\\in D_X there exists values y_i,...,y_ky_i,...,y_k for the other variables involved in cc,      such that x,y_i,...,y_kx,y_i,...,y_k is consistent with cc</li> </ul> <p>A constraint network is arc consistent, if all its arcs are arc consistent</p> <p></p> <p>Examples</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#algorithm-outline","title":"Algorithm Outline","text":"<p>Example: Slide 18 (Appendix of this page)</p> <p>Algorithm Outcomes</p> <p>Algorithm is guaranteed to terminate. Result independent of order in which arcs are processed.</p> <p>Possible cases at termination:</p> <ul> <li> <p>D_X=\\emptyD_X=\\empty for some X:X: </p> <ul> <li>CSP has no solution</li> </ul> </li> <li> <p>D_XD_X contains exactly one value for each X:X: </p> <ul> <li>CSP has unique solution, given by the D_XD_X values.</li> </ul> </li> <li>Other<ul> <li>If the CSP has a solution, then the solution can only consist of current D_XD_X values</li> </ul> </li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#variable-elimination","title":"Variable Elimination","text":"<ul> <li>Simplify problem by eliminating variables</li> </ul> <p>Operates on extensional (table) representations of constraints</p> <p></p> <p>Algorithm requires projection and join operations on tables</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#project","title":"Project","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#join","title":"Join","text":"<p>Given two tables r_1, r_2r_1, r_2 for variables vars_1,vars_2vars_1,vars_2.</p> <p>The join is the table r_3=r_1 \\bowtie r_2r_3=r_1 \\bowtie r_2 for variables vars_1 \\cup vars_2vars_1 \\cup vars_2 that</p> <ul> <li>contains all tuples, which restricted to vars_1vars_1 are in r_1r_1, and restricted to vars_2vars_2 are in r_2r_2</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#example_1","title":"Example","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#algorithm-outline_1","title":"Algorithm Outline","text":"<p>Example slide 24 (Appendix of this page)</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#properties","title":"Properties","text":"<ul> <li>The algorithm terminates</li> <li>The CSP has a solution if and only if the final constraint is non-empty</li> <li>The set of all solutions can be generated by joining the final constraint with the intermediate \"summarizing\" constraint generated in line 5.</li> <li>Algorithm operates on extensional constraint representations, therefore<ul> <li>constraints must not contain too many tuples (initial and constructed constraints)</li> </ul> </li> <li>Worst case: VE is not more efficient than enumerating all possible worlds and checking whether they are solutions</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#constraint-graph","title":"Constraint Graph","text":"<p>Consider the graph where</p> <ul> <li>there is one node for each variable</li> <li>two variables are connected when they appear together in one constraint</li> </ul> <p></p> <p>Then VE will work better if the constraint graph is sparsely connected!</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#local-search","title":"Local Search","text":"<p>So far all methods systematically explored the state space (possible worlds)</p> <p>Problem: Time and space when search space is large</p> <p>Local Search approach:</p> <ul> <li>Explore state space without \"bookkeeping\" (where have we been, and what needs to be explored?)</li> <li>no success/terminatiuon guarantees</li> <li>in practice, often the only thing that works</li> </ul> <p>Another state space graph representation for CSPs:</p> <ul> <li>Nodes are possible worlds</li> <li>Neighbors are possible worlds that differ in the value of exactly one variable</li> </ul> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#algorithm-outline_2","title":"Algorithm Outline","text":"<pre><code>select some node in state space graph as current_state\nwhile current_state is not a solution\n    current_state = some neighbor of current_state\n</code></pre>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#random-search","title":"Random Search","text":"<ul> <li>Make choices in line 1. and 3. completely random</li> <li>\"Random Walk\"</li> <li>Unlikely to find a solution if state space is large with only a few solutions</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#greedy-search","title":"Greedy Search","text":"<p>AKA Hill Climbing.</p> <ul> <li>Use an evaluation function on states<ul> <li>Example: number of constraints not satisfied by state</li> </ul> </li> <li>Always choose neighbor with minimal evaluation function value</li> <li>Terminates when all neighbors have higher value than current state<ul> <li>(Current  state is a local minimum)</li> </ul> </li> </ul> <p>Possible greedy search paths starting from different states:</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#problem","title":"Problem","text":"<p>Search terminates with local minimum of evaluation function. This may not be a solution to the CSP</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#solution-approaches","title":"Solution Approaches","text":"<ul> <li>Random restarts<ul> <li>repeat greedy search with several randomly chosen initial states</li> </ul> </li> <li>Random moves<ul> <li>combine greedy moves with random steps</li> </ul> </li> </ul> <p>Examples</p> <p>a)  Small number of random restarts will find global minimum</p> <p>b)  Make random move when local minimum reached</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#local-seach","title":"Local Seach","text":"<ul> <li>Maintain an assignment of a value to each variable</li> <li>At each step, select a \"neighbor\" of the current assignment (e.g. one that improves some heuristic value)</li> <li>Stop when a satisfying assignement is found, or return the best assignment found</li> </ul> <p>Requires</p> <ul> <li>What is a neighbor?</li> <li>Which neighbor should be selected?</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#most-improving-step","title":"Most Improving Step","text":"<p>Select the variable-value pair that gives the highest improvement</p> <ul> <li>Maintain a priority queue with variable-value pairs not part of the current assignment</li> <li>Weight\\langle X,v \\rangle=eval(current\\ assignment)-eval(current\\ assignment\\ but\\ with\\ X=v)Weight\\langle X,v \\rangle=eval(current\\ assignment)-eval(current\\ assignment\\ but\\ with\\ X=v)</li> <li>If XX is given a new value, update the weight of all pairs participating in a changed constraint</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#two-stage-choice","title":"Two-Stage Choice","text":"<ol> <li>Choose variable</li> <li>Choose state</li> </ol> <p>Data Structure</p> <ul> <li>Maintain priority queue of variables; weight is the number of participating conflicts</li> <li>After selecting a variable, pick the value minimizes the  number of conflicts</li> <li>Update weights of variables that participate in a conflict that is changed</li> </ul>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#simulated-annealing","title":"Simulated Annealing","text":"<p>Algorithm</p> <ul> <li>Pick a variable at random and a new value at random</li> <li>If it is an improvement, adopt it.</li> <li>If it isnt an improvement, adopt it probabilistically depending on a temperature paramenter, TT<ul> <li>With current assignment nn and proposed assignment n'n' we move to n'n' with probability:</li> </ul> </li> </ul>  e^{(h(n')-h(n))/T}   e^{(h(n')-h(n))/T}  <ul> <li>Reduce the temperature</li> </ul> <p>Probability of Accepting a Change</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#propositional-logic-basics","title":"Propositional Logic Basics","text":"<p>Provides a formal language for representing constraints on binary variables</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#syntax","title":"Syntax","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#atomic-propositions","title":"Atomic Propositions","text":"<p>Convention: Start with lowercase letter</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#propositions","title":"Propositions","text":"<p>A set of propositions is also called a Knowledge Base</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#example_2","title":"Example","text":"<p>\"If it rains I'll take my umbrella, or I'll stay home\"</p>  rains\\to(umbrella \\or home)   rains\\to(umbrella \\or home)"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#semantics","title":"Semantics","text":""},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#interpretation","title":"Interpretation","text":"<p>An interpretation \\pi\\pi for a set of atomic propositions a_1,a_2,...,a_na_1,a_2,...,a_n is an assignment of a truth value to each proposition</p> <ul> <li>Equal to possible world when atomic propositions seen as boolean variables</li> </ul>  \\pi(a_i)\\in\\{true,false\\}   \\pi(a_i)\\in\\{true,false\\}  <p>An interpretation defines a thruth value for all propositions</p> <p></p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#models","title":"Models","text":"<p>A model of a proposition (knowledge base) is an interpretation in which the proposition is true</p> <p>Propositions as constraints: a model is a possible world that satisfies the constraint</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#logical-consequence","title":"Logical Consequence","text":"<p>A proposition gg is a logical consequence of a knowledge base KB, if every model of KB is a model of gg</p>  KB \\models g   KB \\models g  <p>(Whenever KB is true, then g is also true)</p>"},{"location":"5-semester/MI/09-16-constrains-satisfaction-problems/#example_3","title":"Example","text":"<p>KB=\\{man\\to mortal,man\\}KB=\\{man\\to mortal,man\\} then:</p>  KB\\models mortal   KB\\models mortal  <p></p>"},{"location":"5-semester/MI/09-16appendix/","title":"Constraints Satisfaction Problems - Appendix","text":""},{"location":"5-semester/MI/09-16appendix/#generalized-arc-consistency-algorithm-example","title":"Generalized Arc Consistency Algorithm Example","text":""},{"location":"5-semester/MI/09-16appendix/#variable-elimination-example","title":"Variable Elimination Example","text":""},{"location":"5-semester/MI/09-23-reasoning-under-certainty/","title":"Reasoning Under Uncertainty","text":"<p>Epistemological</p> <ul> <li>Pertaining to an agent\u2019s beliefs of the world</li> </ul> <p>Ontological</p> <ul> <li>How the world is.</li> </ul>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#semantics-of-probability","title":"Semantics of Probability","text":"<p>Probability theory is built on the foundation of worlds and variables.</p> <p>The variables in probability theory are referred to as random variables.</p> <p>Variables are written starting with an uppercase letter.</p> <ul> <li>Each variable has a domain. The set of values that it can take.</li> <li>A discrete variable has a domain that is a finite or countable set.</li> </ul> <p>A primitive proposition is an assignment of a value to a variable or an inequality between variables, or variables and values.</p> <p>Examples:</p> <ul> <li>A=true</li> <li>X&lt;7X&lt;7</li> <li>Y&gt;ZY&gt;Z</li> </ul> <p>Propositions are built from primitive propositions using logical connectives.</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#probability-measures","title":"Probability Measures","text":"<p>A probability measure is a function PP from worlds into non-negative real numbers</p>  P(\\Omega')\\in[0,1]   P(\\Omega')\\in[0,1]  <p>to subsets \\Omega'\\subseteq \\Omega\\Omega'\\subseteq \\Omega such that</p> <p>Axiom 1: P(\\Omega)=1P(\\Omega)=1</p> <p>Axiom 2:    if \\Omega_1 \\cap \\Omega_2=\\empty\\Omega_1 \\cap \\Omega_2=\\empty, then P(\\Omega_1\\cup\\Omega_2)=P(\\Omega_1)+P(\\Omega_2)P(\\Omega_1\\cup\\Omega_2)=P(\\Omega_1)+P(\\Omega_2)</p> <p>If all variables have a finite domain, then</p> <ul> <li>\\Omega\\Omega is finite, and</li> <li>a probability distribution is defined by assigning a probability value P(\\omega)P(\\omega)     to each individual possible world \\omega\\in\\Omega\\omega\\in\\Omega</li> </ul> <p>For any \\Omega' \\subseteq \\Omega\\Omega' \\subseteq \\Omega then</p>  P(\\Omega')=\\sum_{\\omega\\in\\Omega'}P(\\omega)   P(\\Omega')=\\sum_{\\omega\\in\\Omega'}P(\\omega)  <p>Example</p> <p></p>  P(\\Omega')=0.08+0.13+0.03+0.21=0.45   P(\\Omega')=0.08+0.13+0.03+0.21=0.45"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#probability-of-propositions","title":"Probability of Propositions","text":"<p>The definition of PP is extended to cover propositions.</p> <p>The probability of proposition \\alpha\\alpha written P(\\alpha)P(\\alpha), is the sum of the probabilities of possible worlds in which \\alpha\\alpha is true.</p>  P(a)= \\sum_{\\omega\\ :\\ \\alpha \\text{ is true in } \\omega}{P(\\omega)}   P(a)= \\sum_{\\omega\\ :\\ \\alpha \\text{ is true in } \\omega}{P(\\omega)}  <p>Example</p> <p></p>  P(Color=red)=0.08+0.13+0.03+0.21=0.45   P(Color=red)=0.08+0.13+0.03+0.21=0.45"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#probability-distribution","title":"Probability Distribution","text":"<p>If XX is a random variable, a probability distribution P(X)P(X) over XX is a function from the domain of XX into the real numbers, such that given a value</p> <p>\u200b   x\\in domain(X)x\\in domain(X), P(x)P(x) is the probability of the proposition X=xX=x.</p> <p>A probability distribution over a set of variables is a function from the values of those variables into a probability. Example:</p> <p>\u200b   P(X,Y)P(X,Y) is a probability distribution over XX and YY such that</p> <p>\u200b   P(X=x,Y=y)P(X=x,Y=y), where x\\in domain(X)x\\in domain(X) and y\\in domain(Y)y\\in domain(Y)</p> <p>has the value P(X=x \\and Y=y)P(X=x \\and Y=y) where X=x \\and Y=yX=x \\and Y=y is a proposition and PP is the function on propositions defined above.</p> <p>If X_1 \\dots X_nX_1 \\dots X_n are all of the random variables, then an assignment to all of the random variables corresponds to a world,</p> <p>and the probability of the proposition defining a world is equal to the probability of the world.</p> <p>The distribution over all worlds, P(X_1, \\dots,X_n)P(X_1, \\dots,X_n) is called the joint probability distribution.</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#axioms-for-probability","title":"Axioms for Probability","text":"<p>Axiom</p> <p>If AA and BB are disjoint, then P(A\\cup B)=P(A)+P(B)P(A\\cup B)=P(A)+P(B)</p> <p>\u200b   Example</p> <p>Consider a deck with 52 cards. If A=\\{2,3,4,5\\}A=\\{2,3,4,5\\} and B=\\{7,8\\}B=\\{7,8\\} then</p>  P(A\\cup B)=P(A)+P(B)=4/13+2/13=\\frac{6}{13}   P(A\\cup B)=P(A)+P(B)=4/13+2/13=\\frac{6}{13}  <p>More Generally</p> <p>If CC and DD are not disjoint, then P(C\\cup D)=P(C)+P(D)-P(C\\cap D)P(C\\cup D)=P(C)+P(D)-P(C\\cap D)</p> <p>\u200b   Example</p> <p>If C=\\{2,3,4,5\\}C=\\{2,3,4,5\\} and D=\\{\\spadesuit\\}D=\\{\\spadesuit\\} then</p>  P(C\\cup D)=4/13+1/4-4/52= \\frac{25}{52}   P(C\\cup D)=4/13+1/4-4/52= \\frac{25}{52}  <p></p> <p>From The Book</p> <p>Suppose PP is a function from propositions into real numbers that satisfies the following three axioms of probability:</p> <p>Axiom 1</p> <p>\u200b   0\\leq P(\\alpha)0\\leq P(\\alpha) for any proposition \\alpha\\alpha. That is, the belief in any proposition cannot be negative.</p> <p>Axiom 2</p> <p>\u200b   P(\\tau)=1P(\\tau)=1 if \\tau\\tau is a tautology. That is, if \\tau\\tau is true in all possible worlds, its probability is 1.</p> <p>Axiom 3</p> <p>\u200b   P(\\alpha \\or \\beta)=P(\\alpha)+P(\\beta)P(\\alpha \\or \\beta)=P(\\alpha)+P(\\beta) if \\alpha\\alpha and \\beta\\beta are contradictory propositions;</p> <p>That is, if \\neg(\\alpha \\or \\beta)\\neg(\\alpha \\or \\beta) is a tautology. In other words, if two propositions cannot both be true (mutually exclusive), the probability of their disjunction, is the sum of their probabilities.</p> <p>If a measure of belief follows these intuitive axioms, it is covered by probability theory.</p> <p>Proposition 8.1: </p> <p>If there are a finite number of finite discrete random variables, Axioms 1, 2 and 3 are sound and complete with respect to the semantics</p> <p>Proposition 8.2:</p> <p>The following holds for all propositions \\alpha\\alpha and \\beta\\beta:</p> <ol> <li>Negation of a proposition:</li> </ol>  P(\\neg\\alpha)=1-P(\\alpha)   P(\\neg\\alpha)=1-P(\\alpha)  <ol> <li> <p>If \\alpha \\leftrightarrow \\beta\\alpha \\leftrightarrow \\beta, then P(\\alpha)=P(\\beta)P(\\alpha)=P(\\beta). That is, logically equivalent propositions have the same probability.</p> </li> <li> <p>Reasoning by cases:</p> </li> </ol>  P(\\alpha)=P(\\alpha \\and \\beta)+P(\\alpha \\and \\neg \\beta)   P(\\alpha)=P(\\alpha \\and \\beta)+P(\\alpha \\and \\neg \\beta)  <ol> <li>If VV is a random variable with domain DD, then, for all propositions \\alpha\\alpha</li> </ol>  P(\\alpha)=\\sum_{d\\in D}{P(\\alpha \\and V = d)}   P(\\alpha)=\\sum_{d\\in D}{P(\\alpha \\and V = d)}  <ol> <li>Disjunction for non-exclusive propositions:</li> </ol>  P(\\alpha \\or \\beta)=P(\\alpha) + P(\\beta) - P(\\alpha \\and \\beta)   P(\\alpha \\or \\beta)=P(\\alpha) + P(\\beta) - P(\\alpha \\and \\beta)  <p>Proof</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#updating-probability","title":"Updating Probability","text":"<p>Given new information (evidence), degrees of belief change</p> <p>Evidence can be represented as the set of possible world \\Omega'\\Omega' not ruled out by the observation</p> <p></p> <p>When we observe \\Omega'\\Omega'</p> <ul> <li>Worlds that are not consistent with evidence have probability 0</li> <li>The probabilities of worlds consistent with evidence are proportional to their probability before observation, and must sum to 1</li> </ul> <p></p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#conditional-probability","title":"Conditional Probability","text":"<p>The measure of belief in proposition pp given proposition ee is called the conditional probability of pp given ee. Written:</p>  P(p\\mid e)   P(p\\mid e)  <p>A proposition ee representing the conjunction of all of the agent\u2019s observations of the world is called evidence.</p> <p>Given evidence ee, the conditional probability P(p\\mid e)P(p\\mid e) is the agents posterior probability of pp. The probability P(p)P(p) is the prior probability of pp and is the same as P(p\\mid true)P(p\\mid true).</p> <p>The conditional probability of pp given ee is:</p>  P(p\\mid e)=\\frac{P(p\\and e)}{P(e)}   P(p\\mid e)=\\frac{P(p\\and e)}{P(e)}  <p>Example</p> <p></p> <p>(probability for each world is 0.1) $$ P(S=circle\\mid Fill=f)=\\frac{P(S=cicle\\and Fill=f)}{P(Fill=f)}=0.1/0.4=0.25 $$</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#bayes-rule","title":"Bayes Rule","text":"<p>For propositions p,ep,e:</p>  P(p\\mid e)=\\frac{P(e\\and p)}{P(e)}=\\frac{P(e\\mid p)\\cdot P(p)}{P(e)}=\\frac{P(e\\mid p)\\cdot P(p)}{P(e\\and p)+P(e\\and \\neg p)}   P(p\\mid e)=\\frac{P(e\\and p)}{P(e)}=\\frac{P(e\\mid p)\\cdot P(p)}{P(e)}=\\frac{P(e\\mid p)\\cdot P(p)}{P(e\\and p)+P(e\\and \\neg p)}  <p>Example</p> <p>A doctor observes symptoms and wishes to find the probability of a disease:</p>  P(disease\\mid symp.)=\\frac{P(symp.\\mid disease)\\cdot P(disease)}{P(sympt.)}   P(disease\\mid symp.)=\\frac{P(symp.\\mid disease)\\cdot P(disease)}{P(sympt.)}"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#chain-rule","title":"Chain Rule","text":"<p>For propositions p_1,...,p_np_1,...,p_n:</p>  P(p_1\\and \\dots \\and p_n)=P(p_1)P(p_2\\mid p_1)\\cdots P(p_i\\mid p_1\\and\\dots\\and p_{i-1})\\cdots P(p_n\\mid p_1 \\and\\dots\\and p_{n-1})   P(p_1\\and \\dots \\and p_n)=P(p_1)P(p_2\\mid p_1)\\cdots P(p_i\\mid p_1\\and\\dots\\and p_{i-1})\\cdots P(p_n\\mid p_1 \\and\\dots\\and p_{n-1})"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#semantics-of-conditional-probability","title":"Semantics of Conditional Probability","text":"<p>Evidence e ee where ee is a proposition, will rule out all possible worlds that are incompatible with ee.</p> <p>Evidence ee induces a new probability P(w\\mid e)P(w\\mid e) of world  ww given ee. Any world where ee is false has conditional probability 00, and remaining worlds are normalized so their probabilities sum to 11:</p>  P(w\\mid e)= \\left\\{{ \\begin{array}{rcl} c \\cdot P(w) &amp; \\text{if} &amp; e \\text{ is true in world } w  \\\\  0 &amp; \\text{if} &amp; e \\text{ is false in world } w \\end{array}}\\right.   P(w\\mid e)= \\left\\{{ \\begin{array}{rcl} c \\cdot P(w) &amp; \\text{if} &amp; e \\text{ is true in world } w  \\\\  0 &amp; \\text{if} &amp; e \\text{ is false in world } w \\end{array}}\\right.  <p>where cc is a constant (that depends on ee) that ensures the posterior probability of all worlds sums to 11.</p> <p>For P(w \\mid e)P(w \\mid e) to be a probability measure over worlds for each ee:</p> <p></p> <p>Therefore, c=1/P(e)c=1/P(e). Thus, the conditional probability is only defined if P(e)&gt;0P(e)&gt;0</p> <p>The conditional probability of proposition hh given evidence ee is the sum of the conditional probabilities of the possible worlds in which hh is true:</p> <p></p> <p>A conditional probability distribution, written P(X \\mid Y)P(X \\mid Y), where XX and YY are variables or sets of variables, is a function of the variables:</p> <p>Given a value x\\in domain(X)x\\in domain(X) for XX and a value y \\in domain(Y)y \\in domain(Y) for YY, it gives the value P(X=x \\mid Y= y)P(X=x \\mid Y= y).</p> <p>Proposition 8.3 (Chain rule):</p> <p>For any propositions a_1,\\dots,a_na_1,\\dots,a_n:</p>  \\begin{align*} P(a_1 \\and a_2 \\and \\dots \\and a_n) &amp;= &amp;&amp;P(a_1)^*\\\\ &amp; &amp;&amp; P(a_2 \\mid a_1)^*\\\\ &amp; &amp;&amp; P(a_3 \\mid a_1 \\and a_2)^*\\\\ &amp; &amp;&amp; \\vdots \\\\ &amp; &amp;&amp; P(a_n \\mid a_1 \\and \\dots \\and a_n-1)\\\\ &amp;= &amp;&amp; \\prod^n_{i=1}{P(a_i \\mid a_1 \\and \\dots \\and a_i-1),} \\end{align*}   \\begin{align*} P(a_1 \\and a_2 \\and \\dots \\and a_n) &amp;= &amp;&amp;P(a_1)^*\\\\ &amp; &amp;&amp; P(a_2 \\mid a_1)^*\\\\ &amp; &amp;&amp; P(a_3 \\mid a_1 \\and a_2)^*\\\\ &amp; &amp;&amp; \\vdots \\\\ &amp; &amp;&amp; P(a_n \\mid a_1 \\and \\dots \\and a_n-1)\\\\ &amp;= &amp;&amp; \\prod^n_{i=1}{P(a_i \\mid a_1 \\and \\dots \\and a_i-1),} \\end{align*}  <p>\u200b   where the right-hand side is assumed to be zero if any of the products are zero (even if some of them are  undefined.</p> <p>Note</p> <p>Complete notes. From Bayes' Rule</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#random-variables-and-distributions","title":"Random Variables and Distributions","text":"<p>Random Variables</p> <p>Variables defining possible worlds on which probabilities are defined.</p> <p>Distributions</p> <p>For a random variable AA, and a\\in D_Aa\\in D_A we have the probability</p>  P(A=a)=P(\\{ \\omega\\in\\Omega \\mid A=a \\text{ in } \\omega\\})   P(A=a)=P(\\{ \\omega\\in\\Omega \\mid A=a \\text{ in } \\omega\\})  <p>The probability distribution of AA is the function on D_AD_A that maps aa to P(A=a)P(A=a) The distribution of AA is denoted</p>  P(A)   P(A)  <p>Joint Distributions</p> <p>Extension to several random variables</p>  P(A_1,\\dots,A_k)   P(A_1,\\dots,A_k)  <p>is the joint distribution of A_1,\\dots,A_kA_1,\\dots,A_k The joint distribution tuples (a_1,\\dots,a_k)(a_1,\\dots,a_k) with a_i\\in D_{A_i}a_i\\in D_{A_i} to the probability $$ P(A_1=a_1,\\dots,A_k=a_k) $$</p>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#chain-rule-for-distributions","title":"Chain Rule for Distributions","text":"P(A_1,\\dots,A_n)=P(A_1)P(A_2\\mid A_1)\\cdots P(A_i\\mid A_1,\\dots,A_{i-1})\\cdots P(A_n\\mid A_1,\\dots,A_{n-1})   P(A_1,\\dots,A_n)=P(A_1)P(A_2\\mid A_1)\\cdots P(A_i\\mid A_1,\\dots,A_{i-1})\\cdots P(A_n\\mid A_1,\\dots,A_{n-1})  <p>Note: </p> <ul> <li>Each P(p_i\\mid p_1\\and\\dots\\and p_{i-1})P(p_i\\mid p_1\\and\\dots\\and p_{i-1}) was a number.</li> <li>Each P(A_i\\mid A_1,\\dots,A_{i-1})P(A_i\\mid A_1,\\dots,A_{i-1}) is a function on tuples (a_1,\\dots,a_i)(a_1,\\dots,a_i)</li> </ul>"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#bayes-rules-for-variables","title":"Bayes rules for Variables","text":""},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#independence","title":"Independence","text":"<p>The variables A_i,\\dots,A_kA_i,\\dots,A_k and B_1,\\dots,B_mB_1,\\dots,B_m are independent if:</p>  P(A_1,\\dots,A_k \\mid B_1,\\dots,B_m)=P(A_1,\\dots,A_k)   P(A_1,\\dots,A_k \\mid B_1,\\dots,B_m)=P(A_1,\\dots,A_k)  <p>Which is equivalent to</p>  P(B_1,\\dots,B_m \\mid A_1,\\dots,A_k)=P(B_1,\\dots,B_m)   P(B_1,\\dots,B_m \\mid A_1,\\dots,A_k)=P(B_1,\\dots,B_m)  <p>and</p>  P(A_1,\\dots,A_k,B_1,\\dots,B_m)=P(A_1,\\dots,A_k)\\cdot P(B_1,\\dots,B_m)   P(A_1,\\dots,A_k,B_1,\\dots,B_m)=P(A_1,\\dots,A_k)\\cdot P(B_1,\\dots,B_m)"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#example","title":"Example","text":"<p>Results for Bayern Munich and SC Freiburg in seasons 2001/02and 2003/04. (Not counting thematches Munich vs. Freiburg):</p>  D_{Munich}=D_{Freiburg}=\\{Win,Draw,Loss\\}   D_{Munich}=D_{Freiburg}=\\{Win,Draw,Loss\\}  <p></p> <p>Summary:</p> <p></p> <p>Joint distribution</p> <p></p> <p>Conditional Distribution \\color{blue}P(Munich\\mid Freiburg)\\color{blue}P(Munich\\mid Freiburg)</p> <p></p> <p>We have (almost): P(Munich \\mid Freiburg)=P(Munich)P(Munich \\mid Freiburg)=P(Munich)</p> <p>The variables Munich and Freiburg are independant</p> <p>Independance can greatly simplify the specification of a joint distribution:</p> <p></p> <p>The probability for each possible world is then defined e.g. </p>  P(M=D,F=L)=0.25\\cdot 0.4062 = 0.10155   P(M=D,F=L)=0.25\\cdot 0.4062 = 0.10155"},{"location":"5-semester/MI/09-23-reasoning-under-certainty/#conditionally-independent-variables","title":"Conditionally Independent Variables","text":"<p>The variables A_1,\\dots,A_nA_1,\\dots,A_n are conditionally independent of the variables B_1,\\dots,B_mB_1,\\dots,B_m given C_1,\\dots,C_kC_1,\\dots,C_k if</p>  P(A_1,\\dots,A_n \\mid B_1,\\dots,B_m,C_1,\\dots,C_k)=P(A_1,\\dots,A_n\\mid C_1,\\dots,C_k)   P(A_1,\\dots,A_n \\mid B_1,\\dots,B_m,C_1,\\dots,C_k)=P(A_1,\\dots,A_n\\mid C_1,\\dots,C_k)"},{"location":"5-semester/MI/10-07-bayesian-networks/","title":"Bayesian Networks","text":""},{"location":"5-semester/MI/10-07-bayesian-networks/#reasoning-under-uncertainty","title":"Reasoning Under Uncertainty","text":"<p>Example: Car-start-problem:</p> <p>\u201cIn the morning, my car will not start. I can hear the starter turn, but nothing happens. There may be several reasons for my problem. I can hear the starter roll, so there must be power from the battery. Therefore, the most probable causes are that the fuel has been stolen overnight or that the spark plugs are dirty. It may also be due to dirt in the carburetor, a loose connection in the ignition system, or something more serious. To find out, I first look at the fuel meter. It shows half full, so I decide to clean the spark plugs.\u201d</p> <ul> <li>How can you make a computer do these assumptions, and make a choice what to check?</li> </ul> <p>For propositional logic we have Boolean logic as a framework.</p> <p>When we deal with uncertain events, it would be nice to have something similar. We can extend the truth values of propositional logic to \"certainties\" which are numbers between 1 and 0.</p> <p>Certainties: </p> <ul> <li>A certainty of 0 means \"certainly not true\"</li> <li>A certainty of 1 means \"certainly true\"</li> </ul> <p>Example:</p> <p>\u201cif I take a cup of coffee while on break, I will with certainty 0.5 stay awake during the next lecture\u201d</p> <p>or</p> <p>\u201cif I take a short walk during the break, I will with certainty 0.8 stay awake during the next lecture.\u201d</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#casual-perspective-on-car-start-problem","title":"Casual Perspective on Car Start Problem","text":"<p>To simplify, we assume that we have</p> <ul> <li>${yes, no} $ for Fuel?</li> <li>\\{yes, no\\}\\{yes, no\\} for Clean\\ Spark\\ Plugs?Clean\\ Spark\\ Plugs?</li> <li>\\{full, 1/2, empty\\}\\{full, 1/2, empty\\} for Fuel\\ MeterFuel\\ Meter</li> <li>\\{yes, no\\}\\{yes, no\\} for Start?Start?.</li> </ul> <p>AKA states.</p> <p>We know that the state of Fuel?Fuel? and Clean\\ Spark\\ Plugs?Clean\\ Spark\\ Plugs? have a casual impact on the state of Start?Start?.</p> <p>Also, the state of Fuel?Fuel? has an impact on the state of Fuel\\ MeterFuel\\ Meter.</p> <p>This can be represented with a graph:</p> <p></p> <p>If we add a direction from nono to yesyes in each variable, we can represent directions of the impact. (Fig. 2.2.)</p> <p></p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#casual-networks-and-d-separation","title":"Casual Networks and d-Separation","text":"<p>A Casual Network consists of</p> <ul> <li>A set of variables</li> <li>A set of directed links (aka arcs)</li> </ul> <p>Mathematically a directed graph.</p> <p>If there is a link from A to B we say that B is a child of A, and A is a parent of B.</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#bayesian-network","title":"Bayesian Network","text":"<p>A Bayesian Network for variables A_1,\\dots,A_kA_1,\\dots,A_k consists of</p> <ul> <li>a directed acyclic graph with nodes A_1,...,A_kA_1,...,A_k</li> <li>for each node a conditional probability table specifying the conditional distribution     P(A_i\\mid parents(A_i))P(A_i\\mid parents(A_i))<ul> <li>parents(A_i)parents(A_i) denotes the parents of A_iA_i in the graph</li> </ul> </li> </ul> <p>and through the chain rule provides a compact representation of a joint probability distribution</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#example","title":"Example","text":"<p>To turn this graph into a Bayesian network, the following conditional probability tables must be specified:</p>  \\begin{align*} &amp;P(A)\\\\&amp;P(B)\\\\&amp;P(C\\mid A,B)\\\\&amp;P(D\\mid A,C)\\\\&amp;P(E\\mid B,D,F)\\\\&amp;P(F\\mid A) \\end{align*}   \\begin{align*} &amp;P(A)\\\\&amp;P(B)\\\\&amp;P(C\\mid A,B)\\\\&amp;P(D\\mid A,C)\\\\&amp;P(E\\mid B,D,F)\\\\&amp;P(F\\mid A) \\end{align*}"},{"location":"5-semester/MI/10-07-bayesian-networks/#constructing-a-bayesian-network","title":"Constructing a Bayesian Network","text":""},{"location":"5-semester/MI/10-07-bayesian-networks/#via-chain-rule","title":"Via Chain Rule","text":"<ol> <li>Put the random variables in some order</li> <li>Write the joint distribution using chain rule</li> <li>Simplify conditional probability factors by conditional independence assumptions.     That determines the parents of each node i.e. the graph structure</li> <li>Specify the conditional probability tables</li> </ol> <p>Note: The structure of the resulting network strongly depends on the chosen order of the variables.</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#via-causality","title":"Via Causality","text":"<ul> <li>Draw an edge from variable AA to variable BB if AA has a direct casual influence on AA</li> </ul> <p>Note: This may not always be possible:</p> <ul> <li>Inflation \\to\\to salaries or salaries \\to\\to inflation?</li> <li>Rain doesn't cause Sun, and Sun doesn't cause Rain, but they are not independent either.</li> </ul>"},{"location":"5-semester/MI/10-07-bayesian-networks/#transmission-of-evidence","title":"Transmission of Evidence","text":""},{"location":"5-semester/MI/10-07-bayesian-networks/#serial-connection","title":"Serial Connection","text":"<p>Consider fig 2.3:</p> <p></p> <p>Evidence about A will influence the certainty of B, which influences the certainty of C. Similarly, evidence about C will influence the certainty of A through B.</p> <p>If the state of B is known, the channel is \"blocked\" and we say that A and C are d-separated given B.</p> <p>When a state of a variable is known, we say that the variable is instantiated.</p> <p>We conclude that evidence may be transmitted through a serial connection unless the state of the variable in the connection is known</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#diverging-connection","title":"Diverging Connection","text":"<p>Influence can pass between all the children of A unless the state of A is known.</p> <ul> <li>B,C,...,E are d-separated given A</li> </ul>"},{"location":"5-semester/MI/10-07-bayesian-networks/#converging-connection","title":"Converging Connection","text":"<ul> <li>If nothing is known about A except what may be inferred from knowledge of its parents, then the parents are independent.</li> <li>However, if anything is known about the consequences, then information on on possible cause may tell us something about the other causes.</li> </ul>"},{"location":"5-semester/MI/10-07-bayesian-networks/#d-separation","title":"D-Separation","text":"<p>Definition</p> <p>Two distinct variables AA and BB in a casual network are d-separated if for all paths between AA and BB, there is an intermediate variable V\\neq A \\and V\\neq BV\\neq A \\and V\\neq B such that either:</p> <ul> <li>the connection is serial or diverging and VV is instantiated, or</li> <li>the connection is converging, and neither VV nor any of VV's descendants have received evidence.</li> </ul> <p>If AA and BB are not d-separated, we call them d-connected</p> <p>Theorem</p> <p>For all pairwise disjoint sets A,B,CA,B,C of nodes in a Bayesian network:</p> <ul> <li>If CC d-separates AA from BB then P(A\\mid B,C)=P(A\\mid C)P(A\\mid B,C)=P(A\\mid C)</li> </ul> <p>Note:</p> <p>N\u00e5r man tjekker efter d-seperation, s\u00e5 tjek hele ruten p\u00e5 en gang!</p> <p>Tjek efter d-seperated, og IKKE efter d-connection</p>"},{"location":"5-semester/MI/10-07-bayesian-networks/#probabilities-in-bayesian-network","title":"Probabilities in Bayesian Network","text":"<p>Define parents of random variable X_iX_i written parents(X_i)parents(X_i) to be a minimal set of predecessors of X_iX_i in the total ordering such that the other predecessors fo X_iX_i asre conditionally independent of X_iX_i given parents(X_i)parents(X_i).</p> <p>Thus X_iX_i probabilistically depends on each of its parents, but is independant of its other predecessors.</p> <p>$$ P(X_i\\mid X_1,\\dots,X_i-1)=P(X_i\\mid parents(X_i)) $$ Putting the chain rule and the definition of parents together gives.</p>  P(X_1,X_2,\\dots,X_n)=\\prod_{i=1}^n P(X_i \\mid parents(X_i))   P(X_1,X_2,\\dots,X_n)=\\prod_{i=1}^n P(X_i \\mid parents(X_i))  <p>If network contains \\{A,B,C\\}\\{A,B,C\\} then</p>  P(A,C)=\\sum_{B}P(A,B,C)   P(A,C)=\\sum_{B}P(A,B,C)  <p>and</p> <p></p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/","title":"Inference in Bayesian Networks","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#inference","title":"Inference","text":"<p>Inference Problem:</p> <ul> <li>Given: a Bayesian network</li> <li>Given an assignment of values to some of the variables in the network: E_i=e_i(i=1,\\dots,l)<ul> <li>\"Instantiation of the nodes \\bold E\\bold E\"</li> <li>\"Evidence \\bold E=e\\bold E=e entered\"</li> <li>\"Findings entered\"</li> <li>...</li> </ul> </li> <li>Want: for variables A\\notin \\bold EA\\notin \\bold E the posterior margnial P(A\\mid \\bold E=e)P(A\\mid \\bold E=e)</li> </ul> <p>According to the definition of conditional probability, it is sufficient to compute for each A\\in D_AA\\in D_A the value</p>  P(A=a,\\bold E=e)   P(A=a,\\bold E=e)  <p>Together with</p>  P(\\bold E=e)=\\sum_{a\\in D_A}P(A=a,\\bold E=e)   P(\\bold E=e)=\\sum_{a\\in D_A}P(A=a,\\bold E=e)  <p>This gives the posterior distribution</p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#inference-as-summation","title":"Inference as Summation","text":"<p>Let AA be the variable of interest, \\bold E\\bold E the evidence variables, and \\bold Y=Y_1,\\dots,Y_l\\bold Y=Y_1,\\dots,Y_l the remaining variables in the network not belonging to A\\cup \\bold EA\\cup \\bold E. Then</p> <p>$$ P(A=a,\\bold E=e)=\\sum_{y_1\\in D_{Y_1}}\\cdots\\sum_{y_l\\in D_{Y_l}}P(A=a,\\bold E=e,Y_1=y_1,\\dots,Y_l=y_l) $$ Note:</p> <ul> <li>For each \\bold y\\bold y the probability P(A=a,\\bold E = \\bold e, \\bold Y = \\bold y)P(A=a,\\bold E = \\bold e, \\bold Y = \\bold y) can be computed from the network      In time linear in the number of random variables</li> <li>The number of configurations over \\bold Y\\bold Y is exponential in ll</li> </ul>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#inference-problems","title":"Inference Problems","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#first-problem","title":"First Problem","text":"<p>Find P(B\\mid a,f,g,h)={P(B,a,f,g,h)\\over P(a,f,g,h)}P(B\\mid a,f,g,h)={P(B,a,f,g,h)\\over P(a,f,g,h)}</p> <p>We can if we have access to P(A,B,C,D,E,F,G,H)P(A,B,C,D,E,F,G,H)</p>  P(A,B,C,D,E,F,G,H)=P(A)P(B)P(C)P(D\\mid A,B)\\cdots P(H\\mid E)   P(A,B,C,D,E,F,G,H)=P(A)P(B)P(C)P(D\\mid A,B)\\cdots P(H\\mid E)  <p>Inserting evidence we get:</p> <p></p> <p>and</p> <p></p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#second-problem","title":"Second Problem","text":"<p>See naive solution in Lecture 14.10 Slides 8-11</p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#naive-solution-summary","title":"Naive Solution Summary","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#variable-elimination","title":"Variable Elimination","text":"<p>Problem</p> <p>The joint probability distribution will contain exponentially many entries</p> <p>Idea</p> <p>We can use</p> <ul> <li>the form of the joint distribution PP, and</li> <li>the law of distributivity</li> </ul> <p>to make the computation of the sum more efficient</p> <p>Thus, we can adapt our elimination procedure so that:</p> <ul> <li>we marginalize out variables sequentially</li> <li>when marginalizing out a particular variable XX, we only need to consider the factors involving XX</li> </ul>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#example","title":"Example","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#factors","title":"Factors","text":"<p>Calculus of factors</p> <ul> <li> <p>The procedure operates on factors: functions of subsets of variables</p> </li> <li> <p>Required operations on factors:</p> <ul> <li>multiplication</li> <li>marginalization (summing out selected variables)</li> <li>restriction (setting selected variables to specific values)</li> </ul> </li> </ul> <p>Complexity</p> <p></p> <p>See example in Lecture 14.10 Slides 16-17</p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#singly-connected-networks","title":"Singly Connected Networks","text":"<p>A singly connected network is a network in which any two nodes are connected by at most one path of undirected edges.</p> <p></p> <p>For singly connected network: any elimination order that \"peels\" variables from outside will only create factors of one variable.</p> <p>The complexity of inference is therefore linear in the total size of the network ( = combined size of all conditional probability tables)</p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#approximate-inference","title":"Approximate Inference","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#sample-generator","title":"Sample Generator","text":"<p>Observation: can use Bayesian network as random generator that produces states \\bold X = \\bold x\\bold X = \\bold x according to distribution PP defined by the network</p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#example_1","title":"Example","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#approximate-inference-from-samples","title":"Approximate Inference from Samples","text":"<p>To compute an approximation of P(\\bold E = \\bold e)P(\\bold E = \\bold e) (\\bold E\\bold E is a subset of the variables in the Bayesian network):</p> <ul> <li>generate a (large) number of random states</li> <li>count the frequency of states in which \\bold E = \\bold e\\bold E = \\bold e</li> </ul> <p></p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#hoeffding-bound","title":"Hoeffding Bound","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#required-sample-size","title":"Required Sample Size","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#example_2","title":"Example","text":""},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#rejection-sampling","title":"Rejection Sampling","text":"<p>The simplest approach: Rejection Sampling</p> <p></p> <p>Problem</p> <p>Samples with \\bold E \\neq \\bold e\\bold E \\neq \\bold e are useless!</p> <p>Ideally: would draw samples directly from the conditional distribution P(\\bold A \\mid \\bold E = \\bold e)P(\\bold A \\mid \\bold E = \\bold e)</p> <p></p>"},{"location":"5-semester/MI/10-14-inference-in-bayesian-networks/#likelihood-weighting","title":"Likelihood Weighting","text":"<p>We would like to sample from</p> <p></p> <p>So instead weigh each generated sample with a weight corresponding to Part 2</p> <p></p> <p></p>"},{"location":"5-semester/MI/10-21-decision-trees/","title":"Learning: Introduction and Decision Trees","text":"<p>Learning: The ability of an agent to improve its behavior based on experience, e.g.:</p> <ul> <li>The range of behaviors is expanded; the agent can do more. </li> <li>The accuracy on tasks is improved; the agent can do things better. </li> <li>The speed is improved; the agent can do things faster. </li> </ul>  \\newcommand{pval}{\\widehat Y}\\nonumber"},{"location":"5-semester/MI/10-21-decision-trees/#learning-issues","title":"Learning Issues","text":"<p>The following components are part of any learning problem:</p> <ul> <li>Task: The behavior or task that is being improved</li> <li>Data: The experiences that are used to improve performance in the task, usually in the form of a sequence of examples</li> <li>Measure of improvement: How the improvement is measured. Examples:<ul> <li>New skills that were not present initially</li> <li>Increasing accuracy in prediction</li> <li>Improved speed</li> </ul> </li> </ul> <p>Learning techniques face the following issues:</p>"},{"location":"5-semester/MI/10-21-decision-trees/#task","title":"Task","text":"<p>7.1: Task</p> <p>The most commonly studied learning task is supervised learning:</p> <ul> <li>Given some input features, some target features, and a set of training examples where the input features and target features are specified, predict the value of target features for new examples given their values on the input features.<ul> <li>This is called classification when the target features are discrete,</li> <li>And regression when the target features are continuous.</li> </ul> </li> </ul> <p>Other learning tasks include:</p> <ul> <li>Unsupervised learning<ul> <li>Without defined targets</li> </ul> </li> <li>Reinforced learning<ul> <li>Based on rewards and punishments</li> </ul> </li> <li>Analytic learning<ul> <li>Learning to reason faster</li> </ul> </li> <li>Inductive logic programming<ul> <li>Learning richer representation such as logic programs</li> </ul> </li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#feedback","title":"Feedback","text":"<p>7.1: Feedback</p> <p>Learning tasks can be characterized by the feedback given to the learner.</p> <ul> <li>Supervised Learning: What has to be learned is specified for each training example.</li> <li>Unsupervised Learning: No classifications are given, and the learner must discover categories and regularities in the data.</li> </ul> <p>Feedback often falls between these extremes, such as:</p> <ul> <li> <p>Reinforcement Learning: Feedback in terms of rewards and punishments occurs after a sequence of actions</p> <ul> <li>This leads to the credit assignment problem of determining which actions were responsible for the rewards or punishments.</li> </ul> </li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#representation","title":"Representation","text":"<p>7.1: Representation</p> <p>Experiences must affect the agents internal representation. This internal representation could be the raw experiences, but it is typically a compact representation that generalizes the data.</p> <ul> <li> <p>The problem of inferring an internal representation based on examples is called induction.</p> </li> <li> <p>The problem of deriving consequences of a knowledge base is called deduction</p> </li> <li>Hypothesizing what may be true about a particular case is called abduction</li> </ul> <p>Two principles are at odds:</p> <ul> <li>The richer the representation, the more useful it is for subsequent problem solving. </li> <li>The richer the representation, the more difficult it is to learn.</li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#online-and-offline","title":"Online and Offline","text":"<ul> <li>Online Learning: Training examples arrive as the agent is acting.</li> <li>Offline Learning: All of the training examples are available to an agent before it needs to act.</li> </ul> <p>An agent that learns online requires some representation of its previously seen examples before it has seen all of its examples. As new examples are observed, the agent must update its representation. </p> <p>Active learning is a form of online learning in which the agent acts to acquire useful examples from which to learn.</p>"},{"location":"5-semester/MI/10-21-decision-trees/#measuring-success","title":"Measuring Success","text":"<p>To know whether an agent has learned, we must define a measure of success. The measure is usually not how well the agent performs on the training data, but how well the agent performs for new data. </p> <p>Success in learning should not be judged on correctly classifying the training set, but  on being able to correctly classify unseen examples.</p> <ul> <li>Thus, the learner must generalize: go beyond the specific given examples to classify unseen examples.</li> </ul> <p>To evaluate a learning procedure, we can divide the examples into training examples and test examples.</p>"},{"location":"5-semester/MI/10-21-decision-trees/#bias","title":"Bias","text":"<p>The tendency to prefer one hypothesis over another is called a bias.</p> <ul> <li>Without a bias, an agent will not be able to make any predictions on unseen examples.</li> <li>What constitutes a good bias is an empirical question about which biases work best in practice.</li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#learning-as-search","title":"Learning as Search","text":"<p>Given a representation and a bias, the problem of learning can be reduced to one of search.</p> <p>Unfortunately, the search spaces are typically prohibitively large for systematic search.</p> <ul> <li>The definition of the learning algorithm then becomes one of defining the search space, evaluation function and search method.</li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#noise","title":"Noise","text":"<p>In most real-world situations, the data are not perfect. </p> <p>There can be noise where the observed features are not adequate to predict the classification, missing data where the observations of some of the features for some or all of the examples are missing, and errors where some of the features have been assigned wrong values. </p> <p>One of the important properties of a learning algorithm is its ability to handle noisy data in all of its forms. </p>"},{"location":"5-semester/MI/10-21-decision-trees/#interpolation-and-extrapolation","title":"Interpolation and Extrapolation","text":"<p>Interpolation: Making a prediction between cases for which there are  data.</p> <p>Extrapolation: Making a prediction that goes beyond the seen examples.</p> <p>Extrapolation is usually much less accurate than interpolation.</p>"},{"location":"5-semester/MI/10-21-decision-trees/#supervised-learning","title":"Supervised Learning","text":"<p>7.2 Supervised Learning</p> <p>A set of examples and a set of features, partitioned into input features and target features.</p> <p>The aim is to predict the values of the target features from the input features.</p> <p>A feature is a function from examples into a value.</p> <p>If ee is an example, and FF is a feature, then F(e)F(e) is the value of feature FF for example ee.</p> <p>The domain of a feature is the set of values it can return.</p> <p>In a supervised learning task, the learner is given:</p> <ul> <li>a set of input features, X_1,\\dots,X_nX_1,\\dots,X_n</li> <li>a set of target features,  Y_1,\\dots,Y_nY_1,\\dots,Y_n</li> <li>a set of training examples, where the values for the input and target features are given for each example</li> <li>a set of test examples, where only the values for the input features are given.</li> </ul> <p>The aim is to predict the values of the target features for the test examples and as-yet-unseen examples.</p> <p>Example 7.1</p> <p></p> <p>See the image above. </p> <p>Predicting the value of YY is a regression task, because YY is a real-valued feature.</p> <p>Example e_8e_8 is an interpolation problem, because the value of XX is between the values of the training examples.</p> <p>Example e_9e_9 is an extrapolation problem, because the value of XX is outside the range of the range of the training examples.</p>"},{"location":"5-semester/MI/10-21-decision-trees/#evaluating-predictions","title":"Evaluating Predictions","text":"<p>A point estimate for target feature YY on example ee is a prediction of the value of Y(e)Y(e).</p> <p>Let \\widehat{Y}(e)\\widehat{Y}(e) be the predicted value for target feature YY on example ee.</p> <p>The error for this example on this feature is a measure of how close \\widehat Y(e)\\widehat Y(e) is to Y(e)Y(e).</p> <p>For regression, both \\widehat Y(e)\\widehat Y(e) and Y(e)Y(e) are real numbers that can be compared arithmetically.</p> <p>For classification, when the target feature YY is a discrete function, there are a number of alternatives:</p> <ul> <li> <p>When the domain of YY is binary, we can associate one value with 0 and the other with 1, and the prediction can be some real number.</p> </li> <li> <p>In a cardinal feature the values are mapped to real numbers. This is appropriate when the values in the domain are totally ordered,  and the differences between the numbers are meaningful.</p> <p>Often,  mapping values to the real line is not appropriate even if the values are totally ordered.</p> <ul> <li>Example: Values = short, medium, longshort, medium, long. The prediction that the value is either shortshort or longlong is very different from the prediction that the value is mediummedium</li> </ul> <p>When the domain of a feature is totally ordered, but the differences between the values are not comparable, the features is called an ordinal feature</p> </li> <li> <p>For a totally ordered feature, either cardinal or ordinal, and for a given value vv, a Boolean feature can be constructed as a cut:</p> <ul> <li>A new feature that has value 11 when Y\\leq vY\\leq v and 00 otherwise.</li> </ul> <p>Combining cuts allows for features that are true for intervals.</p> </li> <li> <p>When YY is discrete with domain \\{v_1,\\dots,v_k\\}\\{v_1,\\dots,v_k\\}, where k&gt;2k&gt;2, a separate prediction can be made for each v_iv_i.     This can be modeled by having a binary indicator variable, Y_iY_i, associated with each value v_iv_i,      where Y_i(e)=1Y_i(e)=1 if Y(e)=v_iY(e)=v_i, and Y_i(e)=0Y_i(e)=0 otherwise.</p> </li> </ul> <p>Example 7.3</p>"},{"location":"5-semester/MI/10-21-decision-trees/#prediction-error","title":"Prediction Error","text":"<p>In the following measures of prediction error,</p> <p>\u200b   EE is a set of examples, and \u200b   TT is a set of target features.</p> <p>For target feature Y\\in TY\\in T and example e\\in Ee\\in E, the actual value is Y(e)Y(e) and the predicted value is \\pval\\pval.</p> <p>The 0/1 error on EE is the sum of the number of predictions that are wrong:</p> <p>$$ \\sum_{e\\in E} \\sum_{Y\\in T}Y(e) \\neq \\pval(e)\\ , $$ \u200b   where Y(e)\\neq \\pval(e)Y(e)\\neq \\pval(e) is 0 when false and 1 when true.</p> <p>This is the number of incorrect predictions, not taking into account how wrong the predictions are.</p> <p>The absolute error on EE is the sum of the absolute differences between the actual and predicted values:</p> <p>$$ \\sum_{e\\in E}\\sum_{Y \\in T} \\left| Y(e)-\\pval(e) \\right| $$ This is always non-negative, and is only zero when all predictions exactly fit the observed values.  Here close predictions are better than far-away predictions.</p> <p>The sum-of-squares error on EE is:</p>  \\sum_{e\\in E}\\sum_{Y \\in T}(Y(e)-\\pval(e))^2   \\sum_{e\\in E}\\sum_{Y \\in T}(Y(e)-\\pval(e))^2  <p>This treats large errors as much worse than small errors.</p> <p>The worst-case error on EE is the maximum absolute difference: $$ \\max_{e\\in E}\\max_{Y\\in T} \\left| Y(e) - \\pval(e) \\right| $$ In this case, the learner is evaluated by how bad it can be.</p> <p>These are often described in terms of the norms of the differences between the predicted and actual values.</p> <p>The 0/1 error is the L_0L_0 error, the absolute error is the L_1L_1 error, the sum-of-squares error is the square of the L_2L_2 error, and the worst-case error is the L_\\inftyL_\\infty error.</p> <p>The sum-of-squares error is often written as L_2^2L_2^2 as the L_2L_2 norm takes the square root of the sum of squares.</p> <p>Example 7.4</p> <p>For the special case where the domain of YY is \\{0,1\\}\\{0,1\\}, and the prediction is in the range [0,1][0,1] (and so for Boolean domains where truetrue is treated as 1, and falsefalse as 0), the following can also be used to evaluate predictions: </p> <ul> <li>likelihood of the data</li> <li>log-likelihood </li> </ul> <p>See https://artint.info/2e/html/ArtInt2e.Ch7.S2.SS1.html#p5 </p>"},{"location":"5-semester/MI/10-21-decision-trees/#types-of-errors","title":"Types of Errors","text":"<ul> <li>A false-positive error (type I error)</li> <li>A false-negative error (type II error)</li> </ul> <p>For a given predictor for a given set of examples, suppose</p> <ul> <li>tptp is the number of true positives,</li> <li>fpfp is the number of false positives,</li> <li>fnfn is the number of false negatives, and</li> <li>tntn is the number of true negatives</li> </ul> <p>The following measures are often used:</p> <ul> <li> <p>The precision is \\frac{tp}{tp+fp}\\frac{tp}{tp+fp} the proportion of positive predictions that are actual positives.</p> </li> <li> <p>The recall or true-positive rate is \\frac{tp}{tp+fn}\\frac{tp}{tp+fn} the proportion of actual positives that are predicted to be positive.</p> </li> <li> <p>The false-positive rate is \\frac{fp}{fp+tn}\\frac{fp}{fp+tn} the proportion of actual negatives predicted to be positive.</p> </li> </ul> <p>An agent should try to maximize precision and recall, and to minimize the false-positive rate.</p> <p>These goals are incompatible however.</p> <p>To compare predictors for a given set of examples, an ROC space or receiver operating characteristic space** plots the false-positive rate against the true-positive rate.</p> <ul> <li>Each predictor these examples becomes a point in the space.</li> </ul> <p>A precision-recall space plots the precision against the recall.</p> <p>Example 7.6</p>"},{"location":"5-semester/MI/10-21-decision-trees/#point-estimates-with-no-input-features","title":"Point Estimates with No Input Features","text":"<p>The simplest case for learning is when there are no input features, and where there is a single target feature.</p> <ul> <li>Best-case for many learning algorithms.</li> </ul> <p>Proposition 7.1</p> <p>Suppose VV is the multiset of values of Y(e)Y(e) for e\\in Ee\\in E</p> <ol> <li>A prediction that minimizes the 0/1 error is a mode;<ul> <li>one of the values that appears most often.</li> <li>When there are multiple modes, any can be chosen.</li> </ul> </li> <li>The prediction that minimizes the sum-of-squares error on EE is the mean of VV (average value)</li> <li>The absolute error is minimized by any median of VV</li> <li>The value that minimizes the worst-case error is (max+min)/2(max+min)/2 where maxmax is the maximum value and minmin is the minimum value.</li> </ol> <p>Full Proposition + proof</p> <p>When the target has domain \\{0,1\\}\\{0,1\\} the training examples can be summarized in</p> <ul> <li>n_0n_0: the number of examples with the value 0</li> <li>n_1n_1: the number of examples with the value 1.</li> </ul> <p>The prediction for each new case is the same number, pp</p> <p>The optimal prediction for pp:</p> <p></p>"},{"location":"5-semester/MI/10-21-decision-trees/#learning-decision-trees","title":"Learning Decision Trees","text":"<p>Decision tree learning is one of the simplest useful techniques for supervised classification learning.</p> <p>For this section we assume there is a single discrete target feature called the classification.</p> <ul> <li>Each element of the domain of the classification is called a class</li> </ul> <p>A decision tree or a classification tree is a tree in which</p> <ul> <li>each internal (non-leaf) node is labeled with a condition, a Boolean function of examples</li> <li>each internal node has two children, one labeled with truetrue and the other with falsefalse</li> <li>each leaf of the tree is labeled with a point estimate on the class</li> </ul> <p></p> <p>Example 7.7</p>"},{"location":"5-semester/MI/10-21-decision-trees/#algorithm","title":"Algorithm","text":"<p>Key question: Which X_iX_i to choose in line 4?</p> <p>Approach: Choose the feature that would provide the best classifier if construction would terminate with that feature.</p> <p></p> <p>Showing:</p> <ul> <li>Number of examples with class labels skip, reads, belonging to different sub-trees</li> <li>\\color{green} \\text{Green}:\\color{green} \\text{Green}: Predicted class label (possibly a tie between two labels)</li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#class-purity","title":"Class Purity","text":"<p>Principle: Prefer features that split the examples into class pure subsets</p> <p></p> <p>Normalized to probabilities:</p> <p></p>"},{"location":"5-semester/MI/10-21-decision-trees/#entropy","title":"Entropy","text":""},{"location":"5-semester/MI/10-21-decision-trees/#purity-measure","title":"Purity Measure:","text":"<p>For a probability distribution (p,1-p)(p,1-p) of a two-valued class label, define^log2:</p>  h(p,1-p)=-p\\cdot\\log_2(p)-(1-p)\\cdot\\log_2(1-p)   h(p,1-p)=-p\\cdot\\log_2(p)-(1-p)\\cdot\\log_2(1-p)  <p></p> <ul> <li>High values for impure distributions</li> <li>Maximal for (0.5,0.5)(0.5,0.5)</li> <li>Zero for (1,0)(1,0) and (0,1)(0,1)</li> </ul> <p>Example</p> <p></p>"},{"location":"5-semester/MI/10-21-decision-trees/#generalization-to-larger-domain","title":"Generalization to Larger Domain","text":"<p>For probability distribution on domain with nn elements:</p>  \\bold p=(p_1,\\dots,p_n)\\quad (p_n=1-\\sum_{i=1}^{n-1}p_i)   \\bold p=(p_1,\\dots,p_n)\\quad (p_n=1-\\sum_{i=1}^{n-1}p_i)  <p>define entropy^log2:</p>  h(\\bold p)=-\\sum_{i=1}^n p_i\\cdot\\log_2(p_i)   h(\\bold p)=-\\sum_{i=1}^n p_i\\cdot\\log_2(p_i)  <p>Again:</p> <ul> <li>Maximal for \\bold p=(1/n,\\dots,1/n)\\bold p=(1/n,\\dots,1/n)</li> <li>Zero for \\bold p = (1,0,\\dots,0)\\bold p = (1,0,\\dots,0) and so on</li> </ul>"},{"location":"5-semester/MI/10-21-decision-trees/#entropy-example","title":"Entropy Example","text":"<p>We prefer features that split into subsets with low entropy, but consider example for binary class variable (values c_1,c_2c_1,c_2 with initial counts c_1:20,c_2:20c_1:20,c_2:20), and two 3-valued features X_1,X_2X_1,X_2:</p> <p></p> <p>X_2X_2 provides a better division of examples than X_1X_1. It gives a lower expected entropy:</p>  (1/40)\u00b7 0+(1/40)\u00b7(38/40)\u00b71&gt;(15/40)\u00b70 + (15/40)\u00b70 + (10/40)\u00b71   (1/40)\u00b7 0+(1/40)\u00b7(38/40)\u00b71&gt;(15/40)\u00b70 + (15/40)\u00b70 + (10/40)\u00b71"},{"location":"5-semester/MI/10-21-decision-trees/#expected-entropy-and-information-gain","title":"Expected Entropy and Information Gain","text":"<p>For feature XX with domain v_1,\\dots,v_nv_1,\\dots,v_n let:</p> <ul> <li>E_iE_i be the set of examples with X=v_iX=v_i</li> <li>q_i=|E_i|/|E|q_i=|E_i|/|E|</li> <li>h_ih_i the entropy of the class label distribution in E_iE_i</li> </ul> <p>The expected entropy from splitting on XX then is: $$ h(Class\\mid X)=\\sum_{i=1}^n q_i\\cdot h_i $$ Let h(Class)h(Class): entropy of class label distribution before splitting</p> <p>The Information Gain from splitting on XX then is: $$ h(Class)-h(Class \\mid X) $$</p> <p>Information Gain in Decision Tree Learning</p> <p>In line 4 of the algorithm choose feature X_iX_i that gives the highest information gain</p> <p></p> <p></p>"},{"location":"5-semester/MI/10-21-decision-trees/#continuousmany-valued-attributes","title":"Continuous/Many-Valued Attributes","text":"<p>The information gain measure favors attributes with many values</p> <ul> <li>For example, the attribute Date will have a very high information gain, but is unable to generalize</li> </ul> <p>One approach for avoiding this, is to select attributes based on GainRation: $$ GainRation(S,A)=\\frac{Gain(S,A)}{SplitInformation(S,A)}\\ SplitInformation(S,A)=-\\sum_{i=1}^c\\frac{|S_i|}{|S|}\\log_2 \\frac{|S_i|}{|S|} $$ where S_iS_i is the subset of examples produced by splitting on the ii'th value of AA</p> <p>Note that SplitInformation is the entropy of SS with regard to the values of AA</p> <p>We require that the attributes being tested are discrete valued. So in order to test a continuous valued attribute we need to \"discretize\" it.</p> <p>Suppose that the training examples are associated with the attribute Temperature:</p> <p></p> <p>Create a new boolean valued attribute by first testing the two candidate thresholds:</p> <ul> <li>(48+60)/2(48+60)/2</li> <li>(80+90)/2(80+90)/2</li> </ul> <p>Next pick the one with the highest information gain (i.e., Temperature_{\\gt 54}Temperature_{\\gt 54})</p>"},{"location":"5-semester/MI/10-21-decision-trees/#overfitting","title":"Overfitting","text":"<p>Noise in data may lead to a bad classifier. In particularly, if the decision tree fits the data perfectly.</p> <p>This is called overfitting.</p> <p>Definition</p> <p>A hypothesis hh is said to overfit the training data if there exists some alternative hypothesis h'h', such that:</p> <ul> <li>hh has a smaller error than h'h' over the training data, but</li> <li>h'h' has a smaller error than hh over the entire distribution of instances</li> </ul> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/","title":"Learning: Neural Networks","text":"<p>Tensorflow Playground</p>  \\newcommand{\\derr}[1]{\\frac{\\part}{\\part {#1}}}\\nonumber"},{"location":"5-semester/MI/10-28-neural-networks/#linear-regression-and-classification","title":"Linear Regression and Classification","text":"<p>Linear Regression: The problem of fitting a linear function to a set of training examples, in which the input and target features are numeric.</p>  \\begin{align*} \\hat Y^{\\overline w}(e) &amp;= w_0+w_1 * X_1(e)+\\dots +w_n * X_n(e)\\\\ &amp;= \\sum^n_{i=0}w_i*X_i(e) \\end{align*}   \\begin{align*} \\hat Y^{\\overline w}(e) &amp;= w_0+w_1 * X_1(e)+\\dots +w_n * X_n(e)\\\\ &amp;= \\sum^n_{i=0}w_i*X_i(e) \\end{align*}  <p>where \\overline w=\\langle w_0,w_1,\\dots,w_n\\rangle\\overline w=\\langle w_0,w_1,\\dots,w_n\\rangle is a tuple of weights.</p> <p>To make w_0w_0 not be a special case, new feature X_0X_0 is always 1.</p> <p>Suppose EE is a set of examples. The sum-of-squares error on EE for YY is:</p>  \\begin{align*} error(E,\\overline w) &amp;= \\sum_{e\\in E}\\left( Y(e)-\\hat Y^{\\overline w}(e) \\right)^2 \\\\ &amp;= \\sum_{e\\in E}\\left( Y(e)- \\sum^n_{i=0}w_i*X_i(e) \\right)^2 \\end{align*}   \\begin{align*} error(E,\\overline w) &amp;= \\sum_{e\\in E}\\left( Y(e)-\\hat Y^{\\overline w}(e) \\right)^2 \\\\ &amp;= \\sum_{e\\in E}\\left( Y(e)- \\sum^n_{i=0}w_i*X_i(e) \\right)^2 \\end{align*}  <p>The weights that minimize the error can be computed analytically. A more general approach, is to compute the weights iteratively.</p>"},{"location":"5-semester/MI/10-28-neural-networks/#gradient-descent","title":"Gradient Descent","text":"<p>An iterative method for finding the minimum of a function.</p> <ul> <li>Starts with an initial set of weights</li> <li>In each step, it decreases each weight in proportion to its partial derivative.</li> </ul>  w_i:=w_i-\\eta *\\frac{\\partial}{\\partial w_i}error(E, \\overline w)   w_i:=w_i-\\eta *\\frac{\\partial}{\\partial w_i}error(E, \\overline w)  <p>where \\eta\\eta, the gradient descent step size, is called the learning rate.</p> <ul> <li>Given as the input to the learning algorithm</li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#linear-learner","title":"Linear Learner","text":"<ul> <li>Termination is usually after some number of steps, when the error is small or when the changes get small. </li> </ul> <p>Not strictly implementing gradient descent.</p> <p>Weights change while it iterates through the examples (Incremental gradient descent)</p> <p>If examples are selected at random, its called stochastic gradient descent</p> <p>Batched gradient descent updates the weights after a batch of examples.</p> <ul> <li>If batch is equal to all examples, its equivalent to gradient descent.</li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#squashed-linear-functions","title":"Squashed Linear Functions","text":"<p>Consider binary classification. (domain of target is \\{0,1\\}\\{0,1\\})</p> <p>The use of a linear function does not work well for such classification tasks; a learner should never make a prediction of greater than 1 or less than 0. </p> <p>A squashed linear function is of the form:</p> <p></p> <p>where ff, an activation function, is a function from the real line [-\\infty,\\infty][-\\infty,\\infty] into some subset of the real line, such as [0,1][0,1]</p> <ul> <li>A prediction based on a squashed linear function is a linear classifier.</li> <li>A simple activation function is the step function,  step_0(x)step_0(x), defined by:</li> </ul>  step_0(x)=  \\left \\{ \\begin{array}\\     1 &amp; \\text{if } x \\geq0 \\\\     0 &amp; \\text{if } x &lt; 0 \\end{array} \\right .   step_0(x)=  \\left \\{ \\begin{array}\\     1 &amp; \\text{if } x \\geq0 \\\\     0 &amp; \\text{if } x &lt; 0 \\end{array} \\right .  <p>One differentiable activation function is the sigmoid or logistic function:</p> <p> </p> <p>$$ sigmoid(x)=\\frac{1}{1+e^{-x}} $$ This function squashes the real line into the interval (0,1)(0,1)</p> <ul> <li>Appropriate for classification</li> <li>Differentiable<ul> <li>\\frac{d}{dx}sigmoid(x)=sigmoid(x)*(1-sigmoid(x))\\frac{d}{dx}sigmoid(x)=sigmoid(x)*(1-sigmoid(x))</li> </ul> </li> </ul> <p>The problem of determining weights for the sigmoid of a linear function that minimize an error on a set of examples is called logistic regression</p> <p>To optimize the log loss error for logistic regression, minimize the negative log-likelihood:</p> <p></p> <p>where \\delta(e)=Y(e)-\\hat Y^{\\overline w}(e)\\delta(e)=Y(e)-\\hat Y^{\\overline w}(e)</p> <p>The Linear\\_learnerLinear\\_learner algorithm can be modified to carry out logistic regression to minimize log loss.</p> <p></p> <p>Example 7.11</p>"},{"location":"5-semester/MI/10-28-neural-networks/#linearly-separable","title":"Linearly Separable","text":"<p>Consider each input feature as a dimension.</p> <p>If there are nn features, there will be nn dimensions.</p> <p>A hyperplane in an nn-dimensional space is a set of points that all satisfies a constraint that some linear function of the variable is zero.</p> <p>The hyperplane forms a (n-1)(n-1)-dimensional space.</p> <ul> <li>In 2D that's a line</li> <li>In 3D that's a plane</li> </ul> <p>A classification is linearly separable if there exists a hyperplane where the classification is true on one side of the hyperplane and false on the other side.</p> <p>Figure 7.11: Linear separators for Boolean functions:</p> <p> </p> <p>Example 7.12 + 7.13</p>"},{"location":"5-semester/MI/10-28-neural-networks/#neural-networks","title":"Neural Networks","text":"<p>There are many different types of neural networks. The book considers feed-forward neural networks.</p> <ul> <li>Hierarchy consisting of linear functions interleaved with activation functions</li> </ul> <p></p> <p>Neural network can have multiple input and target features (real-valued)</p> <ul> <li> <p>Discrete features can be transformed into indicator variables or ordinal features.</p> </li> <li> <p>Inputs feed into layers of hidden units</p> <ul> <li>Features never directly observed</li> <li>A simple function of the units in a lower layer.</li> </ul> </li> </ul> <p> </p> <p>Figure 7.16: A deep neural network.</p>"},{"location":"5-semester/MI/10-28-neural-networks/#single-neuron","title":"Single Neuron","text":"<p>Two step computation</p> <ul> <li>Combine inputs as weighted sum</li> <li>Compute output by activation function of combined inputs</li> </ul> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/#activation-functions","title":"Activation Functions","text":"<p>The most common activation functions are:</p> <p></p> <p>If activation function is sigmoid, i.e. out=\\sigma(\\sum_j i_j\\cdot w_j)out=\\sigma(\\sum_j i_j\\cdot w_j) we also talk of squashed linear function</p> <p>For the output neuron also the identity function is used: af(x)=id(x)=xaf(x)=id(x)=x</p>"},{"location":"5-semester/MI/10-28-neural-networks/#layers","title":"Layers","text":"<p>Each layer of units is a function of the previous layer. Each example has a value for each unit. We consider 3 kinds of layers:</p> <ul> <li> <p>An input layer consists of a unit for each input feature.</p> <ul> <li>Gets its value for an example from the value for the corresponding input feature for that example.</li> </ul> </li> <li> <p>A complete linear layer, where each output o_jo_j is a linear function of the input values v_iv_i to the layer (and, as in linear regression, an extra constant input that has value \u201c1\u201d is added) defined by:</p> <p>\u200b   o_j=\\sum_i w_{ji}v_io_j=\\sum_i w_{ji}v_i</p> <p>for weights w_{ji}w_{ji} that are learned. There is a weight for every input-output pair of the layer. in the diagram of Figure 7.16 there is a weight for every arc for the linear functions.</p> </li> <li> <p>An activation layer, where each output o_io_i is a function of the corresponding input value;</p> <ul> <li>thus o_i=f(v_i)o_i=f(v_i) for activation function ff.</li> </ul> <p>Typical activation functions are the </p> <ul> <li>sigmoid: \\quad f(x)=1/(1+e^{-x})sigmoid: \\quad f(x)=1/(1+e^{-x}),  and the </li> <li>rectified linear unit ReLU:\\quad f(x)=\\max(0,x)ReLU:\\quad f(x)=\\max(0,x)</li> </ul> </li> </ul> <p>For regression, where the prediction can be any real number, its typical for the last layer to be complete linear layer.</p> <p>For binary classification, where the output values can be mapped to \\{0,1\\}\\{0,1\\} it is typical for the output to be a sigmoid function of its input</p> <ul> <li>We never want to predict a value greater or less than zero.</li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#discrete-inputs","title":"Discrete Inputs","text":"<p>If the regression should also use discrete predictor attributes, e.g.:</p> <p></p> <p>replace discrete attributes with 0-1-valued indicator variables for their possible values:</p> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/#indicator-variables","title":"Indicator Variables","text":"<ul> <li>For each value x_ix_i of XX with domain \\{x_1,\\dots,x_k\\}\\{x_1,\\dots,x_k\\} introduce a binary feature X\\_is\\_x_iX\\_is\\_x_i with values 0,10,1</li> <li>Encode input X=x_iX=x_i by inputs<ul> <li>X\\_is\\_x_0=0,\\dots,X\\_is\\_x_{i-1}=0,X\\_is\\_x_i=1,X\\_is\\_x_{i+1},\\dots,X\\_is\\_x_k=0X\\_is\\_x_0=0,\\dots,X\\_is\\_x_{i-1}=0,X\\_is\\_x_i=1,X\\_is\\_x_{i+1},\\dots,X\\_is\\_x_k=0 </li> </ul> </li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#numerical-encoding","title":"Numerical Encoding","text":"<p>Translate values into numbers:</p> <ul> <li>true, false \\mapsto 0,1true, false \\mapsto 0,1</li> <li>low,medium,high\\mapsto 0,1,2low,medium,high\\mapsto 0,1,2</li> </ul> <p>Probably not sensible:</p> <ul> <li>red,green,blue \\mapsto 0,1,2red,green,blue \\mapsto 0,1,2<ul> <li>blueblue is not \"two times greengreen\"</li> </ul> </li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#neural-networks-for-classification","title":"Neural Networks for Classification","text":"<p>Use one output node for each class label.</p> <p>Classify instance by class label associated with output node with highest output value.</p> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/#propagation-in-neural-networks","title":"Propagation in Neural Networks","text":"<p>The output of neuron HH is:</p> <p>$$ o_H=\\sigma(1\\cdot0.1+0\\cdot0.1+1\\cdot0.1)=\\color{blue} 0.5498 $$ The output of neuron OO is:</p>  o_O=\\sigma(\\color{blue}{0.5498} \\color{black} \\cdot 0.1+1\\cdot0.1)=\\color{red}{0.53867}   o_O=\\sigma(\\color{blue}{0.5498} \\color{black} \\cdot 0.1+1\\cdot0.1)=\\color{red}{0.53867}"},{"location":"5-semester/MI/10-28-neural-networks/#the-perceptron","title":"The Perceptron","text":"<ul> <li>No hidden layer</li> <li>One output neuron oo</li> <li>signsign activation function</li> </ul> <p>Computed:</p>  O(x_1,\\dots,x_n)= \\left\\{\\begin{array}{}\\begin{align*}     1   \\quad &amp;\\text{if } w_0x_0+w_1x_1+\\dots w_n x_n\\\\     -1  \\quad &amp;\\text{otherwise} \\end{align*}\\end{array}\\right.   O(x_1,\\dots,x_n)= \\left\\{\\begin{array}{}\\begin{align*}     1   \\quad &amp;\\text{if } w_0x_0+w_1x_1+\\dots w_n x_n\\\\     -1  \\quad &amp;\\text{otherwise} \\end{align*}\\end{array}\\right.  <p>Convention from now on assume that x_0x_0 is an input neuron with constant input value 1. Then write \\bold w \\cdot \\bold x\\bold w \\cdot \\bold x for w_0 x_0+w_1x_1+\\dots w_n x_nw_0 x_0+w_1x_1+\\dots w_n x_n</p>"},{"location":"5-semester/MI/10-28-neural-networks/#expressive-power","title":"Expressive Power","text":"<p>The decision surface of a two-input perceptron is given by a straight line, separating positive and negative examples</p> <p></p> <p>Can represent x_1 \\and x_2x_1 \\and x_2</p> <p></p> <p>Can represent x_1 \\or x_2x_1 \\or x_2</p> <p></p> <p>Cannot! represent x_1 \\text{ xor } x_2x_1 \\text{ xor } x_2</p> <ul> <li>The examples are not linear separable</li> </ul> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/#multiple-neurons","title":"Multiple Neurons","text":""},{"location":"5-semester/MI/10-28-neural-networks/#learning","title":"Learning","text":"<p>We have</p> <ul> <li>\\mathcal{D}=(x_1,x_2,x_3,x_4)\\mathcal{D}=(x_1,x_2,x_3,x_4) input vectors (cases)</li> <li>\\bold t=(-1,1,-1,-1)\\bold t=(-1,1,-1,-1) vector of target outputs</li> <li>\\bold w=(w_0,w_1,w_2)\\bold w=(w_0,w_1,w_2) vector of current parameters</li> <li>\\bold o=(o_1,o_2,o_3,o_4)\\bold o=(o_1,o_2,o_3,o_4) vector of current outputs</li> </ul> <p>We request</p> <ul> <li>\\bold w^*\\bold w^* parameters yielding \\bold o = \\bold t\\bold o = \\bold t</li> </ul> <p></p> <p>Weight Updating Procedure</p> <ul> <li>E&gt;0 \\Rightarrow oE&gt;0 \\Rightarrow o shall be increased  \\Rightarrow \\bold x \\cdot \\bold w\\Rightarrow \\bold x \\cdot \\bold w up \\Rightarrow \\bold w:= \\bold w+ \\alpha E x\\Rightarrow \\bold w:= \\bold w+ \\alpha E x</li> <li>E&lt;0 \\Rightarrow oE&lt;0 \\Rightarrow o shall be decreased \\Rightarrow \\bold x \\cdot \\bold w\\Rightarrow \\bold x \\cdot \\bold w down \\Rightarrow \\bold w:= \\bold w+ \\alpha E x\\Rightarrow \\bold w:= \\bold w+ \\alpha E x</li> </ul> <p>\\alpha\\alpha is called the learning rate</p> <p>With \\mathcal D\\mathcal D linearly separable and \\alpha\\alpha not too large, this procedure will converge to a correct set of parameters</p> <p>See example in slides 24 (appendix of this page)</p>"},{"location":"5-semester/MI/10-28-neural-networks/#sum-of-squared-errors","title":"Sum of Squared Errors","text":"<p>Given</p> <ul> <li>data (training examples): (x_i,y_i)\\quad (i=1,\\dots,N)(x_i,y_i)\\quad (i=1,\\dots,N) with<ul> <li>x_ix_i: value of input features \\bold X\\bold X</li> <li>y_iy_i: value of output feature YY</li> </ul> </li> <li>a neural network that computes outputs o_i=out(x_i)o_i=out(x_i)</li> </ul> <p>define sum of squared error</p>  SSE=\\sum^N_{i=1}(y_i-o_i)^2   SSE=\\sum^N_{i=1}(y_i-o_i)^2  <p></p> <p>For a given dataset the SSE is a smooth, convex function of the weights</p> <p>Example for n=2n=2 and a linear activation function:</p> <p></p> <p>Weights \\bold w\\bold w that minimize E(\\bold w)E(\\bold w) can be found by gradient descent</p>"},{"location":"5-semester/MI/10-28-neural-networks/#gradient-descent-learning","title":"Gradient Descent Learning","text":"<p>The gradient is the vector of partial derivatives:</p>  \\nabla E[\\bold w]=\\left(\\frac{\\partial E}{\\partial w_o},\\frac{\\partial E}{\\partial w_1},\\dots,\\frac{\\partial E}{\\partial w_n}  \\right)   \\nabla E[\\bold w]=\\left(\\frac{\\partial E}{\\partial w_o},\\frac{\\partial E}{\\partial w_1},\\dots,\\frac{\\partial E}{\\partial w_n}  \\right)  <p>The partial derivatives are (with linear activation function):</p> <p>$$ \\frac{\\partial E}{\\partial w_k}=\\sum_{i=1}^N(t_i-\\bold w\\cdot x_i)(-x_{i,k})\\label{gradiant_descent} $$ Gradient descent rule:</p> <ol> <li>Initialize \\bold w\\bold w with random values</li> <li>repeat<ol> <li>\\bold w := \\bold w - \\eta \\nabla E(\\bold w)\\bold w := \\bold w - \\eta \\nabla E(\\bold w)</li> </ol> </li> <li>until \\nabla E(\\bold w) \\approx 0\\nabla E(\\bold w) \\approx 0</li> </ol> <p>\\eta\\eta is a small constant, the learning rate</p> <p>Properties</p> <ul> <li>The procedure converges to the weights \\bold w\\bold w that minimize the SSE (if \\eta\\eta is small enough)</li> </ul>"},{"location":"5-semester/MI/10-28-neural-networks/#stochastic-gradient-descent","title":"Stochastic Gradient Descent","text":"<p>Variation of gradient descent: Instead of following the gradient computed from the whole dataset (\\ref{gradiant_descent}\\ref{gradiant_descent})</p> <p>iterate through the data instances one by one, and in one iteration follow the gradient defined by a single data instance (x_k,t_k)(x_k,t_k)</p>  \\frac{\\partial E}{\\partial w_i}=(t_k-\\bold w\\cdot x_k)(-x_k,i)   \\frac{\\partial E}{\\partial w_i}=(t_k-\\bold w\\cdot x_k)(-x_k,i)"},{"location":"5-semester/MI/10-28-neural-networks/#the-task-of-learning","title":"The Task of Learning","text":"<p>Given: structure and activation functions. To be learned: weights.</p> <p>Goal: given the training examples</p> <p></p> <p>Find the weights that minimize the sum of squared errors (SSE)</p> <p>$$ \\sum_{i=1}^N\\sum_{j=1}^m(t_{j,i}-o_{j,i})^2, $$ where o_{j,i}o_{j,i} is the value of the jjth output neuron for the iith data instance.</p>"},{"location":"5-semester/MI/10-28-neural-networks/#back-propagation","title":"Back-Propagation","text":"<p>Back-propagation implements stochastic gradient descent for all weights.</p> <p>There are two properties of differentiation used in back-propagation:</p> <ul> <li>Linear rule: the derivative of a linear function is given by;</li> </ul>  \\derr{w}(aw+b)=a   \\derr{w}(aw+b)=a  <ul> <li>Chain rule: if gg is a function  of ww and function ff, which does not depend on ww, is applied to g(w)g(w), then</li> </ul>  \\derr w f(g(w))=f'(g(w))*\\derr w g(w)   \\derr w f(g(w))=f'(g(w))*\\derr w g(w)  <p>Learning consists of two passes through the network for each example:</p> <ul> <li>Prediction: given the values on the inputs for each layer, compute a value for the outputs of the layer</li> <li>Back-propagation: go backwards through the layers to update all of the weights of the network.</li> </ul> <p>Calculate an error term \\delta_h\\delta_h for a hidden unit by taking the weighted sum of the error terms, \\delta_k\\delta_k for each output units it influences.</p> <p></p>"},{"location":"5-semester/MI/10-28-neural-networks/#updating-rules","title":"Updating Rules","text":"<p>When using a sigmoid activation function we can derive the following update rule:</p> <p></p> <p>where $$ \\delta_j=\\begin{array}{}\\left{ \\begin{align}     &amp;o_j(1-o_j)(t-o_j) &amp;&amp;\\quad \\text{for output nodes}\\     &amp;o_j(1-o_j) \\sum_{k=1}^m w_{jk}\\delta_k &amp;&amp;\\quad \\text{for hidden nodes} \\end{align}\\right. \\end{array} $$</p> <p>See example in slides 34 (appendix of this page)</p>"},{"location":"5-semester/MI/10-28appendix/","title":"Learning: Neural Network - Appendix","text":""},{"location":"5-semester/MI/10-28appendix/#learning-weights-and-threshold-example","title":"Learning Weights and Threshold Example","text":""},{"location":"5-semester/MI/10-28appendix/#back-propagation-example","title":"Back Propagation Example","text":""},{"location":"5-semester/MI/11-04-methods-and-issues/","title":"Learning: Methods and Issues","text":""},{"location":"5-semester/MI/11-04-methods-and-issues/#probabilistic-models","title":"Probabilistic Models","text":"<p>Word occurrence in emails (thousands of input features!):</p> <p></p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#naive-bayes-classifier","title":"Naive Bayes Classifier","text":"<p>Assumption</p> <ul> <li>The input features are conditionally independent of each other given the classification</li> </ul> <p></p> <p>Classify email as spam if </p> <p>$$ P(Spam=yes \\mid \\bold X = \\bold x) &gt; threshold $$ where \\bold X=(abacus, \\dots ,zytogenic) and \\bold x\\bold x is a corresponding set of y/n values</p> <p>Structural Assumption</p> <p></p> <p>Learning</p> <ul> <li>Need to learn entries in conditional probability tables</li> <li>Simplest approach: use empirical frequencies, e.g.:</li> </ul> <p></p> <p>Given an example with inputs X_1=x_1,\\dots, X_k=x_kX_1=x_1,\\dots, X_k=x_k, Bayes Rule is used to compute the posterior probability distribution of the example's classification, YY $$ P(Y \\mid X_1=x_1,\\dots, X_k=x_k)= {P(Y)\\cdot P(x_1 \\mid Y)\\cdots P(x_k \\mid Y) \\over \\sum_Y P(Y)\\cdot P(x_1 \\mid Y)\\cdots P(x_k \\mid Y)} $$</p> <p></p> <p></p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#example","title":"Example","text":""},{"location":"5-semester/MI/11-04-methods-and-issues/#pseudo-counts","title":"Pseudo Counts","text":"<p>When leaning the naive Bayes model, we estimated P(long \\mid reads)P(long \\mid reads) as $$ P(long \\mid reads) = {0\\over 9} $$ based on 9 cases only, \\leadsto\\leadsto unreliable parameter estimates and risk of zero probabilities.</p> <p>The solution is pseudo counts</p> <p></p> <p>where</p> <ul> <li>p_{ac}p_{ac} is our prior estimate of the probability (often chosen as a uniform distribution), and</li> <li>mm is a virtual sample size (determining the weight of p_acp_ac relative to the observed data)</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#example_1","title":"Example","text":"P(known \\mid reads) = {2+0.5\\cdot m \\over 3+m}   P(known \\mid reads) = {2+0.5\\cdot m \\over 3+m}"},{"location":"5-semester/MI/11-04-methods-and-issues/#assumptions","title":"Assumptions","text":"Attributes not independent given Symbol=1! Attributes not independent given Spam=yes! <p>\\leadsto\\leadsto Naive Bayes assumption often not realistic. Nevertheless, Naive Bayes often successful.</p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#when-naive-bayes-must-fail","title":"When Naive Bayes Must Fail","text":"<p>No Naive Bayes Classifier can produce the following classification</p> <p></p> <p>because assume it did, then:</p> <p></p> <p>Multiplying the four left sides and the four right sides of these inequalities:</p>  \\prod^4_{i=1}(left\\ side\\ of\\ i) &gt; \\prod^4_{i=1}(right\\ side\\ of\\ i)   \\prod^4_{i=1}(left\\ side\\ of\\ i) &gt; \\prod^4_{i=1}(right\\ side\\ of\\ i)  <p>But this is false, because both products are actually equal.</p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#case-based-reasoning","title":"Case-based Reasoning","text":"<p>Idea:</p> <p>To predict the output feature of a new example ee</p> <ul> <li>find among the training examples the one (several) most similar to ee</li> <li>predict the output for ee from the known output values of the similar cases</li> </ul> <p>Several names for this approach</p> <ul> <li>Instance Based Learning</li> <li>Lazy Learning</li> <li>Case-based Reasoning</li> </ul> <p>Required:</p> <ul> <li>Distance measure on values of input features</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#distance-measures-for-numeric-features","title":"Distance Measures for Numeric Features","text":"<p>If all features \\bold X\\bold X are numeric:</p> <ul> <li>Euclidian distance</li> </ul>  d(x,x')=\\sqrt{\\Sigma_i(x_i-x'_i)^2}   d(x,x')=\\sqrt{\\Sigma_i(x_i-x'_i)^2}  <ul> <li>Manhattan distance</li> </ul>  d(x,x')=\\Sigma_i|x_i-x_i'|   d(x,x')=\\Sigma_i|x_i-x_i'|"},{"location":"5-semester/MI/11-04-methods-and-issues/#distance-measure-for-discrete-features","title":"Distance Measure for Discrete Features","text":"<p>For a single feature XX with domain \\{x_i,\\dots x_k\\}:\\{x_i,\\dots x_k\\}:</p> <ul> <li>Zero-One distance</li> </ul>  d(x_i,x_j) = \\begin{array}{}\\left\\{\\begin{align*}      &amp;0 &amp;&amp;\\quad\\text{if } j=i\\\\     &amp;1 &amp;&amp;\\quad\\text{if } j\\neq i \\end{align*}\\right.\\end{array}   d(x_i,x_j) = \\begin{array}{}\\left\\{\\begin{align*}      &amp;0 &amp;&amp;\\quad\\text{if } j=i\\\\     &amp;1 &amp;&amp;\\quad\\text{if } j\\neq i \\end{align*}\\right.\\end{array}  <ul> <li>Distance Matrix<ul> <li>For each pair x_i,x_jx_i,x_j specify the distance d(x_i,x_j)d(x_i,x_j) in a k\\times kk\\times k-matrix. Example</li> </ul> </li> </ul> <p></p> <p>For a set of discrete features \\bold X\\bold X:</p> <ul> <li>Define distance d_id_i and weight w_iw_i for each X_i\\in \\bold XX_i\\in \\bold X</li> <li>Define d(x,x')=\\Sigma_i w_i d_i (x_i,x_i')d(x,x')=\\Sigma_i w_i d_i (x_i,x_i')</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#k-nearest-neighbor-classifier","title":"K-Nearest-Neighbor Classifier","text":"<p>Given</p> <ul> <li>training examples (x_i,y_i)\\quad(i=1,\\dots N)(x_i,y_i)\\quad(i=1,\\dots N),</li> <li>a new case \\bold x\\bold x to be classified, and</li> <li>a distance measure d(x,x')d(x,x')</li> </ul> <p>classify \\bold x\\bold x as follows:</p> <ul> <li>Find the KK training examples x_{i_1},\\dots x_{i_K}x_{i_1},\\dots x_{i_K} with minimal distance to \\bold x\\bold x</li> <li>Predict for \\bold x\\bold x the most frequent value in y_{i_1},\\dots y_{i_K}y_{i_1},\\dots y_{i_K}</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#example_2","title":"Example","text":"<ul> <li>Output feature: red, blue, greenred, blue, green</li> <li>Two numeric input features</li> <li>Euclidian distance</li> <li>Colored dots: training examples</li> <li>Colored regions: regions of input values that will be classified as that color</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#overfitting","title":"Overfitting","text":"<p>Occurs when the learner makes predictions based on regularities that appears in the training examples, but not in the test examples or the real world.</p> <p>Example 7.14</p> <p>Example 7.15 Overfitting caused by model complexity</p> <p></p> <p></p> <p>A model overfits the training data if a smaller error on future data would be obtained by a less complex model.</p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#avoid-overfitting","title":"Avoid Overfitting","text":"<p>Do not allow overly complex models:</p> <ul> <li>Naive Bayes model</li> <li>K-NN for \"large\" K</li> </ul> <p>Do not allow to learn models that are too complex (relative to the available data):</p> <ul> <li>Decision Trees: use an early stopping criterion, e.g. stop construction when (sub-)set of trainnig examples contains fewer than kk elements (for not too small kk)</li> <li>Add to evaluation: measure a penalty term for complexity. This penalty term can have an interpretation as a prior model probability, or model description length</li> </ul> <p>These techniques will usually lead to more complex models only when the data strongly supports it (especially: large number of examples)</p>"},{"location":"5-semester/MI/11-04-methods-and-issues/#validation-data","title":"Validation Data","text":"<p>Idea</p> <p>Reserve part of the training examples as a validation set</p> <ul> <li>Not used during model search</li> <li>Used as proxy for future data in model evaluation</li> </ul> <p>Train/Validation Split</p> <p>Simplest approach: split the available data randomly into a training and a validation set.</p> <p>Typically:</p> <ul> <li>50/50, or</li> <li>66/33</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#example-decision-trees","title":"Example: Decision Trees","text":"<p>Post Pruning</p> <p>Use of validation set in decision tree learning:</p> <ul> <li>Build decision tree using training set</li> <li>For each internal node:<ul> <li>Test whether accuracy on validation set is improved by replacing sub-tree rooted at this node by single leaf (labeled with most frequent target feature value of training examples in this sub-tree)</li> <li>If yes: replace sub-tree with leaf (prune sub-tree)</li> </ul> </li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#example-k-nn-and-neural-networks","title":"Example K-NN and Neural Networks","text":"<p>Selection of  KK</p> <p>For K=1,2,3,\\dotsK=1,2,3,\\dots</p> <ul> <li>Measure accuracy of KK-NN based on training examples for validation examples</li> <li>Use KK with best performance on validation examples</li> <li>Validation examples can now be merged with training examples for prediction future cases</li> </ul> <p>Selection of Neural Network Structure</p> <p>For \\#hl=1,2,\\dots ,max\\#hl=1,2,\\dots ,max and \\#nd=1,2,\\dots,max\\#nd=1,2,\\dots,max:</p> <ul> <li>Learn neural network with #hl hidden layers and #nd nodes per hidden layer using training examples</li> <li>Evaluate SSE of learned network on validation examples</li> <li>Select a network structure with minimal SSE</li> <li>Re-learn weights using merged training and validation examples</li> </ul>"},{"location":"5-semester/MI/11-04-methods-and-issues/#cross-validation","title":"Cross Validation","text":"<p>The idea of using part of the training data as a surrogate for test data.</p> <p>Simplest:</p> <ul> <li>We split the data into two:<ul> <li>A set of examples</li> <li>A validation set</li> </ul> </li> </ul> <p>The idea is to choose a parameter setting or a representation in which the error of the validation set is a minimum (see figure 7.14)</p> <p>The method of k-fold cross validation allows us to reuse examples for both training and validation. It has the following steps:</p> <ul> <li> <p>Partition training set into kk sets, of approximately equal size called folds</p> </li> <li> <p>To evaluate a parameter setting, train kk times for that parameter setting, each time using one of the folds as the validation set, and the remaining for training.</p> <p>The accuracy is evaluated using the validation set. For example, if k=10k=10 then 90\\%90\\% of the training examples are used for training and 10\\%10\\% for validation.</p> <p>It does this 10 times, so each example is used once in a validation set.</p> </li> <li> <p>Optimize parameter settings based on the error on each example when it is used in the validation set.</p> </li> <li> <p>Return the model with the selected parameter settings, trained on all of the data.</p> </li> </ul> <p>Example 7.19</p> <p>At one extreme when k is the number of training examples, it becomes leave-one-out cross validation.</p> <p></p>"},{"location":"5-semester/MI/11-11-clustering/","title":"Learning: Clustering","text":"<p>Examples:</p> <ul> <li>Based on customer data, find group of customers with similar profiles</li> <li>Based on image data, find groups of images with similar motif.</li> <li>Based on article data, find groups of articles with the same topics</li> <li>...</li> </ul>"},{"location":"5-semester/MI/11-11-clustering/#k-means-algorithm","title":"K-Means Algorithm","text":"<p>General goal: find clustering with:</p> <ul> <li>Large between-cluster variation</li> <li>small within-cluster variation </li> </ul> <p>We consider the scenario, where</p> <ul> <li>the number k of clusters is known</li> <li>we have a distance measure d(x_i,x_j)d(x_i,x_j) between pairs of data points (feature vectors)</li> <li>we can calculate a centroid for a collection of data points S=\\{x_1,\\dots,x_n\\}S=\\{x_1,\\dots,x_n\\}</li> </ul> <p></p> <p>Example: Session 11.11 Slide 9</p> <p>Result can depend on choice of initial cluster centers!</p>"},{"location":"5-semester/MI/11-11-clustering/#k-means-as-an-optimization-problem","title":"K-means as an Optimization Problem","text":"<p>Assume we use Euclidian distance d as proximity measure and that the quality of the clustering is measured by the sum of squared errors:</p> <p></p> <p>where </p> <ul> <li>c_ic_i is the i'th centroid</li> <li>C_i\\in SC_i\\in S is the points closets to c_ic_i according to dd</li> </ul> <p>In principle</p> <p>We can minimize the SSE by looking at all possible partitionings \\leadsto\\leadsto not feasible though! </p> <p>Instead, k-means:</p> <p>The centroid that minimizes the SSE is the mean of the data-points in that cluster:</p>  c_i = \\frac{1}{|C_i|}*\\sum_{x\\in C_i}{x}   c_i = \\frac{1}{|C_i|}*\\sum_{x\\in C_i}{x}  <p>Local optimum found by alternating between cluster assignments and centroid estimation.</p>"},{"location":"5-semester/MI/11-11-clustering/#convergence","title":"Convergence","text":"<p>The k-means algorithm is guaranteed to converge</p> <ul> <li>Each step reduces the sum of squared errors</li> <li>There is only a finite number of cluster assignments</li> </ul> <p>There is no guarantee of reaching the global optimum:</p> <ul> <li>Improve by running with multiple random restarts</li> </ul>"},{"location":"5-semester/MI/11-11-clustering/#outliers","title":"Outliers","text":"<p>The result of partitional clustering can be skewed by outliers</p> <p></p>"},{"location":"5-semester/MI/11-11-clustering/#different-measuring-scales","title":"Different Measuring Scales","text":"<p>Instances defined by attributes</p> <p></p> <ul> <li>All distance functions for continuous attributes dominated by income values<ul> <li>\\leadsto\\leadsto may need to rescale or normalize continuous attributes</li> </ul> </li> </ul>"},{"location":"5-semester/MI/11-11-clustering/#min-max-normalization","title":"Min-Max Normalization","text":"<p>Replace A_iA_i with</p> <p>$$ A_i-\\min(A_i)\\over \\max(A_i)-\\min(A_i) $$ where \\min(A_i),\\max(A_i)\\min(A_i),\\max(A_i) are min/max values of A_iA_i appearing in the data</p> <p></p> <ul> <li>Will always be between 0 and 1</li> <li>Be careful for extreme values (See the lowest green value)</li> </ul>"},{"location":"5-semester/MI/11-11-clustering/#z-score-standardization","title":"Z-Score Standardization","text":"<p>Replace A_iA_i with</p>  A_i-mean(A_i) \\over standard\\ deviation(A_i)   A_i-mean(A_i) \\over standard\\ deviation(A_i)  <p>where</p> <ul> <li>mean(A_i)mean(A_i) </li> <li>standard\\ deviationstandard\\ deviation </li> </ul> <p></p> <ul> <li>Is not between 0 and 1, we have no min and max value</li> <li>Slightly less sensitive to outliers</li> </ul>"},{"location":"5-semester/MI/11-11-clustering/#soft-clustering","title":"Soft Clustering","text":"<p>The k-means algorithm generates a hard clustering: each example is assigned to a single cluster.</p> <p>Alternatively:</p> <p>In soft clustering, each example is assigned to a cluster with a certain probability.</p> <p></p>"},{"location":"5-semester/MI/11-11-clustering/#em-algorithm","title":"EM-Algorithm","text":"<p>When learning the probability distributions of the model, the variable CC is hidden</p> <ul> <li>\\leadsto\\leadsto we cannot directly estimate the probabilities using frequency counts</li> </ul> <p>Instead we employ the EM Algorithm</p> <p>The Expectation-maximization algorithm</p> <ul> <li>Combined with a naive Bayes classifier, it does soft clustering.</li> </ul> <p>The main idea:</p> <ul> <li> <p>Use hypothetical completions of the data using the current probability estimates</p> </li> <li> <p>Infer the maximum likelihood probabilities for the model based on completed data set.</p> </li> </ul> <p></p> <p>Each original example gets mapped into kk augmented examples, one for each class.  The count for these are aassigned to sum to 1.</p> <p>Example for 4 features and 3 classes:</p> <p></p> <p>The EM algorithm repeats the two steps:</p> <ul> <li> <p>E step: Update the augmented counts based on the probability distribution.     For each example \\langle X_1 = x_1, \\dots,X_n=x_n \\rangle\\langle X_1 = x_1, \\dots,X_n=x_n \\rangle in the original data, the count associated with     \\langle X_1 = x_1, \\dots,X_n=x_n, C=c \\rangle\\langle X_1 = x_1, \\dots,X_n=x_n, C=c \\rangle in the augmented data is updated to</p> <ul> <li>P(C=c\\mid X_1=x_1,\\dots,X_n=x_n)P(C=c\\mid X_1=x_1,\\dots,X_n=x_n)</li> </ul> <p>Note that this step involves probabilistic inference. This is an expectation step because it computes the expected values.</p> </li> <li> <p>M step: Infer the probabilities for the model from the augmented data. Because the augmented data has values associated with all the variables, this is the same problem as learning probabilities from data in a naive Bayes classifier.</p> <p>This is a maximization step because it computes the maximum likelihood estimate or the maximum a posteriori probability (MAP) estimate of the probability.</p> </li> </ul> <p>Example: Session 11.11 Slide 20</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/","title":"Planning Under Uncertainty","text":""},{"location":"5-semester/MI/11-18-planning-uncertainty/#preferences-and-utility","title":"Preferences and Utility","text":"<p>Agent chooses actions based on outcome.</p> <ul> <li>Whatever the agent has preferences over.</li> <li>If it does not prefer any outcome, it doesn't matter what it does.</li> </ul> <p>Assume finite number of outcomes.</p> <p>Weakly Preferred</p> <p>Suppose o_1 and o_2o_2 are outcomes. We say that o_1o_1 is weakly preferred to o_2o_2, written $o_1 \\succeq o_2 $, if o_1o_1 is at least as desirable as o_2o_2</p> <p>Equally Preferred</p> <p>Define o_1 \\sim o_2o_1 \\sim o_2 if o_1 \\succeq o_2o_1 \\succeq o_2 and o_2 \\succeq o_1o_2 \\succeq o_1.</p> <ul> <li>They are equally preferred</li> <li>The agent is indifferent between o_1o_1 and o_2o_2</li> </ul> <p>Strictly Preferred</p> <p>Define o_1 \\succ o_2o_1 \\succ o_2 to mean o_1 \\succeq o_2o_1 \\succeq o_2 and o_2 \\nsucceq o_1o_2 \\nsucceq o_1 </p> <ul> <li>We say o_1o_1 is strictly preferred to outcome o_2o_2</li> </ul> <p>A lottery is defined to be a finite distribution over outcomes, written:</p>  [p_1:o_1,p_2:o_2,\\dots , p_k:o_k]   [p_1:o_1,p_2:o_2,\\dots , p_k:o_k]  <p>where each o_io_i is an outcome and p_ip_i is a non-negative real number such that \\sum_ip_i=1\\sum_ip_i=1</p> <p>The lottery specifies that outcome o_io_i occurs with probability p_ip_i.</p> <p>Axiom 9.1 - Completeness</p> <p>An agent has preference between all pairs of outcomes:</p>  o_1 \\succeq o_2\\ or\\ o_2 \\succeq o_1   o_1 \\succeq o_2\\ or\\ o_2 \\succeq o_1  <p>Axiom 9.2 - Transitivity</p> <p>Preferences must be transitive:</p>  if\\ o_1 \\succeq o_2\\ and\\ o_2 \\succeq o_3\\ then\\ o_1 \\succeq o_3   if\\ o_1 \\succeq o_2\\ and\\ o_2 \\succeq o_3\\ then\\ o_1 \\succeq o_3  <p>Axiom 9.3 - Monotonicity</p> <p>An agent prefers a larger chance of getting a better outcome than a smaller chance of getting the better outcome. That is, if o_1\\succ o_2o_1\\succ o_2 and p&gt;qp&gt;q then</p>  [p:o_1, (1-p): o_2] \\succ [q:o_1, (1-q):o_2]   [p:o_1, (1-p): o_2] \\succ [q:o_1, (1-q):o_2]"},{"location":"5-semester/MI/11-18-planning-uncertainty/#lotteries","title":"Lotteries","text":"<p>A lottery is a probability distribution over outcomes, e.g.:</p> <ul> <li>[0.4:\\$100,0.6:-\\$20][0.4:\\$100,0.6:-\\$20] means you win $100 with probability 0.4, and loose $20 with probability 0.6</li> <li>[0.3:00,0.5:7,0.2:10][0.3:00,0.5:7,0.2:10]</li> </ul> <p>Preference between lotteries with \"money outcomes\" are not always determined by expected monetary value.</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#preference-from-utilities","title":"Preference from Utilities","text":"<p>A classical result:</p> <p>If preferences between lotteries obey a certain set of plausible rules, then there exists an assignment of real numbers (utilities) to all outcomes, such that one lottery is preferredover another if and only if it has a higher expected utility**</p> <p>Example</p> <p></p> <p>Utility function of a risk-averse agent:</p> <p></p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#ensurance-example","title":"Ensurance Example","text":"<p>Assume Utility(\\$999k)=0.9997Utility(\\$999k)=0.9997 </p> <p>Then agent is indifferent between lotteries</p> <p></p> <p>and prefers</p> <p></p> <p>Interpretation</p> <ul> <li>right lottery: 0.03 risk of loosing a $ 1000k property</li> <li>left lottery: buying insurance against that risk for $ 600</li> </ul> <p>The insurance company prefers</p> <p></p> <p>\\leadsto\\leadsto the insurance company has a different utility function (near linear).</p> <p></p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#factored-utility","title":"Factored Utility","text":"<p>Two compont utility function:</p> <p></p> <p>Utility of full outcome (state) is sum of utility factors:</p> <p></p> <p>Assumption: The utility contribution from one factor is independent of the values of other factors. E.g.: (rhc,swc) should perhaps be worth less than 5 when at the same time (mr, mw), because mail needs to be delivered first (the two utility factors are substitutes)</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#single-stage-decision-networks","title":"Single Stage Decision Networks","text":"<p>Simple decisions can be seen as choices over lotteries.</p> <p></p> <p>Decisions, outcomes, and utilities can all be composed of features or factors:</p> <p>Two components of decision: prepare some / all, start preparations sooner / later</p> <p>Two utility factors: utility of grade, and utility (cost) of preparation time</p> <p>Outcome composed of Grade, Attempt</p> <p></p> <p>Graph represents:</p> <ul> <li>One utility factor depends on Attempt and Grade, another only on Start</li> <li>Both the Prepare and Start decision influence the probabilities for Grade</li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#in-general","title":"In General","text":"<p>A Single-Stage Decision Network (SSDN) is a directed acyclic graph with three types of nodes:</p> <ul> <li>Decision nodes \\bold D\\bold D</li> <li>Chance Nodes \\bold C\\bold C</li> <li>Utility Nodes \\bold U\\bold U</li> </ul> <p></p> <p>The graph must have the following structure:</p> <ul> <li>All decision nodes are connected in one linear sequence (representing the order in which the different sub-decisions are taken)</li> <li>The only parent of a decision node is its predecessor in the order</li> <li>Chance Nodes can have Decision Node and Chance Node parent</li> <li>Utility nodes can have decision node and chance node parents</li> </ul> <p>Tables</p> <ul> <li>No table is associated with decision nodes (only the  list of available decisions)</li> <li>A chance node is labeled with a conditional probability table that specifies for each value assignment to its parents (decision and chance nodes) a probability distribution over thedomain of the chance node.</li> <li>A utility node is labeled with a utility table that specifies for each value assignment to its parents (decision and chance nodes) a utility value</li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#semantics","title":"Semantics","text":"<p>A possible world \\omega\\omega is an assignment of values to all decision and chance variables.</p> <p>An SSDN defines:</p> <ul> <li> <p>For each assignment \\bold D = \\bold d\\bold D = \\bold d of values to the decision nodes a probability distribution</p> <ul> <li>P(\\omega \\mid \\bold D = \\bold d)P(\\omega \\mid \\bold D = \\bold d)</li> </ul> <p>over possible worlds</p> </li> <li> <p>For each possible world \\omega\\omega a utility value</p> <ul> <li>U(\\omega)U(\\omega)</li> </ul> </li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#solving-an-ssdn","title":"Solving an SSDN","text":"<p>To solve an SSDN means to find the decisions \\bold d\\bold d that maximize the expected utility $$ \\varepsilon(U\\mid \\bold D = \\bold d)=\\sum_\\omega U(\\omega)P(\\omega \\mid \\bold D = \\bold d) $$</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#robot-example","title":"Robot Example","text":""},{"location":"5-semester/MI/11-18-planning-uncertainty/#solving-by-chance-variable-elimination","title":"Solving By (Chance) Variable Elimination","text":""},{"location":"5-semester/MI/11-18-planning-uncertainty/#sequential-decisions","title":"Sequential Decisions","text":"<p>SSDNs are generalized to sequential decision problems by.</p> <ul> <li>Several decisions are taken (in fixed order)</li> <li>Some chance variables may be observed before the next decision is taken </li> </ul> <p>Examples</p> <ul> <li>Doctor first decides which test to perform, then observes test outcome, then decides which treatment to prescribe</li> <li>Before we decide to take the umbrella with us, we observe the weather forecast</li> <li>A company first decides whether to develop a certain product, then observes the customer reaction in a test market, then decides whether to go into full production.</li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#example-fire-scenario","title":"Example: Fire Scenario","text":""},{"location":"5-semester/MI/11-18-planning-uncertainty/#decision-function","title":"Decision Function","text":"<p>A Decision Function for a decision node DD is an assignment of a decision dd to each possible configuration of D'sD's parents.</p> <p></p> <p>A Policy \\pi\\pi consists of one decision function for each decision node.</p> <ul> <li>General strategy for actions (decisions), taking into account the possible (uncertain) effects of previous actions</li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#semantics_1","title":"Semantics","text":"<p>As before: possible worlds \\omega\\omega are assignments for all decision and chance variables.</p> <ul> <li> <p>A policy \\pi\\pi defines a probability distribution</p> <p>$$ P(\\omega \\mid \\pi) $$ over possible worlds:</p> <ul> <li>If \\omega\\omega contains assignments to a decision node DD and its parents which is not consistent with the decision function for DD<ul> <li>\\to\\to P(\\omega \\mid \\pi) = 0P(\\omega \\mid \\pi) = 0</li> </ul> </li> <li>otherwise P(\\omega\\mid\\pi)P(\\omega\\mid\\pi) is the product of all conditional probability values for the assignments to chance nodes CC, givenb the assignment to the parents of CC</li> </ul> </li> <li> <p>Each possible world has a utility</p>  U(\\omega)   U(\\omega)  </li> <li> <p>Obtain expected utility of a policy</p> </li> </ul>  \\varepsilon(U\\mid \\pi)=\\sum_\\omega U(\\omega)P(\\omega\\mid\\pi)   \\varepsilon(U\\mid \\pi)=\\sum_\\omega U(\\omega)P(\\omega\\mid\\pi)  <p>An optimal policy is a policy with maximal expected utility (among all possible policies)</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#solving-sequential-decision-problems","title":"Solving Sequential Decision Problems","text":"<p>We now have a new decision problem with one decision less. This decision problem can be solved using the same procedure until no decisions are left.</p>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#intuition","title":"Intuition","text":"<ul> <li>Given values assigned to its parents, the last decision node can be seen as a single-stage decision</li> <li>When all decisions following a given decision DD are taken according to fixed decision rules, then DD also behaves like a single-stage decision</li> <li>Backwards stragegy<ul> <li>find the decision rule for the last decision DD that is not yet eliminated</li> <li>eliminate DD by replacing it with the resulting utlity factor</li> </ul> </li> <li>Form way of \"What would I do if ...\" reasoning</li> </ul>"},{"location":"5-semester/MI/11-18-planning-uncertainty/#variable-elimination","title":"Variable Elimination","text":""},{"location":"5-semester/MI/11-18-planning-uncertainty/#value-of-information","title":"Value of Information","text":"<p>Question: what is it worth to know the exact state of Forecast F when making decision Umbrella?</p> <p>Answer: Compare maximal expected utilities of </p> <p></p> <p>Question: what is it worth to know the exact state of a random variable CC when making decision DD?</p> <p>Answer: Compute</p> <ul> <li>the expected value val_0val_0 of optimal policy in given decision network</li> <li>the expected value val_1val_1 of optimal policy in midified decision network<ul> <li>add an edge from CC to DD and all subsequent decisions</li> </ul> </li> <li>val_1-val_0val_1-val_0 is the value of knowing CC</li> </ul> <p>Properties</p> <ul> <li>Value of information is always non-negative</li> <li>Value of knowing CC for decision DD is zero, if no observed value of CC can change the decision rule,      i.e. for all values \\bold p\\bold p of existing parents of DD, and all values cc of CC, the optimal decision given (\\bold p,c)(\\bold p,c) is the same as the optimal decision given (\\bold p)(\\bold p) </li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/","title":"Multi-Agent Systems","text":""},{"location":"5-semester/MI/11-25-multi-agent/#game-trees","title":"Game Trees","text":"<p>Sharing game. Andy and Barb share two pieces of pie:</p> <p></p> <p>Representation by game tree:</p> <ul> <li>tree whose nodes are labeled with agents</li> <li>outgoing arcs labeled by actions of agent</li> <li>leaves labeled with one utility value for each agent</li> <li>(can also have nature nodes that represent uncertainty from random effects, e.g. dealing of cards, rolling of dice)</li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#imperfect-information-games","title":"Imperfect Information Games","text":"<p>Representation of game with simultaneous moves:</p> <p></p> <p>Collect in an information set the nodes that the agent (Bob) can not distinguish (at all nodes in an information set the same actions must be possible)</p> <p>Other sources for imperfect information:</p> <ul> <li>Unobserved, random moves by nature (dealing of cards)</li> <li>Hidden moves by other agent</li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#strategies","title":"Strategies","text":"<p>A (pure) strategy for one agent is a mapping from information sets to (possible) actions.</p> <p></p> <ul> <li>(Essentially a policy)</li> </ul> <p>A strategy profile consists of a strategy for each agent.</p>"},{"location":"5-semester/MI/11-25-multi-agent/#utility","title":"Utility","text":"<p>Utility for each agent given a strategy profile:</p> <ul> <li>each node has the utilities that will be reached at a leaf by following the strategy profile</li> <li>the utilities at the node represent the outcome of the game (given the strategy profile)</li> <li>(utilities at a nature node are computed by taking the expectation over the utilities of its successors)</li> </ul> <p></p>"},{"location":"5-semester/MI/11-25-multi-agent/#solving-perfect-information-gain","title":"Solving Perfect Information Gain","text":"<p>If </p> <ul> <li>game is perfect information (no information sets with more than 1 node)</li> <li>both agents play rationally (optimize their own utility)</li> </ul> <p>then the optimal strategies for both players are determined by</p> <ul> <li>bottom-up propagation of utilities under optimal strategies, where</li> <li>each player selects the action that leads to the child with the highest utility (for that player)</li> </ul> <p></p> <p>Often these game trees can be extremely large.</p> <ul> <li>Example: Chess</li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#pruning","title":"Pruning","text":"<p>Zero Sum Game</p> <p>For two players: utility_1=-utility_2</p> <p>In this case:</p> <ul> <li>need only one utility value at leaves</li> <li>one player (Max) wants to reach leaf with max value, other (Min) wants to reach leaf with min value.</li> </ul> <p>In bottom-up utility computation, some sub trees can be pruned </p> <p>(\\alpha\\text{-}\\beta \\text{ pruning}\\alpha\\text{-}\\beta \\text{ pruning})</p> <p></p>"},{"location":"5-semester/MI/11-25-multi-agent/#imperfect-information","title":"Imperfect Information","text":"<p>Game Trees can be represented as tables</p> <p></p> <p>Share Game</p> <p></p> <p>Rock Paper Scissors</p> <p></p> <p>Difference between perfect and imperfect information not directly visible in normal form representation.</p>"},{"location":"5-semester/MI/11-25-multi-agent/#nash-equilibrium","title":"Nash Equilibrium","text":"<p>Consider optimal strategy profile for share game:</p> <p></p> <p>The two strategies are in Nash equilibrium </p> <ul> <li>no agent can improve utility by switching strategy while other agent keeps its strategy </li> <li>this also means: agent will stick to strategy when it knows the strategy of the other player </li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#example-prisoners-dilemma","title":"Example Prisoner's Dilemma","text":"<p>Alice and Bob are arrested for burglary. They are separately questioned by police. Alice and Bob are both given the offer to testify, in which case:</p> <p></p> <p></p> <ul> <li>The only Nash Equilibrium is Alice: testify, Bob: testify</li> <li>Nash equilibria do not represent cooperative behavior!</li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#mixed-strategies","title":"Mixed Strategies","text":"<p>No pure strategy Nash Equilibrium in Rock Paper Scissors</p> <p></p> <p>A mixed strategy is a probability distribution over actions:</p> <p></p> <p>Expected utility for Alice = expected utility for Bob =</p>  1/9*(0+1-1-1+0+1+1-1+0)=0   1/9*(0+1-1-1+0+1+1-1+0)=0  <p>Suppose Alice plays some other strategy: r:p_r\\ p:p_p\\ s:p_sr:p_r\\ p:p_p\\ s:p_s Expected utility for Alice then:</p> <p></p> <ul> <li>If Bob plays r:1/3\\ p: 1/3\\ s: 1/3r:1/3\\ p: 1/3\\ s: 1/3, Alice cannot do better than playing r:1/3\\ p: 1/3\\ s: 1/3r:1/3\\ p: 1/3\\ s: 1/3 also.</li> <li>Same for Bob</li> <li>Both playing r:1/3\\ p: 1/3\\ s: 1/3r:1/3\\ p: 1/3\\ s: 1/3 is a (the only) Nash equilibrium.</li> </ul>"},{"location":"5-semester/MI/11-25-multi-agent/#key-results","title":"Key Results","text":"<ul> <li>Every (finite) game has a Nash equilibrium (using mixed strategies)<ul> <li>There can be multiple</li> </ul> </li> <li>Playing a Nash equilibrium strategy profile does not necessarily lead to optimal utilities for the agents (prisoners dilemma )</li> </ul>"},{"location":"5-semester/MI/99_exam/","title":"Exam","text":"<p>You can bring books, notes, pocket calculator.</p> <p>No computer.</p> <p></p>"},{"location":"5-semester/MI/probability-calculus-cheatsheet/","title":"Cheat Sheet for Probability Calculus","text":"<p>We consider probability distributions over variables.</p> <p>A variable can be considered an experiment, and for each outcome of the experiement, the variable has a corresponding state.</p> <p>We use upper case letters to denote vriables, eg. A, and lower case to denote  states.</p> <p>The state space of a variable AA is denoted sp(A)=(a_1,a_2,...,a_n)sp(A)=(a_1,a_2,...,a_n)</p>"},{"location":"5-semester/MI/probability-calculus-cheatsheet/#notation","title":"Notation","text":"<p>The probability of AA being in state a_ia_i is denoted P(a_i)P(a_i) or P(A=a_i)P(A=a_i)</p> <p>If we omit the state and write P(A)P(A) we have a table with probabilities, on one for each state of AA</p> <p>Example</p> <p>AA is tenary with states sp(A)=(a_1,a_2,a_3)sp(A)=(a_1,a_2,a_3) and P(A)=(0.1,0.3,0.6)P(A)=(0.1,0.3,0.6). Thus P(A=a_1)=0.1P(A=a_1)=0.1</p>"},{"location":"5-semester/MI/probability-calculus-cheatsheet/#marginelization","title":"Marginelization","text":"<p>Given P(A,B)P(A,B), we want P(A)P(A)</p>  P(A)=\\sum_BP(A,B)= \\sum_{B=b}P(A,B=b)   P(A)=\\sum_BP(A,B)= \\sum_{B=b}P(A,B=b)  <p>P(A,B)=P(A,B)=</p> A \\ B b_1b_1 b_2b_2 a_1a_1 0.2 0.1 a_2a_2 0.3 0.4 <p>P(A)=(\\overset{a_1}{0.2+0.1},\\overset{a_2}{0.3+0.4})=(0.3,0.7)P(A)=(\\overset{a_1}{0.2+0.1},\\overset{a_2}{0.3+0.4})=(0.3,0.7)</p>"},{"location":"5-semester/MI/probability-calculus-cheatsheet/#conditional-probability","title":"Conditional Probability","text":"<p>(Can be seen either as a definititon or a theorem)</p>  P(B|A)=\\frac{P(A,B)}{P(A)}   P(B|A)=\\frac{P(A,B)}{P(A)}  <p>Using the tables above we get</p> <p></p>"},{"location":"5-semester/MI/probability-calculus-cheatsheet/#bayes-rule","title":"Bayes Rule","text":"<p>Given P(A|B)P(A|B) and P(B)P(B), we want P(B|A)P(B|A)</p>  \\begin{align*} P(B|A)&amp;=\\frac{P(A|B)\\cdot P(B)}{P(A)}\\\\\\\\ &amp;=\\frac{P(A,B)}{P(A)}\\quad \\text{(due to the chain rule below)} \\end{align*}   \\begin{align*} P(B|A)&amp;=\\frac{P(A|B)\\cdot P(B)}{P(A)}\\\\\\\\ &amp;=\\frac{P(A,B)}{P(A)}\\quad \\text{(due to the chain rule below)} \\end{align*}  <p>Note that by marginelization we have</p>  P(A)=\\sum_B P(A,B)   P(A)=\\sum_B P(A,B)"},{"location":"5-semester/MI/probability-calculus-cheatsheet/#the-chain-rule","title":"The Chain Rule","text":"<p>AKA Fundamental Rule</p> <p>Given P(A|B)P(A|B) and P(B)P(B), we want P(A,B)P(A,B) $$ P(A,B)=P(A|B)\\cdot P(B) $$</p> <p></p>"},{"location":"5-semester/SOE/","title":"SOE - Software Engineering","text":"<p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=31432</p> <p></p>"},{"location":"5-semester/SOE/01-introduction/","title":"Software Engineering","text":""},{"location":"5-semester/SOE/01-introduction/#se-process-activities","title":"SE Process Activities","text":"<p>Four fundamental software engineering activities</p> <ol> <li> <p>Software specification</p> <ul> <li> <p>The functionality of the software and constraints on its operation must be defined</p> <p></p> </li> </ul> </li> <li> <p>Software development</p> <ul> <li>The software to meet the specification must be produced</li> </ul> <p></p> </li> <li> <p>Software Validation</p> <ul> <li>The software must be validated to ensure that it does what the customer wants</li> <li>Validation:<ul> <li>Are we building the right systems?</li> <li>Conforms to customers' expectations and experience</li> </ul> </li> <li>Verification<ul> <li>Are we building the system right?</li> <li>Conforms to specification</li> </ul> </li> <li>Techniques:<ul> <li>Testing of programs and prototypes</li> <li>Reviewing of specifications, documentation and programs</li> </ul> </li> <li>Stages of testing<ul> <li>Component testing \\to System testing \\to\\to Customer testing</li> </ul> </li> </ul> </li> <li> <p>Software evolution</p> <ul> <li>The software must evolve to meet changing customer needs</li> </ul> </li> </ol> <p></p>"},{"location":"5-semester/SOE/01-introduction/#software-process-models","title":"Software Process Models","text":"<ol> <li> <p>Waterfall Model (Plan-driven)</p> <ul> <li>Seperate and distinct phases of specification, design, implementation, test, and operations</li> </ul> <p></p> </li> <li> <p>Incremental Model (Plan-driven, agile or mix)</p> <ul> <li>Specification, development and validation are interleaved.</li> <li>System is developed as a series of versions (increments), with each version adding functionality to the previous version.</li> </ul> <p></p> </li> <li> <p>Integration &amp; configurations model (Reuse)</p> <ul> <li>System is assembled from existing configurable components.</li> <li>Plan-driven or agile</li> <li></li> </ul> <p></p> </li> </ol>"},{"location":"5-semester/SOE/01-introduction/#waterfall","title":"Waterfall","text":"<p>It is a plan-driven process, as the process activities are planned and scheduled before starting development.</p> <ol> <li>Requirements analysis and definition <ul> <li>The system\u2019s services, constraints and     goals are established by consultation with system users. They are then     defined in detail and serve as a system specification.</li> </ul> </li> <li>System and software design <ul> <li>The systems design process allocates the     requirements to either hardware or software systems. It establishes an     overall system architecture. Software design involves identifying and     describing the fundamental software system abstractions and their     relationships.</li> </ul> </li> <li>Implementation and unit testing <ul> <li>During this stage, the software design is     realized as a set of programs or program units. Unit testing involves verifying     that each unit meets its specification.</li> </ul> </li> <li>Integration and system testing <ul> <li>The individual program units or programs     are integrated and tested as a complete system to ensure that the software     requirements have been met. After testing, the software system is delivered     to the customer.</li> </ul> </li> <li>Operation and maintenance <ul> <li>Normally, this is the longest life-cycle phase.     The system is installed and put into practical use. Maintenance involves     correcting errors that were not discovered in earlier stages of the life cycle,     improving the implementation of system units, and enhancing the system\u2019s     services as new requirements are discovered.</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/01-introduction/#when-should-you-consider-waterfall","title":"When should you consider waterfall?","text":"<ol> <li>Embedded systems Because of the inflexibility of hardware it is usually not     possibly to delay decisions on the software\u2019s functionality until it is being     implemented.</li> <li>Life critical systems Because the specification and design documents must     be complete so that it is possible to create an extensive security analysis of     the software specification and design. Safety-related problems in the specs     and design are usually very expensive to correct at the implementation     stage.</li> <li>Large software systems that are a part of broader engineering systems     Because the hardware in the system may be developed using a similar     model and companies find it easier to use a common model for hardware     and software. Furthermore, where several companies are involved,     complete specs may be needed to allow for the independent development     of different subsystems.</li> </ol>"},{"location":"5-semester/SOE/01-introduction/#how-can-i-decide-if-agile-or-waterfall-is-best-fit-for-my-situation","title":"How can I decide if agile or waterfall is best fit for my situation?","text":"<p>Boehm: Analyse af home ground</p> <p>The waterfall model should not be used in developing systems where informal team communication is possible and software requirements change quickly. In this case, iterative and agile methods are better.</p> <p></p> <p></p>"},{"location":"5-semester/SOE/02-agile-xp-and-scrum/","title":"Agile, XP, and Scrum","text":""},{"location":"5-semester/SOE/02-agile-xp-and-scrum/#extreme-programming-xp","title":"Extreme Programming (XP)","text":"<p>Emphasizes collaboration, quick and early software creation, and skillful development practices.</p> <p>Values communication, simplicity, feedback, and courage</p> <p>It recommends 12 core practices:</p> <ol> <li>Planning Game</li> <li>Small, frequent releases</li> <li>System metaphors</li> <li>Simple designs</li> <li>Testing</li> <li>Frequent refactoring</li> <li>Pair programming (PP)</li> <li>Team code ownership</li> <li>Continuous integration</li> <li>Sustainable pace</li> <li>Whole team together</li> <li>Coding standards</li> </ol>"},{"location":"5-semester/SOE/02-agile-xp-and-scrum/#scrum","title":"Scrum","text":""},{"location":"5-semester/SOE/02-agile-xp-and-scrum/#pillars","title":"Pillars","text":"<ul> <li>Transparency<ul> <li>Significant aspects of the process must be visible to those responsible for the outcome. Transparency requires those aspects be defined by a common standard so observers share a common understanding of what is being seen.</li> </ul> </li> <li>Inspection<ul> <li>Scrum users must frequently inspect Scrum artifacts and progress toward a Sprint Goal to detect undesirable variances.      Their inspection should not be so frequent that inspection gets in the way of the work.      Inspections are most beneficial when diligently performed by skilled inspectors at the point of work</li> </ul> </li> <li>Adaption<ul> <li>If an inspector determines that one or more aspects of a process deviate outside acceptable limits, and that the resulting product will be unacceptable, the process or the material being processed must be adjusted.      An adjustment must be made as soon as possible to minimize further deviation.</li> <li>Scrum prescribes four formal events for inspection and adaptation<ul> <li>Sprint Planning</li> <li>Daily Scrum</li> <li>Sprint Review</li> <li>Sprint Retrospective</li> </ul> </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/02-agile-xp-and-scrum/#values","title":"Values","text":"<ul> <li>Commitment<ul> <li>People personally commit to achieving the goals of the Scrum Team</li> </ul> </li> <li>Courage<ul> <li>The Scrum Team members have courage to do the right thing and work on tough problems</li> </ul> </li> <li>Focus<ul> <li>Everyone focuses on the work of the Sprint and the goals of the Scrum Team</li> </ul> </li> <li>Openness<ul> <li>The Scrum Team and its stakeholders agree to be open about all the work and the challenges with performing the work</li> </ul> </li> <li>Respect<ul> <li>Scrum Team members respect each other to be capable, independent people</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/02-agile-xp-and-scrum/#scrum-roles","title":"Scrum Roles","text":"<p>There are 3 roles:</p> <ul> <li> <p>Product Owner</p> <ul> <li> <p>The Product Owner is one person, not a committee. The Product Owner may represent the desires of a committee in the Product Backlog, but those wanting to change a Product Backlog item\u2019s priority must address the Product Owner. </p> <p>The Product Owner is responsible for maximizing the value of the product resulting from work of the Development Team.</p> <p>The Product Owner is the sole person responsible for managing the Product Backlog, this being a list of all things that needs to be done within the project.</p> </li> </ul> </li> <li> <p>Scrum Master</p> <ul> <li> <p>The Scrum Master is responsible for promoting and supporting Scrum as defined in the Scrum Guide.     Scrum Masters do this by helping everyone understand Scrum theory, practices, rules, and values.</p> <p>The Scrum Master helps those outside the Scrum Team understand which of their interactions with the Scrum Team are helpful and which aren\u2019t. </p> <p>The Scrum Master helps everyone change these interactions to maximize the value created by the Scrum Team.</p> </li> </ul> </li> <li> <p>Development Team</p> <ul> <li> <p>The Development Team consists of professionals who do the work of delivering a potentially releasable Increment of \u201cDone\u201d product at the end of each Sprint. </p> <p>Development Teams are structured and empowered by the organization to organize and manage their own work.</p> <p>The resulting synergy optimizes the Development Team\u2019s overall efficiency and effectiveness. </p> </li> <li> <p>They are self-organizing.      No one (not even the Scrum Master) tells the Development Team how to turn Product Backlog into Increments of potentially releasable functionality and they are crossfunctional, with all the skills as a team necessary to create a product Increment.</p> </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/04a-rup/","title":"UP","text":"<p>Unified Process (UP)</p> <ul> <li>Refined in Rational Unified Process (RUP)</li> </ul> <p>An iterative process framework</p> <p>Key practices and guidelines</p> <ul> <li>Develop in short timeboxed iterations</li> <li>Develop the high-risk and high-value elements (fx the core architecture) in ealy iterations, preferring re-use of existing components</li> <li>Ensure that you deliver value to your customer</li> <li>Accomedate change early in the project</li> <li>Work together as one team</li> </ul>"},{"location":"5-semester/SOE/04a-rup/#up-phases","title":"UP Phases","text":"<p>Organizes iteratiosn within four phases.</p> <ul> <li> <p>Inception</p> <ul> <li>The purpose with this phase is to define the scope and priorities and identify the key risks.      This is the shortest phase, from a few days to weeks.</li> </ul> </li> <li> <p>Elaboration</p> <ul> <li>The purpose with this phase is that the vision, requirements and architecture are stabilised.      The major risks will be mitigated and architecturally significant elements will be programmed. Here the risky stuff will be build and tested. Contains several iterations.</li> </ul> </li> <li> <p>Construction</p> <ul> <li>Here the purpose is to have a system that is ready to deploy by building and testing the rest \u2013 this is the largest phase.      Contains the most iterations.</li> </ul> </li> <li> <p>Transition</p> <ul> <li>The goal with this phase is to deploy the system.</li> </ul> </li> </ul> <p></p> <p></p>"},{"location":"5-semester/SOE/04a-rup/#time","title":"Time","text":""},{"location":"5-semester/SOE/04a-rup/#milestones","title":"Milestones","text":""},{"location":"5-semester/SOE/05-planning/","title":"Project Planning and Management","text":""},{"location":"5-semester/SOE/05-planning/#software-pricing","title":"Software Pricing","text":"<p>Price is affected by (not complete)</p> <ul> <li>Estimate of cost to build</li> <li>Overhead<ul> <li>Management</li> <li>Building, offices, training</li> <li>Expenses to write bid</li> </ul> </li> <li>Discount - search for price that will beat competitive offers</li> <li>What is the value for the customer (as oppsed to production cost)</li> </ul>"},{"location":"5-semester/SOE/05-planning/#plan-driven-development","title":"Plan-driven Development","text":"<p>The development process is planned in detail</p> <p>A project plan is created that records the work to be done, who will do it, the development schedule, and the work products</p> <p>Managers use the plan to support project decision making and as a way of measuring progress</p>"},{"location":"5-semester/SOE/05-planning/#project-planning","title":"Project Planning","text":"<p>Involves</p> <ul> <li>breaking down the work into parts</li> <li>assign these to project team members</li> <li>anticipate problems that might arise</li> <li>prepare tentative solutions to those problems</li> </ul> <p>The project plan is used to:</p> <ul> <li>communicate how the work will be done to the project team and customers</li> <li>assess progress on the project</li> </ul>"},{"location":"5-semester/SOE/05-planning/#startup-planning","title":"Startup Planning","text":"<p>At this stage, you know more about the system requirements but do not have design or implementation information</p> <p>Create a plan with enough detail to make decisions about the project budget and staffing. </p> <ul> <li>This plan is the basis for project resource allocation</li> </ul> <p>The startup plan should also define project monitoring mechanisms</p> <p>A startup plan is still needed for agile development to allow resources to be allocated to the project</p>"},{"location":"5-semester/SOE/05-planning/#pros-and-cons","title":"Pros and Cons","text":"<p>The arguments in favor of a plan-driven approach are that early planning allows organizational issues (availability of staff, other projects, etc.) to be closely taken into account, and that potential problems and dependencies are discovered before the project starts, rather than once the project is underway.</p> <p>The principal argument against plan-driven development is that many early decisions have to be revised because of changes to the environment in which the software is to be developed and used.</p>"},{"location":"5-semester/SOE/05-planning/#process","title":"Process","text":""},{"location":"5-semester/SOE/05-planning/#work-breakdown","title":"Work Breakdown","text":"<p>Break the work into activities and sub-activities</p> <ul> <li>Gantt charts</li> <li>PERT diagrams</li> <li>Text</li> </ul> <p>Progress measured against milestones (project monitoring)</p> <ul> <li>Milestone specification</li> <li>Assessing whether the milestone has been reached</li> </ul>"},{"location":"5-semester/SOE/05-planning/#gantt-chart","title":"Gantt Chart","text":""},{"location":"5-semester/SOE/05-planning/#pert-diagram","title":"PERT Diagram","text":""},{"location":"5-semester/SOE/05-planning/#milestones","title":"Milestones","text":"<p>Specify products and results</p> <ul> <li>Which product?</li> <li>What state?</li> <li>When?</li> </ul> <p>Specify the assessment criteria and process</p>"},{"location":"5-semester/SOE/05-planning/#agile-planning","title":"Agile Planning","text":"<p>Agile methods of software development are iterative approaches where the software is developed and delivered to customers in increments/iterations.</p> <p>The functionality of increments is not planned in advance but is decided during the development. </p> <ul> <li>The decision on what to include in an increment depends on progress and on the customer\u2019s priorities. </li> </ul> <p>The customer\u2019s priorities and requirements change so it makes sense to have a flexible plan that can accommodate these changes</p>"},{"location":"5-semester/SOE/05-planning/#xp-story-based-estimation-and-planning","title":"XP: Story-based Estimation and Planning","text":"<p>The planning game is based on user stories that reflect the features that should be included in the system. </p> <p>The project team read and discuss the stories and rank them in order of the amount of time they think it will take to implement the story.</p> <p>Stories are assigned \u2018effort points\u2019 (also called story points) reflecting their size and difficulty of implementation</p> <p>The number of effort/story points implemented per day/sprint is measured giving an estimate of the team\u2019s \u2018velocity'</p> <p>This allows the total effort required to implement the system to be estimated</p> <p></p>"},{"location":"5-semester/SOE/05-planning/#agile-planning-applicability","title":"Agile Planning Applicability","text":"<p>Agile planning works well with small, stable development teams that can get together and discuss the stories to be implemented. </p> <p>However, where teams are large and/or geographically distributed, or when team membership changes frequently, it is practically impossible for everyone to be involved in the collaborative planning that is essential for agile project management</p>"},{"location":"5-semester/SOE/05-planning/#agile-estimation","title":"Agile Estimation","text":"<ul> <li>Based on requirements items</li> <li>XP: story points</li> <li>Scrum: Planning poker</li> <li>Experience-based</li> </ul>"},{"location":"5-semester/SOE/05-planning/#scrum","title":"Scrum","text":""},{"location":"5-semester/SOE/05-planning/#sprint-planning","title":"Sprint Planning","text":""},{"location":"5-semester/SOE/05-planning/#monitor-progress","title":"Monitor Progress","text":"<p>Daily Scrum:</p> <ul> <li>Stand-up meeting every morning</li> <li>Organised by Scrum Master</li> <li>Update Scrum board<ul> <li>Move items</li> <li>Update estimates on items</li> </ul> </li> <li>Remove obstacles</li> </ul> <p>Update burn-down chart</p> <p></p>"},{"location":"5-semester/SOE/05-planning/#scrum-boards","title":"Scrum Boards","text":""},{"location":"5-semester/SOE/05-planning/#estimation","title":"Estimation","text":"<p>Organizations need to make software effort and cost estimates</p> <ul> <li>Experience-based techniques</li> <li>Algorithmic cost modeling</li> </ul>"},{"location":"5-semester/SOE/05-planning/#estimate-uncertainty","title":"Estimate Uncertainty","text":""},{"location":"5-semester/SOE/05-planning/#experience-based-estimation","title":"Experience-based Estimation","text":"<p>Based on a triangular distribution</p>  E=(a+m+b)\\ /\\ 3  <p>Based on a double triangular distribution</p>  E=(a+4m+b)\\ /\\ 6\\\\ SD= (b-a)\\ /\\ 6   E=(a+4m+b)\\ /\\ 6\\\\ SD= (b-a)\\ /\\ 6  <p>where </p> <ul> <li>aa is best-case estimate</li> <li>mm is most likely estimate</li> <li>bb is worst-case estimate</li> </ul>"},{"location":"5-semester/SOE/05-planning/#algorithmic-cost-modeling","title":"Algorithmic Cost Modeling","text":"<p>Cost is estimated as a mathematical function of product, project and process attributes whose values are estimated by project managers:</p> <ul> <li>Effort = A  \u0301Size^B^   \u0301M</li> <li>A is an organisation-dependent constant, B reflects the disproportionate effort for laarge projects and M is a multiplier reflecting product, process, and people attributes</li> </ul> <p>The most commonly used product attribute for cost estimation is code size, (lines of code: LOC)</p> <p>Most models are similar but they use different values for A, B and M.</p>"},{"location":"5-semester/SOE/05-planning/#cocomo","title":"COCOMO","text":"<p>An empirical model based on project experience.</p> <p>Well-documented, \u2018independent\u2019 model which is not tied to a specific software vendor.</p> <p>Long history from initial version published in 1981 (COCOMO-81) through various instantiations to COCOMO 2.</p> <p>COCOMO 2 takes into account different approaches to software development, reuse, etc. </p> <p></p> <ol> <li> <p>An application-composition  model  This  models  the  effort  required  to develop  systems  that  are  created from reusable components, scripting,  or database programming.      Software size estimates are based on application points, and a simple size/productivity formula is used to estimate the effort required. </p> <p>The number of application points in a program is a weighted estimate of the number of separate screens that are displayed, the number of reports that are produced, the number of modules in imperative programming languages (such as Java), and the number of lines of scripting language or database programming code.</p> </li> <li> <p>An early design model  This model is used during early stages of the system design after the requirements have been established.      The estimate is based on the standard estimation formula that I discussed in the introduction, with a simplified set of seven multipliers.      Estimates are based on function points, which are then converted to number of lines of source code. Function points are a language-independent way of quantifying program functionality. </p> <p>You compute the total number of function points in a program by measuring or estimating the number of external inputs and outputs, user interactions, external interfaces, and files or database tables used by the system.</p> </li> <li> <p>A reuse model  This model is used to compute the effort required to integrate reusable components and/or automatically generated program code.      It is normally used in conjunction with the post-architecture model.</p> </li> <li> <p>A post-architecture model   Once the system architecture has been designed, amore accurate estimate of the software size can be made.      Again, this model uses the standard formula for cost estimation discussed above. However, it includes a more extensive set of 17 multipliers reflecting personnel capability, product, and project characteristics.</p> </li> </ol>"},{"location":"5-semester/SOE/06-risk-management/","title":"Risk Management","text":"<p>First, risk concerns future happenings. Today and yesterday are beyond active concern, as we are already reaping what was previously sowed by our past actions. The question is, can we, therefore, by changing our actions today, create an opportunity for a different and hopefully better situation for ourselves tomorrow. This means, second, that risk involves change, such as in changes of mind, opinion, actions, or places. . . . [Third,] risk involves choice, and the uncertainty that choice itself entails. Thus paradoxically, risk, like death and taxes, is one of the few certainties of life.  - Robert Charette</p>"},{"location":"5-semester/SOE/06-risk-management/#what-is-a-risk","title":"What is a Risk?","text":"<p>It's not a risk if its certain to happen.</p> <ul> <li>A possible consequence of a choice</li> </ul> <p>Risiko - Negativt Oportunity - Positivt</p>"},{"location":"5-semester/SOE/06-risk-management/#reactive-vs-proactive-risk-strategies","title":"Reactive vs Proactive Risk Strategies","text":"<p>Reactive Risk Strategy</p> <p>Laughingly called \"Indiana Jones school of risk management\"</p> <p>At best, monitors the project for likely risks.</p> <ul> <li>Resources are set aside to deal with them, should they become problems.</li> </ul> <p>More commonly, team does nothing until something goes wrong.</p> <ul> <li>Often called fire fighting mode</li> </ul> <p>Proactive Risk Strategy</p> <p>A more intelligent strategy.</p> <p>Begins long before technical work is initiated.</p> <ul> <li>Potential Risks are identified.</li> <li>Their probability and impact are assessed.</li> <li>They are ranked by importance</li> </ul>"},{"location":"5-semester/SOE/06-risk-management/#software-risks","title":"Software Risks","text":"<p>Risk always involves two factors:</p> <ul> <li>Uncertainty</li> <li>Loss</li> </ul> <p>Different categories are created:</p> <ul> <li>Project Risks<ul> <li>Threatens project plan.<ul> <li>Increases cost</li> </ul> </li> <li>Project risks identify potential budgetary, schedule, personnel (staffing and organization), resource, stakeholder, and requirements problems and their impact on a software project.</li> </ul> </li> <li>Technical Risks<ul> <li>Threatens the quality and timeliness of the software.</li> <li>Technical risks identify potential design, implementation, interface, verification, and maintenance problems. </li> <li>In addition, specification ambiguity, technical uncertainty, technical obsolescence, and \u201cleading- edge\u201d technology are also risk factors.</li> <li>\"the problem is harder to solve than you thought it would be\"</li> </ul> </li> <li>Business Risks<ul> <li>Candidates for the top five business risks are <ol> <li>Market Risk: Building an excellent product or system that no one really wants</li> <li>Strategic Risk: Building a product that no longer fits into the overall business strategy for the company</li> <li>Sales Risk: Building a product that the sales force doesn\u2019t understand how to sell</li> <li>Management Risk: Losing the support of senior management due to a change in focus or a change in people </li> <li>Budget Risks: Losing budgetary or personnel commitment.</li> </ol> </li> </ul> </li> </ul> <p>Another general categorization has been proposed:</p> <ul> <li>Known Risks<ul> <li>Can be uncovered by careful evaluation of the project plan.</li> </ul> </li> <li>Predictable Risks<ul> <li>Extrapolated from past project plans</li> <li>e.g. staff turnover, poor communication with the customer, dilution of staff effort     as ongoing maintenance requests are serviced</li> </ul> </li> <li>Unpredictable Risks<ul> <li>They can and do occur, but they are extremely difficult to identify in advance.</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/06-risk-management/#risk-identification","title":"Risk Identification","text":"<p>Two distinct types of risks in each category:</p> <ul> <li>Generic risks<ul> <li>Potential threat for every software project</li> </ul> </li> <li>Product-specific risks<ul> <li>Identified only by those with a clear understanding of the technology, the people, and the environment that is specific to the software that is to be built</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/06-risk-management/#risk-item-checklist","title":"Risk Item Checklist","text":"<p>Used for identification and focuses of some subset of known and predictable risks in the following generic subcategories:</p> <ul> <li>Product size\u2014risks associated with the overall size of the software to be built or modified.</li> <li>Business impact\u2014risks associated with constraints imposed by management or the marketplace.</li> <li>Stakeholder characteristics\u2014risks associated with the sophistication of the stakeholders and the developer\u2019s ability to communicate with stakeholders in a timely manner.</li> <li>Process definition\u2014risks associated with the degree to which the software process has been defined and is followed by the development organization.</li> <li>Development environment\u2014risks associated with the availability and quality of the tools to be used to build the product.</li> <li>Technology to be built\u2014risks associated with the complexity of the system to be built and the \u201cnewness\u201d of the technology that is packaged by the system.</li> <li>Staff size and experience\u2014risks associated with the overall technical and project experience of the software engineers who will do the work.</li> </ul> <p>A number of comprehensive checklists for software project risk are available on the Web.</p>"},{"location":"5-semester/SOE/06-risk-management/#assessing-overall-project-risk","title":"Assessing Overall Project Risk","text":"<p>The following questions have been derived from risk data obtained by surveying: </p> <ol> <li>Have top software and customer managers formally committed to support the project?</li> <li>Are end users enthusiastically committed to the project and the system/ product to be built?</li> <li>Are requirements fully understood by the software engineering team and its customers?</li> <li>Have customers been involved fully in the definition of requirements?</li> <li>Do end users have realistic expectations?</li> <li>Is the project scope stable?</li> <li>Does the software engineering team have the right mix of skills?</li> <li>Are project requirements stable?</li> <li>Does the project team have experience with the technology to be implemented?</li> <li>Is the number of people on the project team adequate to do the job? </li> <li>Do all customer/user constituencies agree on the importance of the project and on the requirements for the system/product to be built?</li> </ol> <p>If any of these are answered negatively, then mitigation, monitoring and management should be instituted without fail.</p> <p>The degree to which the project is at risk is directly proportional to the number of negative responses to these questions.</p>"},{"location":"5-semester/SOE/06-risk-management/#risk-components-and-drivers","title":"Risk Components and Drivers","text":"<p>The US Air Force have published guidelines for software risk identification and abatement. </p> <p>Risk components are defined:</p> <ul> <li>Performance risk\u2014the degree of uncertainty that the product will meet its requirements and be fit for its intended use.</li> <li>Cost risk\u2014the degree of uncertainty that the project budget will be maintained.</li> <li>Support risk\u2014the degree of uncertainty that the resultant software will be easy to correct, adapt, and enhance.</li> <li>Schedule risk\u2014the degree of uncertainty that the project schedule will be maintained and that the product will be delivered on time.</li> </ul> <p>The impact of each risk driver is divided into one of:</p> <ul> <li>Negligible</li> <li>Marginal</li> <li>Critical</li> <li>Catastrophic</li> </ul> <p></p>"},{"location":"5-semester/SOE/06-risk-management/#risk-projection-risk-estimation","title":"Risk Projection (Risk Estimation)","text":"<p>Attempts to rate each risk in:</p> <ol> <li> <p>The probability that risk is real</p> </li> <li> <p>The consequences </p> </li> </ol> <p>There are four risk projection steps:</p> <ol> <li>Establish a scale that reflects the perceived likelihood of a risk.</li> <li>Delineate the consequences of the risk</li> <li>Estimate the impact of the risk on the project and the product</li> <li>Assess the overall accuracy of the risk projection so that there will be no misunderstandings</li> </ol>"},{"location":"5-semester/SOE/06-risk-management/#risk-table","title":"Risk Table","text":"<ul> <li>Sorted by probability and impact to rank risks</li> <li> <p>You can define a cutoff line.</p> <ul> <li>Horizontal line somewhere in the table</li> <li>Only risks above the line are given further attention.</li> </ul> </li> <li> <p>RMMM contains a pointer into a risk mitigation, monitoring, and management plan</p> </li> </ul>"},{"location":"5-semester/SOE/06-risk-management/#risk-impact","title":"Risk Impact","text":"<p>Three factors affect the consequences.</p> <ul> <li>Its nature</li> <li>Its scope</li> <li>Its timing</li> </ul> <p>Overall risk exposure RE is calculated: $$ RE=P\\times C $$ where PP is the probability of the risk, and CC is the cost to the project if the risk occurs.</p> <p></p>"},{"location":"5-semester/SOE/06-risk-management/#example","title":"Example:","text":""},{"location":"5-semester/SOE/06-risk-management/#risk-refinement","title":"Risk Refinement","text":"<p>Refine risks into a set of more detailed risks, each somewhat easier to mitigate, monitor and manage.</p>"},{"location":"5-semester/SOE/06-risk-management/#condition-transition-consequence-ctc-format","title":"Condition-Transition-Consequence (CTC) Format","text":"<p>Using the CTC format for the example from before:</p> <p>Given that all reusable software components must conform to specific design standards and that some do not conform, then there is concern that (possibly) only 70 percent of the planned reusable modules may actually be integrated into the as-built system, resulting in the need to custom engineer the remaining 30 percent of components.</p> <p>This can be refined:</p> <p>Subcondition 1 Certain reusable components were developed by a third party with no knowledge of internal design standards.</p> <p>Subcondition 2 The design standard for component interfaces has not been solidified and may not conform to certain existing reusable components.</p> <p>Subcondition 3 Certain reusable components have been implemented in a language that is not supported on the target environment.</p>"},{"location":"5-semester/SOE/06-risk-management/#risk-mitigation-monitoring-and-management","title":"Risk Mitigation, Monitoring, and Management","text":"<p>An effective strategy must consider three issues:</p> <ul> <li>Risk avoidance</li> <li>Risk monitoring</li> <li>Risk Management</li> </ul> <p>Avoidance is always the best strategy.</p> <ul> <li>Achieved by making a risk mitigation plan.</li> </ul> <p></p> <p>RMMM ( Risk - Mititgate - Monitor - Manage)</p>"},{"location":"5-semester/SOE/07-quality/","title":"Quality","text":"<p>Definition</p> <p>Quality is a reflection of one or more peoples' assessment of correspondence between their expectations and experience of a product or a service</p> <p>Can be divided into three categories</p> <ul> <li>Product Quality</li> <li>Process Quality</li> <li>Quality of expectations</li> </ul> <p>Cost of bad quality</p> <p>Direct cost:</p> <ul> <li>Loss</li> <li>Wasted work</li> <li>Maintenance usually more expensive than development</li> </ul> <p>Indirect cost</p> <ul> <li>Follows from poor quality</li> <li>Has potentially severe consequences</li> </ul>"},{"location":"5-semester/SOE/07-quality/#quality-management","title":"Quality Management","text":"<p>Quality Management consists of</p> <ul> <li>Quality Assurance<ul> <li>Plan or design processes to prevent bad quality</li> </ul> </li> <li>Quality Control<ul> <li>Monitor that work products meet quality standards</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/07-quality/#theory-of-cost-and-quality","title":"Theory of Cost and Quality","text":"<ul> <li>Low quality(low quality management) is initially cheap, but becomes gradually very expensive</li> <li>High quality management, has an initial cost when quality processes are defined, but is cheaper later because users are reporting much less errors, and code is more stable</li> <li>The amount of quality management should be balanced to the cost \u2013 a process that is 100% defect free is often too expensive, so an appropriate compromise is normally made.      As a result the initial cost is a little less than for very high quality management, at the cost that slightly more defects are reported over time.</li> <li>We plan and design, how and when to do verification and validation in our process</li> </ul>"},{"location":"5-semester/SOE/07-quality/#quality-assurance","title":"Quality Assurance","text":"<p>Validation (fit for use)</p> <ul> <li>Are we building the right systems?</li> <li>Conforms to customers' expectations and experience</li> </ul> <p>Verification (are all requirements implemented)</p> <ul> <li>Are we building the system right?</li> <li>Conforms to specification</li> <li>Relatively objective process</li> </ul> <p>Techniques</p> <ul> <li>Testing of programs and prototypes</li> <li>Reviewing of specifications, documentation and programs</li> </ul> <p></p>"},{"location":"5-semester/SOE/07-quality/#in-the-different-models","title":"In the Different Models","text":""},{"location":"5-semester/SOE/07-quality/#waterfall","title":"Waterfall","text":""},{"location":"5-semester/SOE/07-quality/#incremental","title":"Incremental","text":""},{"location":"5-semester/SOE/07-quality/#integration-and-configuration","title":"Integration and Configuration","text":""},{"location":"5-semester/SOE/07-quality/#quality-management-and-agile-development","title":"Quality Management and Agile Development","text":"<p>Quality management in agile is informal rather than document-based</p> <p>It relies on establishing a quality culture, where all team members feel responsible for software quality and take actions to ensure that quality is maintained. This quality culture is established through agile quality practices</p>"},{"location":"5-semester/SOE/07-quality/#agile-quality-practices","title":"Agile Quality Practices","text":"<ul> <li> <p>Definition of Done</p> <ul> <li>Team agree on what criteria must be met before a task is complete</li> </ul> </li> <li> <p>Sprint Review</p> <ul> <li>Product Owner and other stakeholders validate the sprint delivery meets expectations</li> </ul> </li> <li> <p>Check before check-in</p> <ul> <li>Developers are responsible for organizing their own code reviews with other team members before the code is checked in to the build system</li> </ul> </li> <li> <p>Never break the build</p> <ul> <li> <p>Team members should not check in code that causes the system to fail</p> <p>Developers have to test their code changes against the whole system and be confident that these work as expected</p> </li> </ul> </li> <li> <p>Fix problems when you see them</p> <ul> <li>If a programmer discovers problems or obscurities in code developed by someone else, they can fix these directly rather than referring them back to the original developer</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/07-quality/#fundamental-process-theory-process-quality","title":"Fundamental Process Theory (Process Quality)","text":"<ul> <li>A software product can only be as good as the process through which it is produced</li> <li>You can only improve the quality of the product if you improve the process<ul> <li>Repeating the same process, will create same level of quality</li> <li>Sources of bad quality can be used as input to improve the process</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/9ba-test/","title":"Test","text":""},{"location":"5-semester/SOE/9ba-test/#test-driven-development-tdd","title":"Test-driven Development (TDD)","text":"<ul> <li>Tests are written before code and 'passing' the test is the critical driver of development</li> <li>You develop code incrementally, along with a test for that increment.     You dont move on to the next increment before code has passed its test</li> <li>TDD was introduced as part of agile methods such as XP.     However, it can also be used in plan-driven development processes.</li> </ul>"},{"location":"5-semester/SOE/9ba-test/#process-activities","title":"Process Activities","text":"<ul> <li>Start by identifying the increment of functionality that is required. This should normally be small and implementable in a few lines of code</li> <li>Write a test for this functionality and implement this as an automated test</li> <li>Run the test, along with all other tests that have been implemented. Initially, you have not implemented the functionality so the new test will fail</li> <li>Implement the functionality and re-run the test</li> <li>Once all tests run successfully, you move on to implementing the next chunk of functionality</li> </ul>"},{"location":"5-semester/SOE/9ba-test/#benefits","title":"Benefits","text":"<ul> <li>Code Coverage<ul> <li>Every code segment that you write has at least one associated test so all code written has at least one test</li> </ul> </li> <li>Regression Testing<ul> <li>A regression test suite is developed incrementally as a program is developed.</li> </ul> </li> <li>Simplified Debugging<ul> <li>When a test fails, it should be obvious where the problem lies. The newly written code needs to be checked and modified</li> </ul> </li> <li>System Documentation<ul> <li>The tests themselves are a form of documentation that describe what the code should be doing. </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/9ba-test/#plan-driven-testing","title":"Plan-Driven Testing","text":""},{"location":"5-semester/SOE/9ba-test/#v-model","title":"V Model","text":""},{"location":"5-semester/SOE/exam/","title":"Exam Questions","text":"<ol> <li>Software process models: waterfall</li> <li>Software process model: incremental and iterative</li> <li>Software process model: integration &amp; configuration</li> <li>Comparison of plan-driven and agile software engineering processes, including analysis of home grounds</li> <li>Key features of Scrum</li> <li>Key features of RUP</li> <li>Requirements Elicitation and Managing change to requirements</li> <li>Quality Control: Verification and Validation</li> <li>Risk Management</li> <li>Project Planning and Management</li> <li>Quality Management: How is quality defined - agile versus plan driven approaches</li> <li>Configuration Management</li> </ol>"},{"location":"5-semester/SOE/exam/01-waterfall/","title":"Software process models: Waterfall","text":""},{"location":"5-semester/SOE/exam/01-waterfall/#software-engineering","title":"Software Engineering","text":"<p>Pga. ingen fysiske constraints, kan software systemer hurtigt blive ekstrem komplekse, sv\u00e6re at forst\u00e5, og dyre at \u00e6ndre i.</p> <p>Mange fejl i software projekter skyldes 2 faktorer</p> <ol> <li>Increasing System Complexity<ul> <li>Demands change, systemr skal leveres hurtigere; st\u00f8rre, endnu mere komplekse.</li> </ul> </li> <li>Failure to use software engineering methods<ul> <li>Det er nemt at skrive computer programmer uden at bruge SE metoder og teknikker.</li> <li>Mange selskaber er blevet software udviklere med tiden<ul> <li>De bruger ikke SE metoder i deres hverdagsarbejde</li> <li>Derfor bliver deres software ofte dyrere og mindre reliable end det burde.</li> </ul> </li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/01-waterfall/#se-process-activities","title":"SE Process Activities","text":"<ol> <li>Software specification <ul> <li>The functionality of the software and constraints on its operation must be defined.</li> </ul> </li> <li>Software development <ul> <li>The software to meet the specification must be produced.</li> </ul> </li> <li>Software validation <ul> <li>The software must be validated to ensure that it does what the customer wants.</li> </ul> </li> <li>Software evolution <ul> <li>The software must evolve to meet changing customer needs.</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/01-waterfall/#waterfall","title":"Waterfall","text":"<p>Aktiviteter foreg\u00e5r i sekvens, overlevering af work products mellem faser, milestones og relateret work products bruges til at overv\u00e5ge progress</p> <p></p>"},{"location":"5-semester/SOE/exam/01-waterfall/#plan-drevet","title":"Plan Drevet","text":"<p>Plan drevet, da process aktiviteterne er planlagt f\u00f8r start.</p> <ol> <li>Requirements analysis and definition <ul> <li>Services, constraints, og m\u00e5l etableres ved konsultation med system brugere.</li> <li>Beskrives i detajler som system specifikation</li> </ul> </li> <li>System and software design <ul> <li>Allokerer requirements til hardware eller software systems.     Etablerer en overall system arkitektur</li> <li>Identificering og beskrivesle af fundamental software system abstraktion og relationships</li> </ul> </li> <li>Implementation and unit testing <ul> <li>Software design udarbejdes og unit testing verificerer at hver unit overholder dets specifikation</li> </ul> </li> <li>Integration and system testing <ul> <li>Program units eller programmer integrerets og testes som helhed.</li> <li>Udleveres til kunden efter testing</li> </ul> </li> <li>Operation and maintenance <ul> <li>System installeres og tages i brug.</li> <li>Vedligeholdelse</li> <li>Opdatering</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/01-waterfall/#hvornar-waterfall","title":"Hvorn\u00e5r waterfall?","text":"<ul> <li>Embedded systems<ul> <li>Infleksibilt hardware</li> </ul> </li> <li>Life critical systems<ul> <li>Specs og design documents skal v\u00e6re komplet.</li> <li>Ekstensiv sikkerhedsanalyse</li> </ul> </li> <li>Store software systemer<ul> <li>Del af bredere ingeni\u00f8r systemer</li> <li>Hardwaren kan v\u00e6re udviklet med lignende model.<ul> <li>F\u00e6lles model for hardware og software</li> </ul> </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/02-incremental-iterative/","title":"Software process models: Incremental and Iterative","text":""},{"location":"5-semester/SOE/exam/02-incremental-iterative/#software-engineering","title":"Software Engineering","text":"<p>Pga. ingen fysiske constraints, kan software systemer hurtigt blive ekstrem komplekse, sv\u00e6re at forst\u00e5, og dyre at \u00e6ndre i.</p> <p>Mange fejl i software projekter skyldes 2 faktorer</p> <ol> <li>Increasing System Complexity<ul> <li>Demands change, systemr skal leveres hurtigere; st\u00f8rre, endnu mere komplekse.</li> </ul> </li> <li>Failure to use software engineering methods<ul> <li>Det er nemt at skrive computer programmer uden at bruge SE metoder og teknikker.</li> <li>Mange selskaber er blevet software udviklere med tiden<ul> <li>De bruger ikke SE metoder i deres hverdagsarbejde</li> <li>Derfor bliver deres software ofte dyrere og mindre reliable end det burde.</li> </ul> </li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/02-incremental-iterative/#se-process-activities","title":"SE Process Activities","text":"<ol> <li> <p>Software specification </p> <ul> <li>The functionality of the software and constraints on its operation must be defined.</li> </ul> </li> <li> <p>Software development </p> <ul> <li>The software to meet the specification must be produced.</li> </ul> </li> <li> <p>Software validation </p> <ul> <li>The software must be validated to ensure that it does what the customer wants.</li> </ul> </li> <li> <p>Software evolution </p> <ul> <li>The software must evolve to meet changing customer needs.</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/02-incremental-iterative/#incremental-and-iterative","title":"Incremental and Iterative","text":"<p>Her udvikles systemet i iterationer. Som en serie af \"versioner\"</p> <ul> <li>Hver version tilf\u00f8jer funktionalitet til tidligere version</li> <li>Specifikation, Udvikling/development, og Validation sker i hver iteration.</li> </ul> <p>Planen deles op i flere bidder</p> <p></p> <p>Der laves en initial implementering, hvorfra man f\u00e5r feedback fra brugerer, herefter udvikles softwaren i flere iterationer indtil f\u00e6rdigt.</p> <ul> <li>Det er godt hvis der er h\u00f8j sandsynlighed for at requirements \u00e6ndres undervejs</li> <li>Det er billigere og nemmere at lave \u00e6ndringer undervejs end waterfall</li> </ul> <p>Mest software bliver udviklet med incremental and iterative model.</p> <p>Waterfall fungerer bedst til safety-critical software.</p> <ul> <li>Massere af analyse og dokumentation f\u00f8r implementering</li> </ul>"},{"location":"5-semester/SOE/exam/02-incremental-iterative/#plandrevet-eller-agilt","title":"Plandrevet eller Agilt?","text":"<p>Kan v\u00e6re b\u00e5de plandrevet og agilt.</p> <p>Eksempelvis er det plandrevet hvis en waterfall model deles op i planlagte iterationer fra start.</p> <p>Ved agilt ville man kun planl\u00e6gge \u00e9t inkrement af gangen</p>"},{"location":"5-semester/SOE/exam/02-incremental-iterative/#fordele-og-ulemper","title":"Fordele og Ulemper","text":"<p>Fordele</p> <ul> <li>Billigere at implementere \u00e6ndringer undervejs</li> <li>Nemmere at f\u00e5 feedback p\u00e5 det der er lavet</li> <li>Kan leveres hurtigere til kunden selvom det ikke er f\u00e6rdigt endnu</li> </ul> <p>Ulemper</p> <ul> <li>Usynlig process.<ul> <li>Managers skal have regul\u00e6r delivery af produktet for at m\u00e5le progress</li> </ul> </li> <li>Struktur foringes med antallet af inkrements<ul> <li>Rodet kode</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/03-integration-configuration/","title":"Software process model: integration &amp; configuration","text":""},{"location":"5-semester/SOE/exam/03-integration-configuration/#software-engineering","title":"Software Engineering","text":"<p>Pga. ingen fysiske constraints, kan software systemer hurtigt blive ekstrem komplekse, sv\u00e6re at forst\u00e5, og dyre at \u00e6ndre i.</p> <p>Mange fejl i software projekter skyldes 2 faktorer</p> <ol> <li>Increasing System Complexity<ul> <li>Demands change, systemr skal leveres hurtigere; st\u00f8rre, endnu mere komplekse.</li> </ul> </li> <li>Failure to use software engineering methods<ul> <li>Det er nemt at skrive computer programmer uden at bruge SE metoder og teknikker.</li> <li>Mange selskaber er blevet software udviklere med tiden<ul> <li>De bruger ikke SE metoder i deres hverdagsarbejde</li> <li>Derfor bliver deres software ofte dyrere og mindre reliable end det burde.</li> </ul> </li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/03-integration-configuration/#se-process-activities","title":"SE Process Activities","text":"<ol> <li>Software specification <ul> <li>The functionality of the software and constraints on its operation must be defined.</li> </ul> </li> <li>Software development <ul> <li>The software to meet the specification must be produced.</li> </ul> </li> <li>Software validation <ul> <li>The software must be validated to ensure that it does what the customer wants.</li> </ul> </li> <li>Software evolution <ul> <li>The software must evolve to meet changing customer needs.</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/03-integration-configuration/#integration-and-configuration","title":"Integration and Configuration","text":"<p>Afh\u00e6nger af tilg\u00e6ngeligheden af genbruglige components eller systemer.</p> <p>Fokuserer p\u00e5 at konfigurere disse komponenter til brug i nye omgivelser og integrere dem ind i et system</p> <p>Et system samles fra eksisterende konfigurerbare moduler.</p> <p>Det er meget almindeligt at genbruge kode. Disse 3 typer software genbruges ofte:</p> <ul> <li>Standalone systemer som konfigureres til et bestemt milj\u00f8</li> <li>Collection of objects as component or package</li> <li>Web services, udvikles if\u00f8lge standarder<ul> <li>Kan kaldes remotely, (eks. REST API'er)</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/03-integration-configuration/#plandrevet-eller-agilt","title":"Plandrevet eller Agilt?","text":"<p>Kan b\u00e5de v\u00e6re plandrevet eller agilt</p>"},{"location":"5-semester/SOE/exam/03-integration-configuration/#fordele-og-ulemper","title":"Fordele og Ulemper","text":"<p>Fordele</p> <ul> <li>Reducerer m\u00e6ngden af software der skal udvikles<ul> <li>Cost og risk reduceres </li> </ul> </li> </ul> <p>Ulemper</p> <ul> <li>Uundg\u00e5ligt at kompromittere requirements<ul> <li>Kan f\u00f8re til at system ikke opfylder reel behov fra bruger</li> </ul> </li> <li>Ingen kontrol over genbrugt software<ul> <li>Hvordan og hvorn\u00e5r nye versioner kommer</li> <li>\u00c6ndringer i funktionalitet</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/03-integration-configuration/#model","title":"Model","text":"<ol> <li>Requirements specification<ul> <li>Initial requirements foresl\u00e5s, ikke detaljeret - essential requirements og system features</li> </ul> </li> <li>Software discovery and evaluation<ul> <li>Der s\u00f8ges efter komponenter og systemer der kan give den kr\u00e6vede funktionalitet.</li> <li>Kandidater evalueres efter om de m\u00f8der essential requirements, og hvor suitable de er</li> </ul> </li> <li>Requirements refinement<ul> <li>Requirements refineres efter info om brugbare komponenter/systemer</li> </ul> </li> <li>Application system configuration<ul> <li>Hvis off-the-shelf system findes, konfigureres det til brug i det nye system</li> </ul> </li> <li>Component adaption and integration<ul> <li>Hvis ikke, bliver eksisterende komponenter evt. modificeret, og nye udvilkes til at integrere i systemet</li> </ul> </li> </ol>"},{"location":"5-semester/SOE/exam/04-plandriven-vs-agile/","title":"Comparison of plan-driven and agile SOE processes","text":""},{"location":"5-semester/SOE/exam/04-plandriven-vs-agile/#plandrevet-vs-agilt","title":"Plandrevet vs Agilt","text":"<p>Plandrevet</p> <ul> <li>Alle \u00f8nskede egenskaber ved slutproduktet kan v\u00e6re kendt og pr\u00e6cist specificeres f\u00f8r start</li> <li>Projekter er predictable og skal derfor planl\u00e6gges i detaljer f\u00f8r start</li> <li>Afvigelse fra planen er tegn p\u00e5 sloppy work i tidlige stadier</li> </ul> <p>Agilt</p> <ul> <li>\u00d8nskede egenskaber kendes ikke f\u00f8r mindst en del af l\u00f8sningen er bygget</li> <li>Projekter er af princip uforudsigelige</li> </ul>"},{"location":"5-semester/SOE/exam/04-plandriven-vs-agile/#bohmturner-primary-factors","title":"B\u00f6hm/Turner Primary Factors","text":"<p>Application</p> <ul> <li>Agilt<ul> <li>rapid value, reagere p\u00e5 \u00e6ndringer, mindre team og projekt</li> <li>turbulent, high chance, projekfokuseret</li> </ul> </li> <li>Plandrevet<ul> <li>forudsigligt, h\u00f8j forsikring, stabilitet, st\u00f8rre team og projekt</li> <li>stabil milj\u00f8, projek og organization fokus</li> </ul> </li> </ul> <p>Management</p> <ul> <li>Agilt<ul> <li>dedikerede on-site kunder, fokus p\u00e5 priorietet inkrements</li> <li>planer og viden er mere implicit og intern</li> </ul> </li> <li>Plandrevet<ul> <li>kun kundeinteraction n\u00e5r brug for det, kontrakt</li> <li>planer og viden er dokumenteret</li> </ul> </li> </ul> <p>Technical</p> <ul> <li>Agilt<ul> <li>Korte inkrements, simple design, billig refactoring, informelle stories og test cases prioriteret, uforudsiglige \u00e6ndringer</li> </ul> </li> <li>Plandrevet<ul> <li>struktureret og formel projekt, udviklingen er forudsiglig, dokumenterede test og procedurer, l\u00e6ngere increments, dyr refactoring</li> </ul> </li> </ul> <p>Personell</p> <ul> <li>Agilt<ul> <li>konstant tilg\u00e6ngelig kunde, stort behov for level 2 udviklere, ogs\u00e5 level 3, komfort og empowerment fra frihed</li> </ul> </li> <li>Plandrevet<ul> <li>ikke-konstant tilg\u00e6ngelig kunde, stort behov for level 3 udviklere, og level 1B, komfort og empowerment fra orden</li> </ul> </li> </ul> <p></p> <p></p> <p></p>"},{"location":"5-semester/SOE/exam/04-plandriven-vs-agile/#cynefin","title":"Cynefin","text":"<p>Framework til beslutningstagning. </p> <p>Kan v\u00e6re sv\u00e6rt at vide hvor man ligger.</p> <p>Simple: oplagt at bruge plan-driven</p> <p>Complex, Complicated: m\u00e5ske bedre at bruge agilt.</p>"},{"location":"5-semester/SOE/exam/04-plandriven-vs-agile/#ndringer-i-requirements","title":"\u00c6ndringer i Requirements","text":"<p>Requirements kan \u00e6ndre sig. Eksempelvis hvis teknologien bliver outdated eller hvis markedet \u00e6ndrer sig.</p> <ul> <li>Eksempelvis hvis der udkommer et system der kan det samme</li> </ul> <p>Eller hvis product owner l\u00e6rer noget nyt i l\u00f8bet af udviklingsfasen</p>"},{"location":"5-semester/SOE/exam/05-scrum/","title":"Key features of Scrum","text":"<p>Scrum er en iterativ agil metode</p> <p>3-5-3 struktur</p> <ul> <li>3 roller: <ul> <li>Product Owner, Scrum Master, Team</li> </ul> </li> <li>5 events: <ul> <li>sprint, sprint plan, daily scrum, sprint review, sprint retrospective</li> </ul> </li> <li>3 artifacts<ul> <li>Product backlog, sprint backlog, product increment</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#scrum-roller","title":"Scrum Roller","text":"<ul> <li>Product Owner<ul> <li>1 person. \u00c6ndringer i backlog sker gennem Product Owner.</li> <li>Ansvarlig for maximering af produktets v\u00e6rdi fra arbejde fra Dev team</li> </ul> </li> <li>Scrum Master<ul> <li>Ansvarlig for at bruge Scrum p\u00e5 den rigtige m\u00e5de (iflg. Scrum Guide)<ul> <li>Hj\u00e6lper med at forst\u00e5 Scrum teori, practices, regler og v\u00e6rdier</li> </ul> </li> <li>Hj\u00e6lper dem udefra med at forst\u00e5 hvad der er nyttigt interaktion med Scrum team.</li> </ul> </li> <li>Development Team<ul> <li>Best\u00e5r af profesionelle, som leverer potentiel releasable inkrement af \"done\" produkt i slutningen af hver sprint</li> <li>Organizerer deres eget arbejde</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#scrum-aktiviteter","title":"Scrum Aktiviteter","text":"<ul> <li>Sprint<ul> <li>Max en m\u00e5ned hvori en brugbar og potentiel udgivelig produkt inkrement udvikles.</li> <li>Starter med det samme efter konklusionen p\u00e5 en tidligere sprint</li> <li>Hver sprint har et m\u00e5l med hvad der skal udvikles<ul> <li>Ingen \u00e6ndringer der kan endanger m\u00e5let m\u00e5 laves</li> </ul> </li> </ul> </li> <li>Sprint Planning<ul> <li>Maximalt 8 timer for en 1 month sprint.</li> <li>En plan udarbejdes fra hele Scrum Team<ol> <li>Hvad kan leveres i den kommende sprint?</li> <li>Hvordan kan vi levere det?</li> </ol> </li> </ul> </li> <li>Daily Scrum<ul> <li>Stand-up m\u00f8de (15 min)<ul> <li>Samme tid, samme sted hver dag</li> </ul> </li> <li>Arbejde til de n\u00e6ste 24 timer bestemmes</li> <li>Bruges til at m\u00e5le progress imod sprint goal</li> </ul> </li> <li>Sprint Review<ul> <li>Holdes i slutningen af en sprint (4 timer)</li> <li>What was done? What to do?</li> <li>Resulterer i et genovervejet product backlog</li> </ul> </li> <li>Sprint Retrospective<ul> <li>Efter sprint review, f\u00f8r n\u00e6ste sprint planning (3 timer)</li> <li>Scrum Master holder det positivt og produktivt</li> <li>Kigger p\u00e5 sidste sprint ifht. mennesker, forhold, process, og v\u00e6rkt\u00f8jer<ul> <li>identificerer potentielle forbedringer</li> </ul> </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#scrum-assets","title":"Scrum Assets","text":"<p>Sprint Burndown Chart</p> <ul> <li>Bruges af development team til at overv\u00e5ge progress under en sprint</li> </ul> <p>Product Burndown Chart</p> <ul> <li>Bruges af management til at overv\u00e5ge produktets progress</li> <li>Product mangement purposes</li> </ul> <p>Scrum Board</p> <ul> <li>G\u00f8r product backlog visuel</li> <li>Opdateres af development team</li> <li>Viser alle items, der skal g\u00f8res under sprint</li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#scrum-sjler","title":"Scrum S\u00f8jler","text":"<p>Transparency</p> <ul> <li>Vigtige aspekter af processen skal v\u00e6re synlig for dem der er ansvarlige for outcome</li> <li>f\u00e6lles standard<ul> <li>Eks. f\u00e6lles forst\u00e5else af \"done\"</li> </ul> </li> </ul> <p>Inspection</p> <ul> <li>Scrum bruger skal ofte inspecte Scrum artifacts og progress for at opdate u\u00f8nsket varians<ul> <li>Skal ikke komme i vejen for arbejde (ikke for tit)</li> </ul> </li> </ul> <p>Adaption</p> <ul> <li>Hvis en inspector finder et aspekt uacceptabelt, skal processen \u00e6ndres<ul> <li>Hurtigst muligt</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#core-values","title":"Core Values","text":"<ul> <li>Commitment<ul> <li>People personally commit to achieving the goals of the Scrum Team</li> </ul> </li> <li>Courage<ul> <li>The Scrum Team members have courage to do the right thing and work on tough problems</li> </ul> </li> <li>Focus<ul> <li>Everyone focuses on the work of the Sprint and the goals of the Scrum Team</li> </ul> </li> <li>Openness<ul> <li>The Scrum Team and its stakeholders agree to be open about all the work and the challenges with performing the work</li> </ul> </li> <li>Respect<ul> <li>Scrum Team members respect each other to be capable, independent people</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/05-scrum/#scrum-fejl","title":"Scrum Fejl","text":"Scrum Master fungerer som manager <ul> <li>Agile teams er self-organizing, Scrum Master skal ikke styre hvordan development team arbejder </li> <li>Scrum Master skal fungere som coach, ikke leder</li> </ul> Kunder er ikke involveret i hver iteration <ul> <li>Product Owner skal v\u00e6re involveret i hver iteration, ellers kan der opst\u00e5 forskellige visioner</li> </ul> Nye requirements eller opgaver tilf\u00f8jes under en iteration <ul> <li>Kan komme i vejen for at den nuv\u00e6rende inkrement bliver s\u00e5 v\u00e6rdifuld som muligt.</li> </ul>"},{"location":"5-semester/SOE/exam/06-rup/","title":"Key features of RUP","text":"<p>RUP er inkrementiel iterativt metode framework.</p> <p>Rational Unified Process</p> <ul> <li>Udvikles i korte timeboxed iterationer.</li> <li>High risk, high-value udvikles i de tidlige iterationer</li> <li>re-use af eksisterende komponenter</li> <li>Accomedate \u00e6ndringer tidligt i projektet</li> <li>Work together as one team</li> </ul> <p>UP definerer omkring 50 optional artifacts eller work products (ex Vision, Risk List)</p> <ul> <li>Less is better: Brug en minimal m\u00e6ngde af work products</li> </ul> <p>RUP er baseret p\u00e5 et s\u00e6t \"byggeklodser\"</p> <ul> <li>Roles (Who)<ul> <li>Defineret s\u00e6t af relaterede skills og ansvarligheder</li> </ul> </li> <li>Work Product (What)<ul> <li>Resultat fra en tasks, inkl. dokumenter og modeller</li> </ul> </li> <li>Tasks (How)<ul> <li>En unit arbejde assigned til en rolle</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/06-rup/#tasks","title":"Tasks","text":"<p>Tasks deles op i discipliner</p> <p></p>"},{"location":"5-semester/SOE/exam/06-rup/#faser","title":"Faser","text":"<p>4 faser</p> <ul> <li> <p>Inception</p> <ul> <li>Scope og prioriteter definieres</li> <li>Key risks identificeres.</li> <li>Korteste fase (f\u00e5 date til uger)</li> </ul> </li> <li> <p>Elaboration</p> <ul> <li>Vision, requirements og arkitektur stabiliseres.</li> <li>Major risks mitigeres og arkitektuelt signifikante elementer programmeres</li> <li>Risky stuff bygges og testes</li> </ul> </li> <li> <p>Construction</p> <ul> <li>Resten bygges og testes</li> <li>Systemet klarg\u00f8res og er ready-to-deply i slutningen</li> <li>St\u00f8rste fase</li> </ul> </li> <li> <p>Transition</p> <ul> <li>Systemet deployes</li> </ul> </li> </ul> <p></p> <p></p>"},{"location":"5-semester/SOE/exam/06-rup/#hvad-skrdersyes-til-hvert-projekt","title":"Hvad Skr\u00e6dersyes til hvert projekt","text":"<p>Practices og work products udv\u00e6lges fra en stor bunke af valgbare elementer.</p> <ul> <li>Less is better</li> </ul>"},{"location":"5-semester/SOE/exam/06-rup/#up-best-practices","title":"UP Best Practices","text":"<ol> <li> <p>Udvikl ved brug af timeboxed iterations</p> <ul> <li>Anbefalet mellem 2 og 6 uger</li> </ul> <p>Start udvikling tidligt</p> </li> <li> <p>Understreg programmering af high-risk, high-value elementer og sammenh\u00e6ngende arkitektur i tidlige iterationer</p> <p>Re-use eksisterende komponenter</p> </li> <li> <p>Kontinuerligt verificer kvalitet.</p> <p>Test tidligt, ofte og realistisk</p> <p>TDD og Continous Integration</p> </li> <li> <p>Lav en lille smule visuel modelling f\u00f8r start programmering af iteration.</p> </li> <li>Manage requirements <ul> <li>Find og refiner requirements iterativt og inkrementielt</li> </ul> </li> <li>Manage Change gennem disciplinerede configuration management og versions-kontrol</li> </ol>"},{"location":"5-semester/SOE/exam/06-rup/#typiske-pitfalls-ved-rup","title":"Typiske Pitfalls ved RUP","text":"<p>RUP er ikke waterfall.</p> <ul> <li>De forskellige faser er et mix af disciplinerne</li> </ul> <p>RUP iterationer b\u00f8r ikke v\u00e6re l\u00e6ngere end 6 uger.</p> <ul> <li>Hvis m\u00e5l ikke kan opn\u00e5s, flyttes eller simplificeres m\u00e5l.</li> </ul>"},{"location":"5-semester/SOE/exam/06-rup/#scrum-og-xp-med-rup","title":"Scrum og XP med RUP","text":""},{"location":"5-semester/SOE/exam/06-rup/#scrum","title":"Scrum","text":"<p>Scrum practices er consistent med UP practices.</p> <ul> <li>Projekt manager fungere som Scrum Master</li> <li>Sprint Backlog svarer til UP artifact; Iteration Plan</li> </ul> <p>UP er mere defineret end Scrum i dets processer</p>"},{"location":"5-semester/SOE/exam/06-rup/#xp","title":"XP","text":"<p>Fleste XP practices er consistent med UP practices</p> <ul> <li>TDD er specialisering af UP quality; continously verifying quality</li> <li>Alle UP workprodukts er optional<ul> <li>Passer med XPs \"minimal modeling and documentation\"</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/07-requirements/","title":"Requirements Elicitation and Managing change to requirements","text":""},{"location":"5-semester/SOE/exam/07-requirements/#requirement-elicitation","title":"Requirement Elicitation","text":"<p>Er sv\u00e6rt da:</p> <ul> <li>Stakeholders ved ikke hvad de vil have</li> <li>Stakeholders bruger deres eget sprog og implicit viden</li> <li>Forskellige stakeholders med diverse eller modstridende requirements</li> <li>Politik</li> <li>\u00d8konomisk og business milj\u00f8 er dynamisk</li> </ul> <p></p>"},{"location":"5-semester/SOE/exam/07-requirements/#teknikker","title":"Teknikker","text":"<p>Interview</p> <ul> <li>Lukkede interviews<ul> <li>Predefinerede sp\u00f8rgsm\u00e5l</li> </ul> </li> <li>\u00c5bne intervies<ul> <li>Ingen predefieret agenda</li> </ul> </li> </ul> <p>Observation / Ethnography</p> <ul> <li>Se folk g\u00f8re deres arbejde<ul> <li>Se hvordan arbejdet virkeligt udf\u00f8res</li> <li>Requirements gennem samarbejde og awareness</li> <li>Forst\u00e5 eksisterende systemer</li> </ul> </li> </ul> <p></p> <p>Stories og Scenarier</p> <p>Nemmere at relatere real-life eksempler end abstrakte beskrivelser</p>"},{"location":"5-semester/SOE/exam/07-requirements/#requirements-ndringer","title":"Requirements \u00c6ndringer","text":"<p>I Waterfall bliver \u00e6ndringer approved af en project manager eller en styringsgruppe</p> <ul> <li>Dog ofte ikke gjort i waterfall</li> </ul> <p>I agilt kan kun Product owner approve changes ved at opdatere product backlog</p>"},{"location":"5-semester/SOE/exam/07-requirements/#reducer-cost-ved-ndringer","title":"Reducer Cost ved \u00c6ndringer","text":"<p>Change Anticipation</p> <p>Eksempelvis ved brug af prototyper som kan vise key features til kunden</p> <p>Change Tolerance</p> <p>Eksempelvis via inkrementiel udvilking</p>"},{"location":"5-semester/SOE/exam/07-requirements/#prototyper","title":"Prototyper","text":"<p>Kan bruges til at validate fra brugere at del af l\u00f8sningen er \"fit for use\"</p> <ul> <li>Bruges i tidlig fase til at pr\u00f8ve design muligheder eller l\u00e6re mere om problemet</li> <li>Kan give brugere nye ideer til requirements</li> </ul>"},{"location":"5-semester/SOE/exam/07-requirements/#configuration-management","title":"Configuration Management","text":"<p>Faktorer ved \u00e6ndringer i systemet</p> <ul> <li>Konsekvens ved ikke at lave \u00e6ndring<ul> <li>Hvis \u00e6ndring er associeret med system fejl, skal seri\u00f8siteten af fejlen vurderes.</li> </ul> </li> <li>Fordele ved \u00e6ndringen<ul> <li>Vil det v\u00e6re til fordel fore mange brugere eller kun enkelte?</li> </ul> </li> <li>Antal brugerer p\u00e5virket af \u00e6ndringen<ul> <li>Hvis kun f\u00e5 brugere bliver affected er det m\u00e5ske lav prioritet</li> </ul> </li> <li>Cost ved at lave \u00e6ndringen<ul> <li>Hvis \u00e6ndringen p\u00e5virker mange system komponenter, og derfor st\u00f8rre chance for nye bugs</li> <li>Eller \u00e6ndringen tager lang lang tid</li> </ul> </li> <li>Product release cycle<ul> <li>Er der lige udgivet nyt release er det m\u00e5ske bedre at vente til n\u00e6\u00e6ste release</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/07-requirements/#version-management","title":"Version Management","text":"<p>Eksempelvis vha. Git</p> <ul> <li>Version and release identification<ul> <li>Managed versioner assignes identifiers n\u00e5r de submittes til systemet</li> </ul> </li> <li>Storage Management<ul> <li>VM holder delta'er (list of diferences) for at reduce storage</li> </ul> </li> <li>Change history<ul> <li>Alle \u00e6ndringer i systemet er recorded og listed</li> </ul> </li> <li>Independant developement<ul> <li>VM lader udviklere arbejde p\u00e5 samme komponent p\u00e5 samme tid.</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/","title":"Quality Control: Verification and Validation","text":"<p>Kvalitet kan deles ind i 3 kategorier</p> <ul> <li>Produkt kvalitet</li> <li>Process kvalitet</li> <li>Forventingskvalitet</li> </ul> <p>D\u00e5rlig kvalitet kan koste</p> <ul> <li>Tab</li> <li>Spildt arbejde</li> <li>Vedligeholdelse er ofte dyrere end udvikling</li> </ul> <p></p>"},{"location":"5-semester/SOE/exam/08-quality-control/#quality-management","title":"Quality Management","text":"<ul> <li>Quality Assurance<ul> <li>Planl\u00e6gge eller designe processer for at undg\u00e5 d\u00e5rlig kvalitet</li> </ul> </li> <li>Quality Control<ul> <li>Det at overv\u00e5ge at work products overholder kvalitetsstandarder</li> </ul> </li> </ul> <ul> <li> <p>Lav quality management er billigt i starten, men bliver dyrerer og dyrerer</p> </li> <li> <p>H\u00f8j quality management har initial cost, men bliver billigere senere fordi der sker f\u00e6rre fejl, og koden er mere stabil</p> </li> <li> <p>Det handler om at finde en balance</p> </li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/#validation-and-verification","title":"Validation and Verification","text":"<p>Validation</p> <ul> <li>Bygger vi de rigtige systemer?</li> <li>Overholder kundens forventninger og erfaringer</li> </ul> <p>Verifikation</p> <ul> <li>Bygger vi systemet ordenligt?</li> <li>Overholder specifikationer</li> <li>Objektiv process</li> <li>Tjekker om softwaren er af h\u00f8j kvalitet, men ikke om det er brugbart</li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/#teknikker","title":"Teknikker","text":"<ul> <li>Testing af programmer og prototyper</li> <li>Reviewing af specifikationer, dokumentation og programmer</li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/#inspection","title":"Inspection","text":"<p>Verifikation, tjekker om specifikationerne overholdes, men ikke med kunden.</p> <p>Tjekker ikke ikke-funktionelle karaktaristika s\u00e5som reliability og maintainability.</p> <p>Menneske-baseret tjek af dokumenter og filer s\u00e5som kode.</p> <ul> <li>Ikke eksekvering af kode</li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/#testing","title":"Testing","text":"<p>Validation, da vi tester produktet eller prototyper.</p> <p>Eksekvering af kode.</p>"},{"location":"5-semester/SOE/exam/08-quality-control/#peer-review","title":"Peer Review","text":"<p>Software review, work product unders\u00f8ges af skaber, samt en eller flere kollegaer.</p> <ul> <li>Evaluerer teknisk indhold og kvalitet.</li> </ul>"},{"location":"5-semester/SOE/exam/08-quality-control/#v-modellen","title":"V-Modellen","text":""},{"location":"5-semester/SOE/exam/09-risk-management/","title":"Risk Management","text":"<p>Risk - Risiko</p> <ul> <li>En mulig konsekvens af en beslutning</li> </ul> <p>Noget der er sikker p\u00e5 at ske er ikke en risiko</p>"},{"location":"5-semester/SOE/exam/09-risk-management/#risk-strategies","title":"Risk Strategies","text":"<p>Reaktive Risk Strategi</p> <p>Overv\u00e5ger i bedste fald projektet for mulige risici.</p> <ul> <li>Resourcer s\u00e6ttes til side for at h\u00e5ndtere dem hvis de bliver problemer</li> </ul> <p>Oftes sker der ikke noget f\u00f8r noget g\u00e5r galt.</p> <ul> <li>fire fighting mode</li> </ul> <p>Proaktiv Risk Strategi</p> <p>Mere inteligent end reaktiv</p> <p>Her starter man f\u00f8r det tekniske arbejde g\u00e5r igang.</p> <ul> <li>Potentielle risici identificeres</li> <li>Deres sandsynlighed og impact vurdereres</li> <li>De rangeres efter vigtighed</li> </ul>"},{"location":"5-semester/SOE/exam/09-risk-management/#risici-i-software","title":"Risici i Software","text":"<p>Risk involverere to faktorer</p> <ul> <li>Uncertainty</li> <li>Loss</li> </ul> <p>Deles op i kategorier</p> <ul> <li>Project Risks<ul> <li>Truer projekt planen<ul> <li>stigning i cost</li> </ul> </li> <li>budget, tidsplan, personale, ressource, stakeholder, og requirement problemer</li> </ul> </li> <li>Technical Risks<ul> <li>Truer kvalitet og aktualitet af softwaren</li> <li>design, implementering, interface, verifikation, og vedligholdelses problemer</li> </ul> </li> <li>Business Risks<ul> <li>Market<ul> <li>Bygge et produkt som ingen vil have</li> </ul> </li> <li>Strategic<ul> <li>Bygge et produkt der ikke passer in i business strategi</li> </ul> </li> <li>Sales<ul> <li>Bygge et produkt som ikke kan s\u00e6lges af s\u00e6lgerne</li> </ul> </li> <li>Management<ul> <li>Miste support fra senior management pga. fokusskifte eller menneske forandringer</li> </ul> </li> <li>Budget<ul> <li>Miste budget eller personale engagement</li> </ul> </li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/09-risk-management/#risk-analysis","title":"Risk Analysis","text":"<p>Risk exposure = probability * loss</p> <p>Risici prioritetes efter exposure, herefter etableres en cut-line.</p> <ul> <li>Alle risks under cut-lines reevalueres</li> </ul> <p>For hver risk over cut-line: RMMM: Risk Mitigation Monitoring Management</p> <ul> <li>Mitigation<ul> <li>Hvordan kan vi undg\u00e5 at en risk sker?</li> </ul> </li> <li>Managemen<ul> <li>Hvad g\u00f8r vi hvis det sker alligevel?</li> </ul> </li> <li>Monitoring<ul> <li>Hvordan overv\u00e5ger vi udviklingen af risicien?</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/10-project-planning-management/","title":"Project Planning and Management","text":""},{"location":"5-semester/SOE/exam/10-project-planning-management/#plan-driven-development","title":"Plan-driven Development","text":"<p>Udviklingsprocessen er planlagt i detaljer inden teknisk arbejde startes.</p> <p>Managers kan bruge planen til at underst\u00f8tte projekt decision making, og til at m\u00e5le progress</p>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#project-planning","title":"Project Planning","text":"<ul> <li>Opdele arbjedet i dele</li> <li>Tildele dem til project team members</li> <li>Forudse problemer der m\u00e5ske opst\u00e5r</li> <li>Forberede forel\u00f8bige l\u00f8sninger til disse problemer</li> </ul> <p>En plan indeholder normalt:</p> <ul> <li>Introduktion</li> <li>Organization<ul> <li>Bekriver organizationen af devteam</li> </ul> </li> <li>Risk analysis</li> <li>Hardware / Software resource requirements</li> <li>Work Breakdown<ul> <li>Opdeling af arbejde into aktiviteter og identificering af milestones</li> </ul> </li> <li>Project Schedule<ul> <li>Dependency between activities, estimated time for hver milestone</li> </ul> </li> <li>Monitoring and reporting mechanisms</li> </ul>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#fordele-og-ulemper","title":"Fordele og Ulemper","text":"<p>Fordele</p> <ul> <li>Kan tage h\u00e5nd om organizational issues.</li> <li>Potentielle problemer og dependancies opdages f\u00f8r start</li> </ul> <p>Ulemper</p> <ul> <li>Mange beslutninger skal laves om pga. \u00e6ndringer i milj\u00f8 hvori softwaren udvikles og skal bruges</li> </ul>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#maling-af-progress","title":"M\u00e5ling af Progress","text":"<p>M\u00e5les vha. Milestones og relateret dokumentation</p>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#process","title":"Process","text":""},{"location":"5-semester/SOE/exam/10-project-planning-management/#agile-planning","title":"Agile Planning","text":""},{"location":"5-semester/SOE/exam/10-project-planning-management/#xp-story-based-estimation-and-planning","title":"XP: Story-based Estimation and Planning","text":"<p>Planning game, baseret p\u00e5 user stories der reflekterer features der burde v\u00e6re inkluderet i systemet.</p> <p>Projekt team l\u00e6ser og diskuterer stories og rangerer dem ifht. hvor lang tid de synes at tage at implementere.</p> <ul> <li>Stories tildeles effort points / story points</li> <li>antallet af story points implemteret pr. dag/sprint m\u00e5les ud fra devteams \"velocity\"</li> </ul> <p></p>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#scrum-planning","title":"Scrum Planning","text":""},{"location":"5-semester/SOE/exam/10-project-planning-management/#estimation","title":"Estimation","text":"<p>Based on a triangular distribution</p>  E=(a+m+b)\\ /\\ 3  <p>Based on a double triangular distribution</p>  E=(a+4m+b)\\ /\\ 6\\\\ SD= (b-a)\\ /\\ 6   E=(a+4m+b)\\ /\\ 6\\\\ SD= (b-a)\\ /\\ 6  <p>where </p> <ul> <li>aa is best-case estimate</li> <li>mm is most likely estimate</li> <li>bb is worst-case estimate</li> </ul>"},{"location":"5-semester/SOE/exam/10-project-planning-management/#cocomo","title":"COCOMO","text":"<p>An empirical model based on project experience.</p> <p>Well-documented, \u2018independent\u2019 model which is not tied to a specific software vendor.</p> <p>Long history from initial version published in 1981 (COCOMO-81) through various instantiations to COCOMO 2.</p> <p>COCOMO 2 takes into account different approaches to software development, reuse, etc. </p> <p></p>"},{"location":"5-semester/SOE/exam/11-quality-management/","title":"Quality Management","text":"<p>\"Quality Management: How is quality defined - agile versus plan driven approaches\"</p> <p>Kvalitet kan deles ind i 3 kategorier</p> <ul> <li>Produkt kvalitet</li> <li>Process kvalitet</li> <li>Forventingskvalitet</li> </ul> <p>D\u00e5rlig kvalitet kan koste</p> <ul> <li> <p>Tab</p> </li> <li> <p>Spildt arbejde</p> </li> <li> <p>Vedligeholdelse er ofte dyrere end udvikling</p> </li> </ul> <p>\u200b    </p>"},{"location":"5-semester/SOE/exam/11-quality-management/#software-qualities","title":"Software Qualities","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#trade-off","title":"Trade-off","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#quality-management_1","title":"Quality Management","text":"<ul> <li>Quality Assurance<ul> <li>Planl\u00e6gge eller designe processer for at undg\u00e5 d\u00e5rlig kvalitet</li> </ul> </li> <li>Quality Control<ul> <li>Det at overv\u00e5ge at work products overholder kvalitetsstandarder</li> </ul> </li> </ul> <ul> <li> <p>Lav quality management er billigt i starten, men bliver dyrerer og dyrerer</p> </li> <li> <p>H\u00f8j quality management har initial cost, men bliver billigere senere fordi der sker f\u00e6rre fejl, og koden er mere stabil</p> </li> <li> <p>Det handler om at finde en balance</p> </li> </ul> <p>\u200b    </p>"},{"location":"5-semester/SOE/exam/11-quality-management/#validation-and-verification","title":"Validation and Verification","text":"<p>Validation</p> <ul> <li>Bygger vi de rigtige systemer?</li> <li>Overholder kundens forventninger og erfaringer</li> </ul> <p>Verifikation</p> <ul> <li>Bygger vi systemet ordenligt?</li> <li>Overholder specifikationer</li> <li>Objektiv process</li> <li>Tjekker om softwaren er af h\u00f8j kvalitet, men ikke om det er brugbart</li> </ul>"},{"location":"5-semester/SOE/exam/11-quality-management/#teknikker","title":"Teknikker","text":"<ul> <li>Testing af programmer og prototyper</li> <li>Reviewing af specifikationer, dokumentation og programmer</li> </ul>"},{"location":"5-semester/SOE/exam/11-quality-management/#inspection","title":"Inspection","text":"<p>Verifikation, tjekker om specifikationerne overholdes, men ikke med kunden.</p> <p>Tjekker ikke ikke-funktionelle karaktaristika s\u00e5som reliability og maintainability.</p> <p>Menneske-baseret tjek af dokumenter og filer s\u00e5som kode.</p> <ul> <li>Ikke eksekvering af kode</li> </ul>"},{"location":"5-semester/SOE/exam/11-quality-management/#testing","title":"Testing","text":"<p>Validation, da vi tester produktet eller prototyper.</p> <p>Eksekvering af kode.</p>"},{"location":"5-semester/SOE/exam/11-quality-management/#peer-review","title":"Peer Review","text":"<p>Software review, work product unders\u00f8ges af skaber, samt en eller flere kollegaer.</p> <ul> <li>Evaluerer teknisk indhold og kvalitet.</li> </ul>"},{"location":"5-semester/SOE/exam/11-quality-management/#v-modellen","title":"V-Modellen","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#test-and-review-in-models","title":"Test and Review in Models","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#waterfall","title":"Waterfall","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#incremental-and-iterative","title":"Incremental and Iterative","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#integration-and-configuration","title":"Integration and Configuration","text":""},{"location":"5-semester/SOE/exam/11-quality-management/#quality-in-agile","title":"Quality in Agile","text":"<ul> <li> <p>Definition of Done</p> <ul> <li>Team agree on what criteria must be met before a task is complete</li> </ul> </li> <li> <p>Sprint Review</p> <ul> <li>Product Owner and other stakeholders validate the sprint delivery meets expectations</li> </ul> </li> <li> <p>Check before check-in</p> <ul> <li>Developers are responsible for organizing their own code reviews with other team members before the code is checked in to the build system</li> </ul> </li> <li> <p>Never break the build</p> <ul> <li> <p>Team members should not check in code that causes the system to fail</p> <p>Developers have to test their code changes against the whole system and be confident that these work as expected</p> </li> </ul> </li> <li> <p>Fix problems when you see them</p> <ul> <li>If a programmer discovers problems or obscurities in code developed by someone else, they can fix these directly rather than referring them back to the original developer</li> </ul> </li> </ul> <p>Pair Programming in XP</p> <ul> <li>Flere programmeringstimer i stedet for procrastinating</li> <li>Stamina og insight i koden hvis en i parret er syg</li> <li>Real-time code review</li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/","title":"Configuration Management","text":"<p>Configuration management har at g\u00f8re med policies, processer, og v\u00e6rkt\u00f8jer til at h\u00e5ndtere skiftende software versioner.</p> <ul> <li>Der kan v\u00e6re flere versioner under udvikling p\u00e5 samme tid</li> </ul> <p>Essentielt for teams der arbejder p\u00e5 samme tid p\u00e5 koden.</p> <p>Configuration Management policies og processes definerer hvordan forsl\u00e5ede system \u00e6ndringer skal processeres og recordes.</p>"},{"location":"5-semester/SOE/exam/12-configuration-management/#key-activities","title":"Key Activities","text":"<ul> <li>Change Management<ul> <li>Hold styr p\u00e5 foresl\u00e5ede \u00e6ndringer i software fra udviklere og kunder.</li> <li>Udregn cost og impact ved \u00e6ndringer</li> </ul> </li> <li>Version Management<ul> <li>Holde styr p\u00e5 de forskellige versioner af system komponenter</li> <li>Sikre sig at \u00e6ndringer ikke interfere med hinanden</li> </ul> </li> <li>System Building<ul> <li>Samle program komponenter, data og libraries.</li> <li>Compile og linke disse for at lave et eksekverbart system</li> </ul> </li> <li>Release Management<ul> <li>G\u00f8re software klar til ekstern release</li> <li>Holde styr p\u00e5 de versioner der er released til kunder.</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/#challenges","title":"Challenges","text":"<p>To personer vil \u00e6ndre i den samme fil.</p> <ul> <li>Pessimistisk file locking<ul> <li>Filen kan kun \u00e5bnes af en person af gangen</li> <li>Ikke optimalt</li> </ul> </li> <li>Optimisisk version merging (Git)<ul> <li>VM holder styr p\u00e5 de \u00e6ndringer der er lavet i filen fra hver bruger.</li> <li>VM kan herefter merge \u00e6ndringer sammen.</li> </ul> </li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/#centraliseret-vs-distribueret-vc","title":"Centraliseret vs Distribueret VC","text":"<p>Centraliseret</p> <ul> <li>Et single master repository holder styr p\u00e5 alle versioner der er under udvilking</li> <li>Subversion (SVN)</li> </ul> <p>Decentraliseret</p> <ul> <li>Flere versioner af repository eksistere p\u00e5 samme tid.</li> <li>Git</li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/#release","title":"Release","text":"<p>Best\u00e5r af:</p> <ul> <li>Eksekverbar kode</li> <li>Konfigurationsfiler</li> <li>Data filer</li> <li>Installer</li> <li>Elektronisk eller papir dokumentation</li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/#continous-integration-agile","title":"Continous Integration (Agile)","text":"<ol> <li>Check out mainline fra VM into udviklers workspace</li> <li>Byg systemet og k\u00f8r automatiske tests<ul> <li>Hvis ikke test passer skal sidste \"committer\" advares</li> </ul> </li> <li>Lav \u00e6ndringer</li> <li>Byg systemet i lokalt workspace</li> <li>N\u00e5r tests er passed, check into build sistem</li> <li>Byg system p\u00e5 build server og k\u00f8r tests</li> <li>Hvis tests passer, commit til ny mainline</li> </ol>"},{"location":"5-semester/SOE/exam/12-configuration-management/#daily-build","title":"Daily Build","text":"<p>Development organization s\u00e6tter en delivery time.</p> <ul> <li>En ny version bygges ud fra leverede komponenter</li> <li>Version udleveres til test team som k\u00f8rer predefinerede tests</li> <li>Fejl fundet under tests dokumenteres og returneres til udviklere, som reparerer disse fejl</li> </ul>"},{"location":"5-semester/SOE/exam/12-configuration-management/#plandriven-vs-agile-cm","title":"Plandriven vs Agile CM","text":""},{"location":"6-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>DBS - Database Systems</li> <li>AALG - Advanced Algorithms</li> </ul> <p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=33030</p> <p></p>"},{"location":"6-semester/AALG/","title":"AALG - Advanced Algorithms","text":"<p>Moodle page:</p> <p>https://www.moodle.aau.dk/course/view.php?id=33044</p> <p></p>"},{"location":"6-semester/AALG/#topics","title":"Topics","text":""},{"location":"6-semester/AALG/#lecture-1","title":"Lecture 1","text":"<ul> <li>Principles of DP<ul> <li>Overlapping sub-problems</li> <li>Optimal sub-structure</li> <li>Top-down with memoization</li> <li>Bottom-up</li> </ul> </li> <li>Examples<ul> <li>Activity Selection</li> <li>Edit Distance</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/01-dc/","title":"Dynamic Programming","text":"\\newcommand{\\dr}[1]{{\\color{darkred}#1}}\\nonumber  <p>Intended Learning Outcome</p> <ul> <li>To understand the principles of dynamic programming.<ul> <li>Overlapping sub-problems and optimal sub-structure. </li> <li>Top-down with memoization and bottom-up. </li> </ul> </li> <li>To understand the DP algorithm for edit distance.</li> <li>To be able to apply the DP algorithm design technique. </li> </ul>"},{"location":"6-semester/AALG/01-dc/#dynamic-programming_1","title":"Dynamic Programming","text":"<ul> <li>A powerful technique to solve optimization problems.</li> <li>An optimization problem can have many possible solutions, each solution has a value, and we wish to find a solution with the optimal (i.e., minimum or maximum) value. </li> <li>An algorithm should compute the optimal value plus, if needed, an optimal solution.</li> </ul>"},{"location":"6-semester/AALG/01-dc/#two-key-characteristics-of-dp","title":"Two Key Characteristics of DP","text":"<p>Overlapping sub-problems</p> <ul> <li>Sub-problems share sub-sub-problems.</li> <li>A divide-and-conquer algorithm does more work than necessary, as it needs to repeatedly solve the common sub-sub-problems. </li> </ul> <p>Optimal Substructure</p> <ul> <li>The optimal solution to a problem incorporates optimal solutions to sub-problems. </li> <li>Un-weighted shortest path (YES)<ul> <li>Shortest path A=&lt;q,r,t&gt;A=&lt;q,r,t&gt;  from q to t.</li> <li>Sub-paths of A, &lt;q,r&gt;A, &lt;q,r&gt; and &lt;r,t&gt;&lt;r,t&gt;, are also the shortest path</li> </ul> </li> <li>Un-weighted longest simple path. (NO)<ul> <li>Longest path B =&lt;q,r,t&gt;B =&lt;q,r,t&gt;  from q to t.</li> <li>Sub-paths of B, &lt;q,r&gt;B, &lt;q,r&gt; and &lt;r,t&gt;&lt;r,t&gt; may not be the longest paths </li> </ul> </li> </ul> <p></p> <ul> <li>&lt;q,s,t,r&gt;&lt;q,s,t,r&gt;</li> <li>&lt;r,q,s,t&gt;&lt;r,q,s,t&gt;</li> </ul>"},{"location":"6-semester/AALG/01-dc/#two-approaches-of-dp","title":"Two approaches of DP","text":"<p>Top-down with memoization</p> <ul> <li>Solve each sub-problem only once and store the answers to the solved sub-problems in a table.</li> <li>Next time, when you need to solve a solved sub-problem, just look up the table to get the answer. </li> </ul> <p>Bottom-up with recursion</p> <ul> <li> <p>Depending on some natural notion on the size of a sub-problem. </p> </li> <li> <p>Solving any particular sub-problem depends only on solving smaller sub-problems. </p> </li> <li>Sort the sub-problems by size and solve them in size order, smallest first. And save the solutions.</li> </ul> <p>Pros and Cons</p> <ul> <li>Both should have the same asymptotic running time.</li> <li>If all sub-problems must be solved, memoization (recursion) is usually slower (by a constant factor) than Bottom-up (loops). </li> <li>If not all sub-problems need to be solved, memoization only solves the necessary ones. </li> </ul>"},{"location":"6-semester/AALG/01-dc/#structure-of-dp","title":"Structure of DP","text":"<p>Construction</p> <p>Recurrence for the optimal value</p> <ul> <li> <p>What are the sub-problems? </p> </li> <li> <p>Which choices have to be considered in order to solve a sub-problem?</p> </li> <li> <p>How are the trivial sub-problems solved? </p> </li> <li> <p>Write a memoized version of the algorithm or in which order do we have to solve the sub-problems (bottom-up)</p> <p>Constructing a solution</p> </li> <li> <p>Remember the (optimal) choices made </p> </li> <li> <p>Use the remembered choices to construct a solution</p> </li> </ul> <p>Analysis</p> <ul> <li>How many different sub-problems are there in total? </li> <li>How many choices have to be considered when solving each subproblem? </li> </ul>"},{"location":"6-semester/AALG/01-dc/#edit-distance-problem","title":"Edit Distance Problem","text":"<p>Definition</p> <ul> <li>Two strings s[1..m]s[1..m] and t[1..n]t[1..n]</li> <li>Find edit distance dist(s,t)dist(s,t) between the two input strings s and t.<ul> <li>The smallest number of edit operations that turns s into t</li> </ul> </li> <li>Edit operations:<ul> <li>Replace one letter with another</li> <li>Delete one letter</li> <li>Insert one letter</li> </ul> </li> </ul> <p>Example</p> <ul> <li>\"ghost\" into \"house\"</li> </ul> <pre><code>ghost   -   delete g\nhost    -   insert u\nhoust   -   replace t by e\nhouse\n</code></pre>"},{"location":"6-semester/AALG/01-dc/#two-cases","title":"Two Cases","text":"<p>The last letters in s and t are different, e.g., s=milk t=windy </p> <ul> <li>Option 1: Replace k by y, dist(s, t)=dist(mil, wind)+1dist(s, t)=dist(mil, wind)+1</li> <li>Option 2: Delete k, dist(s, t) = dist(mil, windy)+1dist(s, t) = dist(mil, windy)+1</li> <li>Option 3: Insert y in the end of s, dist(s, t) = dist(milk, wind)+1dist(s, t) = dist(milk, wind)+1</li> <li>dist(s, t) = min (dist(mil, wind)+1, dist(mil, windy)+1, dist(milk, wind)+1)dist(s, t) = min (dist(mil, wind)+1, dist(mil, windy)+1, dist(milk, wind)+1)</li> </ul> <p>The last letters in s and t are the same, e.g., s=milk t=link</p> <ul> <li>Option 1: Keep k, dist(s, t)=dist(mil, lin)dist(s, t)=dist(mil, lin)</li> <li>Option 2: Delete k, dist(s, t) = dist(mil, link)+1dist(s, t) = dist(mil, link)+1</li> <li>Option 3: Insert k in the end, dist(s, t) = dist(milk, lin)+1dist(s, t) = dist(milk, lin)+1</li> <li>dist(s, t) = min (dist(mil, lin), dist(mil, link)+1, dist(milk, lin)+1)dist(s, t) = min (dist(mil, lin), dist(mil, link)+1, dist(milk, lin)+1)</li> </ul> <p>Optimal sub-structure for edit distance?</p> <ul> <li>YES! The optimal solution to a problem incorporates optimal solutions to sub-problems</li> </ul>"},{"location":"6-semester/AALG/01-dc/#sub-problems","title":"Sub-problems","text":"<p>d_{i,j} = dist (s [1..i ], t [1..j ])d_{i,j} = dist (s [1..i ], t [1..j ])</p> <ul> <li>then dist(s,t)=d_{m,n}dist(s,t)=d_{m,n}</li> </ul> <p>Let\u2019s look at the last symbol: s [i ]s [i ] and t [j ]t [j ]. There are three options, do whatever is the cheapest:</p> <ul> <li>Option 1<ul> <li>If s [i ] = t [j ]s [i ] = t [j ], then turn s [1..i-1]s [1..i-1] to t [1..j-1]t [1..j-1] <ul> <li>milk,link:d_{i,j}=d_{i-1,j-1}milk,link:d_{i,j}=d_{i-1,j-1}</li> </ul> </li> <li>Else replace s[i]s[i] by t[j]t[j] and turn s[1..i-1]s[1..i-1] to t[1..j-1]t[1..j-1]<ul> <li>milk,windy; {\\color{darkred}{mil}}y, {\\color{darkred}{wind}}y:d_{i,j}=1+d_{i-1,j-1}milk,windy; {\\color{darkred}{mil}}y, {\\color{darkred}{wind}}y:d_{i,j}=1+d_{i-1,j-1}</li> </ul> </li> </ul> </li> <li>Option 2 - Delete<ul> <li>Delete s[i]s[i] and turn s[1..i-1]s[1..i-1] into t[1..j]t[1..j]<ul> <li>milk, windy; {\\color{darkred} mil}, {\\color{darkred}windy}: d_{i,j}=1+d_{i-1,j}milk, windy; {\\color{darkred} mil}, {\\color{darkred}windy}: d_{i,j}=1+d_{i-1,j}</li> </ul> </li> </ul> </li> <li>Option 3 - Insert<ul> <li>Insert t[j]t[j] at the end of s[1..i]s[1..i] and turn s[1..i]s[1..i] to t[1..j-1]t[1..j-1]<ul> <li>milk, windy; \\dr{milk}y, \\dr{wind}y: d_{i,j}=1+d_{i,j-1}milk, windy; \\dr{milk}y, \\dr{wind}y: d_{i,j}=1+d_{i,j-1}</li> </ul> </li> </ul> </li> </ul>"},{"location":"6-semester/AALG/01-dc/#recurrence-optimal-substructure","title":"Recurrence, Optimal Substructure","text":"<p>How do we solve trivial sub-problems?</p> <ul> <li>To turn empty string to t [1..j ]t [1..j ], do jj inserts</li> <li>To turn s [1..i ]s [1..i ] to empty string, do ii deletes</li> </ul>"},{"location":"6-semester/AALG/01-dc/#dp-algorithm-memoization","title":"DP Algorithm - Memoization","text":""},{"location":"6-semester/AALG/01-dc/#analysis","title":"Analysis","text":"<ul> <li>How many different sub-problems are there in total?<ul> <li>n*mn*m</li> </ul> </li> <li>How many choices have to be considered when solving each subproblem?<ul> <li>3 (copy/replace, insert, and delete)</li> </ul> </li> <li>Thus, \u0398(nm)</li> </ul> <p>If we solve editor distance in a na\u00efve D&amp;C manner, what is the complexity?</p> <ul> <li>Exponential runtime.</li> </ul>"},{"location":"6-semester/AALG/01-dc/#dp-algorithm-bottom-up","title":"DP Algorithm - Bottom-up","text":""},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/","title":"All-pairs Shortest Paths (Dynamic Programming)","text":"<p>Intended Learning Outcome</p> <ul> <li>Adjacency matrix and distance/predecessor matrix</li> <li>Repeated squaring and Floyd-Warshall algorithm</li> <li>Definition of transitive closure of a directed graph</li> </ul>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#all-pairs-shortest-paths","title":"All-pairs Shortest Paths","text":"<p>Shortest paths between all pairs of vertices in a graph. </p> <p>How to solve the problem efficiently?</p> <ul> <li>Repeatedly run one-to-all shortest paths |V| times.</li> <li>Repeated squaring algorithm</li> <li>Floyd-Warshall algorithm</li> </ul>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#representing-a-graph","title":"Representing a Graph","text":"<p>Graph G=(V,E,W)</p> <p>Adjacency list vs Adjacency matrix</p> <p></p>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#adjacency-list","title":"Adjacency List","text":"<p>Total space: \\Theta(|V|+|E|)\\Theta(|V|+|E|)</p>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#adjacency-matrix","title":"Adjacency Matrix","text":""},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#one-to-all-shortest-path","title":"One-to-All Shortest Path","text":"<p>Input</p> <ul> <li>Directed, weighted graph G=(V,E,W)G=(V,E,W)</li> <li>Source vertex s</li> </ul> <p>Shortest-path weight</p>  \\delta(u,v)= \\left\\{ \\begin{array}{}  \\min\\{w(p):u\\overset{p}{\\leadsto} v\\} &amp; \\mbox{if there is a path from }u\\mbox{ to }v,\\\\  \\infty &amp; \\mbox{otherwise}. \\end{array} \\right.   \\delta(u,v)= \\left\\{ \\begin{array}{}  \\min\\{w(p):u\\overset{p}{\\leadsto} v\\} &amp; \\mbox{if there is a path from }u\\mbox{ to }v,\\\\  \\infty &amp; \\mbox{otherwise}. \\end{array} \\right.  <p>Output</p> <ul> <li>A set of vertices S, |S|=|V|S, |S|=|V|<ul> <li>Each u\\in S: u.d()u\\in S: u.d() and u.parent()u.parent()</li> <li>Not reachable: u.d()=\\inftyu.d()=\\infty</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#relaxing-technique","title":"Relaxing Technique","text":"<p>Relaxing an edge (u,v)(u,v)</p> <ul> <li>u.d() + w(u,v)u.d() + w(u,v) vs v.d()v.d()</li> </ul> <p></p> <p>Intuition</p> <ul> <li>Improve the existing shortest path from ss to vv</li> </ul> <p></p>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#dijkstras-algorithm","title":"Dijkstra's Algorithm","text":"<p>Complexity depends on how to implement the min-priority queue</p> <ul> <li>binary min-heap</li> </ul> <p></p>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#bellman-ford","title":"Bellman-Ford","text":""},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#all-pairs-shortest-path","title":"All-pairs Shortest Path","text":"<p>Input</p> <ul> <li> <p>Let n=|V|n=|V|</p> </li> <li> <p>Adjacency matrix W \\in R^{n\\times n}W \\in R^{n\\times n} where</p> <ul> <li>w_{ij}=0w_{ij}=0 if i=ji=j</li> <li>w_{ij}&gt;0w_{ij}&gt;0 if i\\neq ji\\neq j and edge (i,j)\\in E(i,j)\\in E</li> <li>w_{ij}= \\inftyw_{ij}= \\infty if i\\neq ji\\neq j and edge (i,j) \\notin E(i,j) \\notin E</li> </ul> </li> </ul> <p>Output</p> <ul> <li>Distance matrix D \\in R^{n\\times n}D \\in R^{n\\times n} where<ul> <li>d_{ij}= \\delta(i,j)d_{ij}= \\delta(i,j): the shortest path weight from vertex ii to vertex jj</li> </ul> </li> <li>Predecessor matrix P\\in R ^{n\\times n}P\\in R ^{n\\times n} where<ul> <li>ii-th row == shortest-path tree rooted at vertex ii<ul> <li>One-to-all shortest paths</li> </ul> </li> <li>p_{ij}=Nilp_{ij}=Nil if<ul> <li>i=ji=j or</li> <li>no path from vertex ii to jj</li> </ul> </li> <li>p_{ij}=j.parent()p_{ij}=j.parent()<ul> <li>Vertex jj's parent on the shortest path from vertex ii to vertex jj</li> </ul> </li> </ul> </li> </ul>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#base-case","title":"Base Case","text":"<p>l^{(m)}_{ij}:l^{(m)}_{ij}:</p> <ul> <li>the minimum weight of any path from vertex ii to vertex jj that contains at most \\mathbf m\\mathbf m edges</li> </ul> <p>Matrices L^{(m)}=\\left(l^{(m)}_{ij}\\right)\\in R^{n\\times n},\\quad m\\in [0,n-1]L^{(m)}=\\left(l^{(m)}_{ij}\\right)\\in R^{n\\times n},\\quad m\\in [0,n-1], where n=|V|n=|V|</p> <p>m=0m=0</p> <p></p> <p>m=1m=1</p> <p></p>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#recursive-case","title":"Recursive Case","text":"<p>m\\geq 1m\\geq 1</p> <p></p> <p>Intuition of obtaining l^{(m)}_{ij}l^{(m)}_{ij}</p> <ul> <li>l^{(m-1)}_{ik}l^{(m-1)}_{ik} shortest path weight from ii to kk using at most m-1m-1 edges</li> <li>Extend the shortest path i \\leadsto ki \\leadsto k with one more edge (k,j)(k,j)<ul> <li>l^{(m-1)}_{ik}+w_{kj}l^{(m-1)}_{ik}+w_{kj}</li> <li>1 \\leq k \\leq n1 \\leq k \\leq n</li> </ul> </li> <li>l^{(m)}_{ij}l^{(m)}_{ij} = get minimum = shortest path weight from ii to jj</li> </ul>"},{"location":"6-semester/AALG/02-dp-all-pairs-shortest-paths/#distance-matrix","title":"Distance Matrix","text":"<p>Matrices L^{(m)}=\\left(l^{(m)}_{ij}\\right)\\in R^{n\\times n},\\quad m\\in [0,n-1]L^{(m)}=\\left(l^{(m)}_{ij}\\right)\\in R^{n\\times n},\\quad m\\in [0,n-1], where n=|V|n=|V|</p> <p>Final distance matrix L^{(n-1)}_{ij}L^{(n-1)}_{ij}</p> <ul> <li>Path p=&lt;v_i,v_i+1,\\dots,v_j&gt;p=&lt;v_i,v_i+1,\\dots,v_j&gt;</li> <li>Simple: distinct vertices on the path</li> <li>At most n-1n-1 edges</li> </ul> <p>Shortest path weights</p>  \\delta(i,j)=L^{(n-1)}_{ij}=L^{(n)}_{ij}=L^{(n+1)}_{ij}=\\cdots   \\delta(i,j)=L^{(n-1)}_{ij}=L^{(n)}_{ij}=L^{(n+1)}_{ij}=\\cdots"},{"location":"6-semester/AALG/03-flow-networks/","title":"Flow Networks and Maximum Flow","text":"<p>Intended Learning Outcome</p> <ul> <li>to understand the formalization of flow networks and flows;<ul> <li>and the definition of the maximum-flow problem. </li> </ul> </li> <li>to understand the Ford-Fulkerson method for finding maximum flows. </li> <li>to understand the Edmonds-Karp algorithm and to be able to analyze its worst-case running time;</li> <li>to be able to apply the Ford-Fulkerson method to solve the maximum-bipartite-matching problem.</li> </ul>"},{"location":"6-semester/AALG/03-flow-networks/#flow-network","title":"Flow Network","text":"<p>A flow network G=(V,E) is a directed graph</p> <ul> <li>Each edge (u,v)\\in E(u,v)\\in E has a nonnegative capacity c(u,v)\\geq0c(u,v)\\geq0</li> <li>If (u,v)\\notin E(u,v)\\notin E then c(u,v)=0c(u,v)=0</li> <li>If E contains an edge (u, v), then there is no edge (v, u) in the reverse direction.</li> <li>Two special vertices: a source ss and a sink tt. </li> <li>For any other vertex v, there is a path s\\to v\\to ts\\to v\\to t</li> </ul> <p>A flow in G is a real-valued function f:V\\times V \\to Rf:V\\times V \\to R</p> <p></p> <p>Flow in equals flow out</p>"},{"location":"6-semester/AALG/03-flow-networks/#examples","title":"Examples","text":""},{"location":"6-semester/AALG/03-flow-networks/#maximum-flow-problem","title":"Maximum-flow Problem","text":"<p>Consider the source s</p> <p>The value of flow ff, denoted as |f||f|, is defined as</p>  |f|=\\sum_{v\\in V}f(s,v)-\\sum_{v_\\in V} f(v,s)   |f|=\\sum_{v\\in V}f(s,v)-\\sum_{v_\\in V} f(v,s)  <ul> <li>Total flow out of the source minus the flow into the source.</li> <li>Typically, a flow network will not have any edges into the source, and the flow into the source will be zero. </li> </ul> <p>Maximum-flow problem:</p> <p>Given a flow network G with source s and sink t, we wish to find a flow of maximum value.</p>"},{"location":"6-semester/AALG/03-flow-networks/#anti-parallel-edges","title":"Anti-parallel edges","text":"<p>To simplify the discussion, we do not allow both (u, v) and (v, u) together in the graph.</p> <ul> <li>If E contains an edge (u, v), then there is no edge (v, u) in the reverse direction.</li> </ul> <p>Easy to eliminate such antiparallel edges by introducing artificial vertices.</p> <p></p> <p></p>"},{"location":"6-semester/AALG/03-flow-networks/#multiple-sources-and-multiple-sinks","title":"Multiple sources and multiple sinks","text":"<p>Example: multiple factories and warehouses</p> <p>Introducing a super-source s and super-sink t</p> <ul> <li>Connect s to each of the original source s_is_i and set is capacity to \\infty\\infty</li> <li>Connect t to each of the original sink t_it_i and set its capacity to \\infty\\infty</li> </ul> <p></p>"},{"location":"6-semester/AALG/03-flow-networks/#the-ford-fulkerson-method","title":"The Ford-Fulkerson Method","text":"<p>A method but not an algorithm</p> <ul> <li>It encompasses several implementations with different running times</li> </ul> <p>The Ford-Fulkerson method is based on</p> <ul> <li>Residual Networks</li> <li>Augmenting paths</li> </ul>"},{"location":"6-semester/AALG/03-flow-networks/#residual-networks","title":"Residual Networks","text":"<p>Given a flow network GG and a flow ff, the residual network G_fG_f consists of edges whose residual capacities are greater than 0</p> <ul> <li>Formally: G_f=(V,E_f)G_f=(V,E_f), where E_f=\\{(u,v)\\in V \\times V:c_f(u,v)&gt;0\\}E_f=\\{(u,v)\\in V \\times V:c_f(u,v)&gt;0\\}</li> </ul> <p>Residual capacities:</p> <p></p> <ul> <li>The amount of additional flow that can be allowed on edge (u, v).</li> <li>The amount of flow that can be allowed on edge (v, u), i.e., the amount of flow that can be canceled on the opposite direction of edge (u, v).</li> </ul>"},{"location":"6-semester/AALG/03-flow-networks/#example","title":"Example","text":""},{"location":"6-semester/AALG/03-flow-networks/#augmenting-paths","title":"Augmenting Paths","text":"<p>Given a flow network G and a flow f, an augmenting path pp is a simple path from s to t in the residual network G_fG_f</p> <p></p> <ul> <li>p=&lt;s, v_2, v_3, t&gt;p=&lt;s, v_2, v_3, t&gt;</li> </ul> <p>Residual capacity of an augmenting path pp:</p> <ul> <li>How much additional flow can we send through an augmenting path?</li> <li>c_f(p)=\\min(c_f(u,v):(u,v)c_f(p)=\\min(c_f(u,v):(u,v) is on path p)p)<ul> <li>c_f(p)=\\min(5,4,5)=4c_f(p)=\\min(5,4,5)=4</li> </ul> </li> <li>The edge with the minimum capacity in pp is called critical edge (bottleneck)<ul> <li>(v_2,v_3)(v_2,v_3) is the critical edge of pp</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/03-flow-networks/#augmenting-a-flow","title":"Augmenting a flow","text":"<p>Given an agumenting path pp we define a flow f_pf_p on the residual network G_fG_f</p> <p></p> <ul> <li>the flow value of |f_p|=c_f(p)&gt;0|f_p|=c_f(p)&gt;0</li> </ul> <p></p>"},{"location":"6-semester/AALG/03-flow-networks/#examples_1","title":"Examples","text":""},{"location":"6-semester/AALG/03-flow-networks/#the-method","title":"The Method","text":"<ol> <li>Find an augmenting path in the residual network</li> <li>Augment the existing flow by the flow of the augmenting path</li> <li>Keep doing this until no augmenting path exists in the residual network</li> </ol> <p>The algorithms based on this method differ in how they choose p in line 3</p> <p>Correctness is proved by the Max-flow min-cut theorem</p>"},{"location":"6-semester/AALG/03-flow-networks/#example_1","title":"Example","text":""},{"location":"6-semester/AALG/03-flow-networks/#correctness-of-ford-fulkerson","title":"Correctness of Ford-Fulkerson","text":"<p>Why is this method correct?</p> <p>How do we know that when the method terminates, i.e., when there are no more augmenting paths, we have actually found a maximum flow?</p> <p>Max-flow min-cut theorem</p>"},{"location":"6-semester/AALG/03-flow-networks/#cuts","title":"Cuts","text":""},{"location":"6-semester/AALG/03-flow-networks/#minimum-cut","title":"Minimum Cut","text":""},{"location":"6-semester/AALG/03-flow-networks/#max-flow-min-cut-theorem","title":"Max-flow min-cut theorem","text":"<p>If ff is a flow in GG the follwoing conditions are equivalent:</p> <ol> <li>f is a maximum flow</li> <li>The residual network G_fG_f contains no augmenting paths</li> <li>|f|=c(S,T)|f|=c(S,T) for some cut (S,T)(S,T) of GG</li> </ol> <p>The correctness of Ford-Fulkerson method</p> <ul> <li>2\\to12\\to1</li> <li>We prove 2\\to 32\\to 3 and then 3\\to13\\to1</li> </ul>"},{"location":"6-semester/AALG/03-flow-networks/#2-to-3","title":"2 to 3","text":""},{"location":"6-semester/AALG/03-flow-networks/#3-to-1","title":"3 to 1","text":""},{"location":"6-semester/AALG/03-flow-networks/#worst-case-running-time","title":"Worst-case Running time","text":"<p>Assume integer flows: capacities are integer values</p> <ul> <li>Appropriate scaling transformation can transfer rational numbers to integral numbers</li> </ul> <p>Each augmentation increases the value of the flow by some positive amount</p> <ul> <li>worst case. each time the flow value increases by 1</li> </ul> <p></p> <p>&lt;s,u,v,t&gt;&lt;s,u,v,t&gt;, &lt;s,v,u,t&gt;&lt;s,v,u,t&gt;, &lt;s,u,v,t&gt;&lt;s,u,v,t&gt;, ......</p> <p>Identifying the augmenting path and augmentation can be done in O(E)O(E)</p> <p>Total worst-case running time O(E\\cdot|f^*|)O(E\\cdot|f^*|), where f^*f^* is the max-flow found by the algorithm</p> <p>Lesson learned: how an augmenting path is chosen is very important</p>"},{"location":"6-semester/AALG/03-flow-networks/#the-edmonds-karp-algorithm","title":"The Edmonds-Karp Algorithm","text":"<p>In line 3 of Ford-Fulkerson method, the Edmonds-Karp regards the residual network as an unweighted graph and finds the shortest path as an augmenting path</p> <ul> <li>Finding the shortest path in an un-weighted graph is done by calling breath first search (BFS) from source vertex s.</li> </ul> <p></p> <p>Example on L03 slides 38-42</p>"},{"location":"6-semester/AALG/04-greedy-algorithms/","title":"Greedy Algorithms","text":"<p>We look at the Activity Selection Problem</p>"},{"location":"6-semester/AALG/04-greedy-algorithms/#activity-selection","title":"Activity Selection","text":"<p>Input</p> <ul> <li>A set of n activities, each with start and end times s_is_i and f_if_i<ul> <li>The i-th activity lasts during the period [s_i,f_i)[s_i,f_i)</li> </ul> </li> </ul> <p>Output</p> <ul> <li>The largest subset of mutually compatible activities</li> <li>Activities are compatible if their intervals do not intersect</li> </ul> <p></p>"},{"location":"6-semester/AALG/04-greedy-algorithms/#definitions","title":"Definitions","text":"<ul> <li>Sort activities in A on the end time<ul> <li>We also assume \"sentinel\" activities a_0a_0 and a_{n+1}a_{n+1}</li> </ul> </li> </ul> <ul> <li>S_{i,j}S_{i,j}: a set of activities that start after activity a_ia_i finishes, and that finish before activity a_ja_j starts<ul> <li>S_{2,11}=\\{a_4, a_6, a_7, a_8, a_9\\}S_{2,11}=\\{a_4, a_6, a_7, a_8, a_9\\}<ul> <li>Start after a_2.f=5a_2.f=5 and finish before a_{11}.s=12a_{11}.s=12. Interval [5,12)[5,12)</li> </ul> </li> <li>S_{0,12}=\\{a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,a_{10},a_{11}\\}S_{0,12}=\\{a_1,a_2,a_3,a_4,a_5,a_6,a_7,a_8,a_9,a_{10},a_{11}\\}<ul> <li>Start after a_0.f=-100a_0.f=-100 and finish before a_{12}.s=100a_{12}.s=100. Interval [-100,100)[-100,100)</li> </ul> </li> </ul> </li> <li>M_{i,j}M_{i,j}: a maximum set of mutually compatible activities in S_{i,j}S_{i,j}</li> <li>C_{i,j}C_{i,j}: the cardinality of M{i,j}M{i,j}</li> </ul> <p>Activity Selection: identify C_{0, n+1}C_{0, n+1} (and M_{0,n+1}M_{0,n+1})</p>"},{"location":"6-semester/AALG/04-greedy-algorithms/#greedy-algorithm","title":"Greedy Algorithm","text":""},{"location":"6-semester/AALG/04-greedy-algorithms/#greedy-strategy","title":"Greedy Strategy","text":"<p>What if we only consider \"the best\" (as of now) activity and be sure that it belongs to an optimal solution</p> <ul> <li>Choose the activity that finishes first in S_{i,j}S_{i,j}<ul> <li>Intuition: leave as much time as possible for other activities</li> <li>Then, solve only one sub-problem for the remaining activities</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/04-greedy-algorithms/#greedy-algorithm_1","title":"Greedy Algorithm","text":"<p>MaxN(A,i)MaxN(A,i)</p> <ul> <li>Assume that we have nn activities in total</li> <li>Return the maximum-size set of mutually compatible activities in S_{i,n+1}S_{i,n+1}</li> <li>In the beginning, we call MaxN(A,0)MaxN(A,0) that returns the maximum-size set of mutually compatible activities in S_{0,n+1}S_{0,n+1}</li> </ul> <p></p> <p>The found activity a_ma_m that finishes first must belong to the maximum-size set of mutually compatible activities. </p> <p>Then, we only need to consider activities in S_{m,n+1}S_{m,n+1}.</p>"},{"location":"6-semester/AALG/04-greedy-algorithms/#example","title":"Example","text":"<ul> <li>MaxN(A,0), A[1]MaxN(A,0), A[1] is chosen, so \\{a_1\\}\\{a_1\\}<ul> <li>A[1]A[1] is the activity that finishes first from S_{0,4}S_{0,4}</li> </ul> </li> <li>MaxN(A,1), A[3]MaxN(A,1), A[3] is chosen, so \\{a_1, a_3\\}\\{a_1, a_3\\}<ul> <li>A[3]A[3] is the activity that finishes first from S_{1,4}S_{1,4}</li> </ul> </li> <li>MaxN(A,3)MaxN(A,3), nothing is chosen, so still \\{a_1,a_3\\}\\{a_1,a_3\\}</li> </ul> <p>\\{a_1, a_3\\}\\{a_1, a_3\\} is the maximum-size set of mutually compatible activities</p>"},{"location":"6-semester/AALG/04-greedy-algorithms/#correctness","title":"Correctness","text":"<p>Why the activity that finishes first must be in the maximum-size set of mutually compatible activities</p> <ul> <li> <p>Consider any nonempty sub-problem S_{ij}S_{ij} and let a_xa_x be an activity in S_{ij}S_{ij} with the earliest finish time</p> </li> <li> <p>Let M_{ij}M_{ij} be a maximum-size set of mutually compatible activities in S_{ij}S_{ij}</p> <p>Let a_ya_y be the activity in M_{ij}M_{ij} with the earliest finish time</p> </li> <li> <p>Lucky: if a_x = a_ya_x = a_y we have proved that a_xa_x belongs to a maximum-size set of mutually compatible activities</p> </li> <li> <p>Unlucky: If not, be replacing a_ya_y by a_xa_x, M_{ij}M_{ij} is still a maximum-size set of mutually compatible activities</p> <ul> <li>a_x.f \\leq a_y.fa_x.f \\leq a_y.f</li> </ul> </li> </ul> <p></p> <ul> <li>M_{0,4}=\\{a_2, a_3\\}M_{0,4}=\\{a_2, a_3\\} replacing a_2a_2 with a_1a_1, all activities in \\{a_1,a_3\\}\\{a_1,a_3\\} are still compatible, and thus it is still a maximum-size set</li> </ul>"},{"location":"6-semester/AALG/04-greedy-algorithms/#greedy-exchange","title":"Greedy Exchange","text":"<p>It is a different proof technique compared to contradiction or induction.</p> <p>Greedy exchange is often used in proving the correctness of greedy algorithms.</p> <ul> <li>Assume that we already have an optimal solution that is produced by any other optimal algorithm.<ul> <li>M_{ij}M_{ij} in our previous proof</li> </ul> </li> <li>We show that it is possible to incrementally modify the optimal solution into the solution produced by our greedy algorithm in such a way that does not worsen the solution\u2019s quality.<ul> <li>Replace a_ya_y with a_xa_x, still compatible and with the same cardinality</li> </ul> </li> <li>Thus, the quality of our greedy solution is at least as small as that of any other optimal solution.</li> </ul>"},{"location":"6-semester/AALG/04-greedy-algorithms/#greedy-choice-property","title":"Greedy Choice Property","text":"<p>We can assemble a globally optimal solution by making locally optimal (greedy) choices. </p> <ul> <li>We need to prove that there is always an optimal solution to the original problem that includes the greedy choice, so that the greedy choice is always safe.</li> </ul> <p>The challenge is to choose the right interpretation of \u201cthe best choice\u201d:</p> <ul> <li>How about the activity that starts first?</li> <li>The shortest activity?</li> <li>The activity that overlaps the smallest number of the remaining activities?</li> </ul> <p>The activity that starts first?</p> <p></p> <ul> <li>\\{a_2, a_3\\}\\{a_2, a_3\\}, but not a_1a_1 that starts first.</li> </ul> <p>The shortest activity?</p> <p></p> <ul> <li>\\{a_1, a_2, a_3\\}\\{a_1, a_2, a_3\\}, but not a_4a_4 that is the shortest activity</li> </ul> <p>The activity that overlaps the smallest number of the remaining activities?</p> <p></p> <ul> <li>The second row gives the maximum-size set of mutually compatible activities, but it does not include the activity with the smallest overlaps, i.e., the one with 2</li> </ul>"},{"location":"6-semester/AALG/04-greedy-algorithms/#principles-of-greedy-algorithms","title":"Principles of Greedy Algorithms","text":"<ul> <li>First, we need to show the optimal sub-structure property<ul> <li>Like with DP</li> </ul> </li> <li>The main challenge is to decide the interpretation of \u201cthe best\u201d so that it leads to a global optimal solution, i.e., proving the greedy choice property<ul> <li>Or you find counter-examples demonstrating that your greedy choice does not lead to a global optimal solution.</li> </ul> </li> <li>Greedy exchange is a useful proof technique for proving the greedy choice property.</li> </ul>"},{"location":"6-semester/AALG/05-amortized-analysis/","title":"Amortized Analysis","text":"<p>The Problem Setting</p> <ul> <li>We have a data structure</li> <li>We perform a sequence of operations on the data structure</li> <li>Operations may be of different types (e.g. insertions, deletions)</li> <li>Depending on the state of the structure the actual cost of an operation may differ (e.g. inserting into a sorted array)</li> <li>Just analyzing the worst-case time of a single operation may not say too much</li> <li>We want the amortized running time of an operation</li> </ul>"},{"location":"6-semester/AALG/05-amortized-analysis/#accounting-method","title":"Accounting Method","text":"<p>Charge different operations with different amortized costs</p> <ul> <li>Some operations charged more than they actually cost.</li> <li>Some operations charged less than they actually cost.</li> </ul> <p>If amortized cost (\\hat c_i) &gt; actual cost (c_ic_i), store the remained amount on specific objects as credit</p> <p>If amortized cost (\\hat c_i\\hat c_i) &lt; actual cost (c_ic_i), use credit to compensate</p>"},{"location":"6-semester/AALG/06-computational-geometry-sweeping/","title":"Computational Geometry Algorithms: Sweeping Techniques","text":""},{"location":"6-semester/AALG/06-computational-geometry-sweeping/#basic-geometric-operations","title":"Basic Geometric Operations","text":""},{"location":"6-semester/AALG/06-computational-geometry-sweeping/#line-segment-properties","title":"Line-segment properties","text":"<p>The line-segment \\overline{p_1p_2} between p_1=(x_1,y_1)p_1=(x_1,y_1) and p_2=(x_2,y_2)p_2=(x_2,y_2)</p> <ul> <li>Contains any point p_3p_3 that is on the line passing through p_1p_1 and p_2p_2 and is on or between p_1p_1 and p_2p_2 on the line</li> <li>The set of convex combinations<ul> <li>p_3=\\alpha \\cdot p_1 + (1-\\alpha)p_2p_3=\\alpha \\cdot p_1 + (1-\\alpha)p_2 where 0\\leq \\alpha \\leq0\\leq \\alpha \\leq </li> </ul> </li> <li>We call p_1p_1 and p_2p_2 the endpoints of the line-segment \\overline{p_1p_2}\\overline{p_1p_2}</li> </ul> <p>Directed line-segment \\overrightarrow{p_1p_2}\\overrightarrow{p_1p_2} from p_1p_1 to p_2p_2</p>"},{"location":"6-semester/AALG/06-computational-geometry-sweeping/#cross-product","title":"Cross Product","text":"<p>Cross product</p> <ul> <li>(p_3-p_1)\\times(p_2-p_1)=(x_3-x_1)(y_2-y_1)-(x_2-x_1)(y_3-y_1)(p_3-p_1)\\times(p_2-p_1)=(x_3-x_1)(y_2-y_1)-(x_2-x_1)(y_3-y_1)</li> </ul> <p>Or determinant of the following matrix</p> <ul> <li></li> </ul> <p>Positive \\to\\to p_1p_3p_1p_3 is clockwise from p_1p_2p_1p_2</p> <p>Negative \\to\\to p_1p_3p_1p_3 is counterclockwise from p_1p_2p_1p_2</p> <p>Zero \\to\\to collinear</p> <p></p>"},{"location":"6-semester/AALG/06-computational-geometry-sweeping/#summary","title":"Summary","text":""},{"location":"6-semester/AALG/06-computational-geometry-sweeping/#line-intersection","title":"Line Intersection","text":"<p>A segment \\overline {p_1p_2}\\overline {p_1p_2} straddles a line if point p_1p_1 lies on one side of the line but p_2p_2 lies on the other side</p> <p></p> <ul> <li>Along the line, one needs to turn different directions to go to p_1p_1 and p_2p_2</li> </ul> <p>Two line segments intersect if and only if either of the following two conditions holds:</p> <ul> <li>Each segment straddles the line containing the other</li> <li>An endpoint of one segment lies on the other segment</li> </ul>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/","title":"Computational Geometry Data Structures: Range Searching","text":"<p>Litterature: https://link.springer.com/chapter/10.1007/978-3-540-77974-2_5</p> <p>Queries in a database can be interpreted geometrically</p> <p></p>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#important-factors-in-analysis","title":"Important Factors in Analysis","text":"<ul> <li>Run time for building the data structure</li> <li>Run time for processing range searches</li> <li>Additional space that the data structure takes</li> </ul>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#1-dimensional-range-searching","title":"1-Dimensional Range Searching","text":"<p>Let P:=\\{p_1,p_2,\\dots,p_n\\} be the given set of points on the real line.</p> <p>We can solve the range searching problem with a balanced binary search tree \\mathcal{T}\\mathcal{T} </p> <p></p> <p></p> <p></p>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#kd-trees","title":"Kd-Trees","text":"<p>Let PP be a set of nn points in the plane. We assume that no two points in PP have the same x-coordinate, and no two points have the same y-coordinate.</p> <p>A 2-dimensional rectangular range query on PP asks for the points from PP lying inside a query rectangle [x:x']\\times[y:y'][x:x']\\times[y:y']</p> <p>A point p:=(p_x,p_y)p:=(p_x,p_y) lies inside this rectangle if and only if:</p>  p_x\\in[x:x']\\quad \\text{and}\\quad p_y\\in[y:y'] \\nonumber   p_x\\in[x:x']\\quad \\text{and}\\quad p_y\\in[y:y'] \\nonumber  <p>We could say that a 2-dimensional rectangular range query is composed of two 1-dimensional sub-queries.</p> <p></p> <p>At the root we split the set PP with a vertical line \\ell\\ell into two subsets of roughly equal size.</p> <p>The splitting line is stored at the root. P_\\text{left}P_\\text{left} is stored in the left subtree, and P_\\text{right}P_\\text{right} in the right subtree.</p> <p>In general, we split with a vertical line at nodes whose depth is even, and we split with a horizontal line at nodes whose depth is odd.</p> <p></p>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#building-a-kd-tree","title":"Building a Kd-Tree","text":"<p>Divide-and-conquer</p> <ul> <li>Sort the points in PP w.r.t. their x-coordinates into array XX</li> <li>Sort the points in PP w.r.t. their y-coordinates into array YY</li> <li>Base case:<ul> <li>If PP contains only one point, return a leaf with the point</li> </ul> </li> <li>Otherwise:<ul> <li>Divide into 2 sub-problems and conquer them recursively<ul> <li>If the depth is even (split w.r.t. x-axis or a vertical line)<ul> <li>Take the median vv of XX and create a root v_{root}v_{root}</li> <li>Split XX into sorted X_LX_L and X_RX_R and split YY into sorted Y_LY_L and Y_RY_R<ul> <li>For any p\\in X_Lp\\in X_L or p\\in Y_Lp\\in Y_L,    p.x \\leq v.xp.x \\leq v.x </li> <li>and for any p\\in X_Rp\\in X_R or p\\in Y_Rp\\in Y_R,    p.x &gt; v.xp.x &gt; v.x </li> </ul> </li> <li>Build recursively the left child of v_{root}v_{root} from X_LX_L and Y_LY_L</li> </ul> </li> <li>If the depth is odd (split w.r.t. y-axis or a horizontal line)<ul> <li>Take the median vv of YY and create root v_{root}v_{root}</li> <li>Split XX into sorted X_LX_L and X_RX_R and split YY into sorted Y_LY_L and Y_RY_R<ul> <li>For any p\\in X_Lp\\in X_L or p\\in Y_Lp\\in Y_L,    p.y \\leq v.yp.y \\leq v.y </li> <li>and for any p\\in X_Rp\\in X_R or p\\in Y_Rp\\in Y_R,    p.y &gt; v.yp.y &gt; v.y </li> </ul> </li> <li>Build recursively the right child of v_{root}v_{root} from X_RX_R and Y_RY_R </li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Running time: \\Theta(n \\log n)\\Theta(n \\log n)</p>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#querying-a-kd-tree","title":"Querying a Kd-Tree","text":"<p>A query</p> <p></p> <p></p> <p>It uses a subroutine REPORTSUBTREE(\u03bd), which traverses the subtree rooted at a node \u03bd and reports all the points stored at its leaves.</p> <p>Running time: O(\\sqrt n + k)O(\\sqrt n + k)</p>"},{"location":"6-semester/AALG/08-computational-geometry-range-searching/#range-trees","title":"Range Trees","text":""},{"location":"6-semester/AALG/10-multithreaded-algorithms/","title":"Multithreaded Algorithms","text":""},{"location":"6-semester/AALG/10-multithreaded-algorithms/#concurrency-keywords","title":"Concurrency Keywords","text":"<p>Spawn</p> <ul> <li>If it precedes a procedure call, it indicates a nested parallelism</li> <li>No need to wait for the procedure with keyword spawn</li> </ul> <p>Sync</p> <ul> <li>Must wait for all spawned procedures to complete before going to the statement after sync</li> </ul> <p>Parallel</p> <ul> <li>For parallel loops</li> <li>Just like a for loop, but loop executions run concurrently</li> </ul>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#work-span-parallelism","title":"Work, Span, Parallelism","text":"<p>Work</p> <ul> <li>The running time on a machine with one processor (T_1)</li> <li>Fibonacci: \\Theta(\\phi^n)\\Theta(\\phi^n)</li> </ul> <p>Span</p> <ul> <li>The running time on a machine with infinite processors (T_\\inftyT_\\infty)</li> <li>Fibonacci: \\Theta(n)\\Theta(n)</li> </ul> <p>Parallelism</p> <ul> <li>Work/SpanWork/Span</li> <li>How many processors on average are used by the algorithm</li> <li>Fibonacci: \\Theta(\\phi^n/n)\\Theta(\\phi^n/n)</li> </ul> <p>Multithreaded computation on PP processors: T_PT_P</p>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#computation-dag","title":"Computation DAG","text":"<p>Using an example of computing Fibonacci number of 4</p> <p></p> <p>Edge (u,v)(u,v) means that uu must execute before vv</p> <p></p> <p></p> <ul> <li>Work: The number of vertices</li> <li>17</li> <li>Span: The length of the longest path (critical path) </li> <li>8</li> </ul>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#work-law-and-span-law","title":"Work Law and Span Law","text":"<p>Work Law</p> <ul> <li>T_P \\geq T_1/PT_P \\geq T_1/P</li> <li>An ideal parallel computer with PP processors can do at most PP units of work</li> </ul> <p>Span Law</p> <ul> <li>T_P \\geq T_\\inftyT_P \\geq T_\\infty</li> <li>An ideal parallel computer with PP processors cannot run any faster than a machine with unlimited number of processors</li> </ul> <p>Speedup</p> <ul> <li> <p>T_1/T_PT_1/T_P</p> </li> <li> <p>How many times faster the computation on PP processors than on a single processor</p> </li> <li> <p>Recall the work law says that T_P\\geq T_1/PT_P\\geq T_1/P, so the speedup must be smaller than or equal to PP</p> </li> <li> <p>The speedup on a P-processors machine can at most be P</p> </li> <li>If the speedup is P, we have a perfect linear speedup</li> </ul>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#example","title":"Example","text":"<p>Computing <code>P-Fib(4)</code> we know that the work T_1 = 17T_1 = 17 and span T_\\infty=8T_\\infty=8</p> <ul> <li>P=2</li> <li>Can have perfect linear speedup T_2= 17/2=8.5,\\quad \\geq T_\\inftyT_2= 17/2=8.5,\\quad \\geq T_\\infty</li> <li>P=3</li> <li>Cannot have perfect linear speedup T_3=17/3=5.7, \\quad \\leq T_\\inftyT_3=17/3=5.7, \\quad \\leq T_\\infty<ul> <li>which is impossible</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#slackness","title":"Slackness","text":"<p>Slackness = Parallelism / P</p> <ul> <li>The larger the slackness, the more likely to achieve perfect speedup.</li> <li>When slackness is less than 1, it is impossible to achieve perfect linear speedup</li> </ul>"},{"location":"6-semester/AALG/10-multithreaded-algorithms/#summarize","title":"Summarize","text":""},{"location":"6-semester/AALG/11-approximation/","title":"Approximation for NP-complete Problems","text":""},{"location":"6-semester/AALG/11-approximation/#approximation-ratios","title":"Approximation Ratios","text":"<p>Suppose that</p> <ul> <li>we are working on an optimization problem with input size n</li> <li>each solution has a cost value, and we want to identify the optimal solution, i.e., the one with the minimum or maximum possible cost</li> <li>optimal solution is C^*C^*, returned by an exact algorithm that runs in exponential time</li> <li>approximate solution is CC, returned by an approximation algorithm that runs in polynomial time</li> </ul> <p>Maximization Problem</p> <ul> <li>0&lt;C\\leq C^*0&lt;C\\leq C^*,            C^*/CC^*/C gives a factor</li> <li>E.g. C^*=100,\\quad C=90, \\quad C^*/C=10/9C^*=100,\\quad C=90, \\quad C^*/C=10/9 </li> </ul> <p>Minimization Problem</p> <ul> <li>0&lt; C^* \\leq C0&lt; C^* \\leq C,          C/C^*C/C^* gives a factor</li> <li>E.g. C^*=100,\\quad C=110, \\quad C/C^*=11/10C^*=100,\\quad C=110, \\quad C/C^*=11/10</li> </ul> <p>A p(n)-approximation algorithm has an approximation ratio  p(n), if, for any input size of n, it satisfies \\max({C\\over C^*}, {C^* \\over C})\\leq p(n)\\max({C\\over C^*}, {C^* \\over C})\\leq p(n)</p> <ul> <li>CC is controlled by ratio p(n)p(n)</li> <li>It provides a guarantee on the performance of an approximation algorithm<ul> <li>Consider a 1.2-approximation algorithm with optimal cost C^*=100C^*=100<ul> <li>For a minimization problem, the algorithm returns a value that is no larger than 100*1.2=120100*1.2=120</li> <li>For a maximization problem, the algorithm returns a value that is no smaller than 100/1.2=83.3100/1.2=83.3</li> </ul> </li> </ul> </li> <li>Approximation ratio is never smaller than 1</li> <li>1-approximation algorithm produces the optimal solution</li> </ul>"},{"location":"6-semester/AALG/11-approximation/#approximation-scheme","title":"Approximation Scheme","text":"<p>An approximation scheme for an optimization problem is an approximation algorithm that takes as input </p> <ul> <li>The problem and a value \\varepsilon &gt; 0\\varepsilon &gt; 0</li> <li>Then, the scheme is a (1+\\varepsilon1+\\varepsilon)-approximation algorithm</li> </ul> <p>Polynomial-time approximation scheme, PTAS</p> <ul> <li>Scheme runs in polynomial time of input size nn for any fixed \\varepsilon &gt; 0\\varepsilon &gt; 0, e.g., O(n^{2/\u03b5})O(n^{2/\u03b5})</li> </ul> <p>Fully polynomial-time approximation scheme, FPTAS</p> <ul> <li>Scheme runs in polynomial time of both input size nn and 1/\u03b51/\u03b5, e.g., O((1/\u03b5)^2 n^3O((1/\u03b5)^2 n^3</li> </ul>"},{"location":"6-semester/AALG/11-approximation/#algorithms","title":"Algorithms","text":"<ul> <li> <p>Approximation Algorithm for Vertex-Cover in lecture 11 slides p. 15</p> </li> <li> <p>Approximation Algorithm for Traveling-Salesman in lecture 11 slides p. 22</p> </li> </ul>"},{"location":"6-semester/AALG/12-backtracking/","title":"Backtracking and Branch-and-Bound","text":"<p>We can use heuristics to speed up exponential running time, to solve NP-complete problems.</p> <ul> <li>Backtracking for decision problems, and</li> <li>branch-and-bound for optimization problems</li> </ul>"},{"location":"6-semester/AALG/12-backtracking/#satisfiability-problem","title":"Satisfiability Problem","text":"<p>http://www.nytimes.com/library/national/science/071399sci-satisfiability-problems.html</p> <p>Four actors become Boolean variables: a, b, c, d</p> <ul> <li>true: play; false: not play</li> </ul> <p>Constraints</p> <ul> <li>a\\or c</li> <li>a \\to \\neg ca \\to \\neg c</li> <li>dd</li> <li>bb</li> <li>b \\to (\\neg a \\and \\neg d)b \\to (\\neg a \\and \\neg d)</li> </ul> <p></p> <p>It is impossible to satisfy all constraints!</p>"},{"location":"6-semester/AALG/12-backtracking/#definition","title":"Definition","text":"<p>Given a Boolean formula that is composed of</p> <ul> <li>n Boolean variables: x_1, \\dots, x_nx_1, \\dots, x_n</li> <li>m Boolean connectives: and (\\and\\and), or (\\or)(\\or), not (\\neg)(\\neg), implication (\\to)(\\to), if and only if (\\leftrightarrow)(\\leftrightarrow), and parentheses ( )</li> </ul> <p>We want to see if there is a satisfying assignment for the Boolean formula</p> <ul> <li>A set of values for the variables such that makes the formula be true</li> </ul>"},{"location":"6-semester/AALG/12-backtracking/#cnf-sat","title":"CNF-Sat","text":"<p>Conjunctive Normal Form (CNF) for Boolean formulas</p> <ul> <li>A literal is a variables or its negation<ul> <li>x, y,\\neg x, \\neg yx, y,\\neg x, \\neg y</li> </ul> </li> <li>Each clause is a disjunction of literals<ul> <li>OR of one or more literals: x\\or yx\\or y, \\neg x \\or y \\or x\\neg x \\or y \\or x</li> </ul> </li> <li>CNF is a conjunctyion of clauses<ul> <li>AND of clauses (x\\or y) \\and (x\\or \\neg y)(x\\or y) \\and (x\\or \\neg y)</li> </ul> </li> </ul> <p>Any Boolean formula can be transformed to CNF!</p> <p>CNF-Sat is NP-complete</p>"},{"location":"6-semester/AALG/12-backtracking/#backtracking","title":"Backtracking","text":"<p>We use the structure of an NP-complete problem:</p> <ul> <li>If we have a certificate, we can check<ul> <li>NP-complete problems can be verified in pol. time</li> </ul> </li> <li>A certificate is constructed by making a number of choices</li> <li>What are these choices for CNF-Sat?<ul> <li>Assign T or F to variables</li> </ul> </li> </ul> <p>A backtracking algorithm searches through a large (possibly even exponential-size) set of possibilities in a systematic way.</p> <p>It traverses through possible search paths to locate solutions or dead ends.</p> <p>The configuration of a path consists of a pair (X, Y)</p> <ul> <li>X is the remaining sub-problem to be solved. </li> <li>Y is the set of choices that have been made to get to this sub-problem x from the original problem instance.</li> </ul> <p>Dead end: a configuration (X, Y) that cannot lead to a valid solution no matter how additional choices are made</p> <ul> <li>Cuts off all future searches from this configuration and backtracks to another configuration. </li> </ul>"},{"location":"6-semester/AALG/12-backtracking/#example","title":"Example","text":""},{"location":"6-semester/AALG/guides/amortized-analysis/","title":"Amortized Analysis","text":""},{"location":"6-semester/AALG/guides/amortized-analysis/#amortized-analysis","title":"Amortized Analysis","text":"<ul> <li>The overall idea is to find out how much the average operation costs, because worst case running time may be too pessimistic</li> <li>Divide by n to get the cost of a single operation<ul> <li>If specified by the exercise</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/amortized-analysis/#aggregate-analysis","title":"Aggregate Analysis","text":"<ul> <li>Start by figuring out what it costs to make n operations</li> <li>Figure out the costs of \"standard\" operations<ul> <li>For example: For a dynamic table, there are \\sim n \\Rightarrow\\Rightarrow O(n)O(n) insertions without doing any expansions</li> </ul> </li> <li>Figure out the costs of \"dynamic\"/\"varying\" cost operations<ul> <li>For example: For a dynamic table, that doubles its size when filled, there are log2(n)log2(n) expansions, that each cost 2^j2^j </li> <li>because we have to copy all elements to the next table</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/amortized-analysis/#amortized-analysis-of-dynamic-tables-little-bit-of-a-hack","title":"Amortized Analysis of Dynamic Tables (little bit of a hack)","text":"<ul> <li> <p>If the dynamic table expands by a factor, the amortized complexity is O(1)O(1)</p> </li> <li> <p>If the dynamic table expands by a set amount, the amortized complexity is O(n)O(n)</p> </li> </ul>"},{"location":"6-semester/AALG/guides/approx-and-parallel/","title":"Approximation and Parallelism","text":""},{"location":"6-semester/AALG/guides/approx-and-parallel/#minimization-and-maximization-algorithms","title":"Minimization and Maximization Algorithms","text":"<p>Based on the 2017 exam set</p> <p>More about approximation algorithms in lecture 11 notes</p> <ul> <li>Consider a 1.2-approximation algorithm with optimal cost C^* = 100</li> <li>For a minimization problem, the algorithm returns a value that is no larger than C*1.2 = 100 * 1.2 = 120C*1.2 = 100 * 1.2 = 120</li> <li>For a maximization problem, the algorithm returns a value that is no smaller than C*1.2 = 100 / 1.2 = 83.3C*1.2 = 100 / 1.2 = 83.3</li> </ul> <p>We have the optimal solution C^*C^* and the approximate solution CC. </p> <p>To calculate the approximation ratio:</p> <ul> <li>Minimization problem:<ul> <li>C / C^*C / C^*</li> <li>Example: 120 / 100 = 1.2120 / 100 = 1.2</li> </ul> </li> <li>Maximization problem:<ul> <li>C^* / CC^* / C</li> <li>Example: 100 / 83,3 = 1.2100 / 83,3 = 1.2</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/approx-and-parallel/#vertex-cover-approximation","title":"Vertex Cover Approximation","text":"<p>Based on the 2015 exam set</p> <ul> <li>A solution to the vertex cover problem, is a set of vertices so that each edge is defined by a least one of the vertices<ul> <li>The minimum vertex cover problem tries to calculate the least amount of vertices that covers all edges</li> <li>An alternative explanation is police men who has to look down a number of streets, where vertices is places they can stand and edges are streets they have to keep an eye on</li> </ul> </li> </ul> <p></p> <ul> <li>There must always be an even number of vertices in the result, since the algorithm always picks a pair of vertices in line 4 and 5</li> </ul>"},{"location":"6-semester/AALG/guides/approx-and-parallel/#perfect-linear-speedup","title":"Perfect Linear Speedup","text":"<p>Based on the 2016 exam set</p> <p>See more about multithreaded algorithms in lecture 10 notes</p> <ul> <li>Slackness = parallelism/number_of_processors</li> <li>Number of processor start at one and increase by one <ul> <li>PP = number_of_processors</li> </ul> </li> <li>Slackness \\geq 1Slackness \\geq 1 \\Rightarrow\\Rightarrow possible perfect linear speedup</li> <li>Slackness cannot be more than the parallelism </li> <li>If slackness &lt; 1 the possibility of perfect linear speedup is very decreased</li> </ul> <p></p>"},{"location":"6-semester/AALG/guides/approx-and-parallel/#check-for-perfect-linear-speedup","title":"Check for Perfect Linear Speedup","text":"<ol> <li>If slackness \\geq 1slackness \\geq 1  then it is possible to achieve perfect linear speedup</li> <li>slackness= {parallelism \\over P}slackness= {parallelism \\over P}</li> <li>parallelism = {T_1 \\over T_{\\infty}}parallelism = {T_1 \\over T_{\\infty}}</li> </ol>"},{"location":"6-semester/AALG/guides/flow-networks/","title":"Flow Networks","text":""},{"location":"6-semester/AALG/guides/flow-networks/#augmenting-path-chosen-by-edmonds-karp-algorithm","title":"Augmenting Path Chosen by Edmonds-Karp Algorithm","text":"<p>Based on the 2015 exam set</p> <ol> <li>Draw a new graph, called the residual network, with the same vertices as the original but without any edges</li> <li>For each set of vertices connected by an edge in the original flow network, decide from the following formula if they should be connected in the residual network</li> </ol> <p></p> <ol> <li> <p>The algorithm chooses the path with the lowest flow in the residual network using breath first search (BFS)</p> </li> <li> <p>The first line in the formula expresses that the arrow should go in the same direction as in the original flow network</p> </li> <li>The second line in the formula expresses that the arrow should go in the opposite direction as in the original flow network</li> <li> <p>The third line in the formula expresses that non connected vertices should not be considered</p> </li> <li> <p>The function f denotes the flow, the first number</p> </li> <li>The function c denotes the capacity, the last number</li> <li>Eventually, set u and v to the two vertices involved in the path</li> <li> <p>If the result is 0 in any case, do not draw the edge in the residual network</p> </li> <li> <p>See the example below</p> </li> </ol> <p></p>"},{"location":"6-semester/AALG/guides/graphs/","title":"Graphs","text":""},{"location":"6-semester/AALG/guides/graphs/#adjacency-matrix","title":"Adjacency matrix","text":"<ul> <li>Represents the original graph, when related to a graph created by the Floyd-Warshll algorithm<ul> <li>Is also equivalent to the D^0 graph</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/graphs/#predecessor-matrix","title":"Predecessor matrix","text":"<ul> <li>Describes the previous visited node to get the specified cost in the distance matrix.</li> <li>When used together with a distance matrix, it describes the cheapest path from ii to jj. The distance matrix provides the cheapest cost and the predecessor provides how to get the cheapest cost.</li> <li>Each entry P[i][j]P[i][j] represents the last node visited before j when taking the cheapest path from ii to jj</li> <li>kk describes what number of row the algorithm has processed</li> </ul>"},{"location":"6-semester/AALG/guides/graphs/#distance-matrix-based-on-floyd-warshall-algorithm","title":"Distance matrix based on Floyd-Warshall algorithm","text":"<p>Based on the 2015 exam set</p> <ul> <li> <p>The overall idea is to create a matrix that describes what the shortest distance between each vertex is</p> </li> <li> <p>Create a matrix of size n*nn*n, where nn is the number of vertices</p> </li> <li> <p>Fill out the matrix with the weights between each set of vertices</p> <ul> <li>Read numbers along the x-axis as \"from x\" and numbers from the y-axis as \"to y\"<ul> <li>From xx to yy</li> </ul> </li> <li>A row of 00's will always run down across, since the distance from a vertex to ifself is always 00</li> <li>If it is not possible to go from one vertex to another, write the distance as \\infin\\infin</li> <li>If the exercise only asks for a single row, i.e the 4th, only fill out the numbers for that row</li> </ul> </li> <li> <p>Update each distance between all vertices by using 1 + k1 + k number of edges, if the new distance is shorter</p> <ul> <li> <p>You can only use vertices \\leq k\\leq k</p> <ul> <li>If k=2k=2 we only check shortcuts that go through 11 or 22</li> </ul> </li> <li> <p>Step 2 uses only a single edge, that is k = 0k = 0</p> </li> <li>If the exercise only asks for a single row, only update numbers for that row</li> <li>Check each field in the matrix and look at the graph to see if there is a faster way than the last path</li> <li>Repeat this step as many times as required by the exercise, specified through kk</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/others/","title":"Others","text":""},{"location":"6-semester/AALG/guides/others/#huffman-coding","title":"Huffman Coding","text":"<p>Based on the 2016 exam set</p> <ul> <li> <p>The goal is to create a tree where the leaves represents each letter and the lower frequency is always to the left</p> </li> <li> <p>Count the frequency/how often each letter is found in a string</p> <ul> <li>It is helpful to create a table</li> </ul> </li> <li> <p>Do until there is only one root node:</p> <ol> <li>Combine the lowest frequency leaves and/or node and create a new node with their frequencies added together<ul> <li>The element with the lowest frequency is put to the left</li> <li>The path of the leaves/nodes to the left are marked with a 0 and the right leaves/nodes with a 1</li> </ul> </li> </ol> </li> <li> <p>To encode a letter with the created coding, navigate through the tree until you find the specified letter</p> </li> <li>Remember to read the exercise because it might specify some order of clashing frequencies</li> </ul>"},{"location":"6-semester/AALG/guides/range-queries/","title":"Range Queries and Trees","text":""},{"location":"6-semester/AALG/guides/range-queries/#2d-range-tree-vs-kd-tree-vs-1d-bsts-search-time","title":"2D Range Tree vs KD-tree vs 1D BSTs Search Time","text":"<p>Based on the 2017 exam set</p> <p>If</p> <ul> <li>n = size of the input</li> <li>kk = total number of points in the output</li> </ul> <p>Then</p> Data Structure 2D Query Search Time 2D Range Tree \\Theta((lg(n))^2+k)\\Theta((lg(n))^2+k) KD-tree \\Theta(\\sqrt{n}+k)\\Theta(\\sqrt{n}+k) 2 x 1D BSTs \\Theta(lg(n) + k)\\Theta(lg(n) + k) <ul> <li>log^2(n) = log(n)^2log^2(n) = log(n)^2</li> <li>The log base is unimportant in asymptotic notation eg.  O(lg(n)) = O(log(n))O(lg(n)) = O(log(n))</li> </ul>"},{"location":"6-semester/AALG/guides/range-queries/#big-o-cheat-sheet","title":"Big-O Cheat Sheet","text":"<p>From good to bad:</p> <p></p> <p></p>"},{"location":"6-semester/AALG/guides/range-queries/#building-a-kd-tree-with-n-dimensions","title":"Building a KD-tree with n Dimensions","text":"<p>Based on the 2016 exam set</p> <ul> <li> <p>The exercise will specify the order the attributes should be split on</p> </li> <li> <p>Do until no entries/tuples are left:</p> <ol> <li>Split on the current attribute (order specified by the exercise)<ul> <li>Splitting means sorting the attribute and taking the lower half based on their value<ul> <li>Example: \\{1, 2, 3, 4\\} \\Rightarrow \\{1, 2\\}\\{1, 2, 3, 4\\} \\Rightarrow \\{1, 2\\} and \\{3, 4\\}\\{3, 4\\} </li> <li>Example: \\{1, 2, 3\\} \\Rightarrow \\{1, 2\\}\\{1, 2, 3\\} \\Rightarrow \\{1, 2\\} and \\{3\\}\\{3\\}</li> <li>The lower half should contain values less than or equal to the split value</li> </ul> </li> </ul> </li> <li>Put the group of elements with the lower values in a new left node and the group of elements with the higher values in a right node</li> <li>Go to 1.1 and split on the next attribute specified by the exercise</li> </ol> </li> <li> <p>The KD tree is done when all elements/tuples have been added as a leaf node</p> </li> <li>Each internal node describes the attribute it has split on and the value that its left subtree is less than or equal to, with regards to the nodes split attribute</li> </ul>"},{"location":"6-semester/AALG/guides/range-queries/#querying-a-kd-tree","title":"Querying a KD-tree","text":"<ol> <li>On a split node/internal node check each subtree that satisfies the query constraints<ul> <li>Example: Query; a &lt; 10. The split node/internal node splits on a = 20, which means the left subtree must be checked, as the split node/internal node specifies that all elements/tuples in its left subtree contains a-values less than 20</li> </ul> </li> </ol>"},{"location":"6-semester/AALG/guides/range-queries/#b-tree","title":"B+ tree","text":"<p>Based on the 2016 exam set</p>"},{"location":"6-semester/AALG/guides/range-queries/#insertion","title":"Insertion","text":"<ol> <li>Find the correct place for the element<ul> <li>All elements should appear in a sorted order, based on size or alphabetical order</li> </ul> </li> <li>If there is room for the element in the leaf, simply insert<ul> <li>Number of elements for a leaf is specified in the exercise</li> </ul> </li> <li>If not, insert the element and split the node into two new nodes, each with half of the elements<ul> <li>The left node should contain less than or equal to the middle element</li> </ul> </li> <li>If the node is a leaf copy the rightmost element in the left node to the parent, if it is an internal node, move the element to the parent</li> <li>If the parent node has no room, go to step 3 and handle it as a normal leaf node</li> <li>If the root node has no room,  create a new root with a single key</li> </ol>"},{"location":"6-semester/AALG/guides/range-queries/#search","title":"Search","text":"<ul> <li> <p>The idea is to find the node where the range start and then use the links between nodes to find all elements in the range</p> </li> <li> <p>Traverse the tree recursively until the start of the range is found</p> </li> <li>Use the linked lists between leaves to find the end of the range, or the specific element the search is run for</li> </ul>"},{"location":"6-semester/AALG/guides/range-queries/#kd-tree-construction","title":"KD Tree Construction","text":"<p>Based on the 2015 exam set</p> <ol> <li> <p>Do until all points have their own box</p> <ol> <li> <p>Draw a line through the point that splits all points in the current box</p> <ul> <li>If the depth is even, split with regards to the x-axis (draw a vertical line)</li> <li>If the depth is uneven, split with regards to the y-axis (draw a horizontal line)</li> <li> <p>Since depth starts even, start by splitting with a vertical line</p> </li> <li> <p>The exercise will specify whether the point being split is in the left or right subtree, for example based on if it is smaller or equal</p> </li> </ul> </li> </ol> </li> </ol> <p></p> <ul> <li>The image above shows the order to add the lines splitting the boxes</li> </ul> <p></p> <ul> <li>The image above shows how each of the points has their own box when the point being split on is in the less or equal box</li> </ul>"},{"location":"6-semester/AALG/guides/sweeping/","title":"Sweeping","text":""},{"location":"6-semester/AALG/guides/sweeping/#sweeping-techniques","title":"Sweeping techniques","text":"<p>Based on the 2016 exam set</p> <ul> <li>The idea is to add the points to a list and check if a line is immediately above or below the line. If it is, check if they intersect. <ul> <li>If they do, return true and terminate</li> </ul> </li> <li>When an endpoint of a line is reached, check if there exists a line immediately above and below the endpoint, check if they intersect (the line above and the line below). Remove the endpoint from the list.<ul> <li>If they do, return true and terminate</li> </ul> </li> <li>The goal of the algorithm is to check if ANY intersection exists. As such, it will terminate upon finding an intersection.</li> </ul> <p></p> <p></p>"},{"location":"6-semester/AALG/guides/sweeping/#grahams-vs-jarvis-march","title":"Graham's vs Jarvis' march","text":"<p>Based on the 2016 exam set</p> <ul> <li>When the output H is asymptotically smaller than \\lg(n) Jarvis' march is faster<ul> <li>H &lt; lg(n)H &lt; lg(n): Jarvis</li> </ul> </li> </ul>"},{"location":"6-semester/AALG/guides/sweeping/#grahams-scan","title":"Graham's scan","text":"<p>Based on the 2015 exam set</p> <ul> <li>All points are/should be sorted by their angle to P_0P_0<ul> <li>The angle is calculated from a horizontal line going out from P_0P_0 in both directions</li> </ul> </li> </ul> <p></p> <ol> <li> <p>Push the first 3 points onto the stack</p> </li> <li> <p>Repeat for all points:</p> <ol> <li> <p>While the next point, called P_iP_i, lies to the right or straight ahead in regards to the top two points on the stack:</p> <ol> <li>Pop the top point on the stack</li> <li> <p>Check again with the new two top points on the stack</p> </li> <li> <p>Right and left of a point is defined by the line going through the point on top of the stack and the point before it on to the stack</p> </li> </ol> </li> <li> <p>When making a left turn push P_iP_i on top of the stack and go to 2.1</p> </li> </ol> </li> <li> <p>If all points have been checked, the convex hull should have been finished.</p> </li> </ol>"},{"location":"6-semester/AALG/guides/year-based-old/2015/","title":"2015","text":""},{"location":"6-semester/AALG/guides/year-based-old/2015/#distance-matrix-based-on-floyd-warshall-algorithm","title":"Distance matrix based on Floyd-Warshall algorithm","text":"<ul> <li> <p>The overall idea is to create a matrix that describes what the shortest distance between each vertex is</p> </li> <li> <p>Create a matrix of size n*n, where n is the number of vertices</p> </li> <li> <p>Fill out the matrix with the weights between each set of vertices</p> </li> <li>Read numbers along the x-axis as \"from x\" and numbers from the y-axis as \"to y\"<ul> <li>From x to y</li> </ul> </li> <li>A row of 0's will always run down across, since the distance from a vertex to ifself is always 0</li> <li>If it is not possible to go from one vertex to another, write the distance as \\infin</li> <li>If the exercise only asks for a single row, i.e the 4th, only fill out the numbers for that row</li> <li>Update each distance between all vertices by using 1 + k number of edges, if the new distance is shorter</li> <li>Step 2 uses only a single edge, that is k = 0</li> <li>If the exercise only asks for a single row, only update numbers for that row</li> <li>Check each field in the matrix and look at the graph to see if there is a faster way than the last path</li> <li>Repeat this step as many times as required by the exercise, specified through k</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2015/#augmenting-path-chosen-by-edmonds-karp-algorithm","title":"Augmenting path chosen by Edmonds-Karp algorithm","text":"<ol> <li>Draw a new graph, called the residual network, with the same vertices as the original but without any edges</li> <li>For each set of vertices connected by an edge in the original flow network, decide from the following formula if they should be connected in the residual network</li> </ol> <ol> <li> <p>The algorithm chooses the path with the lowest flow in the residual network using breath first search (BFS)</p> </li> <li> <p>The first line in the formula expresses that the arrow should go in the same direction as in the original flow network</p> </li> <li>The second line in the formula expresses that the arrow should go in the opposite direction as in the original flow network</li> <li> <p>The third line in the formula expresses that non connected vertices should not be considered</p> </li> <li> <p>The function f denotes the flow, the first number</p> </li> <li>The function c denotes the capacity, the last number</li> <li>Eventually, set u and v to the two vertices involved in the path</li> <li> <p>If the result is 0 in any case, do not draw the edge in the residual network</p> </li> <li> <p>See the example below</p> </li> </ol> <p></p>"},{"location":"6-semester/AALG/guides/year-based-old/2015/#grahams-scan","title":"Graham's scan","text":"<ul> <li>All points are/should be sorted by their angle to P_0</li> <li>The angle is calculated from a horizontal line going out from P_0 in both directions</li> </ul> <ol> <li> <p>Push the first 3 points onto the stack</p> </li> <li> <p>Repeat for all points:</p> </li> <li> <p>While the next point, called P_i, lies to the right or straight ahead in regards to the top two points on the stack:</p> <ol> <li>Pop the top point on the stack</li> <li> <p>Check again with the new two top points on the stack</p> </li> <li> <p>Right and left of a point is defined by the line going through the point on top of the stack and the point before it on to the stack</p> </li> </ol> </li> <li> <p>When making a left turn push P_i on top of the stack and go to 2.1</p> </li> <li> <p>If all points have been checked, the convex hull should have been finished.</p> </li> </ol>"},{"location":"6-semester/AALG/guides/year-based-old/2015/#vertex-cover-approximation","title":"Vertex cover approximation","text":"<ul> <li>A solution to the vertex cover problem, is a set of vertices so that each edge is defined by a least one of the vertices</li> <li>The minimum vertex cover problem tries to calculate the least amount of vertices that covers all edges</li> <li>An alternative explanation is police men who has to look down a number of streets, where vertices is places they can stand and edges are streets they have to keep an eye on</li> </ul> <ul> <li>There must always be an even number of vertices in the result, since the algorithm always picks a pair of vertices in line 4 and 5</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2015/#kd-tree-construction","title":"KD tree construction","text":"<ol> <li> <p>Do until all points have their own box</p> </li> <li> <p>Draw a line through the point that splits all points in the current box</p> <ul> <li>If the depth is even, split with regards to the x-axis (draw a vertical line)</li> <li>If the depth is uneven, split with regards to the y-axis (draw a horizontal line)</li> <li>Since depth starts even, start by splitting with a vertical line</li> <li>The exercise will specify whether the point being split is in the left or right subtree, for example based on if it is smaller or equal</li> </ul> </li> </ol> <p></p> <ul> <li>The image above shows the order to add the lines splitting the boxes</li> </ul> <p></p> <ul> <li>The image above shows how each of the points has their own box when the point being split on is in the less or equal box</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/","title":"2016","text":""},{"location":"6-semester/AALG/guides/year-based-old/2016/#adjacency-matrix","title":"Adjacency matrix","text":"<ul> <li>Represents the original graph, when related to a graph created by the Floyd-Warshll algorithm</li> <li>Is also equivalent to the D^(0) graph</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#predecessor-matrix","title":"Predecessor matrix","text":"<ul> <li>Describes the previous visited node to get the specified cost in the distance matrix.</li> <li>When used together with a distance matrix, it describes the cheapest path from i to j. The distance matrix provides the cheapest cost and the predecessor provides how to get the cheapest cost.</li> <li>Each entry P[i][j] represents the last node visited before j when taking the cheapest path from i to j</li> <li>k describes what number of row the algorithm has processed</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#huffman-coding","title":"Huffman coding","text":"<ul> <li> <p>The goal is to create a tree where the leaves represents each letter and the lower frequency is always to the left</p> </li> <li> <p>Count the frequency/how often each letter is found in a string</p> </li> <li>It is helpful to create a table</li> <li>Do until there is only one root node:</li> <li> <p>Combine the lowest frequency leaves and/or node and create a new node with their frequencies added together</p> <ul> <li>The element with the lowest frequency is put to the left</li> <li>The path of the leaves/nodes to the left are marked with a 0 and the right leaves/nodes with a 1</li> </ul> </li> <li> <p>To encode a letter with the created coding, navigate through the tree until you find the specified letter</p> </li> <li>Remember to read the exercise because it might specify some order of clashing frequencies</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#sweeping-techniques","title":"Sweeping techniques","text":"<ul> <li>The idea is to add the points to a list and check if a line is immediately above or below the line. If it is, check if they intersect. </li> <li>If they do, return true and terminate</li> <li>When an endpoint of a line is reached, check if there exists a line immediately above and below the endpoint, check if they intersect (the line above and the line below). Remove the endpoint from the list.</li> <li>If they do, return true and terminate</li> <li>The goal of the algorithm is to check if ANY intersection exists. As such, it will terminate upon finding an intersection.</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#grahams-vs-jarvis-march","title":"Graham's vs Jarvis' march","text":"<ul> <li>When the output H is asymptotically smaller than \\lg(n) Jarvis' march is faster</li> <li>H &lt; lg(n)H &lt; lg(n): Jarvis</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#building-a-kd-tree-with-n-dimensions","title":"Building a KD-tree with n dimensions","text":"<ul> <li> <p>The exercise will specify the order the attributes should be split on</p> </li> <li> <p>Do until no entries/tuples are left:</p> </li> <li>Split on the current attribute (order specified by the exercise)<ul> <li>Splitting means sorting the attribute and taking the lower half based on their value<ul> <li>Example: {1, 2, 3, 4} =&gt; {1, 2} and {3, 4} </li> <li>Example: {1, 2, 3} =&gt; {1, 2} and {3}</li> <li>The lower half should contain values less than or equal to the split value</li> </ul> </li> </ul> </li> <li>Put the group of elements with the lower values in a new left node and the group of elements with the higher values in a right node</li> <li> <p>Go to 1.1 and split on the next attribute specified by the exercise</p> </li> <li> <p>The KD tree is done when all elements/tuples have been added as a leaf node</p> </li> <li>Each internal node describes the attribute it has split on and the value that its left subtree is less than or equal to, with regards to the nodes split attribute</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#querying-a-kd-tree","title":"Querying a KD-tree","text":"<ol> <li>On a split node/internal node check each subtree that satisfies the query constraints</li> <li>Example: Query; a &lt; 10. The split node/internal node splits on a = 20, which means the left subtree must be checked, as the split node/internal node specifies that all elements/tuples in its left subtree contains a-values less than 20</li> </ol>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#b-tree","title":"B+ tree","text":""},{"location":"6-semester/AALG/guides/year-based-old/2016/#insertion","title":"Insertion","text":"<ol> <li>Find the correct place for the element</li> <li>All elements should appear in a sorted order, based on size or alphabetical order</li> <li>If there is room for the element in the leaf, simply insert</li> <li>Number of elements for a leaf is specified in the exercise</li> <li>If not, insert the element and split the node into two new nodes, each with half of the elements</li> <li>The left node should contain less than or equal to the middle element</li> <li>If the node is a leaf copy the rightmost element in the left node to the parent, if it is an internal node, move the element to the parent</li> <li>If the parent node has no room, go to step 3 and handle it as a normal leaf node</li> <li>If the root node has no room,  create a new root with a single key</li> </ol>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#search","title":"Search","text":"<ul> <li> <p>The idea is to find the node where the range start and then use the links between nodes to find all elements in the range</p> </li> <li> <p>Traverse the tree recursively until the start of the range is found</p> </li> <li>Use the linked lists between leaves to find the end of the range, or the specific element the search is run for</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2016/#perfect-linear-speedup","title":"Perfect linear speedup","text":"<ul> <li>Slackness = parallelism/number_of_processors</li> <li>Number of processor start at one and increase by one </li> <li>P = number_of_processors</li> <li>Slackness &gt;= 1 = possible perfect linear speedup</li> <li>Slackness cannot be more than the parallelism </li> <li>If slackness &lt; 1 the possibility of perfect linear speedup is very decreased</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2017/","title":"2017","text":""},{"location":"6-semester/AALG/guides/year-based-old/2017/#2d-range-tree-vs-kd-tree-vs-1d-bsts-search-time","title":"2D range tree vs KD-tree vs 1D BSTs search time","text":"<ul> <li>2D range tree: \\Theta(lg^2n+k)</li> <li>log^2(n) = log(n)^2log^2(n) = log(n)^2</li> <li>lg = loglg = log</li> <li> <p>KD-tree: \\Theta(\\sqrt{n}+k)\\Theta(\\sqrt{n}+k)</p> </li> <li> <p>2x 1D BSTs: \\Theta(lg(n) + k)\\Theta(lg(n) + k)</p> </li> <li> <p>nn = size of the input</p> </li> <li>kk = total number of points in the output</li> </ul> <p></p> <p></p>"},{"location":"6-semester/AALG/guides/year-based-old/2017/#merge-sort-algorithms","title":"Merge sort algorithms","text":"<ul> <li>N = 1000</li> <li>M = 50</li> <li>B = 1</li> <li>n = 1000 = N</li> <li>m = M = 50</li> </ul>"},{"location":"6-semester/AALG/guides/year-based-old/2017/#minimization-and-maximization-algorithms","title":"Minimization and maximization algorithms","text":"<ul> <li>Consider a 1.2-approximation algorithm with optimal cost C* = 100</li> <li>For a minimization problem, the algorithm returns a value that is no larger than C*1.2 = 100 * 1.2 = 120</li> <li> <p>For a maximization problem, the algorithm returns a value that is no smaller than C*1.2 = 100 / 1.2 = 83.3</p> </li> <li> <p>We have the optimal solution C* and the approximate solution C. To calculate the approximation ratio:</p> </li> <li>Minimization problem:</li> <li>C / C*</li> <li>Example: 120 / 100 = 1.2</li> <li>Maximization problem:</li> <li>C* / C</li> <li>Example: 100 / 83,3 = 1.2</li> </ul>"},{"location":"6-semester/DBS/","title":"DBS - Database Systems","text":"<p>Moodle page:</p> <p>https://www.moodle.aau.dk/course/view.php?id=33037</p> <p></p>"},{"location":"6-semester/DBS/01-introduction/","title":"Introduction","text":""},{"location":"6-semester/DBS/01-introduction/#database-system","title":"Database System","text":""},{"location":"6-semester/DBS/01-introduction/#3-layer-schema-architecture","title":"3-Layer Schema Architecture","text":""},{"location":"6-semester/DBS/01-introduction/#physical-data-independence","title":"Physical Data Independence","text":"<p>Changes regarding file structure and access paths (physical layer) have no influence on the conceptual schema (logical layer)</p> <p>Examples of changes on physical layer:</p> <ul> <li>New hard disk added</li> <li>New processor added</li> <li>Files are split into multiple files</li> </ul>"},{"location":"6-semester/DBS/01-introduction/#logical-data-independence","title":"Logical Data Independence","text":"<p>Changes on the logical layer have no influence on external schemas and applications</p> <p>Examples of changes on the logical layer:</p> <ul> <li>Adding another attribute to the conceptual schema<ul> <li>Users still see the same set of attributes</li> </ul> </li> <li>Changing the name of an attribute on the conceptual schema<ul> <li>In the users view the attributes still has the same name</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/01-introduction/#definitions","title":"Definitions","text":"<p>Mini-world</p> <ul> <li>Some part of the real world about which information is stored</li> </ul> <p>Data/Information</p> <ul> <li>Known facts about the mini-world that can be recorded and have an implicit meaning</li> </ul> <p>Database (DB)</p> <ul> <li>A collection of related data</li> </ul> <p>Database Management Systems (DBMS)</p> <ul> <li>A software package to facilitate the creation and maintenance of a database</li> </ul> <p>Database Systems (DBS)</p> <ul> <li>A database and a DBMS</li> </ul> <p>Database Instance</p> <ul> <li>The content of a DB at a particular time</li> </ul>"},{"location":"6-semester/DBS/01-introduction/#entity-relationship-modeling","title":"Entity Relationship Modeling","text":"<ol> <li>Entity \\to Entity type</li> <li>Relationship \\to\\to Relationship type</li> <li>Attribute (characteristics)</li> <li>Primary Key (identification)</li> <li>Role (clarification)</li> </ol>"},{"location":"6-semester/DBS/01-introduction/#relational-model","title":"Relational Model","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/","title":"Relational Model and Relational Algebra","text":"<p>Learning Goals</p> <ul> <li>Explain the relational model</li> <li>Create non-trivial relational algebra queries</li> <li>Use the various join types in relational algebra queries</li> <li>Explain the limitations of relational algebra</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#the-relational-model","title":"The Relational Model","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#foundations","title":"Foundations","text":"<p>Assume D_1, D_2,\\dots,D_n are domains</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#relation","title":"Relation:","text":"<p>R\\subseteq D_1\\times \\dots \\times D_nR\\subseteq D_1\\times \\dots \\times D_n</p> <ul> <li>Example: telephoneBook\\subseteq string \\times string \\times integertelephoneBook\\subseteq string \\times string \\times integer</li> <li>Domains can be identical D_i=D_jD_i=D_j for i \\neq ji \\neq j</li> <li>Based on mathematical sets</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#relational-schema","title":"Relational Schema","text":"<ul> <li>Defines the structure of stored data</li> <li>Is denoted as sch(R)sch(R) or \\mathcal R\\mathcal R</li> <li>Notation: R(A_1: D_1, A_2:D_2, \\dots)R(A_1: D_1, A_2:D_2, \\dots) with A_iA_i denoting attributes</li> <li>Example:<ul> <li>telephoneBook(name: string, street:string, \\underline{phoneNumber:integer})telephoneBook(name: string, street:string, \\underline{phoneNumber:integer})</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#illustration-of-basic-concepts","title":"Illustration of Basic Concepts","text":"<ul> <li>Header: relation schema</li> <li>Column header: attribute</li> <li>Entries in the table: relation</li> <li>Row in the table: tuble</li> <li>An entry of a cell: attribute value</li> <li>Underlined attributes: primary keys</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#foreign-key","title":"Foreign Key","text":"<ul> <li>A relation may include the primary key attributes of another table</li> <li>Valid values for foreign key attributes must appear in the primary key of the referenced table</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#example","title":"Example","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#characteristics","title":"Characteristics","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#tuple-ordering","title":"Tuple Ordering","text":"<p>Tuples in a relation are unordered</p> <p>These relations have the same information content:</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#attribute-ordering","title":"Attribute Ordering","text":"<p>In accordance with the mathematical definition of tuples, attributes in a tuple/relation are ordered**</p> <p>These relations have different information content:</p> <p></p> <p>However: </p> <ul> <li>The order of attributes are immaterial for most applications</li> <li>Using attribute names instead of ordering is more convenient</li> <li>The Cartisian product becomes commutative</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#atomic-values","title":"Atomic Values","text":"<ul> <li>Values in a tuple are atomic (indivisible)</li> <li>A value cannot be a structure, a record, a collection type, or a relation</li> </ul> <p>Example:</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#null-values","title":"Null Values","text":"<p>A special null value is used to represent values that are unknown or inapplicable to certain tuples</p> <p>Example:</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#duplicates","title":"Duplicates","text":"<p>A relation adheres to the mathematical definition of a set</p> <ul> <li>No two tuples in a relation may have identical values for all attributes</li> </ul> <p>Example:</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#relational-algebra","title":"Relational Algebra","text":"\\newcommand{\\leftouterjoin}{\u27d5} \\newcommand{\\rightouterjoin}{\u27d6} \\newcommand{\\outerjoin}{\u27d7} \\newcommand{\\leftsemijoin}{\u22c9} \\newcommand{\\rightsemijoin}{\u22ca} \\nonumber   \\newcommand{\\leftouterjoin}{\u27d5} \\newcommand{\\rightouterjoin}{\u27d6} \\newcommand{\\outerjoin}{\u27d7} \\newcommand{\\leftsemijoin}{\u22c9} \\newcommand{\\rightsemijoin}{\u22ca} \\nonumber"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#relational-algebra-operations","title":"Relational Algebra Operations","text":"Name Symbol Projection \\pi\\pi Selection \\sigma\\sigma Rename \\rho\\rho Cartesian product \\times\\times Union \\cup\\cup Difference -- Intersection \\cap\\cap Join \\Join\\Join Left Outer Join \\leftouterjoin\\leftouterjoin Right Outer Join \\rightouterjoin\\rightouterjoin Outer Join \\outerjoin\\outerjoin Left Semi Join \\leftsemijoin\\leftsemijoin Right Semi Join \\rightsemijoin\\rightsemijoin Grouping \\gamma\\gamma Division \\div\\div <p>The operations marked with bold is the fundamental operations</p> <ul> <li>Any relational algebra query can be expressed with the set of fundamental operations only</li> <li>Removing any one of these operations reduces the expressive power</li> </ul> <p>Unary vs Binary operations</p> <ul> <li>Unary operations: \\sigma, \\pi, \\rho\\sigma, \\pi, \\rho</li> <li>Binary operations: \\times, \\cup, -\\times, \\cup, -</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#fundamental-operations","title":"Fundamental Operations","text":"<p>Operations and their use:</p> <ul> <li>Input: one or multiple relations</li> <li>Output: a relation</li> </ul> <p>Operations can be combined (with some rules)</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#projection","title":"Projection","text":"<p>The result is a relation of nn columns obtained by removing the columns that are not specified.</p> <p></p> <p></p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#extended-projection","title":"Extended Projection","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#selection","title":"Selection","text":"<p>Symbol: \\sigma_F\\sigma_F</p> <ul> <li>Selection predicate FF consist of:<ul> <li>Logic operations: \\or\\or (or), \\and\\and (and), \\neg\\neg (not)</li> <li>Arithmetic comparison operators: &lt;, \\leq, =, &gt;, \\geq, \\neq&lt;, \\leq, =, &gt;, \\geq, \\neq</li> <li>Attribute names of the argument relations or constants as operands</li> </ul> </li> </ul> <p>Selecting/filtering rows of a table according to the selection predicate</p> <p></p> <p>$$ \\sigma_{salary&gt;80000}(instructor) $$ </p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#rename","title":"Rename","text":"<p>Relation</p> <p>Renaming a relation RR to SS:</p> <ul> <li>\\rho_S(R)\\rho_S(R)</li> </ul> <p>Attribute</p> <p>Renaming attribute BB to AA:</p> <ul> <li>\\rho_{A\\leftarrow B}(R)\\rho_{A\\leftarrow B}(R)</li> </ul> <p>Some literature uses \\beta\\beta for the rename operation</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#cartesian-product","title":"Cartesian Product","text":"<p>AKA Cross Product</p> <p>The Cartesian product (R\\times SR\\times S) between relations RR and SS consists of all possible combinations (|R|*|S||R|*|S| pairs) of tuples from both relations</p> <p>Result schema: $$ sch(R\\times S)=sch(R) \\cup sch(S) = \\mathcal R \\cup \\mathcal S $$  Contains many (useless) combinations!</p> <p>Attributes in the result are referenced as R.AR.A or S.AS.A to resolve ambiguity.</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#set-operations","title":"Set Operations","text":"<p>Set operations union, intersection, and difference can also be applied to relations</p> <p>Requirements</p> <p>Both involved relations must be union-compatible:</p> <ul> <li>they have the same number of attributes</li> <li>the domain of each attribute in column order is the same in both relations</li> </ul>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#union","title":"Union","text":"<p>The result of a union (R\\cup S)(R\\cup S) between two relations RR and SS contains all tuples from both relations without duplicates</p> <p>Example:</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#difference","title":"Difference","text":"<p>The difference (R-SR-S or R \\setminus SR \\setminus S) of two relations RR and SS removes all tuples from the first relation that are also contained in the second relation</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#overview-of-fundamental-operations","title":"Overview of Fundamental Operations","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#non-fundamental-operations","title":"Non-Fundamental Operations","text":""},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#intersection","title":"Intersection","text":"<p>The intersection (R\\cap S)(R\\cap S) of two relations RR and SS consists of a set of tuples that occur in both relations.</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#with-fundamental-operations","title":"With Fundamental Operations","text":"<p>Intersection can be expressed as difference (R\\cap S= R- (R-S))(R\\cap S= R- (R-S))</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#join","title":"Join","text":"<p>The natural join combines two relations via common attributes (same name and domains) by combining only tuples with the same values for common attributes.</p> <p>Given two relations (and their schema)</p> <ul> <li>R(A_1,\\dots,A_m, B_1,\\dots,B_k)R(A_1,\\dots,A_m, B_1,\\dots,B_k)</li> <li>S(B_1,\\dots,B_k,C_1,\\dots,C_n)S(B_1,\\dots,B_k,C_1,\\dots,C_n)</li> </ul> <p></p> <p>Example:</p> <p></p> <p>Result:</p> <p></p> <p>Tuples without matching partners (dangling tuples) are eliminated</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#with-fundamental-operations_1","title":"With Fundamental Operations","text":"<p>Natural join can be expressed as a Cartesian product followed by selections and projections</p> <p>Example</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#is-join-commutative","title":"Is Join Commutative","text":"<p>For now, we do not consider joins and Cartesian products to be commutative.</p> <p>For query optimization later, we usually consider joins as well as Cartesian product and other join variants to be commutative.</p> <p>If we want to hold on to the mathematical definition of tuples and still consider joins to be commutative, we need to apply a projection operation to reorder the attributes: $$ \\pi_L(R\\Join S) = \\pi_L(S\\Join R) $$</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#outer-join","title":"Outer Join","text":"<ul> <li>\u27d5 - Left Outer Join <ul> <li>Keep dangling tuples in the left operand relation</li> </ul> </li> <li>\u27d6 - Right Outer Join<ul> <li>Keep dangling tuples in the right operand relation</li> </ul> </li> <li>\u27d7 - (Full) Outer Join<ul> <li>Keep dangling tuples of both operand relations</li> </ul> </li> </ul> <p>Examples</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#semi-join","title":"Semi Join","text":"<p>Find all tuples in a relation for which there are matching tuples in the other relation</p> <p>Left semi join: $$ L \\leftsemijoin R= \\pi_{\\mathcal L}(L\\Join R) $$</p> <p>where \\mathcal L\\mathcal L represents the set of LL's attributes</p> <p>Right semi join: $$ L\\rightsemijoin R = R \\leftsemijoin L = \\pi_{\\mathcal R}(L \\Join R) $$ Examples</p> <p></p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#grouping","title":"Grouping","text":"<p>Tuples with the same attribute values (for a specified list of attributes) are grouped.</p> <p>An aggregate function is applied to each group (computing one value for each group)</p> <p>Typical aggregate functions:</p> <ul> <li>count - number of tuples in a group</li> <li>sum - sum of attribute values in a group</li> <li>min, max, avg</li> </ul> <p>Notation $$ \\gamma_{L;F}(R) $$</p> <ul> <li>LL: list of attributes for grouping</li> <li>FF: aggregate function</li> </ul> <p>Alternative symbols \\mathcal G\\mathcal G or \\beta\\beta</p> <p>Example:</p> <p>Determine the number of students per semester:</p> <p></p> <p>More examples in DBS2 slides p75</p>"},{"location":"6-semester/DBS/02-relational-model-and-relational-algebra/#division","title":"Division","text":"<p>Example</p> <p>Find all studIDstudIDs of students that took all 4 ECTS courses</p> <ul> <li>takes(studID, courseID)takes(studID, courseID)</li> <li>course(courseID, title, ects, teacher)course(courseID, title, ects, teacher)</li> </ul>  takes \\div \\pi_{courseID}(\\sigma_{ects=4}(course))   takes \\div \\pi_{courseID}(\\sigma_{ects=4}(course))  <p>Formal definition:</p> <p></p> <p>See examples in DBS2 slides p81</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/","title":"The Entity Relationship Model","text":"\\newcommand{\\relationRaw}[3]{     \\newcommand{\\pk}{\\underline}     #3\\mathbf{#1}#3#3:\\{[\\mathrm{#2}]\\} } \\newcommand{\\relation}[2]{\\relationRaw{#1}{#2}{}} \\newcommand{\\relational}[2]{\\relationRaw{#1}{#2}{&amp;}} \\nonumber  <p>Learning Goals</p> <ul> <li>Create non-trivial ER diagrams</li> <li>Assess the quality of an ER diagram</li> <li>Perform and explain the mapping of ER diagrams to relations</li> <li>Use a particular ER notation properly</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#steps-of-database-design","title":"Steps of Database Design","text":"<ol> <li>Requirements analysis<ul> <li>What are we dealing with?</li> </ul> </li> <li>Mapping onto a conceptual model (conceptual design)<ul> <li>What data and relationships have to be captured?</li> </ul> </li> <li>Mapping onto a data model (logical design)<ul> <li>How to structure data in a specific model (here: the relational model)?</li> </ul> </li> <li>Realization and implementation (physical design)<ul> <li>Which adaptations and optimizations does a specific DBMS require?</li> </ul> </li> </ol>"},{"location":"6-semester/DBS/03-entity-relationship-model/#basics-of-entity-relationship-model","title":"Basics of Entity Relationship Model","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#entity-and-entity-types","title":"Entity and Entity Types","text":"<p>Entities are objects of the real world about which we want to store information</p> <p>Entities are grouped into entity types</p> <p></p> <p>The extension of an entity type (entity set) is a particular collection of entities.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#attributes","title":"Attributes","text":"<p>Attributes model characteristics of entities or relationships</p> <ul> <li>All entities of an entity type have the same characteristics</li> <li>Attributes are declared for entity types</li> <li>Attributes have a domain or values set</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#single-valued-vs-multi-valued","title":"Single-Valued vs Multi-Valued","text":"<p>A person might have multiple phone numbers (or a single one)</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#simple-vs-composite","title":"Simple vs Composite","text":"<p>An address can be modeled as a string or composed of street and city</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#stored-vs-derived","title":"Stored vs Derived","text":"<p>Eg. birthday and age</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#keys","title":"Keys","text":"<p>A (super) key consists of a subset of an entity type's attributes E(A_1,\\dots,A_m)E(A_1,\\dots,A_m) $$ {S_1,\\dots,S_k} \\subseteq {A_1, \\dots, A_m} $$ The attributes S_1, \\dots S_kS_1, \\dots S_k of the key are called key attributes</p> <p>The key attribute's values uniquely identify an individual entity</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#candidate-key","title":"Candidate Key","text":"<p>A candidate key corresponds to a minimal subset of attributes that fulfills the above condition</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#primary-key","title":"Primary Key","text":"<p>If there are multiple candidate keys, one is chosen as primary key</p> <p>Primary key attributes are marked by underlining</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#relationships","title":"Relationships","text":"<p>Relationships describe connections between entities</p> <p>Relationships between entities are grouped into relationship types</p> <p></p> <p>An association between two or more entities is called relationship (instance).</p> <p>A relationship set is a collection of relationship instances.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#mathematical","title":"Mathematical","text":"<p>A relationship type RR between entity types E_1, \\dots, E_nE_1, \\dots, E_n can be considered a mathematical relation</p> <p>Instance of a relationship type RR: $$ R \\subseteq E_1 \\times \\dots \\times E_n $$ A particular element (e_1,\\dots,e_n)\\in R(e_1,\\dots,e_n)\\in R is called an  instance of the relationship type with e_i \\in E_ie_i \\in E_i for all 1 \\leq i \\leq n1 \\leq i \\leq n</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#role-names","title":"Role Names","text":"<p>Role names are optional and used to characterize a relationship type.</p> <ul> <li>Especially useful for recursive relationship types, i.e., an entity type is participating multiple times in a relationship type.</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#attributes-of-relationship-types","title":"Attributes of Relationship Types","text":"<p>Relationship types can also have (descriptive) attributes.</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#summary-of-basics","title":"Summary of Basics","text":"<p>student take courses</p> <p></p> <p>See \"animation\" in DBS3 slides p 39</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#characteristics-of-relationship-types","title":"Characteristics of Relationship Types","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#degree","title":"Degree","text":"<ul> <li>Number of participating entity types</li> <li>Mostly: binary</li> <li>Rarely: ternary</li> <li>In general: n-ary or n-way (multiway relationship types)</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#cardinality-ratio-cardinality-limits-participation-constraint","title":"Cardinality Ratio / Cardinality Limits / Participation Constraint","text":"<ul> <li>Number of times entities are involved in relationship instances</li> <li>Cardinality ratio (Chen notation): <ul> <li>1:1, 1:N, N:M</li> </ul> </li> <li>Participation constraint:<ul> <li>partial or total</li> </ul> </li> <li>Cardinality limits ([min,max] notation):<ul> <li>[min, max]</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#chen-notation","title":"Chen Notation","text":"<p>(im using \\nrightarrow\\nrightarrow to express  )</p> <p></p> <p>1:1, 1:N and N:1 can be considered partial functions (often also a total function)</p> <ul> <li>1:1 relationship: R:E_1\\nrightarrow E_2R:E_1\\nrightarrow E_2 and R^{-1}: E_2 \\nrightarrow E_1R^{-1}: E_2 \\nrightarrow E_1 </li> <li>1:N relationship: R^{-1}: E_2 \\nrightarrow E_1R^{-1}: E_2 \\nrightarrow E_1</li> <li>N:1 relationship: R:E_1\\nrightarrow E_2R:E_1\\nrightarrow E_2</li> </ul> <p>also referred to as functional relationship</p> <p>The \"direction\" is important!</p> <p>The function always leads from the \"N\" entity type to the \"1\" entity type.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#graphical-notation","title":"Graphical Notation","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#participation-constraint","title":"Participation Constraint","text":"<p>Total</p> <p>Each entity of an entity type must participate in a relationship, i.e. it cannot exist without any participation (E_2E_2 in the left example)</p> <p></p> <p>Partial</p> <p>Each entity of an entity type can participate in a relationship, i.e., it can exist without any participation.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#graphical-notation_1","title":"Graphical Notation","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#example-relationship","title":"Example Relationship","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#min-max-notation","title":"Min-Max Notation","text":"<p>Special values:</p> <ul> <li>for min: 0</li> <li>for max: *</li> </ul> <p>[0,*] represents no restrictions \\to\\to default</p> <p>The book uses a slightly different notation: 1..* instead of [1, \u2217]</p> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#additional-concepts","title":"Additional Concepts","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#weak-entity-types","title":"Weak Entity Types","text":"<p>The existence of a weak entity depends on the existence of a strong entity (aka. the identifying or owning entity) associated by an identifying relationship</p> <p></p> <ul> <li>Total participation on the weak entity type</li> <li>Only in combination with 1:N (N:1) (or rarely also 1:1) relationship types<ul> <li>The strong entity type is always on the \"1\"-side</li> </ul> </li> <li>Weak entities are uniquely identifiable in combination with the corresponding strong entity's key</li> <li>The weak entity type's key attributes are marked by underlining with a dashed line (partial key, discriminator)</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#isa-relationship-type","title":"ISA Relationship Type","text":"<p>Specialization and generalization is expressed by the ISA relationship type (inheritance)</p> <p></p> <ul> <li> <p>Each sparkling wine entity is associated with exactly one wine entity </p> <p>\\leadsto\\leadsto sparkling wine entities are identifiable by the functional ISA relationship</p> </li> <li> <p>Not every wine is also a sparkling wine</p> </li> <li> <p>Attributes of entity type wine are inherited by entity type sparkling wine</p> </li> </ul> <p></p> <ul> <li>The cardinalities are always<ul> <li>ISA(E_1[1,1],E_2[0,1])ISA(E_1[1,1],E_2[0,1])</li> </ul> </li> <li>Each entity of entity type E_1E_1 (sparkling wine ) participates exactly once, entities of entity type E_2E_2 (wine) participates at most once</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#special-characteristics","title":"Special Characteristics","text":"<ul> <li>Overlapping specialization<ul> <li>An entity may belong to multiple specialized entity sets<ul> <li>separate ISA symbols are used</li> </ul> </li> </ul> </li> <li>Disjoint specialization<ul> <li>An entity may belong to at most one specialized entity set<ul> <li>arrows to a shared ISA symbol in the diagram</li> </ul> </li> </ul> </li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#attributes_1","title":"Attributes","text":"<p>Lower-level entity types inherit:</p> <ul> <li>attributes of the higher-level entity type</li> <li>participation in relationship types of the higher-level entity type</li> </ul> <p>Lower-level entity types can:</p> <ul> <li>have attributes</li> <li>participate in relationship types that the higher-level entity does not participate in</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#participation-constraints","title":"Participation Constraints","text":"<p>Total generalization/specialization</p> <ul> <li>Each higher-level entity must belong to a lower-level entity type<ul> <li>Notation: double line</li> </ul> </li> </ul> <p>Partial generalization/specialization (default)</p> <ul> <li>Each higher-level can (may or may not) belong to a lower-level entity type</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#alternative-notations","title":"Alternative Notations","text":"<p>For alternative notations see DBS3 slides p 108</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#mapping-basic-concepts-to-relations","title":"Mapping Basic Concepts to Relations","text":"<ul> <li>Entities correspond to nouns, relationships to verbs</li> <li>Each statement in the requirement specification should be reflected somewhere in the ER schema</li> <li>Each ER diagram (ERD) should be located somewhere in the requirement specification</li> <li>Conceptual design often reveals inconsistencies and ambiguities in the requirement specification, which must first be resolved.</li> </ul> <p>Basic Approach</p> <ul> <li>For each entity type \\to\\to relation</li> <li>Name of the entity type \\to\\to name of the relation</li> <li>Attributes of the entity type \\to\\to Attributes of the relation</li> <li>Primary key of the entity type \\to\\to Primary key of the relation</li> </ul> <p>We do not care about the order of attributes in this context!</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#mapping-of-nm-relationship-types","title":"Mapping of N:M Relationship Types","text":"<p>Basic Approach</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add the primary key attributes of all involved entity types</li> <li>Primary keys of involved entity types together become the key of the new relation</li> </ul>  \\bold{takes}:\\{[\\underline{\\text{studID} \\to \\text{student}}, \\underline{\\text{courseID} \\to \\text{course}}]\\}   \\bold{takes}:\\{[\\underline{\\text{studID} \\to \\text{student}}, \\underline{\\text{courseID} \\to \\text{course}}]\\}  <p>Key attributes \"imported\" from involved entity types (relations) are called foreign keys</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#in-general","title":"In General","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#mapping-of-1n-relationship-types","title":"Mapping of 1:N Relationship Types","text":"<p>Basic Approach</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add the primary key attributes of all involved entity types</li> <li>Primary key of the \"N\"-side becomes the key in the new relation</li> </ul> <p>Initial</p>  \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ &amp;\\bold{teaches} &amp;&amp;: \\{[\\underline{\\text{courseID}\\to \\text{course}}, \\text{empID} \\to \\text{professor}]\\} \\end{align*}   \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ &amp;\\bold{teaches} &amp;&amp;: \\{[\\underline{\\text{courseID}\\to \\text{course}}, \\text{empID} \\to \\text{professor}]\\} \\end{align*}  <p>Improved by Merging</p>  \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}, \\color{darkred}{\\text{taughtBy} \\to \\text{professor}}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ \\end{align*}   \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}, \\color{darkred}{\\text{taughtBy} \\to \\text{professor}}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ \\end{align*}  <p>Relations with the same key can be combined, but  only these and no others!</p> <p>If the participation is not total, merging requires null values for the foreign key. In such cases, it might be preferable for some applications to have a separate relation.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#mapping-of-11-relationship-types","title":"Mapping of 1:1 Relationship Types","text":"<ul> <li>New relation with all attributes of the relationship type</li> <li>Add primary key attributes of all involved entity types</li> <li>Primary key of any of the involved entity types can become the key in the new relation</li> </ul> <p>Initial</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\underline{vineyard}, address}\\\\ \\relational{owns}{\\underline{licenseID \\to license}, vineyard \\to producer}\\text{ or}\\\\ \\relational{owns}{licenseID \\to license, \\underline{vineyard \\to producer}} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\underline{vineyard}, address}\\\\ \\relational{owns}{\\underline{licenseID \\to license}, vineyard \\to producer}\\text{ or}\\\\ \\relational{owns}{licenseID \\to license, \\underline{vineyard \\to producer}} \\end{align*}  <p>Improvement</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount, ownedBy \\to producer}\\\\ \\relational{producer}{\\pk{vineyard}, address} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount, ownedBy \\to producer}\\\\ \\relational{producer}{\\pk{vineyard}, address} \\end{align*}  <p>Or</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\pk{vineyard}, address, ownsLicense \\to license} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\pk{vineyard}, address, ownsLicense \\to license} \\end{align*}  <p>It is best to extend a relation of an entity type with total participation</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#summary-mapping-relationship-types-to-relations","title":"Summary: Mapping Relationship Types to Relations","text":"<p>M:N</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add attributes referencing the primary keys of the involved entity type relations</li> <li>Primary key: set of foreign keys</li> </ul> <p>1:N</p> <ul> <li>Add information to the entity type relation of the \u201cN\u201d-side:<ul> <li>Add foreign key referencing the primary key of the \u201c1\u201d-side entity type relation</li> <li>Add attributes of the relationship type</li> </ul> </li> </ul> <p>1:1</p> <ul> <li>Add information to one of the involved entity type relations:<ul> <li>Add foreign key referencing the primary key of the other entity type relation</li> <li>Add attributes of the relationship type</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#foreign-keys","title":"Foreign Keys","text":"<p>A foreign key is an attribute (or a combination of attributes) of a relation that references the primary key (or candidate key) of another relation</p> <p>Example</p> <ul> <li>\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy \\to professor}}\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy \\to professor}}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> </ul> <p>Here \\mathrm{taughtBy}\\mathrm{taughtBy} is a foreign key referencing relation professor</p> <p>Alternative Notation</p> <ul> <li>\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy}}\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy}}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> </ul> <p>Foreign key: \\mathrm{course.taughtBy \\to professor.empID}\\mathrm{course.taughtBy \\to professor.empID}</p> <p>Notation for composite keys: \\{R.A_1, R.A_2\\} \\to \\{S.B_1, S.B_2\\}\\{R.A_1, R.A_2\\} \\to \\{S.B_1, S.B_2\\}</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#mapping-additional-concepts-to-relations","title":"Mapping Additional Concepts to Relations","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#weak-entity-types_1","title":"Weak Entity Types","text":"<p>Entities of a weak entity type are</p> <ul> <li>existentially dependent on a strong entity type</li> <li>uniquely identifiable in combination with the strong entity type's key</li> </ul> <p></p> <p>Mapping:</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add primary key attributes of all involved entity types</li> <li>Foreign key of the \"N\"-side becomes the key in the new relation</li> </ul> <p>Initially</p> <ul> <li>\\relation{wine}{color,\\pk{name}}\\relation{wine}{color,\\pk{name}}</li> <li>\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}</li> <li>\\relation{belongsTo}{\\pk{name \\to wine, year \\to vintage}}\\relation{belongsTo}{\\pk{name \\to wine, year \\to vintage}}</li> </ul> <p>Merged</p> <p>Weak entity types and their identifying relationship types can always be merged</p> <ul> <li>\\relation{wine}{color,\\pk{name}}\\relation{wine}{color,\\pk{name}}</li> <li>\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}</li> </ul> <p>More complex example in DBS3 slides p 157</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#recursive-relationship-types","title":"Recursive Relationship Types","text":"<p>Mapping just like standard N:M relationship types and renaming of foreign keys</p> <ul> <li>\\relation{area}{\\pk{name}, region}\\relation{area}{\\pk{name}, region}</li> <li>\\relation{border}{\\pk{from\\to area, to \\to area}}\\relation{border}{\\pk{from\\to area, to \\to area}}</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#recursive-functional-relationship-types","title":"Recursive Functional Relationship Types","text":"<p>Mapping just like standard 1:N relationship types and merging</p> <ul> <li>\\relation{critic}{\\pk{name}, organization, mentor \\to critic}\\relation{critic}{\\pk{name}, organization, mentor \\to critic}</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#n-ary-relationship-types","title":"N-ary Relationship Types","text":"<p>Entity Types</p> <ul> <li>All participating entity types are mapped according to the standard rules</li> <li>\\relation{critic}{\\pk{name}, organization}\\relation{critic}{\\pk{name}, organization}</li> <li>\\relation{dish}{\\pk{description}, sideOrder}\\relation{dish}{\\pk{description}, sideOrder}</li> <li>\\relation{wine}{color, \\pk{WName}, year, residualSweetness}\\relation{wine}{color, \\pk{WName}, year, residualSweetness}</li> </ul> <p>N-ary Relationship Types (N:M:P)</p> <ul> <li>\\relation{recommends}{\\pk{WName \\to wine, description \\to dish, name \\to critic}}\\relation{recommends}{\\pk{WName \\to wine, description \\to dish, name \\to critic}}</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#nm1-relationship-type","title":"N:M:1 Relationship Type","text":"<p>Relations</p> <ul> <li>\\relation{student}{\\pk{studID}, name, semester}\\relation{student}{\\pk{studID}, name, semester}</li> <li>\\relation{course}{\\pk{courseID}, title, ects}\\relation{course}{\\pk{courseID}, title, ects}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{grades}{\\pk{studID\\to student, courseID\\to course},empID \\to professor, grade}\\relation{grades}{\\pk{studID\\to student, courseID\\to course},empID \\to professor, grade}</li> </ul> <p>A student + course only exists once in this relation, since the professor is the (1). Therefore, the professor is not part of the primary key.</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#multi-valued-attributes","title":"Multi-Valued Attributes","text":"<p>Relations</p> <ul> <li>\\relation{person}{\\pk{PID}, name}\\relation{person}{\\pk{PID}, name}</li> <li>\\relation{phoneNumber}{\\pk{PID \\to person, number}}\\relation{phoneNumber}{\\pk{PID \\to person, number}}</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#composite-attributes","title":"Composite Attributes","text":"<p>Include the component attributes in the relation</p> <ul> <li>\\relation{person}{\\pk{PID}, name, street, city}\\relation{person}{\\pk{PID}, name, street, city}</li> </ul>"},{"location":"6-semester/DBS/03-entity-relationship-model/#derived-attributes","title":"Derived Attributes","text":"<p>Ignored during mapping to relations, can be added later by using views</p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#overview-of-the-steps","title":"Overview of the steps","text":"<ol> <li>Regular entity type<ul> <li>Create a relation, consider special attribute types</li> </ul> </li> <li> <p>Weak entity type</p> <ul> <li>Create a relation</li> </ul> </li> <li> <p>1:1 binary relationship type </p> <ul> <li>Extend a relation with foreign key</li> </ul> </li> <li>1:N binary relationship type <ul> <li>Extend a relation with foreign key</li> </ul> </li> <li>N:M relationship type<ul> <li>Create a relation</li> </ul> </li> <li>N-ary relationship type<ul> <li>Create a relation</li> </ul> </li> </ol>"},{"location":"6-semester/DBS/03-entity-relationship-model/#relational-modeling-of-generalization","title":"Relational Modeling of Generalization","text":""},{"location":"6-semester/DBS/03-entity-relationship-model/#alternative-1-main-classes","title":"Alternative 1 - Main Classes","text":"<p>A particular entity is mapped to a single tuple in a single relation (to its main class)</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{assistant}{\\pk{empID}, name, department}\\relation{assistant}{\\pk{empID}, name, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#alternative-2-partitioning","title":"Alternative 2 - Partitioning","text":"<p>Parts of a particular entity are mapped to multiple relations, the key is duplicated</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID \\to employee}, rank, office}\\relation{professor}{\\pk{empID \\to employee}, rank, office}</li> <li>\\relation{assistant}{\\pk{empID\\to employee}, department}\\relation{assistant}{\\pk{empID\\to employee}, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#alternative-3-full-redundancy","title":"Alternative 3 - Full Redundancy","text":"<p>A particular entity is stored redundantly in the relations with all its inherited attributes</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{assistant}{\\pk{empID}, name, department}\\relation{assistant}{\\pk{empID}, name, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#alternative-4-single-relation","title":"Alternative 4 - Single Relation","text":"<p>All entities are stored in a single relation. An additional attribute encodes the membership in a particular entity type.</p> <ul> <li>\\relation{employee}{\\pk{empID}, name, {\\color{darkred}{type}}, rank, office, department}\\relation{employee}{\\pk{empID}, name, {\\color{darkred}{type}}, rank, office, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/03-entity-relationship-model/#appendix","title":"Appendix","text":"<p>Appendix can be seen in DBS3 slides 185</p>"},{"location":"6-semester/DBS/04-relational-database-theory/","title":"Relational Database Design Theory","text":"\\newcommand{\\dep}[2]{\\{#1\\} \\to \\{#2\\}} \\newcommand{\\schema}{\\mathcal{R}} \\newcommand{\\oneton}[1]{\\onetonop{#1}{,}} \\newcommand{\\onetonop}[2]{#1_{n} #2 \\dots #2  #1_{n}} \\nonumber  <p>Learning Goals</p> <ul> <li>Understanding the concepts of functional dependencies and normal forms</li> <li>Describe the quality of a design by using normal forms</li> <li>Improving a database design by decomposition</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#functional-dependencies","title":"Functional Dependencies","text":"<p>Symbols:</p> <ul> <li>Schema \\mathcal R = \\{A,B,C,D\\}\\mathcal R = \\{A,B,C,D\\}</li> <li>Instance RR</li> <li>Let \\alpha \\subseteq \\mathcal R\\alpha \\subseteq \\mathcal R and \\beta \\subseteq \\mathcal R\\beta \\subseteq \\mathcal R be sets of attributes</li> </ul> <p>A functional dependency \\alpha \\to \\beta\\alpha \\to \\beta holds on \\mathcal R\\mathcal R if for all legal instances RR of \\schema\\schema:</p>  \\forall r,s \\in R: r.\\alpha = s.\\alpha \\Rightarrow r.\\beta = s.\\beta   \\forall r,s \\in R: r.\\alpha = s.\\alpha \\Rightarrow r.\\beta = s.\\beta  <p>The \\alpha\\alpha values uniquely identify the \\beta\\beta values</p> <p>\\alpha\\alpha functionally determines \\beta\\beta</p> <p>A functional dependency \\alpha \\to \\beta\\alpha \\to \\beta is called trivial if \\beta \\subseteq \\alpha\\beta \\subseteq \\alpha</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#examples","title":"Examples","text":"<p>If I have a zip code, I know the town</p> <ul> <li>Zip code 9220 gives one and only one town : Aalborg</li> <li>Zip code 9000 will not return { Aalborg, Viborg }</li> </ul> <p>Notation: { zipCode } \\to\\to { town }</p> <p></p> <p>Functional dependencies are semantic constraints that need to be true for all possible instances, not just for the current one!</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#keys","title":"Keys","text":""},{"location":"6-semester/DBS/04-relational-database-theory/#super-keys","title":"Super Keys","text":"<p>\\alpha \\subseteq \\schema\\alpha \\subseteq \\schema is a super key if \\alpha \\to \\schema\\alpha \\to \\schema, i.e. \\alpha\\alpha determines all attribute values</p> <ul> <li>The set of all attributes is a super key: \\schema \\to \\schema\\schema \\to \\schema</li> <li>Super keys are not necessarily minimal</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#fully-functional-dependent","title":"Fully Functional Dependent","text":"<p>\\beta\\beta is fully functionally dependent on \\alpha\\alpha if:</p> <ul> <li>\\alpha \\to \\beta\\alpha \\to \\beta and</li> <li>\\alpha\\alpha cannot be further reduced (= left reduced), i.e.</li> </ul>  \\forall A \\in \\alpha:(\\alpha - \\{A\\}) \\nrightarrow \\beta   \\forall A \\in \\alpha:(\\alpha - \\{A\\}) \\nrightarrow \\beta"},{"location":"6-semester/DBS/04-relational-database-theory/#candidate-keys","title":"Candidate Keys","text":"<p>\\alpha\\in\\schema\\alpha\\in\\schema is a candidate key if \\schema\\schema is fully functionally dependent on \\alpha\\alpha.</p> <ul> <li>One of the candidate keys is chosen as primary key</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#deriving-functional-dependencies","title":"Deriving Functional Dependencies","text":"<p>Given a set of FDs (Functional dependencies) FF we can derive additional FDs</p> <ul> <li>F^+F^+ contains all FDs that can be derived from FF, i.e., all FDs logically implied by dependencies in FF</li> <li>F^+F^+ is FF's closure</li> <li>Inference rules (Armstrong Axioms) help computing F^+F^+</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#armstrong-axioms","title":"Armstrong Axioms","text":"<p>\\alpha, \\beta, \\gamma, \\delta\\alpha, \\beta, \\gamma, \\delta are subsets of attributes in \\schema\\schema</p> <p>Reflexivity</p> <p>If \\beta \\subseteq \\alpha\\beta \\subseteq \\alpha then \\alpha \\to \\beta\\alpha \\to \\beta     in particular: \\alpha \\to \\alpha\\alpha \\to \\alpha</p> <p>Augmentation</p> <p>If \\alpha \\to \\beta\\alpha \\to \\beta then \\alpha \\gamma \\to \\alpha\\gamma\\alpha \\gamma \\to \\alpha\\gamma</p> <p>Transitivity</p> <p>If \\alpha \\to \\beta\\alpha \\to \\beta and \\beta \\to \\gamma\\beta \\to \\gamma then \\alpha \\to \\gamma\\alpha \\to \\gamma</p> <p>The Armstrong axioms are sound and complete.</p> <ul> <li>They are sound in the sense that they generate only correct functional dependencies</li> <li>They are complete in the sense that they generate all possible FDs (F^+F^+) from a given set FF</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#additional-rules","title":"Additional Rules","text":"<p>Not essential, but sound and ease the derivation process</p> <p>Union</p> <p>If \\alpha\\to\\beta\\alpha\\to\\beta and \\alpha\\to\\gamma\\alpha\\to\\gamma then \\alpha\\to\\beta\\gamma\\alpha\\to\\beta\\gamma</p> <p>Decomposition</p> <p>If \\alpha\\to\\beta\\gamma\\alpha\\to\\beta\\gamma then \\alpha\\to\\beta\\alpha\\to\\beta and \\alpha\\to\\gamma\\alpha\\to\\gamma</p> <p>Pseudotransitivity</p> <p>If \\alpha\\to\\beta\\alpha\\to\\beta and \\gamma\\beta\\to\\delta\\gamma\\beta\\to\\delta then \\alpha\\gamma\\to\\delta\\alpha\\gamma\\to\\delta</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#examples_1","title":"Examples","text":"<p>Given the following functional dependencies FF, derive additional ones by applying the Armstrong axioms</p> <ul> <li>A \u2192 BC</li> <li>CD \u2192 E</li> <li>B \u2192 D</li> <li>E \u2192 A</li> </ul> <p>Derived FDs</p> <ul> <li>E \u2192 A and A \u2192 BC, then E \u2192 BC (transitivity)</li> <li>B \u2192 D, then CB \u2192 CD (augmentation)</li> <li>CB \u2192 CD and CD \u2192 E, then CB \u2192 E (transitivity)</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#closure-of-a-set-of-attributes","title":"Closure of a Set of Attributes","text":"<p>The closure of a set of attributes (\\alpha^+\\alpha^+) with respect to a set of FDs FF and a set of attributes \\alpha\\alpha is </p>  \\alpha^+ = \\{A\\mid \\alpha\\to A \\in F^+\\}   \\alpha^+ = \\{A\\mid \\alpha\\to A \\in F^+\\}  <p>Observation:</p> <ul> <li>If \\alpha\\to \\beta\\alpha\\to \\beta is in F^+F^+ then \\beta\\beta is in \\alpha^+\\alpha^+</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#attribute-closure-algorithm","title":"Attribute Closure Algorithm","text":"<p>Input:</p> <ul> <li>a set FF of FDs</li> <li>a set of attributes \\alpha \\in \\schema\\alpha \\in \\schema</li> </ul> <p></p> <p>Applications:</p> <ul> <li>Test if a functional dependency \\alpha \\to \\beta\\alpha \\to \\beta holds</li> <li>Test if a given set of attributes \\kappa \\subseteq \\schema\\kappa \\subseteq \\schema is a super key</li> <li>Test for super keys<ul> <li>By calling attrClosure(F, \\kappaF, \\kappa) we obtain \\kappa^+\\kappa^+<ul> <li>if \\kappa^+ = \\schema\\kappa^+ = \\schema then \\kappa\\kappa is a super key of \\schema\\schema</li> </ul> </li> </ul> </li> </ul> <p>Example in DBS4 slides p 49</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#canonical-cover-minimal-cover","title":"Canonical Cover (Minimal Cover)","text":"<ul> <li>Two sets of FDs FF and GG are considered equivalent F \\equiv GF \\equiv G if their closures are the same i.e. F^+ = G^+F^+ = G^+</li> <li>Both sets allow for deriving the same set of FDs</li> </ul> <p>Observation</p> <ul> <li>F^+F^+ can be huge</li> <li>Many redundant dependencies</li> <li>Difficult to overview</li> </ul> <p>Goal:</p> <ul> <li>Find the smallest possible set F_cF_c for FF so that F^+_c \\equiv F^+F^+_c \\equiv F^+<ul> <li>There might be alternative minimal sets!</li> </ul> </li> </ul> <p>A minimal cover F_cF_c is a canonical representation of a set FF of functional dependencies</p> <p>Characteristics:</p> <ol> <li> <p>F_c \\equiv FF_c \\equiv F therefore F_c^+ = F^+F_c^+ = F^+ (equivalent if closures are the same)</p> </li> <li> <p>FDs \\alpha \\to \\beta\\alpha \\to \\beta in F_cF_c do not contain extraneous attributes, i.e.:</p> <ol> <li>\\forall A \\in \\alpha:(F_c - \\{\\alpha \\to \\beta\\})\\cup \\{(\\alpha - A) \\to \\beta\\} \\not\\equiv F_c\\forall A \\in \\alpha:(F_c - \\{\\alpha \\to \\beta\\})\\cup \\{(\\alpha - A) \\to \\beta\\} \\not\\equiv F_c</li> <li>\\forall B \\in \\beta:(F_c - \\{\\alpha \\to \\beta\\})\\cup \\{\\alpha - (\\beta - B)\\} \\not\\equiv F_c\\forall B \\in \\beta:(F_c - \\{\\alpha \\to \\beta\\})\\cup \\{\\alpha - (\\beta - B)\\} \\not\\equiv F_c</li> </ol> </li> <li> <p>The left side of an FD in F_cF_c is unique.</p> <p>Applying the union rule \\alpha \\to \\beta\\alpha \\to \\beta and \\alpha \\to \\gamma\\alpha \\to \\gamma can be combined to \\alpha\\to\\beta\\gamma\\alpha\\to\\beta\\gamma</p> </li> </ol> <p>Check if Attribute is extraneous</p> <ul> <li>Check if A \u2208 \u03b1 is an extraneous attribute in \u03b1 \u2192 \u03b2 by computing the attribute closure:<ul> <li>A \u2208 \u03b1 is extraneous if \u03b2 \u2286 attrClosure(F, \u03b1 \u2212 A)</li> </ul> </li> <li>Check if B \u2208 \u03b2 is an extraneous attribute in \u03b1 \u2192 \u03b2 by computing the attribute closure:<ul> <li>B \u2208 \u03b2 is extraneous if<ul> <li>B \u2208 attrClosure((F \u2212 {\u03b1 \u2192 \u03b2}) \u222a {\u03b1 \u2192 (\u03b2 \u2212 B)}, \u03b1)</li> </ul> </li> </ul> </li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#minimal-cover-algorithm","title":"Minimal Cover Algorithm","text":"<ul> <li> <p>Page 325 in book (PDF page 354)</p> </li> <li> <p>Example in DBS4 slides p 69</p> </li> <li>See guide in guides/minimal-cover</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#normalization-by-decomposition-of-relations","title":"Normalization by Decomposition of Relations","text":""},{"location":"6-semester/DBS/04-relational-database-theory/#normalization-by-decomposition","title":"Normalization by decomposition","text":"<p>Decompose a relation schema \\schema\\schema into multiple relational schemas \\schema_1,\\dots\\schema_n\\schema_1,\\dots\\schema_n to eliminate problems in the original design</p> <p>Normal forms</p> <ul> <li>Normal forms describe the quality of a design</li> <li>1NF, 2NF, 3NF, BCNF, 4NF, \\dots\\dots</li> <li>Prohibit particular functional dependencies in a relation to avoid redundancy, null values, and anomalies</li> </ul> <p>Good ER modeling typically directly leads to 3NF (or higher NF) relations</p> <p>Normalization eliminates problems caused by functional dependencies among attributes of any entity type</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#valid-and-lossless-decompositions","title":"Valid and Lossless Decompositions","text":"<p>A decomposition is valid if  \\schema = \\schema_1 \\cup \\schema_2\\schema = \\schema_1 \\cup \\schema_2, i.e. no attributes in \\schema\\schema get lost</p> <ul> <li>R_1 := \\pi_{\\schema_1}(R)R_1 := \\pi_{\\schema_1}(R)</li> <li>R_2 := \\pi_{\\schema_2}(R)R_2 := \\pi_{\\schema_2}(R)</li> </ul> <p>A decomposition of \\schema\\schema into \\schema_1\\schema_1 and \\schema_2\\schema_2 is lossless if the following holds for all possible instances RR of \\schema\\schema (also referred to as lossless-join decomposition):</p>  R=R_1 \\Join R_2   R=R_1 \\Join R_2  <p>All data contained in the original instance RR of schema \\schema\\schema must be reconstructible with a natural join from the instances R_1,\\dots,R_nR_1,\\dots,R_n of the new schemas \\schema_1,\\dots,\\schema_n\\schema_1,\\dots,\\schema_n</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#formal-characterization-of-a-lossless-decomposition","title":"Formal Characterization of a Lossless Decomposition","text":"<p>Given</p> <ul> <li>A decomposition of \\schema\\schema into \\schema_1\\schema_1 and \\schema_2\\schema_2</li> <li>F_\\schemaF_\\schema is the set of FDs in \\schema\\schema</li> </ul> <p>A decomposition is lossless if we can derive at least one of the following FDs:</p> <ul> <li>(\\schema_1 \\cap \\schema_2) \\to \\schema_1 \\in F_\\schema^+(\\schema_1 \\cap \\schema_2) \\to \\schema_1 \\in F_\\schema^+     i.e., common attributes are super key in \\schema_1\\schema_1 or</li> <li>(\\schema_1 \\cap \\schema_2) \\to \\schema_2 \\in F_\\schema^+(\\schema_1 \\cap \\schema_2) \\to \\schema_2 \\in F_\\schema^+     i.e., common attributes are super key in \\schema_2\\schema_2</li> </ul> <p>If this is not the case, the decomposition is said to be lossy</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#example-of-a-lossy-decomposition","title":"Example of a LOSSY Decomposition","text":"<p>The relationship between guest, pub, and beer got lost.</p> <p>Lossy decomposition sometimes means that the reconstruction leads to additional tuples.</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#dependency-preservation","title":"Dependency Preservation","text":"<p>Second characteristic of a good decomposition</p> <p>All functional dependencies that hold for \\schema\\schema must be verifiable in the new schemas \\schema_1,\\dots,\\schema_n\\schema_1,\\dots,\\schema_n </p> <ul> <li>We can check all dependencies locally on \\oneton{\\schema}\\oneton{\\schema} </li> <li>We avoid the alternative: computing the join \\onetonop{\\schema}{\\Join}\\onetonop{\\schema}{\\Join} to test if an FD is violated</li> </ul> <p>A decomposition is dependency preserving if $$ F_{\\schema} \\equiv (F_{\\schema_1} \\cup \\cdots \\cup F_{\\schema_n}) $$ i.e. $F^+\\schema = (F{\\schema_1} \\cup \\cdots \\cup F_{\\schema_n})^+ $  with F_{\\schema_i}F_{\\schema_i} representing functional dependencies that can be checked efficiently on R_iR_i</p> <p>Example</p> <p>The following is dependency preserving, since we can check all FDs locally (A\\to BA\\to B on R_1R_1 and B\\to CB\\to C on R_2R_2)</p> <p></p> <p>The next one is not dependency preserving, since we cannot check B\\to CB\\to C on any of the new relations!</p> <p></p> <p></p> <p>Examples in DBS4 slides p 90</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#summary-functional-dependencies","title":"Summary Functional Dependencies","text":""},{"location":"6-semester/DBS/04-relational-database-theory/#normal-forms","title":"Normal Forms","text":"<p>Normal forms</p> <ul> <li>define characteristics of relational schemas</li> <li>forbid certain combinations of FDs in a relation</li> <li>avoid redundancies and anomalies</li> <li>guideline to obtain good decompositions</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#first-normal-form-1nf","title":"First Normal Form 1NF","text":"<p>A relation \\schema\\schema is in 1NF if the domains of all its attributes are atomic (no composite or set-valued domains)</p> <p></p>"},{"location":"6-semester/DBS/04-relational-database-theory/#third-normal-form-3nf","title":"Third Normal Form 3NF","text":"<p>A relation schema \\schema\\schema is in 3NF if at least one of the following conditions holds for each of its FDs \\alpha \\to B\\alpha \\to B with B \\in \\schemaB \\in \\schema</p> <ol> <li>B \\in \\alphaB \\in \\alpha, i.e. the FD is trivial</li> <li>\\alpha\\alpha is a super key of RR</li> <li>BB is part of a candidate key for \\schema\\schema</li> </ol> <p>Main characteristics</p> <ul> <li>3NF prevents (some) transitive dependencies</li> <li>Exception: Condition 3</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#non-example","title":"Non-Example","text":"<p>The relation is not in 3NF</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#eliminates-transitive-dependencies","title":"Eliminates Transitive Dependencies","text":""},{"location":"6-semester/DBS/04-relational-database-theory/#boyce-codd-normal-form-bcnf","title":"Boyce Codd Normal Form BCNF","text":"<p>A relation schema \\schema\\schema is in BCNF if at least one of the following conditions holds for each of its FDs \\alpha \\to B\\alpha \\to B with B \\in \\schemaB \\in \\schema</p> <ol> <li>B \\in \\alphaB \\in \\alpha, i.e. the FD is trivial</li> <li>\\alpha\\alpha is a super key of RR</li> </ol> <p>Main characteristics</p> <ul> <li>Difference to 3NF: no third option (BB is part of a candidate key for \\schema\\schema)</li> <li>BCNF is more strict than 3NF (\u201cincludes\u201d 3NF)</li> <li>BCNF prevents all transitive dependencies</li> </ul>"},{"location":"6-semester/DBS/04-relational-database-theory/#example","title":"Example","text":"<p>3NF vs. BCNF</p> <p></p> <p>Is the relation in 3NF?</p> <p></p> <p>YES</p> <p>Is the relation in BCNF?</p> <p></p> <p>NO</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#decomposition","title":"Decomposition","text":"<p>It is always possible to decompose a relational schema \\schema\\schema with FDs FF into</p> <ul> <li>3NF relational schemas \\oneton{\\schema}\\oneton{\\schema} so that the decomposition is<ul> <li>lossless</li> <li>dependency preserving</li> </ul> </li> <li>BCNF relational schema \\oneton{\\schema}\\oneton{\\schema} so that the decomposition is<ul> <li>lossless</li> </ul> </li> </ul> <p>It is not always possible to create a BCNF decomposition \\oneton{\\schema}\\oneton{\\schema} of \\schema\\schema that is dependency preserving</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#decomposition-algorithm-for-bcnf","title":"Decomposition Algorithm for BCNF","text":"<p>Instead of computing F^+F^+ to check \\alpha\\alpha for its super key characteristics, we can compute \\alpha^+\\alpha^+ for this purpose</p> <p>Example in DBS4 slides p 133-</p>"},{"location":"6-semester/DBS/04-relational-database-theory/#summary","title":"Summary","text":"Normal Form Main Characteristics 1NF Only atomic attributes 3NF Some transitive dependencies BCNF No transitive dependencies <p>In practice, if a BCNF composition is impossible without loosing dependency preservation, we go for the 3NF decomposition (although it allows for some redundancy)</p> <p>Decomp. algorithms for all normal forms guarantee lossless decompositions.</p> <p>Dependency preservation can only be guaranteed until 3NF.</p> <p></p>"},{"location":"6-semester/DBS/05-sql/","title":"SQL","text":"\\newcommand{\\relationRaw}[3]{     \\newcommand{\\pk}{\\underline}     #3\\mathbf{#1}#3#3:\\{[\\mathrm{#2}]\\} } \\newcommand{\\relation}[2]{\\relationRaw{#1}{#2}{}} \\newcommand{\\relational}[2]{\\relationRaw{#1}{#2}{&amp;}} \\nonumber  <p>Learning Goals</p> <ul> <li>Explain and use the SQL data model </li> <li>Create non-trivial database tables </li> <li>Modify non-trivial database tables </li> <li>Create non-trivial SQL statements</li> </ul>"},{"location":"6-semester/DBS/05-sql/#sql_1","title":"SQL","text":"<p>SQL is a declarative query language (\"what\" not \"how\")</p> <p>It consists of multiple parts</p> <p>Data Definition Language (DDL)</p> <ul> <li>Create/change the schema</li> <li>create, alter, drop</li> </ul> <p>Data Manipulation Language (DML)</p> <ul> <li>Changes to an instance</li> <li>insert, update, delete</li> </ul> <p>Data Query Language (DQL)</p> <ul> <li>Evaluate queries on an instance</li> <li>select * from where ... </li> </ul> <p>Transaction Control Language (TCL)</p> <ul> <li>Controls transactions</li> <li>commit, rollback</li> </ul> <p>Data Control Language (DCL)</p> <ul> <li>Grant/revoke access rights</li> <li>grant, revoke</li> </ul>"},{"location":"6-semester/DBS/05-sql/#basic-data-definitions","title":"Basic Data Definitions","text":"<p>Data Types</p> <ul> <li>character(n), char(n)</li> <li>character varying(n), varchar(n)</li> <li>integer, smallint</li> <li>numeric(p,s), decimal(p,s), ...<ul> <li>p - precision: max number of digits in total</li> <li>s - scale: number of digits after the comma</li> </ul> </li> <li>real, double</li> <li>blob or raw for very large binary data</li> <li>clob for large string attributes</li> <li>data for dates</li> <li>xml for xml documents</li> <li>...</li> </ul> <p>varchar vs char</p> <ul> <li>Both are limited to a length of n</li> <li>char always uses n bytes</li> <li>varchar uses only the required place, plus length information</li> </ul>"},{"location":"6-semester/DBS/05-sql/#create-tables","title":"Create Tables","text":"<pre><code>CREATE TABLE professor(\nempidinteger UNIQUE NOT NULL,\nnamevarchar(10) NOT NULL,\nrankchar(2));\n</code></pre> <p>Is equal to</p> <pre><code>CREATE TABLE professor(\nempidinteger PRIMARY KEY,\nnamevarchar(10) NOT NULL,\nrankchar(2));\n</code></pre> <p>The <code>PRIMARY KEY</code> constraint includes the <code>NOT NULL</code> and <code>UNIQUE</code> constraints.</p>"},{"location":"6-semester/DBS/05-sql/#foreign-keys","title":"Foreign Keys","text":"<pre><code>CREATE TABLE course(\ncourseID integer,\ntitle varchar(30) NOT NULL,\nects integer,\ntaughtby integer,\nPRIMARY KEY(courseID),\nFOREIGN KEY(taughtBy) REFERENCES professor(empID)\n);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#default-values","title":"Default Values","text":"<p>When inserting data into a table, all values that are not explicitly stated are set to null (standard default value).</p> <p>When defining a table, we can specify another default value</p> <pre><code>CREATE TABLE wine(\nwineID      integer NOT NULL,\nname        varchar(20) NOT NULL,\ncolor       varchar(10) DEFAULT 'red',\nyear        integer,\nvineyard    varchar(20)\n);\n</code></pre> <p>Here the default value of color will be 'red'</p>"},{"location":"6-semester/DBS/05-sql/#sequence-number-generators","title":"Sequence Number Generators","text":"<p>Sequence number generators automatically create continuous identifiers.</p> <pre><code>CREATE SEQUENCE serial START 101;\nCREATE TABLE wine(\nwineID integer PRIMARY KEY DEFAULT nextval(\u2019serial\u2019),\nname varchar(20) NOT NULL,\ncolor varchar(10),\nyear integer,\nvineyard varchar(20)\n);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#alter-tables","title":"Alter Tables","text":"<p>Initial version</p> <pre><code>CREATE TABLE professor(\nempid integer NOT NULL,\nname varchar(10) NOT NULL,\nrank char(2)\n);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#change-table-definitions","title":"Change Table Definitions","text":"<p>Add an attribute</p> <pre><code>ALTER TABLE professor\nADD COLUMN (office integer);\n</code></pre> <p>Delete an attribute</p> <pre><code>ALTER TABLE professor\nDROP COLUMN name;\n</code></pre> <p>Change an attribute type</p> <pre><code>ALTER TABLE professor\nALTER COLUMN name type varchar(30);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#deletion-of-a-table","title":"Deletion of a Table","text":"<p>Delete a table</p> <pre><code>DROP TABLE professor;\n</code></pre> <p>Delete the content of a table</p> <pre><code>TRUNCATE TABLE professor;\n</code></pre> <p>Cannot be used if there is another table with a foreign key referencing the table that we want to delete.</p>"},{"location":"6-semester/DBS/05-sql/#data-insertion","title":"Data Insertion","text":"<p>Standard insertion w3schools Insert Into:</p> <pre><code>INSERT INTO table_name (column1, column2, column3, ...)\nVALUES (value1, value2, value3, ...); </code></pre> <pre><code>INSERT INTO takees\nSELECT studid, courseid\nFROM student, course\nWHERE title = 'Logics';\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#rights-management","title":"Rights Management","text":"<p>DCL</p> <p>Grant access rights</p> <pre><code>GRANT select, update\nON professor\nTO some user, another user;\n</code></pre> <pre><code>GRANT select (empid), update (office)\nON professor\nTO some user, another user;\n</code></pre> <p>Revoke access rights</p> <pre><code>REVOKE ALL PRIVILEGES\nON professor\nFROM some user, another user;\n</code></pre> <p>Privileges (rights) on tables, columns,. . . : <code>select</code>, <code>insert</code>, <code>update</code>, <code>delete</code>, <code>rule</code>, <code>references</code>, <code>trigger</code></p>"},{"location":"6-semester/DBS/05-sql/#query-language","title":"Query Language","text":"<p>Basic building block of an SQL query (SFW block)</p> <ul> <li><code>SELECT &lt;list of columns&gt;</code><ul> <li>projection list with arithmetic operators and aggregation functions</li> </ul> </li> <li><code>FROM &lt;list of tables&gt;</code><ul> <li>list of involved tables, with optional renaming</li> </ul> </li> <li><code>WHERE &lt;condition&gt;</code><ul> <li>selection and join conditions, nested queries</li> </ul> </li> </ul> <p>Relational algebra \u2192 SQL</p> <ul> <li>projection \u03c0 \u2192 <code>SELECT</code></li> <li>cross product \u00d7 \u2192 <code>FROM</code></li> <li>selection \u03c3 \u2192 <code>WHERE</code></li> </ul>"},{"location":"6-semester/DBS/05-sql/#cross-product","title":"Cross Product","text":"<p>If the from clause enumerates more than a single table, the cross product is computed.</p> <pre><code>SELECT *\nFROM wine, producer;\n</code></pre> <p>The result is the set of all combinations of tuples in the involved tables!</p>"},{"location":"6-semester/DBS/05-sql/#duplicate-elimination","title":"Duplicate Elimination","text":"<p>The <code>DISTINCT</code> keyword removes duplicated entries. </p> <pre><code>SELECT name\nFROM wine;\n</code></pre> <p></p> <pre><code>SELECT DISTINCT name\nFROM wine;\n</code></pre> <p>Corresponds to the projection operation in relational algebra!</p> <p></p>"},{"location":"6-semester/DBS/05-sql/#set-operations","title":"Set Operations","text":"<p>Set operations require union compatibility: </p> <ul> <li> <p>same number of attributes with compatible domains.</p> </li> <li> <p>domains are identical </p> </li> <li>domains are based on characters (length does not matter) </li> <li>domains are based on numerical values (exact type does not matter, e.g., integer and float)</li> </ul> <p>Result schema: column names of the first table</p> <p>For set operations, duplicate elimination (e.g., <code>UNION DISTINCT</code>) is the default!</p> <pre><code>(SELECT name\nFROM assistant)\nUNION\n(SELECT name\nFROM assistant);\n</code></pre> <pre><code>(SELECT name\nFROM assistant)\nUNION DISTINCT\n(SELECT name\nFROM assistant);\n</code></pre> <pre><code>(SELECT name\nFROM assistant)\nUNION ALL\n(SELECT name\nFROM assistant);\n</code></pre> <p>Intersection (<code>INTERSECT</code>) and set minus (<code>EXCEPT</code>) are also supported.</p>"},{"location":"6-semester/DBS/05-sql/#nested-queries","title":"Nested Queries","text":"<p>Subqueries are necessary for comparisons to sets of values.</p> <ul> <li>Standard comparisons in combination with quantifiers: <code>ALL</code> or <code>ANY</code></li> <li>Special keywords to access sets: <code>IN</code> and <code>EXISTS</code></li> </ul>"},{"location":"6-semester/DBS/05-sql/#uncorrelated-subqueries","title":"Uncorrelated Subqueries","text":"<p>Notation:</p> <ul> <li><code>attribute IN ( SFW block )</code></li> </ul> <pre><code>SELECT name\nFROM professor\nWHERE empid IN (SELECT taughtby\nFROM course);\n</code></pre> <p>Comparison of a value to a set of values</p> <p>Negation in combination with the IN keyword</p> <p>Simulation of the difference operator $$ \\mathrm{\\pi_{vineyard}(producer) - \\pi_{vineyard}(wine)} $$ corresponding SQL query</p> <pre><code>SELECT vineyard\nFROM producer\nWHERE vineyard NOT IN (\nsqSELECT vineyard FROM wine);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#correlated-subqueries","title":"Correlated Subqueries","text":"<p>The subquery is correlated to the parent query. See the <code>WHERE</code> clause:</p> <pre><code>SELECT name\nFROM professor p\nWHERE EXISTS (SELECT *\nFROM course v\nWHERE v.taughtby = p.empid);\n</code></pre> <p>Computes names of professors that teach any courses.</p>"},{"location":"6-semester/DBS/05-sql/#quantifiers-in-vs-exists","title":"Quantifiers IN vs EXISTS","text":"<p><code>IN</code></p> <ul> <li>Is the \u201cleft tuple\u201d contained in the \u201cright set\u201d?</li> <li>Example: <code>(studid, courseid) IN (SELECT * FROM takes);</code></li> </ul> <p><code>EXISTS</code></p> <ul> <li>Is the \u201cright set\u201d nonempty?</li> <li>Example: <code>EXISTS (SELECT * FROM takes WHERE ...);</code></li> </ul> <p>There are more quantifiers: <code>ANY</code> and <code>ALL</code></p>"},{"location":"6-semester/DBS/05-sql/#advanced-sql","title":"Advanced SQL","text":"<p>Extension of the SFW block</p> <ul> <li><code>FROM</code> clause: additional join variants</li> <li><code>WHERE</code> clause: additional types of constraints and quantifiers</li> <li><code>SELECT</code> clause: application of scalar operations and aggregate functions</li> </ul>"},{"location":"6-semester/DBS/05-sql/#joins","title":"Joins","text":"<p>Join variants</p> <ul> <li><code>CROSS JOIN</code></li> <li><code>NATURAL JOIN</code></li> <li><code>JOIN</code> or <code>INNER JOIN</code></li> <li><code>LEFT</code>, <code>RIGHT</code>, or <code>FULL OUTER JOIN</code></li> </ul> <p>Standard formulation:</p> <pre><code>SELECT *\nFROM R1, R2\nWHERE R1.A = R2.B;\n</code></pre> <p>Alternative Formulation</p> <pre><code>SELECT *\nFROM R1\nJOIN R2 ON R1.A = R2.B;\n</code></pre> <p>See joins visualized with this tool</p> <p></p>"},{"location":"6-semester/DBS/05-sql/#aggregate-functions","title":"Aggregate Functions","text":"<p>How can we formulate the following queries in SQL?</p> <ul> <li>Average price of all articles on sale</li> <li>Total sales volume of all sold products</li> </ul> <p>Aggregate functions compute new values for a column, e.g., the sum or the average of all values in a column.</p> <p>Aggregate functions: </p> <ul> <li><code>AVG</code>, <code>MAX</code>, <code>MIN</code>, <code>COUNT</code>, <code>SUM</code></li> </ul> <p>The argument columns (except in case of <code>COUNT(\u2217)</code>) can optionally be accompanied by the keyword <code>DISTINCT</code> and <code>ALL</code>.</p> <ul> <li><code>DISTINCT</code><ul> <li>before evaluating the aggregate function, duplicates are removed</li> </ul> </li> <li><code>ALL</code><ul> <li>duplicates are considered for evaluation (default!)</li> </ul> </li> </ul> <p>Null values are removed before evaluation (except in case of <code>COUNT(\u2217)</code>).</p>"},{"location":"6-semester/DBS/05-sql/#examples","title":"Examples","text":"<p>Number of wines</p> <pre><code>SELECT COUNT(*) AS number\nFROM wine;\n</code></pre> <p></p> <p>The number of different regions that produce wine</p> <pre><code>SELECT COUNT(DISTINCT region)\nFROM producer;\n</code></pre> <p>The names and years of wines that are older than the average</p> <pre><code>SELECT name, year\nFROM wine\nWHERE year &lt; ( SELECT AVG(year) FROM wine);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#aggregate-functions-in-the-where-clause","title":"Aggregate Functions in the WHERE Clause","text":"<p>Aggregate functions produce a single value \\leadsto\\leadsto usable in comparison with constants in the WHERE clause.</p> <p>All vineyards producing a single wine</p> <pre><code>SELECT * FROM producer e\nWHERE 1 = (SELECT COUNT(*) FROM wine w\nWHERE w.vineyard = e.vineyard);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#nesting-of-aggregate-functions","title":"Nesting of Aggregate Functions","text":"<p>Nesting of aggregate functions is not allowed!</p> WRONG <pre><code>SELECT f1(f2(A)) AS result FROM R ...;\n</code></pre> <p>Instead</p> <pre><code>SELECT f1(temp) AS result\nFROM ( SELECT f2(A) AS temp FROM R ...);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#grouping","title":"Grouping","text":"<p>Stackoverflow Answer</p> <p>Computation of the aggregate function per group</p> <ul> <li><code>Group By X</code> means put all those with the same value for X in the one group.</li> <li><code>Group By X, Y</code> means put all those with the same values for both X and Y in the one group.</li> </ul> <p>Notation</p> <pre><code>SELECT ...\nFROM ...\n[WHERE ... ]\n[GROUP BY columnList ]\n[HAVING condition ];\n</code></pre> <p>Computation of the aggregate function per group</p> <pre><code>SELECT taughtBy, SUM(ects)\nFROM course\nGROUP BY taughtBy;\n</code></pre> <ul> <li>All tuples with the same value for column <code>taughtBy</code> form a group</li> <li>The sum is computed for each group</li> </ul>"},{"location":"6-semester/DBS/05-sql/#mistakes","title":"Mistakes","text":"<ul> <li>SQL generates one result tuple per group</li> <li>All columns referenced in the <code>SELECT</code> clause must either be listed in the <code>GROUP BY</code> clause or involved only in aggregate functions</li> </ul>"},{"location":"6-semester/DBS/05-sql/#the-having-clause","title":"The HAVING Clause","text":"<p>Example in slides p 122</p>"},{"location":"6-semester/DBS/05-sql/#null-values","title":"Null Values","text":"<p>Null values may lead to unexpected query results.</p> <pre><code>SELECT COUNT(semester) FROM student WHERE semester &lt; 13 OR semester &gt;= 13;\n</code></pre> <p>And</p> <pre><code>SELECT COUNT(semester) FROM student;\n</code></pre> <p>Produces the same result, because tuples with null values in column semester are not counted</p> <p>Arithmetic expressions</p> <ul> <li>\"Propagation\" of null values</li> <li>null + 1 \\leadsto\\leadsto null</li> <li>null * 0 \\leadsto\\leadsto null</li> </ul> <p>Comparison Operations</p> <ul> <li>SQL has a three-valued logic: <code>true</code>, <code>false</code>, and <code>unknown</code></li> <li>If at least one argument is null, then the result is <code>unknown</code></li> <li><code>studid</code> = 5 \\leadsto\\leadsto <code>unknown</code> whenever <code>studid</code> is null</li> </ul> <p>Logical expressions are evaluated according to the following tables</p> <p></p>"},{"location":"6-semester/DBS/05-sql/#null-values-in-where-clause-and-grouping","title":"Null Values in Where Clause and Grouping","text":"<p><code>WHERE</code> clause</p> <ul> <li>The <code>WHERE</code> clause forwards only tuples evaluated to <code>true</code></li> <li>Tuples evaluated to <code>unknown</code> will not be part of the result</li> </ul> <p>Grouping</p> <ul> <li>null is interpreted as an independent value</li> <li>Results in its own group</li> </ul>"},{"location":"6-semester/DBS/05-sql/#recursion","title":"Recursion","text":"<p>Information in slides p. 146 </p> <p>Which courses need to be taken before taking course \u201cTheory of Science\u201d?</p> <p>\u200b   \\relation{requires}{predecessor, successor}\\relation{requires}{predecessor, successor}</p> <p>\u200b   \\relation{course}{courseid, title, ects, taughtBy}\\relation{course}{courseid, title, ects, taughtBy}</p> <p>Non-Recursive</p> <p>This query only finds direct predecessors: </p> <pre><code>SELECT predecessor\nFROM requires, course\nWHERE successor = courseid AND\ntitle = \u2019Theory of Science\u2019;\n</code></pre> <p>Recursive</p> <pre><code>WITH RECURSIVE transitiveCourse (pred, succ) AS (\nSELECT predecessor, successor\nFROM requires\nUNION SELECT DISTINCT t.pred, r.succ\nFROM transitiveCourse t, requires r\nWHERE t.succ = r.succ\n)\nSELECT *\nFROM transitiveCourse\nORDER BY (pred, succ) ASC;\n</code></pre> <p></p>"},{"location":"6-semester/DBS/05-sql/#general-recursive-sql","title":"General Recursive SQL","text":"<pre><code>WITH RECURSIVE mytable(number) AS (     VALUES(1)                           | non-recursive part            UNION                               | UNION\nSELECT number + 1               | recursive part\nFROM mytable                    |   only this part may reference\nWHERE number &lt; 100              |   mytable\n)\nSELECT sum(number)                      | main query\nFROM mytable;\n</code></pre> <p>Result: 5050</p>"},{"location":"6-semester/DBS/05-sql/#avoid-infinite-recursion","title":"Avoid Infinite Recursion","text":"<ul> <li>Most DBMS have a parameter that limits maximum recursion depth</li> <li>Encode it directly in the query</li> </ul> <pre><code>WITH RECURSIVE transitiveCourse (pred, succ, depth)\nAS (\nSELECT predecessor, successor, 0\nFROM requires\nUNION\nSELECT DISTINCT t.pred, r.successor, t.depth+1\nFROM transitiveCourse t, requires r\nWHERE t.succ = r.predecessor AND t.depth &lt; 1\n)\nSELECT *\nFROM transitiveCourse\nORDER BY (pred, succ) ASC;\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#limiting-size-of-results","title":"Limiting Size of Results","text":"<p>Using <code>LIMIT</code> is accepted in exam solutions</p> <pre><code>SELECT * FROM student LIMIT 5;\n</code></pre> <p>Other possible solutions can be seen in DBS5 Slides p. 169</p>"},{"location":"6-semester/DBS/05-sql/#views","title":"Views","text":"<p>Examples of views</p> <pre><code>CREATE VIEW profsAndtheirCourses AS\nSELECT c.title, p.name\nFROM professor p, course c\nWHERE p.empid = c.taughtBy;\n</code></pre> <pre><code>SELECT * FROM profsAndtheirCourses;\n</code></pre> <pre><code>CREATE VIEW ectsPerStud AS\nSELECT s.name, t.studid, SUM(c.ects) AS sum\nFROM student s, takes t, course c\nWHERE t.courseid = c.courseid AND s.studid = t.studid\nGROUP BY s.name, t.studid;\n</code></pre> <pre><code>SELECT sum FROM ectsPerStud;\n</code></pre> <p>Views can be used to represent derived attributes (ER diagram).</p>"},{"location":"6-semester/DBS/05-sql/#altering-views","title":"Altering Views","text":"<p><code>REPLACE VIEW</code> expects the same columns in the same order with the same types.</p> <pre><code>CREATE OR REPLACE VIEW profsAndtheirCourses AS\nSELECT c.title, p.name\nFROM professor p, course c\nWHERE p.empid = c.taughtBy;\n</code></pre> <p>Alternative: Delete the view and recreate it afterwards, or non-standard SQL extensions, e.g., PostgresSQL\u2019s <code>ALTER VIEW</code></p> <pre><code>DROP VIEW ectsPerStud;\nCREATE VIEW ectsPerStud AS\nSELECT s.name, t.studid, SUM(c.ects) AS sum\nFROM student s, takes t, course c\nWHERE t.courseid = c.courseid\nAND s.studid = t.studid\nGROUP BY s.name, t.studid;\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#views-vs-materialized-views","title":"Views vs Materialized Views","text":"<p>(Dynamic) view</p> <ul> <li>Represents a macro of a query</li> <li>The query result is not pre-computed but computed when used</li> </ul> <p>Materialized View</p> <ul> <li>The query result is pre-computed</li> <li>Computation load before any queries are executed</li> </ul> <p>More on views in DBS5 slides p. 184</p>"},{"location":"6-semester/DBS/05-sql/#integrity-constraints","title":"Integrity Constraints","text":"<ul> <li> <p>Additional instrument to avoid inconsistency.</p> </li> <li> <p>Try to avoid insertion of inconsistent data</p> </li> </ul>"},{"location":"6-semester/DBS/05-sql/#static-integrity-constraints","title":"Static Integrity Constraints","text":"<p>Each instance of a database must fulfill all static integrity constraints.</p> <pre><code>CREATE TABLE professor ...\n... empid integer NOT NULL ...\n</code></pre> <p>Restricting the domain of valid values</p> <pre><code>CREATE TABLE student ...\n... CHECK semester BETWEEN 1 AND 20 ...\n</code></pre> <p>Enumeration of valid values</p> <pre><code>CREATE TABLE professor ...\n... CHECK rank IN ('C2', 'C3', 'C4') ...\n</code></pre> <p>Definition of user-defined domains</p> <pre><code>CREATE DOMAIN wineColor varchar(5)\nDEFAULT \u2019red\u2019\nCHECK (VALUE IN (\u2019red\u2019, \u2019white\u2019, \u2019rose\u2019));\n</code></pre> <pre><code>CREATE TABLE wine (\nwineID int PRIMARY KEY,\nname varchar(20) NOT NULL,\ncolor wineColor,\n...);\n</code></pre>"},{"location":"6-semester/DBS/05-sql/#dynamic-integrity-constraints","title":"Dynamic Integrity Constraints","text":"<p>Referential integrity requires that foreign keys must always reference existing tuples or be null.</p> <p>What happens if there is no professor with <code>empid</code> 007?</p> <pre><code>insert into course\nvalues (5100, \u2019Spying for Dummies\u2019, 4, 007)\n</code></pre> <p>And how can we prevent the insertion?</p>"},{"location":"6-semester/DBS/05-sql/#definition-of-keys","title":"Definition of Keys","text":"<p>Candidate keys</p> <ul> <li><code>UNIQUE</code></li> <li>A table can have multiple <code>UNIQUE</code> constraints</li> <li>Allows null values!</li> </ul> <p>Primary Keys</p> <ul> <li><code>PRIMARY KEY</code></li> <li>At most one per table</li> <li>Implies <code>UNIQUE NOT NULL</code></li> </ul> <p>Foreign Keys</p> <ul> <li><code>FOREIGN KEY</code></li> <li>Allows null values</li> </ul>"},{"location":"6-semester/DBS/05-sql/#handling-updates","title":"Handling Updates","text":"<p>Dynamic integrity constraints need to be fulfilled by each change of a database.</p> <p>In response to changes of referenced data:</p> <ul> <li>Rejection of updates (default behavior)</li> <li>Propagation of updates (CASCADE)</li> <li>Set references to \u201cunknown\u201d (SET null)</li> </ul> <p>In addition available in PostgreSQL</p> <ul> <li>Set to a default value (SET DEFAULT)</li> </ul> <p>Examples in DBS5 slides p. 204</p>"},{"location":"6-semester/DBS/05-sql/#complex-constraints","title":"Complex Constraints","text":"<pre><code>CREATE TABLE grades (\nstudid integer REFERENCES student ON DELETE CASCADE,\ncourseid integer REFERENCES course,\ngrade numeric(2,1) CHECK (grade BETWEEN 0.7 AND 5.0),\nPRIMARY KEY(studid, courseid)\nCONSTRAINT hasTaken\nCHECK (EXISTS (SELECT *\nFROM takes h\nWHERE h.courseid = grades.courseid AND\nh.studid = grades.studid))\n);\n</code></pre> <ul> <li>The CHECK clause is evaluated for each update or insert</li> <li>Operation is rejected if the check is evaluated to false! True and unknown do not violate the constraint!</li> <li>Not (yet) supported by PostgreSQL:<ul> <li>ERROR: cannot use subquery in check constraint</li> <li>Workaround by using triggers</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/05-sql/#appendix","title":"Appendix","text":"<p>See Appendix in DBS5 slides p. 222</p>"},{"location":"6-semester/DBS/06-transactions/","title":"Transactions","text":"<p>Learning Goals</p> <ul> <li>Understanding the transaction concept</li> <li>Understanding the ACID properties</li> <li>Understanding the schedule concept</li> <li>Understanding serializability</li> <li>Understanding recoverable and cascadeless schedules</li> </ul> <p>Concurrency Control</p> <ul> <li>Understand and use lock-based concurrency control</li> <li>Understand and use two-phase locking</li> </ul> <p>Recovery</p> <ul> <li>Understanding basic logging algorithms</li> <li>Understanding the importance of atomicity and durability</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#transactions_1","title":"Transactions","text":"<p>A transaction is a collection of operations that forms a logical unit of work, during which various data items are accessed and possibly updated.</p> <p>Transaction boundaries are user-defined!</p>"},{"location":"6-semester/DBS/06-transactions/#acid-properties","title":"ACID Properties","text":"<p>Atomicity</p> <ul> <li>Either all operations of the transaction are properly reflected in the database or none are.</li> <li>Often implemented via logs</li> </ul> <p>Consistency</p> <ul> <li>Execution of a transaction in isolation preserves the consistency of the database.</li> <li>According to constraints, checks, assertions</li> <li>In addition, consistency is defined by the application, e.g., fund transfers should not generate or destroy money \u2013 the overall sum is the same before and afterwards</li> </ul> <p>Isolation</p> <ul> <li>Each transaction appears to have the DB exclusively on its own.</li> <li>Intermediate results must be hidden for other transactions.</li> <li>Often implemented via locks</li> </ul> <p>Durability</p> <ul> <li>Updates of successfully completed transactions must not get lost despite system failures</li> <li>Often implemented via logs</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#operations-on-transactions","title":"Operations on Transactions","text":"<ul> <li><code>BEGIN</code> <ul> <li>Starts a transaction</li> </ul> </li> <li><code>COMMIT</code><ul> <li>Ends a transaction</li> </ul> </li> <li><code>ROLLBACK</code><ul> <li>All changes are undone/discarded</li> </ul> </li> </ul> <p>SAVEPOINT</p> <ul> <li><code>SAVEPOINT &lt;savepoint_name&gt;;</code><ul> <li>Defines a point/state within a transaction</li> <li>A transaction can be rolled back partially back up to the savepoint</li> </ul> </li> <li><code>ROLLBACK TO &lt;savepoint_name&gt;</code><ul> <li>Rolls the active transaction back to the savepoint <code>&lt;savepoint_name&gt;</code></li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#transaction-states","title":"Transaction States","text":""},{"location":"6-semester/DBS/06-transactions/#how-do-dbmss-support-transactions","title":"How do DBMSs Support Transactions?","text":"<p>The two most important components of transaction management are:</p> <p>Multi-user Synchronization (isolation)</p> <ul> <li>Semantic correctness despite concurrency      Concurrency allows for high throughput</li> <li>Serializability</li> <li>Weaker isolation levels</li> </ul> <p>Recovery (atomicity and durability)</p> <ul> <li>Roll back partially executed transactions</li> <li>Re-executing transactions after failures</li> <li>Guaranteeing persistence of transactional updates</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#schedules-and-serializability","title":"Schedules and Serializability","text":""},{"location":"6-semester/DBS/06-transactions/#concurrency","title":"Concurrency","text":"<p>Affects the I in ACID</p> <p>Problems</p> <ul> <li>Lost Updates<ul> <li>Overwriting updates</li> <li></li> </ul> </li> <li>Dirty Read<ul> <li>Dependency on non-committed updates</li> <li></li> </ul> </li> <li>Non-repeatable Read<ul> <li>Dependency on other updates</li> <li>T2 loses the illusion that it is alone in the database</li> <li></li> </ul> </li> <li>Phantom Problem<ul> <li>Dependency on new/deleted tuples</li> <li></li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#schedules","title":"Schedules","text":"<p>A schedule is a sequence of operations from one ore more transactions. For concurrent transactions, the operations are interleaved.</p> <p>Operations</p> <ul> <li><code>read(Q,q)</code><ul> <li>Read the value of database item Q and store it in the local variable q.</li> </ul> </li> <li><code>write(Q,q)</code><ul> <li>Store the value of the local variable q in the database item Q</li> </ul> </li> <li>Arithmetic operations</li> <li><code>commit</code></li> <li><code>abort</code></li> </ul> <p>Serial Schedule The operations of the transactions are executed sequentially with no overlap in time</p> <p>Concurrent Schedule The operations of the transactions are executed with overlap in time</p> <p>Valid Schedule A schedule is valid if the result of its executions is \"correct\"</p>"},{"location":"6-semester/DBS/06-transactions/#example-schedules","title":"Example Schedules","text":""},{"location":"6-semester/DBS/06-transactions/#correctness","title":"Correctness","text":"<p>Definition 1 (D1) A concurrent execution of transactions must leave the database in a consistent state</p> <p>Definition 2 (D2) Concurrent execution of transactions must be (result) equivalent to some serial execution of the transactions</p> <ul> <li>We use Definition 2</li> </ul> <p>Simplifying assumptions</p> <ul> <li>Only reads and writes are used to determine correctness</li> <li>This assumption is stronger than definition D2, as even fewer schedules are considered correct. </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#conflicts","title":"Conflicts","text":"<p>Definition 4 (D4)[^1]</p> <p>A schedule is conflict serializable if it is conflict equivalent to a serial schedule</p> <ul> <li>It ensures that after execution the database is in a consistent state.</li> </ul> <p>[^1]: Third definition D3 is view serializability, and is not covered in the course</p> <p>Alternative Definition from Web</p> <p>A schedule is called conflict serializable if it can be transformed into a serial schedule by swapping non-conflicting operations.</p> <p>There is a conflict if there is a read and a write on the same data unit. Also if there is a write on the same data unit.</p> <p></p> <p>Let I and J be consecutive instructions of a schedule S of multiple transactions</p> <ul> <li> <p>If I and J do not conflict, we can swap their order to produce a new schedule S'</p> </li> <li> <p>The instructions appear in the same order in S and S', except for I and J, whose order does not matter</p> </li> <li> <p>S and S' are termed conflict equivalent schedules</p> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#examples","title":"Examples","text":""},{"location":"6-semester/DBS/06-transactions/#conflict-graph","title":"Conflict Graph","text":"<p>AKA Precedence graph</p> <p>Directed graph</p> <p>Assumption:</p> <ul> <li>A transaction will always read an item before it writes that item</li> </ul> <p>Given a schedule for a set of transactions T_1,T_2,\\dots,T_n</p> <ul> <li>The vertices of the conflict graph are the transactions identifiers</li> <li>An edge from T_iT_i to T_jT_j denotes that the two transactions are conflicting, with T_iT_i making the relevant access earlier</li> <li>Sometimes the edge is labeled with the item involved in the conflict</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#draw-a-conflict-graph","title":"Draw a Conflict Graph","text":"<ol> <li>For each transaction T_xT_x participating in schedule SS, create a node labeled T_iT_i in the precedence graph. </li> <li>For each case in SS where T_jT_j executes a <code>read(X)</code> after T_iT_i executes a <code>write(X)</code>, create an edge (T_i \\to T_jT_i \\to T_j) in the precedence graph. </li> <li>For each case in SS where T_jT_j executes a <code>write(X)</code> after T_iT_i executes a <code>read(X)</code>, create an edge (T_i \\to T_jT_i \\to T_j) in the precedence graph.</li> <li>For each case in S where T_jT_j executes a <code>write(X)</code> after T_iT_i executes a <code>write(X)</code>, create an edge (T_i \\to T_jT_i \\to T_j) in the precedence graph.</li> </ol>"},{"location":"6-semester/DBS/06-transactions/#determining-serializability","title":"Determining Serializability","text":"<p>Given a schedule S and a conflict graph</p> <ul> <li>A schedule is conflict serializable if its conflict graph is acyclic (no cycles)</li> <li>Intuitively, a conflict between two transactions forces an execution order between them (topological sorting)</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#example","title":"Example","text":"<p>Which of the following are conflict serial schedules?</p> <p></p>"},{"location":"6-semester/DBS/06-transactions/#relationship-among-schedules","title":"Relationship Among Schedules","text":""},{"location":"6-semester/DBS/06-transactions/#recoverable-and-cascadeless-schedules","title":"Recoverable and Cascadeless Schedules","text":"<p>Transactions can fail!</p> <ul> <li> <p>If T_iT_i fails, it must be rolled back to retain the atomicity property of transactions</p> </li> <li> <p>If another transaction T_jT_j has read a data item written by T_iT_i, then T_jT_j must also be rolled back</p> <p>\\Rightarrow\\Rightarrow database systems must ensure that schedules are recoverable</p> </li> </ul> <p>This schedule is not recoverable:</p> <p></p>"},{"location":"6-semester/DBS/06-transactions/#recoverable","title":"Recoverable","text":"<p>A schedule is recoverable if for each pair of transactions T_iT_i and T_jT_j      where T_jT_j reads data items written by  T_iT_i,      then T_iT_i must commit before T_jT_j commits.</p> <p></p>"},{"location":"6-semester/DBS/06-transactions/#cascadeless","title":"Cascadeless","text":"<p>A schedule is cascadeless if for each pair of transactions T_iT_i and T_jT_j,      where T_jT_j reads data items written by T_iT_i,      the commit operation of T_iT_i must appear before the read by T_jT_j </p> <ul> <li>In other words, if you only read committed data</li> <li>Every cascadeless schedule is also recoverable.</li> </ul> <p>Cascading rollbacks can easily become expensive.</p> <p>It is desirable to restrict the schedules to those that are cascadeless.</p>"},{"location":"6-semester/DBS/06-transactions/#concurrency-control","title":"Concurrency Control","text":""},{"location":"6-semester/DBS/06-transactions/#scheduler","title":"Scheduler","text":"<p>Task of the scheduler:</p> <ul> <li>produce serializable schedules of instructions (transactions T_1, \\dots, T_nT_1, \\dots, T_n) that avoid cascading rollbacks</li> </ul> <p>Realized by synchronization strategies</p> <ul> <li>pessimistic<ul> <li>lock-based synchronization</li> <li>timestamp-based synchronization</li> </ul> </li> <li>optimistic</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#lock-based-synchronization","title":"Lock-based Synchronization","text":"<p>Ensuring (conflict) serializable schedules by delaying transactions that could violate serializability.</p> <p>Two types of locks can be held on a data item Q</p> <ul> <li>S (shared, read lock)</li> <li>X (exclusive, write lock)</li> </ul> <p>Operations on locks:</p> <ul> <li><code>lock_S(Q)</code><ul> <li>set shared lock on data item Q</li> </ul> </li> <li><code>lock_X(Q)</code><ul> <li>set exclusive lock on data item Q</li> </ul> </li> <li><code>unlock(Q)</code><ul> <li>release lock on data item Q</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#lock-privileges","title":"Lock Privileges","text":"<p>A transaction holding</p> <ul> <li>an exclusive lock may issue a write or read access request on the item</li> <li>a shared lock may issue a read access request on the item</li> </ul> <p>Compatibility Matrix</p> <p></p> <p>NL - no lock</p> <ul> <li>Concurrent transactions can only be granted compatible locks</li> <li>A transaction might have to wait until a requested lock can be granted!</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#problems-with-early-unlocking","title":"Problems with Early Unlocking","text":"<p>Early unlocking can cause incorrect results (non-serializable schedules) but allows for a higher degree of concurrency.</p> <p></p> <ul> <li>Initially A = 100 and B = 200</li> <li>serial schedule T_{15};T_{16}T_{15};T_{16} prints 300</li> <li>serial schedule T_{16};T_{15}T_{16};T_{15} prints 300</li> <li>S_7S_7 prints 250</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#problems-with-late-unlocking","title":"Problems with Late Unlocking","text":"<p>Late unlocking avoids non-serializable schedules. But it increases the chances of deadlocks.</p> <p>Learn to live with it!</p> <p></p>"},{"location":"6-semester/DBS/06-transactions/#two-phase-locking-2pl","title":"Two-Phase Locking (2PL)","text":"<p>Is a protocol</p> <ul> <li>First phase (growing phase):<ul> <li>Transactions may request locks</li> <li>Transactions may not release locks</li> </ul> </li> <li>Second phase (shrinking phase):<ul> <li>Transactions may not request locks</li> <li>Transactions may release locks</li> </ul> </li> </ul> <p></p> <p>When the first lock is release, the we move from first to second phase.</p>"},{"location":"6-semester/DBS/06-transactions/#examples_1","title":"Examples","text":"<p>Remember that we look at transactions indi</p> <p></p>"},{"location":"6-semester/DBS/06-transactions/#characteristics-of-2pl","title":"Characteristics of 2PL","text":"<ul> <li>Produces only serializable schedules<ul> <li>Insures conflict serializability</li> <li>Produces a subset of all possible serializable schedules</li> </ul> </li> <li>Does not prevent deadlocks</li> <li>Does not prevent cascading rollbacks<ul> <li>\"Dirty\" reads are possible (reading from non-committed transactions)</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#variations-of-2pl","title":"Variations of 2PL","text":"<p>Strict 2PL</p> <ul> <li>Exclusive locks are not released before the transaction commits</li> <li>Prevents \"dirty reads\"</li> </ul> <p>Rigorous 2PL</p> <ul> <li>All locks are released after commit time</li> <li>Transactions can be serialized in the order they commit</li> </ul> <p>Advantage</p> <ul> <li>No cascading rollbacks</li> </ul> <p>Disadvantage</p> <ul> <li>Loss of potential concurrency</li> </ul> <p></p>"},{"location":"6-semester/DBS/06-transactions/#lock-conversion","title":"Lock Conversion","text":"<p>Goal: apply 2PL but allow for a higher degree of concurrency</p> <p>First phase</p> <ul> <li>Acquire an S-lock on a data item</li> <li>Acquire an X-lock on a data item</li> <li>Convert (upgrade) an S-lock to an X-lock</li> </ul> <p>Second phase</p> <ul> <li>Release S-, and X-locks</li> <li>Convert (downgrade) an X-lock to an S-lock</li> </ul> <p>This protocol still ensures serializability.  It relies on the application programmer to insert the appropriate locks.</p>"},{"location":"6-semester/DBS/06-transactions/#more-examples","title":"More Examples","text":""},{"location":"6-semester/DBS/06-transactions/#overview","title":"Overview","text":""},{"location":"6-semester/DBS/06-transactions/#deadlocks","title":"Deadlocks","text":"<p>Solutions</p> <ul> <li>detection and recovery</li> <li>prevention</li> <li>timeout (not covered in presentation)</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#deadlock-detection","title":"Deadlock Detection","text":"<p>Create a \"Wait-for graph\" and check for cycles</p> <ul> <li>One node for each active transaction T_iT_i</li> <li>Edge T_i\\to T_jT_i\\to T_j if T_iT_i waits for the release of locks by T_jT_j</li> </ul> <p>A deadlock exists if the wait-for graph has a cycle</p> <p>If a deadlock is detected:</p> <ul> <li>Select an appropriate victim</li> <li>Abort the victim and release its locks</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#example_1","title":"Example","text":""},{"location":"6-semester/DBS/06-transactions/#rollback-candidates","title":"Rollback Candidates","text":"<p>Choosing a good victim transaction</p> <p>Rollback of one or more transactions that are involved in the cycle</p> <ul> <li>The latest (minimization of rollback effort)</li> <li>The one holding the most locks (maximization of released resources)</li> </ul> <p>Prevent that always the same victim is chosen (starvation)</p> <ul> <li>\"rollback counter\"<ul> <li>if above a certain threshold: no more rollbacks to break deadlocks</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#deadlock-prevention","title":"Deadlock Prevention","text":"<p>Conservative 2PL</p> <ul> <li>2PL as well as strict and rigorous 2PL do not prevent deadlocks</li> <li>Additional requirement:<ul> <li>All locks (shared and exclusive) are obtained right in the beginning of a transaction</li> </ul> </li> </ul> <p></p>"},{"location":"6-semester/DBS/06-transactions/#summary-concurrency-control","title":"Summary: Concurrency Control","text":"<ul> <li>Many concurrency control protocols have been developed<ul> <li>Main goal: allowing only serializable, recoverable and cascadeless schedules</li> <li>Two-phase locking (2PL)<ul> <li>Most relational DBMS's use rigorous two-phase locking</li> </ul> </li> </ul> </li> <li>Deadlock detection (wait-for graph) and prevention (conservative 2PL)</li> <li>Serializability vs. concurrency</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#recovery","title":"Recovery","text":"<p>\"Problems\" with transactions</p> <ul> <li>Atomicity<ul> <li>Transactions may abort (rollback)</li> </ul> </li> <li>Durability<ul> <li>What if a DBMS crashes?</li> </ul> </li> </ul> <p>The role of the recovery component is to ensure atomicity and durability of transactions in the presence of system failures.</p>"},{"location":"6-semester/DBS/06-transactions/#durability","title":"Durability","text":"<p>How can durability be guaranteed (DBS6 Slides p. 159)</p> <p>Durability is relative and depends on the number of copies and the geographical location</p> <p>Guarantees only possible if</p> <ul> <li>we first update the copies and</li> <li>notify the user afterwards that a transaction's commit was successful</li> </ul> <p>We hence assume that the WAL (Write Ahead Logging) rule is satisfied</p> <p>Variations of applying the WAL rule:</p> <ul> <li>Log-based recovery</li> <li>Full redundancy:  mirroring/shadowing all data on multiple computers (disks, computing centers) that redundantly do the same<ul> <li>Not covered in course</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#failure-classification","title":"Failure Classification","text":"<p>Transaction failure (failure of a not yet committed transaction)</p> <ul> <li>Undo the changes of the transaction</li> </ul> <p>System crash (failure with main memory loss)</p> <ul> <li>Changes of committed transactions must be preserved</li> <li>Changes of all non-committed transactions need to be undone</li> </ul> <p>Disk failure (failure with hard disk loss)</p> <ul> <li>Recovery based on archives/dumps</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#data-storage","title":"Data Storage","text":"<p>Two-level storage hierarchy</p> <p>Data is organized in pages and blocks</p> <p></p> <ul> <li>Volatile storage (main memory buffer)</li> <li>Non-volatile storage (hard disk)</li> <li>Stable storage (RAIDS, remote backups, ... )<ul> <li>not covered in course</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#movement-of-values","title":"Movement of Values","text":""},{"location":"6-semester/DBS/06-transactions/#storage-operations","title":"Storage Operations","text":"<p>Transactions access and update the database</p> <ul> <li>Operations for moving blocks with data items between disk and main memory (system buffer)<ul> <li>Input(Q)<ul> <li>Transfer block containing data item Q to main memory</li> </ul> </li> <li>Output(Q)<ul> <li>Transfer block containing Q to disk and replace</li> </ul> </li> </ul> </li> <li>Operations for moving values between data items and application variables<ul> <li>read(Q,q)<ul> <li>Assign the value of data item Q to variable q</li> </ul> </li> <li>write(Q,q)<ul> <li>Assign the value of variable q to data item Q</li> </ul> </li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#logging","title":"Logging","text":"<p>WAL (Write Ahead Logging)</p> <ul> <li>Before a transaction enters the commit state, \u201call its\u201d log entries have to be written to stable storage, including the commit log entry</li> <li>Before a modified page (or block) in main memory can be written to the database (non-volatile storage), \u201call its\u201d log entries have to be written to stable storage</li> </ul> <p>During normal operation</p> <ul> <li> <p>When starting, a transaction TT registers itself in the log: [T start]</p> </li> <li> <p>When modifying data item X by write(X,x)</p> <ol> <li>Add log entry with<ul> <li>[TT, X, V-old, V-new]<ul> <li>TT: transaction's ID</li> <li>X: data item name</li> <li>old value of item</li> <li>new value of item</li> </ul> </li> </ul> </li> <li>Write the new value of X</li> </ol> <p>The buffer manager asynchronously outputs the value to disk later</p> </li> <li> <p>When finishing, a transaction TT appends [T commit] to the log, TT then commits</p> <p>The transaction commits precisely when the commit entry (after all previous entries for this transaction) is output to the log!</p> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#log-entries","title":"Log Entries","text":"<p>Structure of a log entry (log record)</p> <p><code>[TID. DID. old, new]</code></p> <ul> <li><code>TID</code><ul> <li>identifier of the transaction that caused the update</li> </ul> </li> <li><code>DID</code><ul> <li>data item identifier     location on disk (page, block, offset)</li> </ul> </li> <li><code>old</code><ul> <li>value of the data item before the update</li> </ul> </li> <li><code>new</code><ul> <li>value of the data item after the update</li> </ul> </li> </ul> <p>Additional entries</p> <ul> <li><code>start</code><ul> <li><code>[TID start]</code></li> <li>Transaction TID has started</li> </ul> </li> <li><code>commit</code><ul> <li><code>[TID commit]</code></li> <li>Transaction TID has committed</li> </ul> </li> <li><code>abort</code><ul> <li><code>[TID abort]</code></li> <li>Transaction TID has aborted</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/06-transactions/#example_2","title":"Example","text":""},{"location":"6-semester/DBS/06-transactions/#log-based-recovery","title":"Log-based Recovery","text":"<p>Operations to recover from failures</p> <ul> <li>Redo: perform the changes to the database again</li> <li>Undo: restore database to state prior to execution</li> </ul> <p></p>"},{"location":"6-semester/DBS/06-transactions/#recovery-algorithm","title":"Recovery Algorithm","text":"<p>To recover from a failure</p> <ul> <li>Reproduce (redo) results for committed transactions</li> <li>Undo changes of transactions that did not commit</li> </ul> <p>Remarks</p> <ul> <li>In a multitasking system, more than one transaction may need to be undone.</li> <li>If a system crashes during the recovery stage, the new recovery must still give correct results (idempotence).</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#phases-of-recovery","title":"Phases of Recovery","text":"<ol> <li>Redo (repeat history)<ul> <li>Forward scan through the log</li> <li>Repeat all updates in the same order as in the log file</li> <li>Determine \"undo\" transactions<ul> <li>[T_iT_i start] add T_iT_i to the \"undo list\"</li> <li>[T_iT_i abort] or [T_iT_i commit] remove T_iT_i from the \"undo list\"</li> </ul> </li> </ul> </li> <li>Undo (rollback) all transactions in the \"undo list\"<ul> <li>Backwards scan through the log</li> <li>Undo all updates of transactions in the \"undo list\"<ul> <li>create a compensating log record</li> </ul> </li> <li>For a [T_iT_i start] record of a transaction T_iT_i in the \"undo list\", add a [T_iT_i abort] record to the log file, remove T_iT_i from the \"undo list\"</li> <li>Stop when \"undo list\" is empty</li> </ul> </li> </ol>"},{"location":"6-semester/DBS/06-transactions/#compensating-log-records","title":"Compensating Log Records","text":"<p><code>[TID, DID, value]</code></p> <ul> <li>Created to undo (compensate) the changes of <code>[TID, DID, value, newValue]</code></li> <li>Redo-only log record</li> <li>Can also be used to rollback a transaction during normal o</li> </ul>"},{"location":"6-semester/DBS/06-transactions/#example_3","title":"Example","text":"<p>Example can be seen in slides: DBS6 - Transactions - Slide 85 - p. 202</p>"},{"location":"6-semester/DBS/07-physical-dbs/","title":"Physical Design","text":"<p>Learning Goals</p> <ul> <li>Understand how tables are stored in files</li> <li>Understand basic indexing techniques</li> <li>Use knowledge of file/index to tune basic SQL queries</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#file-organization","title":"File Organization","text":""},{"location":"6-semester/DBS/07-physical-dbs/#storage-hierarchy","title":"Storage Hierarchy","text":"<ul> <li>Volatile storage (cache, main memory): loses content when power is switched of</li> <li>Non-volatile storage: content persists even when power is switched of</li> <li>The higher the level, the faster the access</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#magnetic-hard-disk","title":"Magnetic Hard Disk","text":"<p>For each disk access</p> <p></p> <ul> <li>Each track is divided into sectors (smallest unit of data that can be read/written)</li> <li>A block (page) is a contiguous sequence of sectors from a single track<ul> <li>Basic unit of data transfer between disk and memory</li> </ul> </li> </ul> <p>Optimization of disk block access</p> <ul> <li>Organize blocks in the way data is accessed</li> <li>Store related information close to each other</li> </ul> <p>Conceptually, relational data is stored as sequences of bits on disk.</p> <p>Functional requirements</p> <ul> <li>Processing records sequentially</li> <li>Efficient key-value search</li> <li>Insertion/deletion of records</li> </ul> <p>Performance objectives</p> <ul> <li>Little wasted space</li> <li>Fast response time</li> <li>High number of transactions</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#files","title":"Files","text":"<p>Storing databases on disks</p> <ul> <li>The database is stored as a collection of files</li> <li>Each file corresponds to a set of records</li> <li>A record contains a number of fields</li> </ul> <p>Multiple records are \u201cgrouped\u201d into blocks (pages)</p> <p>Record size</p> <ul> <li>Fixed</li> <li>Variable</li> </ul> <p>Files reside on mass storage (usually a disk)</p> <ul> <li>Fast random access</li> <li>Non-volatile storage</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#example","title":"Example","text":"<p>Blocks in a file system are not necessarily contiguous</p> <p></p> <p>Speed</p> <ul> <li>Speed of reading a block (an I/O):<ul> <li>\\sim 10 msec to a non-contiguous block read</li> <li>\\sim 1\\sim 1 msec for a contiguous block read</li> </ul> </li> <li>DBMS/OS can reorganize blocks to make them contiguous</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#fixed-size-records","title":"Fixed Size Records","text":"<p>All records use the same length if they occupy the whole space or not</p> <p>Read record ii</p> <ul> <li>Get record at location: \\mathrm{recordSize \\times i}\\mathrm{recordSize \\times i}</li> </ul> <p>Delete record ii</p> <ul> <li> <p>Move records i+1,\\dots,ni+1,\\dots,n to location i,\\dots,n-1i,\\dots,n-1 to close the gap</p> <p>or</p> </li> <li> <p>Move record nn to ii</p> <p>or</p> </li> <li> <p>Mark the gaps and fill them with future insertions</p> <ul> <li>Mark first gap in the file header</li> <li>Use the gaps to point to other gaps (free-list)</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#variable-size-records","title":"Variable Size Records","text":"<p>Records have different lengths and occupy different amounts of disk space</p> <p>Use case: variable-lengths attributes (e.g., varchar)</p> <p>Implementation alternatives</p> <ul> <li>If max. size is known:<ul> <li>Map variable size records to fixed size records</li> </ul> </li> <li>Slotted-page-structure<ul> <li>Records stored contiguously</li> <li>Block header contains pointers to records</li> <li></li> </ul> </li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#organizing-records-in-a-file","title":"Organizing Records in a File","text":"<p>Determine the order of records within a file</p> <p>Heap file organization</p> <ul> <li>A record can be placed anywhere in the file</li> </ul> <p>Sequential file organization</p> <ul> <li>Records stored in sequential order by the value of the search key</li> </ul> <p>Hash file organization</p> <ul> <li>Hash the record to a block based on a hash function and a hash key</li> </ul> <p></p>"},{"location":"6-semester/DBS/07-physical-dbs/#heap","title":"Heap","text":"<ul> <li>No apparent ordering on any of the columns in the table</li> <li>Search: linear scan always works</li> <li>Insert: find a free slot</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#sequential","title":"Sequential","text":"<ul> <li>Example table is stored in order of the ID column</li> <li>The ordering column does not need to be the primary key</li> <li>Search: binary search when search on the ID column</li> <li>Insert: reorganization of the file</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#hashing","title":"Hashing","text":"<ul> <li>Hash function used in this example is: mod(ID, 3)mod(ID, 3)</li> <li>Search: use the hash function on the search key value (ID) to find the right block</li> <li>Insert: use the hash function on the search key value (ID) to find the right block and append</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#indexes","title":"Indexes","text":"<p>Assumptions</p> <ul> <li>Many rows are stored in the database</li> <li>Many queries only access a small fraction of the rows</li> <li>Must be able to modify the rows, i.e., insert, update, and delete</li> <li>Cannot take the database offline to reorganize the files used in the database</li> </ul> <p>Goal: access as little data as possible</p>"},{"location":"6-semester/DBS/07-physical-dbs/#overview","title":"Overview","text":"<p>Classification</p> <p></p> <p>Variations</p> <ul> <li>Single-level index</li> <li>Multi-level index</li> </ul> <p>It is possible to have multiple indexes for the same relation.</p>"},{"location":"6-semester/DBS/07-physical-dbs/#primary-sparse-index","title":"Primary Sparse Index","text":"<ul> <li>Defined on a file ordered on the search key</li> <li>One index entry for each block in the file</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#secondary-dense-index","title":"Secondary Dense Index","text":"<ul> <li>Defined on a file not ordered on the search key</li> <li>One index entry for each record</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#overview_1","title":"Overview","text":"<p>Primary vs. secondary</p> <ul> <li>= clustering vs. non-clustering</li> <li>Is the file ordered on the search key?</li> </ul> <p>Dense vs. sparse</p> <ul> <li>A separate index entry for each record (unique search key value)?</li> <li>Yes \u2192 dense</li> <li>No \u2192 sparse</li> </ul> <p>Tradeoff</p> <ul> <li>Dense indexes: faster location of records</li> <li>Sparse indexes: smaller indexes</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#multi-level-index","title":"Multi-level Index","text":"<ul> <li>Goal: the outer index (sparse) fits into main memory</li> <li>The number of levels can be greater than two</li> </ul> <p>Limitations of index-sequential file organization</p> <ul> <li>Insertions and deletions<ul> <li>Expensive reorganization of multiple levels of ordered files</li> </ul> </li> </ul> <p>B^+^-trees</p> <ul> <li>Balanced search trees     Number of lookups/levels is the same for all entries</li> <li>Leaving some space in each disk block</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#index-concepts-combined","title":"Index Concepts Combined","text":"<p>A secondary sparse index does not make sense!</p> <ul> <li>Since records are not sorted on that key, we cannot predict the location of a record from the location of any other record</li> <li>Thus, secondary indexes are always dense.</li> </ul> <p>Clustering Dense</p> <ul> <li>Index entry has a pointer to the first record</li> </ul> <p>Non-clustering Dense</p> <ul> <li>Index entry has pointers to all the records</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#b-tree","title":"B+-Tree","text":"<ul> <li>n = the fanout = the number of pointers = 3 in the example above</li> <li>\\dashv\\dashv = unused pointer</li> <li>nu = Unused search key value</li> <li>Leaf-level pointers: point to the data file</li> <li>Search: Both key lookups and range queries are well supported</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#node-structure","title":"Node Structure","text":"<p>Node structure used for root, internal, and leaf nodes</p> <p></p> <p>In this example, the fanout n is 10</p> <ul> <li>In each node: 10 (n) pointers (p_i)(p_i)</li> <li>In each node: 9 (n-1) search key values (k_jk_j)</li> </ul> <p>The last pointer in leaf nodes is used to chain together the leaf nodes in search key order</p>"},{"location":"6-semester/DBS/07-physical-dbs/#properties","title":"Properties","text":"<p>Balanced</p> <ul> <li>All paths from the root node to leaf nodes have the same length</li> </ul> <p>Bushy</p> <ul> <li>Each node has between \\lceil {n \\over 2} \\rceil\\lceil {n \\over 2} \\rceil and n children</li> <li>Exception: the root node has between 2 and n children</li> <li>Leaf nodes have between $\\lceil {n-1\\over2} \\rceil $ and n - 1n - 1 pointers to file records and 1 pointer to the next leaf node</li> </ul> <p>Ordered</p> <ul> <li>The key values are sorted in each node, i.e, k_i &lt; k_jk_i &lt; k_j, if i &lt; ji &lt; j</li> <li>The subtrees are ordered</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#minimal-b-tree-example","title":"Minimal B+-Tree Example","text":"<ul> <li>A minimally filled B+-tree for n=3</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#b-tree-in-practice","title":"B+-Tree in Practice","text":"<ul> <li>Each B+-tree node has the size of one I/O block of data.</li> <li>A B+-tree node is at least 50% filled (by design)</li> <li>The B+-tree contains a rather small number of levels, usually logarithmic in the size of the main file</li> <li>The first one or two levels of the tree are stored in main memory</li> <li>\u201cLogically\u201d close does not imply \u201cphysically close\u201d Typically reading a node in a B+-tree requires one random I/O</li> <li>The non-leaf nodes are a hierarchy of sparse indexes</li> </ul> <p>When a primary key constraint for a table is created in a DBMS, then the uniqueness is checked by using a B+-tree.</p>"},{"location":"6-semester/DBS/07-physical-dbs/#b-tree-updates","title":"B+-Tree Updates","text":"<p>Insertions</p> <ul> <li>Overflow, split</li> <li>The tree height may be increased by 1</li> </ul> <p>Deletions</p> <ul> <li>Underflow, borrow, coalesce</li> <li>The tree height may be decreased by 1</li> </ul> <p>Multiple examples in DBS7 Slide 30- p. 54-</p>"},{"location":"6-semester/DBS/07-physical-dbs/#b-trees-online","title":"B+-Trees Online","text":"<p>Interactive apps available on the Web</p> <p>https://goneill.co.nz/btree-demo.php</p> <p>https://www.cs.usfca.edu/~galles/visualization/BPlusTree.html</p> <p>third party material, not fully tested, might have a slightly different implementation (and errors)</p>"},{"location":"6-semester/DBS/07-physical-dbs/#unordered-indexes-hashing","title":"Unordered Indexes (Hashing)","text":""},{"location":"6-semester/DBS/07-physical-dbs/#static-hash-index","title":"Static Hash Index","text":"<p>Build an index based on a hash function (instead of based on a search key order)</p> <ul> <li>Choose an appropriate hash function hh</li> <li>Apply hash function hh to search key value kk to compute h(k)h(k)</li> <li>Bucket (disk block) for each value of h(k)h(k)</li> </ul> <p></p> <ul> <li>Lookup<ul> <li>One access to the bucket directory</li> <li>One access to the data file</li> </ul> </li> <li>Good performance depends on a good hash function</li> <li>Bucket overflow<ul> <li>Too many different key values hash to the same bucket</li> <li>Solution: overflow buckets and overflow chains</li> <li></li> </ul> </li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#open-vs-closed-hashing","title":"Open vs Closed Hashing","text":"<p>Open Hashing</p> <ul> <li>Overflow chains</li> </ul> <p>Closed Hashing</p> <ul> <li>Fixed number of buckets</li> <li>Overflow: use one of the other buckets (linear probing, further hash functions, etc.)</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#static-hashing","title":"Static Hashing","text":"<p>Problem for static hashing:</p> <ul> <li>Hash function and number of buckets determined during initialization</li> </ul> <p>Databases grow or shrink over time!</p> <ul> <li> <p>Initial number of buckets too small</p> <p>\\to\\to many overflows, performance degrades</p> </li> <li> <p>Initial number of buckets too big</p> <p>\\to\\to underflow, space is wasted</p> </li> </ul> <p>Solutions</p> <ul> <li>Periodic re-organization</li> <li>Dynamic hashing:<ul> <li>allows modifications dynamically</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#physical-design-tuning","title":"Physical Design Tuning","text":"<p>Design decisions</p> <ul> <li>Ordered/clustering indexes vs. hashing</li> <li>Sparse vs. dense index</li> <li>Clustering vs. non-clustering indexes</li> <li>Joins and indexes</li> </ul> <p>Tuning questions</p> <ul> <li>Are the costs of periodic reorganization acceptable?</li> <li>How frequent are insertions and deletions?</li> <li>Optimization goal: average access time or worst-case access time?</li> <li>What types of queries are expected?</li> </ul>"},{"location":"6-semester/DBS/07-physical-dbs/#use-of-indexes","title":"Use of Indexes","text":"<p>Sometimes available indexes are not used, why? </p> <ul> <li>Catalog out of date     optimizer may think table is small</li> <li>\u201cGood\u201d and \u201cbad\u201d query examples<ul> <li><code>SELECT * FROM EMP WHERE salary/12 &gt; 4000</code><ul> <li>Operations on conditions may prevent the optimizer from realizing the index could be useful</li> </ul> </li> <li><code>SELECT * FROM EMP WHERE salary &gt; 48000</code><ul> <li>Good</li> </ul> </li> <li><code>SELECT * FROM EMP WHERE SUBSTR(name, 1, 1) = \u2019G\u2019</code><ul> <li>Functions on conditions require function-based indexes</li> </ul> </li> <li><code>SELECT * FROM EMP WHERE name LIKE \u2019G%\u2019</code><ul> <li>Good</li> </ul> </li> <li><code>SELECT * FROM EMP WHERE name = \u2019Smith\u2019</code><ul> <li>Good</li> </ul> </li> <li><code>SELECT * FROM EMP WHERE salary IS NULL</code><ul> <li>Requires an index on nullable values</li> </ul> </li> </ul> </li> <li>Nested sub-query</li> <li>Selection by negation</li> <li>Queries with <code>OR</code></li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/","title":"Query Processing and Optimization","text":"<p>Learning Goals</p> <ul> <li>Understand how selection statements are executed</li> <li>Understand the basic join algorithms</li> <li>Understand the basics of heuristic (logical) query optimization</li> <li>Understand the basics of physical query optimization</li> </ul>  \\newcommand{\\relationRaw}[3]{     \\newcommand{\\pk}{\\underline}     #3\\mathbf{#1}#3#3:\\{[\\mathrm{#2}]\\} } \\newcommand{\\relation}[2]{\\relationRaw{#1}{#2}{}} \\newcommand{\\relational}[2]{\\relationRaw{#1}{#2}{&amp;}} \\nonumber"},{"location":"6-semester/DBS/08-query-optimization/#query-processing","title":"Query Processing","text":""},{"location":"6-semester/DBS/08-query-optimization/#evaluation-of-an-sql-statement","title":"Evaluation of an SQL Statement","text":"<p>The clauses are specified in the following order</p> <ul> <li><code>SELECT</code> column(s)</li> <li><code>FROM</code> table list</li> <li><code>WHERE</code> condition</li> <li><code>GROUP BY</code> grouping column(s)</li> <li><code>HAVING</code> group condition</li> <li><code>ORDER BY</code> sort list</li> </ul> <p>But the query is evaluated in a different order</p> <ul> <li>Cartesian product of tables in the from clause</li> <li>Predicates in the where clause</li> <li>Grouped according to the group by clause</li> <li>Predicate in the having clause applied to (eliminate) groups</li> <li>Compute aggregation functions for each remaining group</li> <li>Projection on columns enumerated in the select clause</li> </ul> <p>SQL is declarative!</p>"},{"location":"6-semester/DBS/08-query-optimization/#steps-of-query-processing","title":"Steps of Query Processing","text":""},{"location":"6-semester/DBS/08-query-optimization/#parsing-a-query","title":"Parsing a Query","text":"<p>Parsing a query into an initial query plan</p> <p></p> <ul> <li>\\pi_{title}(\\sigma_{name='Socrates' \\and empID=taughtBy}(professor \\times course))\\pi_{title}(\\sigma_{name='Socrates' \\and empID=taughtBy}(professor \\times course))</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#alternative-query-plan","title":"Alternative Query Plan","text":""},{"location":"6-semester/DBS/08-query-optimization/#query-optimization","title":"Query Optimization","text":"<p>Alternatives</p> <ul> <li>Equivalent query execution plans</li> <li>Algorithms to compute an algebra operation</li> <li>Methods to access relations (indexes)</li> </ul> <p>Although the result is equivalent, execution costs might be different.</p> <p>Theory meets reality</p> <p>It is not the task of the user to write queries \u201cefficiently\u201d, it is the task of the query optimizer to execute them efficiently! But in reality. . . optimizers are not perfect.</p>"},{"location":"6-semester/DBS/08-query-optimization/#query-costs","title":"Query Costs","text":"<p>Measures</p> <ul> <li>Total elapsed time for answering a query (response time)</li> <li>Many factors contribute to response time<ul> <li>Disk access</li> <li>CPU costs</li> <li>Network communication</li> <li>Query load</li> <li>Parallel processing</li> </ul> </li> <li>Disk access most dominant<ul> <li>Block access time: seek time, rotation time</li> <li>Transfer time</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#query-optimization_1","title":"Query Optimization","text":"<p>Logical query optimization</p> <ul> <li>Relational algebra</li> <li>Equivalence transformation</li> <li>Heuristic optimization</li> </ul> <p>Physical query optimization</p> <ul> <li>Algorithms and implementations of operations</li> <li>Cost model</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#heuristic-logical-query-optimization","title":"Heuristic (Logical) Query Optimization","text":"<p>Logical query optimization</p> <ul> <li>Foundation: algebraic equivalences</li> <li>Algebraic equivalences span the potential search space</li> <li>Given an initial algebraic expression: <ul> <li>apply algebraic equivalences to derive new equivalent algebraic expressions</li> </ul> </li> </ul> <p>What is a good plan?</p> <ul> <li> <p>Difficult to compare plans without a cost function</p> <p>\\to\\to logical query optimization relies on heuristics</p> </li> </ul> <p>Main goal of logical query optimization</p> <p>Reduce the size of intermediate results</p>"},{"location":"6-semester/DBS/08-query-optimization/#equivalences","title":"Equivalences","text":"<p>Break up conjunctions in selection predicates</p>  \\sigma_{c_1 \\and c_2 \\and \\cdots \\and c_n}(R) \\equiv \\sigma_{c_1}(\\sigma_{c_2}(\\dots(\\sigma_{c_n}(R))\\dots))   \\sigma_{c_1 \\and c_2 \\and \\cdots \\and c_n}(R) \\equiv \\sigma_{c_1}(\\sigma_{c_2}(\\dots(\\sigma_{c_n}(R))\\dots))  <p>\\sigma\\sigma is commutative</p>  \\sigma_{c_1}(\\sigma_{c_2}(R)) \\equiv \\sigma_{c_2} ( \\sigma_{c_1}(R))   \\sigma_{c_1}(\\sigma_{c_2}(R)) \\equiv \\sigma_{c_2} ( \\sigma_{c_1}(R))  <p>\\pi\\pi cascades</p> <p>If L_1 \\subseteq L_2 \\subseteq \\cdots \\subseteq L_nL_1 \\subseteq L_2 \\subseteq \\cdots \\subseteq L_n then</p>  \\pi_{L_1}(\\pi_{L_2}(\\dots(\\pi_{L_n}(R))\\dots)) \\equiv \\pi_{L_1}(R)   \\pi_{L_1}(\\pi_{L_2}(\\dots(\\pi_{L_n}(R))\\dots)) \\equiv \\pi_{L_1}(R)  <p>Change the order of \\sigma\\sigma and \\pi\\pi</p> <p>If the selection involves only attributes A_1, \\dots, A_nA_1, \\dots, A_n contained in the projection list, the order of \\sigma\\sigma and \\pi\\pi can be changed</p>  \\pi_{A_1, \\dots, A_n}(\\sigma_c(R)) \\equiv \\sigma_c(\\pi_{A_1, \\dots, A_n}(R))   \\pi_{A_1, \\dots, A_n}(\\sigma_c(R)) \\equiv \\sigma_c(\\pi_{A_1, \\dots, A_n}(R))  <p>\\cup, \\cap\\cup, \\cap and \\Join\\Join are commutative</p>  R\\Join_c S \\equiv S\\Join_c R   R\\Join_c S \\equiv S\\Join_c R  <p>Change the order of  \\sigma\\sigma and \\Join\\Join</p> <p>If the selection predicate cc involves only attributes of relation RR, the order of \\sigma\\sigma and \\Join\\Join can be changed</p>  \\sigma_c(R\\Join_j S) \\equiv \\sigma_c(R) \\Join_j S   \\sigma_c(R\\Join_j S) \\equiv \\sigma_c(R) \\Join_j S  <p>If the selection predicate cc is a conjunction of the form c_1 \\and c_2c_1 \\and c_2 and c_1c_1 involves only attributes in RR and c_2c_2 involves only attributes in S, then we need to split cc</p>  \\sigma_c(R\\Join S) \\equiv \\sigma_{c_1}(R) \\Join_j \\sigma_{c_2}(S)   \\sigma_c(R\\Join S) \\equiv \\sigma_{c_1}(R) \\Join_j \\sigma_{c_2}(S)  <p>Change the order of \\pi\\pi and \\Join\\Join</p> <p>Given the projection list L=\\{A_1,\\dots,A_n, B_1,\\dots,B_m\\}L=\\{A_1,\\dots,A_n, B_1,\\dots,B_m\\} where  A_iA_i represents attributes in RR and B_iB_i represents attributes in SS</p> <p>If the join predicate cc only references attributes in LL the following reformulation holds</p>  \\pi_L (R \\Join_c S) \\equiv (\\pi_{A_1,\\dots,A_n}(R)) \\Join_c (\\pi_{B_1, \\dots , B_m}(S))   \\pi_L (R \\Join_c S) \\equiv (\\pi_{A_1,\\dots,A_n}(R)) \\Join_c (\\pi_{B_1, \\dots , B_m}(S))  <p>\\Join, \\cap, \\cup\\Join, \\cap, \\cup (in separate) are all associative</p> <p>I.e., with \\Phi\\Phi representing either of these operations, the following holds</p>  (R\\ \\Phi\\ S)\\ \\Phi\\ T \\equiv R\\ \\Phi\\ (S\\ \\Phi\\ T)   (R\\ \\Phi\\ S)\\ \\Phi\\ T \\equiv R\\ \\Phi\\ (S\\ \\Phi\\ T)  <p>\\sigma\\sigma is distributive with \\cap, \\cup, -\\cap, \\cup, -</p> <p>I.e., with \\Phi\\Phi representing either of these operations, the following holds</p>  \\sigma_c(R\\ \\Phi\\ S) \\equiv (\\sigma_c(R))\\ \\Phi\\ (\\sigma_c(S))   \\sigma_c(R\\ \\Phi\\ S) \\equiv (\\sigma_c(R))\\ \\Phi\\ (\\sigma_c(S))  <p>\\pi\\pi is distributive with \\cup\\cup</p>  \\pi_c(R\\cup S) \\equiv (\\pi_c(R))\\cup (\\pi_c(S))   \\pi_c(R\\cup S) \\equiv (\\pi_c(R))\\cup (\\pi_c(S))  <p>Join and/or selection predicates can be reformulated based on De Morgan\u2019s laws</p>  \\neg(c_1 \\and c_2) \\equiv (\\neg c_1)\\or(\\neg c_2)\\label{demorgan1}   \\neg(c_1 \\and c_2) \\equiv (\\neg c_1)\\or(\\neg c_2)\\label{demorgan1}   \\neg(c_1 \\or c_2) \\equiv (\\neg c_1)\\and(\\neg c_2)\\label{demorgan2}   \\neg(c_1 \\or c_2) \\equiv (\\neg c_1)\\and(\\neg c_2)\\label{demorgan2}  <p>Combination of Cartesian product and selection </p> <p>A Cartesian product followed by a selection whose predicate involves predicates of both involved operands can be combined to a join</p>  \\sigma_\\theta(R \\times S) \\equiv R \\Join_\\theta S   \\sigma_\\theta(R \\times S) \\equiv R \\Join_\\theta S  <p>Remember the equivalent expressions for operators in relational algebra!</p>"},{"location":"6-semester/DBS/08-query-optimization/#phases-of-logical-query-optimization","title":"Phases of Logical Query Optimization","text":"<ol> <li>Break up conjunctive selection predicates</li> <li>Push selections down</li> <li>Introduce joins by combining selections and cross products</li> <li> <p>Determine join order</p> <p>Heuristic: execute joins with input from selections before executing other joins 5. Introduce and push down projections</p> <p>Not always useful</p> </li> </ol> <p>Example in DBS8 slide 18 p. 35</p>"},{"location":"6-semester/DBS/08-query-optimization/#be-careful","title":"Be Careful!","text":"<p>Find the titles of reserved films</p> <pre><code>SELECT DISTINCT title\nFROM film F, reserved R\nWHERE F.filmID = R.filmID\n</code></pre> <p></p> <p>Find the titles of expensive reserved films</p> <pre><code>SELECT DISTINCT title\nFROM film F, reserved R\nWHERE F.filmID = R.filmID AND F.rentalPrice &gt; 4\n</code></pre> <p></p>"},{"location":"6-semester/DBS/08-query-optimization/#summary-heuristic-query-optimization","title":"Summary: Heuristic Query Optimization","text":"<p>Rules of thumb</p> <ul> <li>Perform selections as early as possible</li> <li>Perform projections as early as possible</li> </ul> <p>The optimization process</p> <ul> <li>Generate initial query plan from SQL statement</li> <li>Transform query plan into more efficient query plan via a series of modifications, each of which hopefully reducing execution time</li> </ul> <p>Note</p> <ul> <li>A single query plan provides all the results</li> <li>Sometimes also called rule-based query optimization</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#operator-implementations","title":"Operator Implementations","text":"<p>Sample Database</p>  \\begin{align*} \\relational{customer}{customerID, name, street, city, state}\\\\ \\relational{reserved}{customerID, filmID, resDate}\\\\ \\relational{film}{filmID, title, kind, rentalPrice} \\end{align*}   \\begin{align*} \\relational{customer}{customerID, name, street, city, state}\\\\ \\relational{reserved}{customerID, filmID, resDate}\\\\ \\relational{film}{filmID, title, kind, rentalPrice} \\end{align*}"},{"location":"6-semester/DBS/08-query-optimization/#selection","title":"Selection","text":""},{"location":"6-semester/DBS/08-query-optimization/#taxonomy","title":"Taxonomy","text":"<ul> <li>Primary key, point<ul> <li>\\sigma_{filmID=2}(film)\\sigma_{filmID=2}(film)</li> <li>Here we could use an index</li> </ul> </li> <li>Point<ul> <li>\\sigma_{title='Terminator'}(film)\\sigma_{title='Terminator'}(film)</li> <li>We may or may not have an index here</li> </ul> </li> <li>Range<ul> <li>\\sigma_{1&lt;rentalPrice&lt;4}(film)\\sigma_{1&lt;rentalPrice&lt;4}(film)</li> </ul> </li> <li>Conjunction (logical and)<ul> <li>\\sigma_{kind='F' \\and rentalPrice=4}(film)\\sigma_{kind='F' \\and rentalPrice=4}(film)</li> </ul> </li> <li>Disjunction (logical or)<ul> <li>\\sigma_{rentalPrice&lt;4 \\or kind='D'}(film)\\sigma_{rentalPrice&lt;4 \\or kind='D'}(film)</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#selection-strategies-pointrange","title":"Selection Strategies - Point/Range","text":"<p>Linear search</p> <ul> <li>Expensive but always applicable</li> </ul> <p>Binary search</p> <ul> <li>Applicable only when the file is appropriately ordered</li> </ul> <p>Primary hash index/table search</p> <ul> <li>Single record retrieval; does not work for range queries</li> <li>Retrieval of multiple records</li> </ul> <p>Primary/clustering index search</p> <ul> <li>Multiple records for each index item</li> <li>Implemented with single pointer to block with first associated record</li> </ul> <p>Secondary index search</p> <ul> <li>Implemented with multiple pointers, each to a single record</li> <li>Might become expensive</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#strategies-for-conjunctive-queries","title":"Strategies for Conjunctive Queries","text":"<pre><code>SELECT *\nFROM customer\nWHERE name = \u2019Jensen \u2019 AND street = \u2019Elm \u2019\nAND state = \u2019Arizona \u2019\n</code></pre> <ul> <li>Can indexes on (name) and (street) be used? Yes</li> <li>Can an index on (name, street, state) be used? Yes</li> <li>Can an index on (name, street) be used? Yes</li> <li>Can an index on (name, street, city) be used? Yes</li> <li>Can an index on (city, name, street) be used? No</li> </ul> <p>Optimization of conjunctive queries</p> <p>Indexing provides good opportunities for improving performance</p> <p>Use available indexes</p> <ul> <li> <p>Ideal: composite index is applicable</p> </li> <li> <p>If multiple are available</p> <p>\\to\\to use the most selective index, then check remaining conditions</p> </li> </ul> <p>Use intersection of record pointers (if multiple indexes applicable)</p> <ul> <li>Index lookups to fetch sets of record pointers</li> <li>Intersect record pointers to perform conjunction</li> <li>Retrieve (and check) the qualifying records</li> </ul> <p>Disjunctive queries provide little opportunity for improving performance.</p> <p>Database tuning and the creation of indexes is important!</p>"},{"location":"6-semester/DBS/08-query-optimization/#join","title":"Join","text":"<p>Join strategies</p> <ul> <li>Nested loop join</li> <li>Index-based join</li> <li>Sort-merge join</li> <li>Hash join</li> </ul> <p>Strategies work on a per block (not per record) basis</p> <ul> <li>Estimate I/Os (block retrievals)</li> <li>Use of main memory buffer</li> </ul> <p>Table sizes and join selectivities influence join costs</p> <ul> <li>Query selectivity: sel = \\mathrm{\\# tuples\\ in\\ result \\over \\# candidates}sel = \\mathrm{\\# tuples\\ in\\ result \\over \\# candidates}</li> <li>For join, #candidates is the size of the Cartesian product</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#nested-loop-join","title":"Nested Loop Join","text":"<p>See example in DBS8 slide 36 p. 68</p> <p>PDF on moodle</p>"},{"location":"6-semester/DBS/08-query-optimization/#block-nested-loop-join","title":"Block Nested Loop Join","text":"<p>Not all blocks fit into main memory</p> <p>Parameters</p> <ul> <li>b_{inner}, b_{outer}:b_{inner}, b_{outer}: number of blocks</li> <li>n_B:n_B: size of main memory buffer</li> </ul> <p></p> <p>Cost estimation (block transfers):</p>  b_{outer}+(\\lceil b_{outer} / (n_B-2)\\rceil) \\cdot b_{inner}   b_{outer}+(\\lceil b_{outer} / (n_B-2)\\rceil) \\cdot b_{inner}  <p>If we know more system parameters (block transfer, disk seeks, CPU speed,. . . ) and the size of input relations, we can estimate the time to compute the join.</p> <p>Example</p> <p>reserved \\Join customerreserved \\Join customer</p> <ul> <li>number of blocks<ul> <li>b_{reserved}=2.000, b_{customer}=10b_{reserved}=2.000, b_{customer}=10</li> </ul> </li> <li>Size of main memory buffer<ul> <li>n_B=6n_B=6</li> </ul> </li> </ul> <p>Cost:</p> <ul> <li>reservedreserved as outer<ul> <li>2.000+\\lceil (2.000/4)\\rceil \\cdot 10 = 7.0002.000+\\lceil (2.000/4)\\rceil \\cdot 10 = 7.000</li> </ul> </li> <li>customercustomer as outer<ul> <li>10+\\lceil (10/4)\\rceil \\cdot 2000 = 6.01010+\\lceil (10/4)\\rceil \\cdot 2000 = 6.010</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#index-based-block-nested-loop-join","title":"Index-based Block Nested Loop Join","text":"<p>Same principle as standard nested loop join</p> <ul> <li>Outer relation</li> <li>Inner relation</li> <li>Index lookups can replace file scans on the inner relation</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#merge-join","title":"Merge Join","text":"<p>Exploit sorted relations</p> <p></p> <p>Assumption: Both input relations are sorted</p> <p>Example in DBS8 slide 42 p. 126</p> <p>PDF on Moodle</p>"},{"location":"6-semester/DBS/08-query-optimization/#cost","title":"Cost","text":"<p>Parameters</p> <ul> <li>b_1, b_2:b_1, b_2: number of blocks</li> </ul> <p>Cost estimation (block transfer)</p>  b_1 + b_2   b_1 + b_2  <p>Extensions</p> <ul> <li>Combination with sorting if input relations are not sorted</li> <li>Not enough main memory</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#hash-join","title":"Hash Join","text":"<p>Apply hash functions to the join attributes</p> <p>\\to\\to partition tuples into buckets</p> <ul> <li>Hash each relation on the join attributes</li> <li>Each bucket must be small enough to fit into memory</li> <li>Join corresponding buckets from each relation</li> </ul> <p></p> <p>Example</p> <p></p> <p></p>"},{"location":"6-semester/DBS/08-query-optimization/#algorithm","title":"Algorithm","text":"<p>Parameters</p> <ul> <li>b_1, b_2b_1, b_2: number of blocks for tables R_1R_1 and R_2R_2</li> </ul> <p>Steps</p> <ul> <li> <p>Partitioning table R_1R_1 with h_1h_1 into buckets r_{1_i}r_{1_i} (read all / write all)</p> <p>2\\times b_12\\times b_1</p> </li> <li> <p>Partitioning table R_2R_2 with h_1h_1 into buckets r_{2_i}r_{2_i} (read all / write all)</p> <p>2\\times b_22\\times b_2</p> </li> <li> <p>Build phase: </p> <p>use h_2h_2 to create an in-memory hash index on bucket r_{1_i}r_{1_i} (read all)</p> <p>b_1b_1</p> </li> <li> <p>Probe phase</p> <p>for corresponding r_{2_i}r_{2_i}, use h_2h_2 to test in-memory index for matches (read all)</p> <p>b2b2</p> </li> </ul> <p>Cost estimation (block transfer)</p>  3 \\times b_1 + 3 \\times b_2 + \\epsilon   3 \\times b_1 + 3 \\times b_2 + \\epsilon  <p>\\epsilon\\epsilon: partially filled blocks</p>"},{"location":"6-semester/DBS/08-query-optimization/#cost-and-applicability-of-join-strategies","title":"Cost and Applicability of Join Strategies","text":"<p>Nested loop join</p> <ul> <li>Can be used for all join types</li> <li>Can be quite expensive</li> </ul> <p>Merge join</p> <ul> <li> <p>Files need to be sorted on the join attributes</p> <p>Sorting can be done for the purpose of the join</p> </li> <li> <p>Can use indexes</p> </li> </ul> <p>Hash join</p> <ul> <li>Good hash functions are essential</li> <li>Performance best if smallest relation fits into main memory</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#cost-based-physical-query-optimization","title":"Cost-based (Physical) Query Optimization","text":"<p>Objective</p> <p>For a given query, find the most efficient query execution plan</p> <p></p>"},{"location":"6-semester/DBS/08-query-optimization/#physical-query-optimization","title":"Physical query optimization","text":"<ul> <li>Generate alternative query execution plans</li> <li>Choose algorithms and access paths</li> <li>Compute costs</li> <li>Choose cheapest query execution plan</li> </ul> <p>Prerequisite</p> <ul> <li>Cost model</li> <li>Statistics on the input to each operation<ul> <li>Statistics on leaf relations: stored in system catalog</li> <li>Statistics on intermediate relations must be estimated (cardinalities)</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#selectivity-and-cardinality","title":"Selectivity and Cardinality","text":"<p>Statistics per Relation</p> <p>For relation rr</p> <ul> <li> <p>Number of tuples (records): n_rn_r</p> </li> <li> <p>Tuple size in relation rr: l_rl_r</p> </li> <li> <p>Load factor (fill factor), percentage of space used in each block</p> </li> <li> <p>Blocking factor (number of records per block)</p> </li> <li> <p>Relation size in blocks: b_rb_r</p> </li> <li> <p>Relation organization</p> <p>Heap, hash, indexes, clustered</p> </li> <li> <p>Number of overflow blocks</p> </li> </ul> <p>Statistics per Attribute</p> <p>For attribute AA in relation rr</p> <ul> <li> <p>Size and type</p> </li> <li> <p>Number of distinct values for attribute A:V(A,r)V(A,r)</p> <p>The same as the size of \\pi_A(r)\\pi_A(r)</p> </li> <li> <p>Selection cardinality S(A,r)S(A,r)</p> <p>The same as the size of \\sigma_{A=a}(r)\\sigma_{A=a}(r) for an arbitrary value aa</p> </li> <li> <p>Probability distribution over the values</p> <p>Alternative: assume uniform distribution</p> </li> </ul> <p>Statistics need to be updated when the table is updated!</p> <p>Statistics per Index</p> <ul> <li>Base relation</li> <li>Indexed attribute(s)</li> <li>Organization, eg. B+-tree, hash</li> <li>Clustering index?</li> <li>On key attribute(s)?</li> <li>Sparse or dense?</li> <li>Number of levels (if appropriate)</li> <li>Number of leaf-level index blocks</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#cost-estimation-example","title":"Cost Estimation Example","text":"<p>See example in DBS8 slide 53 p. 160</p> <p>PDF on Moodle</p>"},{"location":"6-semester/DBS/08-query-optimization/#cost-model","title":"Cost Model","text":"<p>Cost models consider more aspects than only disk access</p> <ul> <li>CPU time</li> <li>Communication time</li> <li>Main memory usage</li> <li>...</li> </ul> <p>For this purpose, we need to estimate input/output sizes of each operator</p> <ul> <li>Statistics on leaf relations: stored in system catalog</li> <li>Statistics on intermediate relations must be estimated (cardinalities)</li> </ul> <p>Additional aspects</p> <ul> <li>Spanning search space (dynamic programming, exhaustive search, ... )</li> <li>Bushy vs. left-deep join trees (parallelism vs. pipelining)</li> <li>Multiquery optimization (shared scans, ... )</li> <li>...</li> </ul>"},{"location":"6-semester/DBS/08-query-optimization/#heuristic-vs-cost-based-query-optimization","title":"Heuristic vs Cost-Based Query Optimization","text":""},{"location":"6-semester/DBS/08-query-optimization/#postgresql","title":"PostgreSQL","text":"<p><code>EXPLAIN</code></p> <ul> <li>Display the execution plan that the PostgreSQL planner generates for the supplied statement</li> </ul> <pre><code>EXPLAIN SELECT DISTINCT s.semester\nFROM student s, takes h,\ncourse v, professor p\nWHERE p.name=\u2018Socrates\u2018 AND\nv.taughtBy = p.empID AND\nv.courseID = h.courseID AND\nh.studID = s.studID;\n</code></pre> <p></p> <p><code>EXPLAIN ANALYZE</code></p> <ul> <li>The additional ANALYZE option causes the statement to be actually executed, not only planned</li> </ul> <p><code>ANALYZE</code></p> <ul> <li>ANALYZE collects statistics about the contents of tables in the database</li> </ul> <p></p> <p></p>"},{"location":"6-semester/DBS/08-query-optimization/#sequential-scans-vs-indexes","title":"Sequential Scans vs Indexes","text":"<p>If an index is \u201cuseful\u201d or not depends on</p> <ul> <li>How much data is relevant to the query</li> <li>Size of the relation</li> <li>Properties of the index (clustered, multiple columns, ... )</li> <li>What algorithm needs the data as input</li> <li>...</li> </ul> <p>Until query optimization is perfected, the main task of database administrators will remain query tuning (creating indexes, etc.).</p>"},{"location":"6-semester/DBS/guides/logical-query-optimization/","title":"Logical (Heuristic) Query Optimization","text":"<ol> <li> <p>Break up conjunctive selection predicates</p> </li> <li> <p>Push selections down</p> </li> <li> <p>Introduce joins by combining selections and cross products</p> </li> <li> <p>Determine join order </p> <p>Heuristic: execute joins with input from selections before executing other joins</p> </li> <li> <p>Introduce and push down projections</p> <p>Not always useful</p> </li> </ol> <p>Rules of thumb</p> <ul> <li>Perform selections as early as possible</li> <li>Perform projections as early as possible</li> </ul> <p>The optimization process</p> <ul> <li>Generate initial query plan from SQL statement</li> <li>Transform query plan into more efficient query plan via a series of modifications, each of which hopefully reducing execution time</li> </ul>"},{"location":"6-semester/DBS/guides/lossless-decomposition-and-dependency-preservation/","title":"Lossless decomposition and Dependency preservation","text":""},{"location":"6-semester/DBS/guides/lossless-decomposition-and-dependency-preservation/#check-for-lossless","title":"Check for Lossless","text":"<ul> <li>Find all common attributes in the two (or more) relations</li> <li>For each common attribute check if it is a super key for one of the relations based on the given functional dependencies<ul> <li>Super key means it can infer all other attributes, in this case in one of the relations</li> </ul> </li> <li>If a common attribute is a super key in one of the relations, the decomposition is lossless</li> </ul>"},{"location":"6-semester/DBS/guides/lossless-decomposition-and-dependency-preservation/#check-for-dependency-preservation","title":"Check for Dependency Preservation","text":"<ul> <li>For each functional dependency, check if they can be applied/is represented in/tested on any of the new relations<ul> <li>Probably easiest way to check: every attribute of a functional dependency, should be found in any single relation. This must be true for each functional dependency<ul> <li>For every functional dependency:<ul> <li>Check all attributes in the dependency, can be found in a single relation</li> </ul> </li> </ul> </li> <li>If true, the decomposition is dependency preserving</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/","title":"Mapping ER to Relations","text":"\\newcommand{\\relationRaw}[3]{     \\newcommand{\\pk}{\\underline}     #3\\mathbf{#1}#3#3:\\{[\\mathrm{#2}]\\} } \\newcommand{\\relation}[2]{\\relationRaw{#1}{#2}{}} \\newcommand{\\relational}[2]{\\relationRaw{#1}{#2}{&amp;}} \\nonumber  <ul> <li>Entities correspond to nouns, relationships to verbs</li> <li>Each statement in the requirement specification should be reflected somewhere in the ER schema</li> <li>Each ER diagram (ERD) should be located somewhere in the requirement specification</li> <li>Conceptual design often reveals inconsistencies and ambiguities in the requirement specification, which must first be resolved.</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#overview-of-the-steps","title":"Overview of the steps","text":"<ol> <li>Regular entity type<ul> <li>Create a relation, consider special attribute types</li> </ul> </li> <li> <p>Weak entity type</p> <ul> <li>Create a relation</li> </ul> </li> <li> <p>1:1 binary relationship type </p> <ul> <li>Extend a relation with foreign key</li> </ul> </li> <li>1:N binary relationship type <ul> <li>Extend a relation with foreign key</li> </ul> </li> <li>N:M relationship type<ul> <li>Create a relation</li> </ul> </li> <li>N-ary relationship type<ul> <li>Create a relation</li> </ul> </li> </ol>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#basic-approach","title":"Basic Approach","text":"<ul> <li>For each entity type \\to\\to relation</li> <li>Name of the entity type \\to\\to name of the relation</li> <li>Attributes of the entity type \\to\\to Attributes of the relation</li> <li>Primary key of the entity type \\to\\to Primary key of the relation</li> </ul> <p>We do not care about the order of attributes in this context!</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#mapping-of-nm-relationship-types","title":"Mapping of N:M Relationship Types","text":"<p>Basic Approach</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add the primary key attributes of all involved entity types</li> <li>Primary keys of involved entity types together become the key of the new relation</li> </ul>  \\bold{takes}:\\{[\\underline{\\text{studID} \\to \\text{student}}, \\underline{\\text{courseID} \\to \\text{course}}]\\}   \\bold{takes}:\\{[\\underline{\\text{studID} \\to \\text{student}}, \\underline{\\text{courseID} \\to \\text{course}}]\\}  <p>Key attributes \"imported\" from involved entity types (relations) are called foreign keys</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#mapping-of-1n-relationship-types","title":"Mapping of 1:N Relationship Types","text":"<p>Basic Approach</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add the primary key attributes of all involved entity types</li> <li>Primary key of the \"N\"-side becomes the key in the new relation</li> </ul> <p>Initial</p>  \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ &amp;\\bold{teaches} &amp;&amp;: \\{[\\underline{\\text{courseID}\\to \\text{course}}, \\text{empID} \\to \\text{professor}]\\} \\end{align*}   \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ &amp;\\bold{teaches} &amp;&amp;: \\{[\\underline{\\text{courseID}\\to \\text{course}}, \\text{empID} \\to \\text{professor}]\\} \\end{align*}  <p>Improved by Merging</p>  \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}, \\color{darkred}{\\text{taughtBy} \\to \\text{professor}}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ \\end{align*}   \\begin{align*} &amp;\\bold{course} &amp;&amp;:\\{[\\underline{\\text{courseID}}, \\text{title}, \\text{ects}, \\color{darkred}{\\text{taughtBy} \\to \\text{professor}}]\\}\\\\ &amp;\\bold{professor} &amp;&amp;:\\{[\\underline{\\text{empID}}, \\text{name}, \\text{rank},\\text{office}]\\}\\\\ \\end{align*}  <p>Relations with the same key can be combined, but  only these and no others!</p> <p>If the participation is not total, merging requires null values for the foreign key. In such cases, it might be preferable for some applications to have a separate relation.</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#mapping-of-11-relationship-types","title":"Mapping of 1:1 Relationship Types","text":"<ul> <li>New relation with all attributes of the relationship type</li> <li>Add primary key attributes of all involved entity types</li> <li>Primary key of any of the involved entity types can become the key in the new relation</li> </ul> <p>Initial</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\underline{vineyard}, address}\\\\ \\relational{owns}{\\underline{licenseID \\to license}, vineyard \\to producer}\\text{ or}\\\\ \\relational{owns}{licenseID \\to license, \\underline{vineyard \\to producer}} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\underline{vineyard}, address}\\\\ \\relational{owns}{\\underline{licenseID \\to license}, vineyard \\to producer}\\text{ or}\\\\ \\relational{owns}{licenseID \\to license, \\underline{vineyard \\to producer}} \\end{align*}  <p>Improvement</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount, ownedBy \\to producer}\\\\ \\relational{producer}{\\pk{vineyard}, address} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount, ownedBy \\to producer}\\\\ \\relational{producer}{\\pk{vineyard}, address} \\end{align*}  <p>Or</p>  \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\pk{vineyard}, address, ownsLicense \\to license} \\end{align*}   \\begin{align*} \\relational{license}{\\underline{licenseID}, amount}\\\\ \\relational{producer}{\\pk{vineyard}, address, ownsLicense \\to license} \\end{align*}  <p>It is best to extend a relation of an entity type with total participation</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#foreign-keys","title":"Foreign Keys","text":""},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#foreign-keys_1","title":"Foreign Keys","text":"<p>A foreign key is an attribute (or a combination of attributes) of a relation that references the primary key (or candidate key) of another relation</p> <p>Example</p> <ul> <li>\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy \\to professor}}\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy \\to professor}}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> </ul> <p>Here \\mathrm{taughtBy}\\mathrm{taughtBy} is a foreign key referencing relation professor</p> <p>Alternative Notation</p> <ul> <li>\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy}}\\relation{course}{\\pk{courseID}, title, ects, \\color{darkred}{taughtBy}}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> </ul> <p>Foreign key: \\mathrm{course.taughtBy \\to professor.empID}\\mathrm{course.taughtBy \\to professor.empID}</p> <p>Notation for composite keys: \\{R.A_1, R.A_2\\} \\to \\{S.B_1, S.B_2\\}\\{R.A_1, R.A_2\\} \\to \\{S.B_1, S.B_2\\}</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#weak-entity-types","title":"Weak Entity Types","text":"<p>Entities of a weak entity type are</p> <ul> <li>existentially dependent on a strong entity type</li> <li>uniquely identifiable in combination with the strong entity type's key</li> </ul> <p></p> <p>Mapping:</p> <ul> <li>New relation with all attributes of the relationship type</li> <li>Add primary key attributes of all involved entity types</li> <li>Foreign key of the \"N\"-side becomes the key in the new relation</li> </ul> <p>Initially</p> <ul> <li>\\relation{wine}{color,\\pk{name}}\\relation{wine}{color,\\pk{name}}</li> <li>\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}</li> <li>\\relation{belongsTo}{\\pk{name \\to wine, year \\to vintage}}\\relation{belongsTo}{\\pk{name \\to wine, year \\to vintage}}</li> </ul> <p>Merged</p> <p>Weak entity types and their identifying relationship types can always be merged</p> <ul> <li>\\relation{wine}{color,\\pk{name}}\\relation{wine}{color,\\pk{name}}</li> <li>\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}\\relation{vintage}{\\pk{name\\to wine, year}, residualSweetness}</li> </ul> <p>More complex example in DBS3 slides p 157</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#recursive-relationship-types","title":"Recursive Relationship Types","text":"<p>Mapping just like standard N:M relationship types and renaming of foreign keys</p> <ul> <li>\\relation{area}{\\pk{name}, region}\\relation{area}{\\pk{name}, region}</li> <li>\\relation{border}{\\pk{from\\to area, to \\to area}}\\relation{border}{\\pk{from\\to area, to \\to area}}</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#recursive-functional-relationship-types","title":"Recursive Functional Relationship Types","text":"<p>Mapping just like standard 1:N relationship types and merging</p> <ul> <li>\\relation{critic}{\\pk{name}, organization, mentor \\to critic}\\relation{critic}{\\pk{name}, organization, mentor \\to critic}</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#n-ary-relationship-types","title":"N-ary Relationship Types","text":"<p>Entity Types</p> <ul> <li>All participating entity types are mapped according to the standard rules</li> <li>\\relation{critic}{\\pk{name}, organization}\\relation{critic}{\\pk{name}, organization}</li> <li>\\relation{dish}{\\pk{description}, sideOrder}\\relation{dish}{\\pk{description}, sideOrder}</li> <li>\\relation{wine}{color, \\pk{WName}, year, residualSweetness}\\relation{wine}{color, \\pk{WName}, year, residualSweetness}</li> </ul> <p>N-ary Relationship Types (N:M:P)</p> <ul> <li>\\relation{recommends}{\\pk{WName \\to wine, description \\to dish, name \\to critic}}\\relation{recommends}{\\pk{WName \\to wine, description \\to dish, name \\to critic}}</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#nm1-relationship-type","title":"N:M:1 Relationship Type","text":"<p>Relations</p> <ul> <li>\\relation{student}{\\pk{studID}, name, semester}\\relation{student}{\\pk{studID}, name, semester}</li> <li>\\relation{course}{\\pk{courseID}, title, ects}\\relation{course}{\\pk{courseID}, title, ects}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{grades}{\\pk{studID\\to student, courseID\\to course},empID \\to professor, grade}\\relation{grades}{\\pk{studID\\to student, courseID\\to course},empID \\to professor, grade}</li> </ul> <p>A student + course only exists once in this relation, since the professor is the (1). Therefore, the professor is not part of the primary key.</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#multi-valued-attributes","title":"Multi-Valued Attributes","text":"<p>Relations</p> <ul> <li>\\relation{person}{\\pk{PID}, name}\\relation{person}{\\pk{PID}, name}</li> <li>\\relation{phoneNumber}{\\pk{PID \\to person, number}}\\relation{phoneNumber}{\\pk{PID \\to person, number}}</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#composite-attributes","title":"Composite Attributes","text":"<p>Include the component attributes in the relation</p> <ul> <li>\\relation{person}{\\pk{PID}, name, street, city}\\relation{person}{\\pk{PID}, name, street, city}</li> </ul>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#derived-attributes","title":"Derived Attributes","text":"<p>Ignored during mapping to relations, can be added later by using views</p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#relational-modeling-of-generalization","title":"Relational Modeling of Generalization","text":""},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#alternative-1-main-classes","title":"Alternative 1 - Main Classes","text":"<p>A particular entity is mapped to a single tuple in a single relation (to its main class)</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{assistant}{\\pk{empID}, name, department}\\relation{assistant}{\\pk{empID}, name, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#alternative-2-partitioning","title":"Alternative 2 - Partitioning","text":"<p>Parts of a particular entity are mapped to multiple relations, the key is duplicated</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID \\to employee}, rank, office}\\relation{professor}{\\pk{empID \\to employee}, rank, office}</li> <li>\\relation{assistant}{\\pk{empID\\to employee}, department}\\relation{assistant}{\\pk{empID\\to employee}, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#alternative-3-full-redundancy","title":"Alternative 3 - Full Redundancy","text":"<p>A particular entity is stored redundantly in the relations with all its inherited attributes</p> <ul> <li>\\relation{eployee}{\\pk{empID}, name}\\relation{eployee}{\\pk{empID}, name}</li> <li>\\relation{professor}{\\pk{empID}, name, rank, office}\\relation{professor}{\\pk{empID}, name, rank, office}</li> <li>\\relation{assistant}{\\pk{empID}, name, department}\\relation{assistant}{\\pk{empID}, name, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/guides/mapping-er-to-relations/#alternative-4-single-relation","title":"Alternative 4 - Single Relation","text":"<p>All entities are stored in a single relation. An additional attribute encodes the membership in a particular entity type.</p> <ul> <li>\\relation{employee}{\\pk{empID}, name, {\\color{darkred}{type}}, rank, office, department}\\relation{employee}{\\pk{empID}, name, {\\color{darkred}{type}}, rank, office, department}</li> </ul> <p></p>"},{"location":"6-semester/DBS/guides/minimal-cover/","title":"Calculate Minimal Cover (Canonical Cover)","text":"<ul> <li>Page 325 in book (PDF page 354)</li> <li>Example in DBS4 slides p 69</li> </ul>"},{"location":"6-semester/DBS/guides/minimal-cover/#left-reduction","title":"Left Reduction","text":"<ul> <li>If A is on the left side, let NL =LeftSide - A and check if NL \\to RightSideNL \\to RightSide</li> <li>NLNL: New Left</li> <li>Remember: only check pairs, as singletons would become empty and meaningless<ul> <li>This explanation is probably not correct, but makes sense</li> </ul> </li> <li>To do so, compute the closure of NL under the set of functional dependencies and check if all attributes in the closure is also in the right side<ul> <li>To compute closure under a functional dependency:</li> <li>Check which attributes can be inferred from the current attribute(s).</li> <li>This is recursive, so if A \\to BA \\to B, then AA can continue inferring what BB infers.</li> <li>Remember: An attribute can always infer itself</li> <li>Remember: The set of functional dependencies temporarily has AA removed from the chosen functional dependency</li> </ul> </li> </ul>"},{"location":"6-semester/DBS/guides/minimal-cover/#right-reduction","title":"Right Reduction","text":"<ul> <li>If AA is on the right side, let  F^*F^* be the set of functional dependencies without AA in its place</li> <li>Alternative explanation: Remove AA from it place in the current chosen functional dependency</li> <li>Check if the chosen dependency/the dependency AA was in still can infer to AA</li> <li>Do this by computing the closure of the chosen dependency under F</li> </ul>"},{"location":"6-semester/DBS/guides/normal-form/","title":"Determine Relational Schema Normal Form","text":"\\newcommand{\\dep}[2]{\\{#1\\} \\to \\{#2\\}} \\newcommand{\\schema}{\\mathcal{R}} \\newcommand{\\oneton}[1]{\\onetonop{#1}{,}} \\newcommand{\\onetonop}[2]{#1_{n} #2 \\dots #2  #1_{n}} \\nonumber"},{"location":"6-semester/DBS/guides/normal-form/#normal-forms","title":"Normal Forms","text":"Normal Form Main Characteristics 1NF Only atomic attributes 3NF Some transitive dependencies BCNF No transitive dependencies"},{"location":"6-semester/DBS/guides/normal-form/#check-1nf","title":"Check 1NF","text":"<p>A relation \\schema\\schema is in 1NF if the domains of all its attributes are atomic (no composite or set-valued domains)</p>"},{"location":"6-semester/DBS/guides/normal-form/#check-3nf","title":"Check 3NF","text":"<p>A relation schema \\schema\\schema is in 3NF if at least one of the following conditions holds for each of its FDs \\alpha \\to B\\alpha \\to B with B \\in \\schemaB \\in \\schema</p> <ol> <li>B \\in \\alphaB \\in \\alpha, i.e. the FD is trivial</li> <li>\\alpha\\alpha is a super key of RR</li> <li>BB is part of a candidate key for \\schema\\schema</li> </ol>"},{"location":"6-semester/DBS/guides/normal-form/#procedure","title":"Procedure","text":"<p>For each FD a\\to Ba\\to B with B \\in \\schemaB \\in \\schema check:</p> <ol> <li> <p>Is the FD trivial?</p> <ul> <li>B \\in aB \\in a</li> <li>E.g. X \\to XX \\to X</li> </ul> </li> <li> <p>Is aa a super key of RR?</p> <ul> <li>Does aa determine alla attribute values of RR?</li> </ul> </li> <li>Is BB part of a candidate key for \\schema\\schema</li> </ol>"},{"location":"6-semester/DBS/guides/normal-form/#check-bcnf","title":"Check BCNF","text":"<p>The same as 3NF except condition (3) is gone.</p> <p>A relation schema \\schema\\schema is in BCNF if at least one of the following conditions holds for each of its FDs \\alpha \\to B\\alpha \\to B with B \\in \\schemaB \\in \\schema</p> <ol> <li>B \\in \\alphaB \\in \\alpha, i.e. the FD is trivial</li> <li>\\alpha\\alpha is a super key of RR</li> </ol>"},{"location":"6-semester/DBS/guides/normal-form/#procedure_1","title":"Procedure","text":"<p>For each FD a\\to Ba\\to B with B \\in \\schemaB \\in \\schema check:</p> <ol> <li> <p>Is the FD trivial?</p> <ul> <li>B \\in aB \\in a</li> <li>E.g. X \\to XX \\to X</li> </ul> </li> <li> <p>Is aa a super key of RR?</p> <ul> <li>Does aa determine alla attribute values of RR?</li> </ul> </li> </ol>"},{"location":"7-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>DS - Distributed Systems</li> <li>PP - Programming Paradigms</li> <li>WI - Web Intelligence</li> </ul> <p>Moodle side:</p> <p>https://www.moodle.aau.dk/course/view.php?id=34705</p> <p></p>"},{"location":"7-semester/DS/","title":"DS - Distributed Systems","text":"<p>Moodle page:</p> <p>https://www.moodle.aau.dk/course/view.php?id=34734</p> <p></p>"},{"location":"7-semester/DS/01-introduction/","title":"Introduction","text":"<p>A distributed system is one in which the failure of a computer you didn\u2019t even know existed can render your own computer unusable.</p> <p>- Leslie Lamport</p> <p>What is a distributed system?</p> <ul> <li>A distributed system is one where hardware and software components in/on networked computers communicate and coordinate their activity only by passing messages.</li> </ul> <p></p> <p></p> <p></p>"},{"location":"7-semester/DS/01-introduction/#consequences","title":"Consequences","text":"<ul> <li> <p>Concurrency</p> <ul> <li>Deadlocks and livelocks</li> <li>Non-determinism</li> </ul> </li> <li> <p>No shared state</p> <ul> <li>Pass messages to synchronize</li> <li>May not agree on time</li> </ul> </li> <li>Everything can fail<ul> <li>Devices</li> <li>Network<ul> <li>Security!</li> <li>Man-in-the-middle</li> <li>Byzantine Failures</li> </ul> </li> <li>Integrity of data</li> </ul> </li> </ul>"},{"location":"7-semester/DS/01-introduction/#non-determinism","title":"Non-determinism","text":"<p>Figure:  Properties of the network can lead to confusion for Alice</p>"},{"location":"7-semester/DS/01-introduction/#pass-messages-to-synchronize","title":"Pass messages to synchronize","text":"<p>Figure: Lack of shared state can lead to unexpected behavior from the perspective of Bob.</p>"},{"location":"7-semester/DS/01-introduction/#may-not-agree-on-time","title":"May not agree on time","text":"<p>Figure: Measuring time is hard.(Texas Instruments xx555PrecisionTimers)</p>"},{"location":"7-semester/DS/01-introduction/#network-failure","title":"Network failure","text":"<p>Figure: Failure of the network can lead to unexpected behavior from the perspective of Alice.</p>"},{"location":"7-semester/DS/01-introduction/#reasons-for-distribution","title":"Reasons for Distribution","text":"<ul> <li>Domain<ul> <li>Physical limits</li> <li>Logical limits</li> </ul> </li> <li>Redundancy<ul> <li>Available</li> <li>Robust</li> </ul> </li> <li>Performance<ul> <li>Economics</li> <li>Scalability</li> </ul> </li> </ul>"},{"location":"7-semester/DS/01-introduction/#domain","title":"Domain","text":"<ul> <li>The internet</li> <li>Wireless Mesh networks</li> <li>Industrial systems</li> <li>Ledgers (BitCoin, Ether)</li> </ul>"},{"location":"7-semester/DS/01-introduction/#redundancy","title":"Redundancy","text":"<ul> <li>99.9% uptime</li> <li>Backup</li> <li>Database</li> <li>Banking</li> </ul>"},{"location":"7-semester/DS/01-introduction/#independent-failure","title":"Independent Failure","text":"<p>Dependent</p> <ul> <li>One fail = system fail</li> <li>uptime = (1-p)^n</li> </ul> <p>Independent</p> <ul> <li>All fail = system fail</li> <li>uptime = 1-p^nuptime = 1-p^n</li> </ul> <p></p> <p></p> <p>Figure: A Netflix approach to fault tolerance.</p>"},{"location":"7-semester/DS/01-introduction/#performance","title":"Performance","text":"<ul> <li>Video streaming</li> <li>Cloud computing</li> <li>Supercomputers<ul> <li>Weather forecast</li> <li>Machine learning</li> </ul> </li> <li>Many inexpensive vs few expensive and specialized</li> </ul>"},{"location":"7-semester/DS/01-introduction/#amdahls-law","title":"Amdahl's Law","text":"speedup = \\frac {1} {1-p + \\frac {p} {n}}   speedup = \\frac {1} {1-p + \\frac {p} {n}}  <ul> <li>pp = fraction of parallel work</li> <li>nn = number of processors</li> </ul> <p>Minimize sequential part</p>"},{"location":"7-semester/DS/01-introduction/#example-f-klub-accounting","title":"Example - F-Klub Accounting","text":"<ul> <li>Each person does accounting for a month</li> <li>After all months are computed<ul> <li>Compute sum of year (1 person)</li> </ul> </li> <li>1 hour per sum computed</li> </ul> <p>1 Person</p> <ul> <li>1+12=13 \\text{ Hours}1+12=13 \\text{ Hours} </li> </ul> <p>12 Person</p> <ul> <li>1+1=2 \\text{ Hours}1+1=2 \\text{ Hours} </li> </ul> <p>Speedup</p> <ul> <li>{13 \\over 2} = 6.5 \\times Speedup{13 \\over 2} = 6.5 \\times Speedup</li> </ul>"},{"location":"7-semester/DS/01-introduction/#speeding-up-is-hard","title":"Speeding up is hard","text":"<ul> <li>Communication Overhead</li> <li>Locking and synchronization</li> </ul>"},{"location":"7-semester/DS/01-introduction/#scalability-examples","title":"Scalability Examples","text":""},{"location":"7-semester/DS/02-os-and-networking-fundamentals/","title":"OS and Networking Fundamentals","text":""},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#processes","title":"Processes","text":"<p>A process is a running program (an instance of a program).</p> <ul> <li>One of the most profound ideas in computer science</li> <li>Not the same as \u201cprogram\u201d or \u201cprocessor\u201d</li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#running-processes","title":"Running Processes","text":"<p>Proces = A running program = A private \u201daddress space\u201d+ one or more \u201dexecution threads\u201d.</p> <ul> <li>Ordinary user program</li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#internet","title":"Internet","text":""},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#internet-protocol-stack","title":"Internet Protocol Stack","text":"<p>Protocol Layers</p> <ul> <li>Protocol layering is the main structuring method used to divide up network functionality.</li> <li>Make abstractions that hide specific complexities/problems of the underlying system</li> <li>A protocol is a set of rules that describe how messages are exchanged and formatted<ul> <li>Each protocol instance talks virtually to its peer</li> <li>Each layer communicates only by using the one below</li> <li>Lower layer services are accessed by an interface</li> <li>At bottom, messages are carried by the medium</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#why-layering","title":"Why Layering?","text":"<ul> <li>To deal with complex systems</li> <li>Explicit structure allows identification, relationship of complex system's pieces<ul> <li>Layered reference model for discussion</li> </ul> </li> <li>Modularization eases maintenance, updating of system<ul> <li>change of implementation of layer\u2019s service transparent to rest of system</li> <li>IPv4 to IPv6 change does not affect hardware layer</li> </ul> </li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#osi-reference-model","title":"OSI Reference Model","text":"<p>A principled, international standard, seven layer model to connect different systems</p> <p></p> <p>CN5E by Tanenbaum &amp; Wetherall, \u00a9 Pearson EducationPrentice Hall and D. Wetherall, 2011</p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#tcpip-reference-model","title":"TCP/IP Reference Model","text":"<p>What we are using today (?)</p> <p>A four layer model derived from experimentation; omits some OSI layers and uses the IP as the network layer</p> <p></p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#critique-of-osi-tcpip","title":"Critique of OSI &amp; TCP/IP","text":"<p>OSI</p> <ul> <li>(+) Very influential model with clear concepts</li> <li>(-) Models, protocols and adoption all bogged down by politics and complexity</li> </ul> <p>TCP/IP</p> <ul> <li>(+) Very successful protocols that worked well and thrived</li> <li>(-) Weak model derived after the fact from protocols</li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#encapsulation","title":"Encapsulation","text":"<ul> <li>Control flow goes down the protocol layers at the sender, and up at the receiver</li> <li>Header-payload model</li> <li>Each lower layer adds its own header (with control information) to the message to transmit and removes it on receive<ul> <li>\u201cEnveloping\u201d</li> </ul> </li> <li>Layers may also split and join messages, etc: Segmentation and re-assembly</li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#an-application-layer-protocol-http","title":"An Application Layer Protocol - HTTP","text":"<p>HTTP: hypertext transfer protocol</p> <ul> <li>Web\u2019s application layer protocol</li> <li>client/server model<ul> <li>client: browser that requests, receives, (using HTTP protocol) and \"displays\" Web objects</li> <li>server: Web server sends (using HTTP protocol) objects in response to requests</li> </ul> </li> <li>client initiates TCP connection (creates socket) to server, port 80</li> </ul> <p></p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#http-messages","title":"HTTP Messages","text":"<p>Client Message</p> <p></p> <p>Server Response</p> <p></p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#non-persistent-http-response-time","title":"Non-Persistent HTTP: Response Time","text":"<p>Slide pdf 57</p>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#transport-layer-protocols","title":"Transport Layer Protocols","text":"<ul> <li>provide logical communication between app processes running on different hosts</li> <li>transport protocols run in end systems<ul> <li>send side: breaks app messages into segments, passes to network layer</li> <li>rcv side: reassembles segments into messages, passes to app layer</li> </ul> </li> <li>more than one transport protocol available to apps<ul> <li>Internet: TCP and UDP</li> </ul> </li> </ul> <p>Transmission control protocol (TCP)</p> <ul> <li>Connection Oriented</li> <li>Reliable*), in-order delivery, byte-stream<ul> <li>congestion control: throttle sender when network overloaded</li> <li>flow control: sender won\u2019t overwhelm receiver</li> <li>connection setup</li> </ul> </li> </ul> <p>(Reliable=if neither sender nor receiver fails during transmissions, and if network failures doesn\u2019t persist (too long), data is eventually delivered!)</p> <p>User datagram Protocol (UDP)</p> <ul> <li>Connectionless, unreliable,<ul> <li>no-frills extension of \u201cbest-effort\u201d IP</li> <li>Message-loss</li> <li>Messages delivered out-of-order</li> </ul> </li> <li>Streaming multimedia apps (loss tolerant, rate sensitive), DN S, SNMP</li> </ul> <p>services not available:</p> <ul> <li>delay guarantees</li> </ul>"},{"location":"7-semester/DS/02-os-and-networking-fundamentals/#sockets","title":"Sockets","text":"<ul> <li>The main API for programming network applications</li> <li>process sends/receives messages to/from its socket</li> <li>socket analogous to door<ul> <li>sending process shoves message out door</li> <li>sending process relies on transport infrastructure on other side of door to deliver message to socket at receiving process</li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/","title":"Mutual Exclusion (Mutex) and Election","text":"<p>Mutual exclusion algorithms ensures that one and only one process can access a shared resource at any given time.</p> <p>Examples</p> <ul> <li>Printing</li> <li>Using Coffee Machine</li> <li>Writing a file</li> <li>Changing an actuator<ul> <li>Arm of robot</li> </ul> </li> <li>Wireless communication</li> <li>Wired communication</li> </ul>"},{"location":"7-semester/DS/03-mutex/#system-model","title":"System Model","text":"<p>What is a (computer science) process?</p> <p>A process p=(S,s_i, M, \\to) in a set of processes p\\in Pp\\in P has</p> <ul> <li>a set of states SS</li> <li>an initial state s_i\\in Ss_i\\in S</li> <li>a set of messages MM<ul> <li>including the empty message \\epsilon \\in M\\epsilon \\in M</li> </ul> </li> <li>and a transition function \\to \\subseteq S \\times M \\mapsto S \\times 2^{P\\times M}\\to \\subseteq S \\times M \\mapsto S \\times 2^{P\\times M}</li> </ul>"},{"location":"7-semester/DS/03-mutex/#example","title":"Example","text":"<pre><code>defmodule Pinger do\ndef start_link() do\nTask.start_link(fn -&gt; loop() end)\nend\n\ndefp loop(output_ping \\\\ false) do\nrecieve do\n{:ping} -&gt;\nif output_ping do\nIO.puts(\"ping\")\nelse\nIO.puts(\"pong\")\nend\nloop(!output_ping)\nend\nend\nend\n</code></pre> <ul> <li>S=\\{loop(output\\_ping = true), loop(output\\_ping = false)\\}S=\\{loop(output\\_ping = true), loop(output\\_ping = false)\\}</li> <li>s_i=\\{(output\\_ping = false\\}s_i=\\{(output\\_ping = false\\}</li> <li>M=\\{:ping\\}M=\\{:ping\\}</li> <li>\\to\\ = recieve\\to\\ = recieve</li> </ul>"},{"location":"7-semester/DS/03-mutex/#events","title":"Events","text":"<ul> <li>Computation is fast</li> <li>Communication is slow</li> </ul> <p>Measure of Performance</p> <p>Time is counted in number of messages/events</p>"},{"location":"7-semester/DS/03-mutex/#network-models","title":"Network Models","text":"<p>Asynchronous</p> <ul> <li>Arbitrary delays</li> <li>Unknown processing time</li> </ul> <p></p> <p>Synchronous</p> <ul> <li>Known delays<ul> <li>or hard limits of them</li> </ul> </li> <li>Known drift</li> </ul> <p></p> <p></p> <p>Figure: Properties of the network can lead to confusion for Alice</p>"},{"location":"7-semester/DS/03-mutex/#assumptions","title":"Assumptions","text":"<ul> <li>Processe have Crash Failures<ul> <li>Stays dead</li> </ul> </li> <li>Direct Communication<ul> <li>Transparent routing</li> <li>No forwarding</li> </ul> </li> <li>Reliable Communication<ul> <li>Synchronous<ul> <li>Delivery within fixed timeframe</li> </ul> </li> <li>Asynchronous<ul> <li>Delivery at at some point</li> <li>Underlying protocol handles re-transmission etc.</li> </ul> </li> <li>Partitions are fixed eventually</li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/#mutex-algorithms","title":"Mutex Algorithms","text":""},{"location":"7-semester/DS/03-mutex/#requirements","title":"Requirements","text":"<ol> <li>Safety<ul> <li>at most one is given access</li> </ul> </li> <li>Liveness<ul> <li>Requests for access are (eventually) granted</li> </ul> </li> <li>Ordering/Fairness<ul> <li>A request AA happened-before request BB \\Rightarrow\\Rightarrow grant AA before BB</li> </ul> </li> </ol>"},{"location":"7-semester/DS/03-mutex/#properties","title":"Properties","text":"<ul> <li>Fault tolerance<ul> <li>What happens when a process crashes?</li> </ul> </li> <li>Performance<ul> <li>Message Complexity<ul> <li>How many messages to get mutex?</li> <li>How many to release? </li> </ul> </li> <li>Client Delay<ul> <li>Time from a request RR to a grant of RR</li> </ul> </li> <li>Synchronization Delay<ul> <li>Time from a release of RR to a grant of the next request QQ</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/#centralized-algorithm","title":"Centralized Algorithm","text":"<ul> <li>Assume one external coordinator<ul> <li>Coordinator has ordered queue</li> </ul> </li> <li>Ask coordinator for access</li> </ul>"},{"location":"7-semester/DS/03-mutex/#code","title":"Code","text":""},{"location":"7-semester/DS/03-mutex/#properties_1","title":"Properties","text":"<p>Requirements</p> <ul> <li>Safe: Yes</li> <li>Liveness: Yes</li> <li>Ordering: No!</li> </ul> <p>Properties</p> <ul> <li>Client Delay<ul> <li>Entry: 2 (request + grant)</li> <li>Exit: 1</li> </ul> </li> <li>Synchronization Delay<ul> <li>2 (release + grant)</li> </ul> </li> <li>Bandwidth: 3</li> </ul> <p>Fault Tolerance</p> <ul> <li>Deadlock if Coordinator fails </li> <li>Deadlock if mutex-holder fails</li> </ul>"},{"location":"7-semester/DS/03-mutex/#token-ring-algorithm","title":"Token Ring Algorithm","text":"<p>Idea</p> <ul> <li>Send token around in a ring<ul> <li>Assumes ordering of processes</li> </ul> </li> <li>Forward token to \"next\" if not using mutex</li> <li>Enter mutex if token is acquired</li> </ul>"},{"location":"7-semester/DS/03-mutex/#code_1","title":"Code","text":""},{"location":"7-semester/DS/03-mutex/#properties_2","title":"Properties","text":"<p>Requirements </p> <ul> <li>Safe: Yes</li> <li>Liveness: Yes</li> <li>Ordering: No (order by ring)</li> </ul> <p>Properties</p> <ul> <li>Client Delay<ul> <li>Entry: n/2n/2 avg, n \u2212 1n \u2212 1 worst case</li> <li>Exit: 1</li> </ul> </li> <li>Synchronization Delay<ul> <li>n/2n/2 avg, n-1n-1 worst case</li> </ul> </li> <li>Bandwidth: \\infty\\infty</li> </ul> <p>Fault Tolerance</p> <ul> <li>Deadlock if any process fail</li> <li>Can be recovered if crash can be detected reliably</li> </ul>"},{"location":"7-semester/DS/03-mutex/#ricard-and-agrawalas-algorithm","title":"Ricard and Agrawala's Algorithm","text":"<p>Idea</p> <ul> <li>Order events!<ul> <li>Extension of shared priority queue (Lamport '78)</li> </ul> </li> <li>Basic algorithm<ul> <li>Request all for access</li> <li>Wait for all to grant</li> </ul> </li> </ul> <p>Secret Ingredient</p> <ul> <li>Lamport clocks</li> </ul>"},{"location":"7-semester/DS/03-mutex/#lamport-clocks","title":"Lamport Clocks","text":"<ul> <li>Counter number of messages/events</li> <li>Annotate messages with clock</li> <li>Increment local before send</li> <li>\"Correct\" local clock on receive, then increment<ul> <li>\\max(A,B)+1\\max(A,B)+1</li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/#protocol-pseudo-code","title":"Protocol Pseudo Code","text":"<pre><code>On initialization\n    state := RELEASED\n\nTo get mutex\n    state := WANTED                                             # \n    Multicast request to every process      #   defer other request here\n    T := request's timestamp                            #\n    wait until (len(replies received) = (N - 1))\n    state := HELD\n\nOn request &lt;T_i, p_i&gt; at p_j (i != j)\n    if (state = HELD or (state = WANTED and (T,p_j) &lt; (T_i, p_i)))\n    then\n        queue request from p_i without reply\n  else\n    reply immediately to p_i\n  end if\n\nTo exit mutex\n    state := RELEASED\n    reply to any queued requests\n</code></pre>"},{"location":"7-semester/DS/03-mutex/#elixir-code","title":"Elixir Code","text":""},{"location":"7-semester/DS/03-mutex/#properties_3","title":"Properties","text":"<p>Requirements</p> <ul> <li>Safe: Yes</li> <li>Liveness: Yes</li> <li>Ordering: Yes</li> </ul> <p>Properties</p> <ul> <li>Client delay:<ul> <li>Entry: 1 (multicast) + 1</li> <li>Exit: 1 (multicast) + 1</li> </ul> </li> <li>Synchronization delay<ul> <li>1</li> </ul> </li> <li>Bandwidth: 2(n-1)2(n-1) if no hardware multicast</li> </ul> <p>Fault Tolerance</p> <ul> <li>Deadlock if any process fails</li> </ul>"},{"location":"7-semester/DS/03-mutex/#maekawas-algorithm","title":"Maekawas Algorithm","text":"<p>Idea</p> <ul> <li>only communicate with a subset (Voting Set VV)</li> <li>pick VV cleverly</li> <li>Basic algorithm<ul> <li>Ask everybody in VV for access</li> <li>Wait for all to grant</li> </ul> </li> </ul> <p></p> <ul> <li> <p>Voting set of p_{14}= \\{p_2, p_8, p_{13}, p_{14}, p_{15}, p_{16}, p_{17}, p_{18}, p_{20}, p_{26}, p_{32}\\}p_{14}= \\{p_2, p_8, p_{13}, p_{14}, p_{15}, p_{16}, p_{17}, p_{18}, p_{20}, p_{26}, p_{32}\\}</p> </li> <li> <p>Voting set of p_{29} = \\{p_5, p_{11}, p_{17}, p_{23}, p_{25}, p_{26}, p_{27}, p_{28}, p_{29}, p_{30}, p_{35}\\}p_{29} = \\{p_5, p_{11}, p_{17}, p_{23}, p_{25}, p_{26}, p_{27}, p_{28}, p_{29}, p_{30}, p_{35}\\}</p> </li> </ul> <p>Notice</p> <ul> <li>Non-trivial to compute optimal sets</li> </ul>"},{"location":"7-semester/DS/03-mutex/#voting-set","title":"Voting Set","text":"<p>Let P=\\{p_0, \\dots, p_n\\}P=\\{p_0, \\dots, p_n\\} be a set of processes, then V_i \\subseteq PV_i \\subseteq P is a voting set for p_i \\in Pp_i \\in P if</p> <ul> <li>any p_i \\in Pp_i \\in P has a V_iV_i, and<ul> <li>p_i \\in V_ip_i \\in V_i,<ul> <li>Every process has a voting set and is member of its own voting set</li> </ul> </li> </ul> </li> <li>for all i,ji,j we have V_i \\cap V_j \\neq \\emptyV_i \\cap V_j \\neq \\empty<ul> <li>At least one shared process between two voting sets</li> </ul> </li> <li>for any ii we have |V_i| = K|V_i| = K,<ul> <li>All voting sets have the same size</li> </ul> </li> <li>for any ii we have |\\{V_k \\mid p_i \\in V_k\\}| = M|\\{V_k \\mid p_i \\in V_k\\}| = M<ul> <li>All processes are members of the same number of voting sets</li> </ul> </li> <li>M=KM=K and K \\geq \\sqrt{n-1}K \\geq \\sqrt{n-1}</li> </ul>"},{"location":"7-semester/DS/03-mutex/#code_2","title":"Code","text":""},{"location":"7-semester/DS/03-mutex/#problem","title":"Problem","text":"<ul> <li>Deadlock can happen with three processes!</li> <li>Can be solved by using Lamport Clocks</li> </ul>"},{"location":"7-semester/DS/03-mutex/#properties_4","title":"Properties","text":"<p>Requirements</p> <ul> <li>Safe: Yes</li> <li>Liveness: Yes</li> <li>Ordering: Yes</li> </ul> <p>Properties</p> <ul> <li>Client delay<ul> <li>Entry: 2 (multicast)</li> <li>Exit: 1 (multicast)</li> </ul> </li> <li>Synchronization delay<ul> <li>2, any two voting sets overlap</li> </ul> </li> <li>Bandwidth: 3 \\sqrt n3 \\sqrt n if no hardware multicast</li> </ul> <p>Fault tolerance</p> <ul> <li>Deadlock in voting-set if process crashes</li> </ul>"},{"location":"7-semester/DS/03-mutex/#overview","title":"Overview","text":"Algorithm Messages Entry/Exit Sync Delay Problems Central 33 22 Coord. Crash, Client Crash w. mutex Token ring 1...\\infty1...\\infty avg n / 2n / 2 Lost token, Crash of process R &amp; A 2(n-1)2(n-1) 11 Crash of any process Maekava 3 \\sqrt n3 \\sqrt n 22 Crash in voting-set = deadlock"},{"location":"7-semester/DS/03-mutex/#summary","title":"Summary","text":"<ul> <li>Crashes are bad</li> <li>Mitigation is non-trivial</li> <li>Detection is hard too</li> </ul>"},{"location":"7-semester/DS/03-mutex/#heartbeat","title":"Heartbeat","text":"<p>For synchronized systems</p> <ul> <li>Assume transmission delay DD</li> <li>Send \"beat\" every TT seconds</li> <li>Declared dead if not observed in last T+DT+D seconds</li> </ul> <p>For asynchronized systems</p> <ul> <li>Guess a DD</li> <li>Send \"beat\" every TT seconds</li> <li>Declared dead if not observed in last T+DT+D seconds<ul> <li>DD too small \\Longrightarrow\\Longrightarrow Inaccurate<ul> <li>alive reported dead</li> </ul> </li> <li>DD too large \\Longrightarrow\\Longrightarrow Incomplete<ul> <li>dead reported alive (zombies!)</li> </ul> </li> </ul> </li> <li>We can only suspect a crash!</li> </ul>"},{"location":"7-semester/DS/03-mutex/#leader-election","title":"Leader Election","text":"<p>Leader election algorithms ensure that one, and only one process is elected as the leader in the event of lack of a leader.</p>"},{"location":"7-semester/DS/03-mutex/#examples","title":"Examples","text":"<ul> <li>Algorithms with coordinator<ul> <li>Mutex?</li> </ul> </li> <li>Distributed replication</li> <li>DNS-servers in case of network partition</li> <li>Failover mechanism for crashes</li> <li>Parliaments?</li> </ul>"},{"location":"7-semester/DS/03-mutex/#requirements_1","title":"Requirements","text":"<p>Let P=\\{p_1, \\dots, p_n\\}P=\\{p_1, \\dots, p_n\\} be a set of processes and let L(p_i) \\in P \\cup \\{\\bot\\}L(p_i) \\in P \\cup \\{\\bot\\} be the leader as seen from a process p_ip_i</p> <ol> <li>Safety<ul> <li>either L(p_i) = \\botL(p_i) = \\bot or L(p_i) = p_jL(p_i) = p_j<ul> <li>p_jp_j is largest non-crashed process (in terms of jj)</li> </ul> </li> </ul> </li> <li>Liveness<ul> <li>All process participate, and either<ul> <li>a process crashes, or</li> <li>L(p_i) \\neq \\botL(p_i) \\neq \\bot</li> </ul> </li> </ul> </li> </ol> <p>Note</p> <p>Processes can crash during the election</p>"},{"location":"7-semester/DS/03-mutex/#assumptions_1","title":"Assumptions","text":"<ul> <li>Processes stay dead</li> <li>Crashes are reliably detected</li> <li>Identifiers are unique</li> </ul>"},{"location":"7-semester/DS/03-mutex/#chang-roberts","title":"Chang Roberts","text":""},{"location":"7-semester/DS/03-mutex/#idea","title":"Idea","text":"<ul> <li>Pass token of largest ID in a ring</li> <li>Basic algorithm in election<ul> <li>Forward ID to \"next\" if higher than own</li> <li>Forward own ID to \"next\" otherwise</li> <li>Only one active election</li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/#code_3","title":"Code","text":""},{"location":"7-semester/DS/03-mutex/#properties_5","title":"Properties","text":"<ul> <li>Safe</li> <li>Live</li> <li>3N -13N -1 messages per election</li> </ul> <p>Crashes?</p> <ul> <li>Can be overcome if reliably detected</li> </ul>"},{"location":"7-semester/DS/03-mutex/#bully-algorithm","title":"Bully Algorithm","text":""},{"location":"7-semester/DS/03-mutex/#idea_1","title":"Idea","text":"<ul> <li>Bully election requests into silence</li> <li>Priority by ID</li> <li>Basic algorithm in election<ul> <li>Send \"shut up\" to lower ID's</li> <li>Request election requests to higher ID's</li> <li>Highest alive ID broadcasts itself</li> </ul> </li> </ul> <p>Note</p> <ul> <li>Depends on Synchronous Behavior! </li> </ul>"},{"location":"7-semester/DS/03-mutex/#code_4","title":"Code","text":""},{"location":"7-semester/DS/03-mutex/#properties_6","title":"Properties","text":"<ul> <li>Safe and Live, assuming<ul> <li>Unique ID's</li> <li>Failure detection is reliable</li> </ul> </li> <li>Best-case: N-2N-2 messages per election</li> <li>Worst-case: O(N^2)O(N^2) messages</li> <li>Election-time: 2 rounds<ul> <li>assuming hardware multicast</li> </ul> </li> </ul>"},{"location":"7-semester/DS/03-mutex/#beware","title":"Beware","text":"<p>Safety is broken if</p> <ul> <li>too tight deadline,</li> <li>process ID's reappear, or</li> <li>system is not synchronous</li> </ul> <p>I.e. does not work in Elixir: Requires</p> <ul> <li>synchronous system**, and</li> <li>ordering of messages</li> </ul>"},{"location":"7-semester/DS/04-multicast/","title":"Multicast","text":"<p>A multicast is one-to-many communication between a single process and a specific group of processes such that all members of the group receive the message</p> <p>Examples</p> <ul> <li>Algorithms with failover/replication/redundancy <ul> <li>DNS </li> <li>Databases</li> <li>Caches</li> <li>Banks! </li> </ul> </li> <li>One-to-many<ul> <li>Streaming of TV/Radio</li> <li>Industrial Systems</li> </ul> </li> <li>Many-to-many<ul> <li>Skype</li> <li>Teams</li> <li>. . .</li> </ul> </li> </ul> <p>Big Question:</p> <p>How do we guarantee that everyone gets the same information?</p> <p>And what do we mean by same?</p> <p>Assumptions</p> <ul> <li>We assume closed groups<ul> <li>No communication from and to outside the group</li> </ul> </li> <li>We assume static groups<ul> <li>Nobody is joining group in the middle of transmission</li> </ul> </li> <li>Not discussing multiple groups<ul> <li>Problems if groups overlaps / shared members</li> </ul> </li> </ul>"},{"location":"7-semester/DS/04-multicast/#ip-multicast","title":"IP Multicast","text":"<ul> <li>Use IGMP (Internet Group Management Protocol)</li> <li>Get IP of group<ul> <li>IPv4: 224.0.0.0 - 239.255.255.255 (-224.0.0.255 for permanent)</li> <li>IPv6: FF00::/8</li> </ul> </li> <li>Build on UDP over IP</li> <li>Careful of firewalls/NAT</li> </ul>"},{"location":"7-semester/DS/04-multicast/#hardware-support","title":"Hardware Support","text":"<p>Without hardware we have to send 3 messages</p> <p>With hardware the router takes care of the message sending</p> <p></p>"},{"location":"7-semester/DS/04-multicast/#with-hardware-support-example","title":"With Hardware Support Example","text":""},{"location":"7-semester/DS/04-multicast/#without-hardware-support-example","title":"Without Hardware Support Example","text":""},{"location":"7-semester/DS/04-multicast/#problems","title":"Problems","text":"<p>UDP has no guarantees</p> <ul> <li>No re-transmission<ul> <li>no reception guaranteed</li> <li>one attempt only</li> </ul> </li> <li>No ordering<ul> <li>Messages are delivered in arbitrary order</li> </ul> </li> </ul> <p></p> <p>UDP can drop packages:</p> <p></p>"},{"location":"7-semester/DS/04-multicast/#requirements","title":"Requirements","text":"<p>Assuming</p> <ul> <li>Reliable 1:1 communication</li> <li>Sender might crash<ul> <li>If it crashes it stays dead</li> </ul> </li> <li>No order<ul> <li>Would work fine in asynchronous setting</li> </ul> </li> </ul> <p>Guarantee</p> <ul> <li>If a message is sent, it is delivered exactly once</li> <li>Messages are eventually delivered to non-crashed processes</li> </ul>"},{"location":"7-semester/DS/04-multicast/#delivery","title":"Delivery","text":""},{"location":"7-semester/DS/04-multicast/#basic-multicast","title":"Basic Multicast","text":"<p><code>:send</code></p> <ul> <li>iterate through the group and send them the message</li> </ul> <p><code>:message</code></p> <ul> <li>sends the message to the application</li> </ul> <p>Sender can fail while sending messages to group</p> <ul> <li>If it crashes midway, some processes will not receive the message while others do</li> </ul> <p>Reliable send =&gt; ACK implosion</p> <ul> <li>If a lot of processes send back acknowledgment, I \"DDOS\" myself</li> </ul>"},{"location":"7-semester/DS/04-multicast/#reliable-multicast","title":"Reliable Multicast","text":"<p>Satisfy these 3 properties</p> <ul> <li>Integrity<ul> <li>No \"identity theft\"</li> <li>implicit here</li> </ul> </li> <li>Validity<ul> <li>A process delivers to itself (or it crashes)</li> </ul> </li> <li>Agreement<ul> <li>All deliver or none deliver</li> </ul> </li> </ul> <p></p> <p></p> <p><code>b_multicast</code> is the basic multipart algorithm from above</p> <p>Everyone broadcasts the message in the \"2nd round\", but does not re-transmit if it comes from itself (26)</p> <p>Integrity: Yes!</p> <p>Validity: Yes!</p> <p>Agreement: Yes!</p> <p>1 multicast = O(N^2) packages in the network</p>"},{"location":"7-semester/DS/04-multicast/#udp-fix-steal-ideas-from-tcp","title":"UDP Fix: Steal ideas from TCP","text":"<ul> <li>Use sequence numbers<ul> <li>to detect duplicates</li> <li>to track lost messages</li> </ul> </li> <li>Use \"hold-back\"-construction<ul> <li>wait for re-transmission</li> <li>replication of messages</li> </ul> </li> <li>Keep track of sequence numbers of others</li> <li>\"gossip\" sequence numbers<ul> <li>whenever a process sends a message</li> <li>every process knows how many messages the other processes has sent</li> </ul> </li> </ul>"},{"location":"7-semester/DS/04-multicast/#hold-back-queue","title":"Hold-back Queue","text":"<p>The delivery queue is handled by Elixir in the code</p> <ul> <li>Keep messages that have a higher sequence number than R+1R+1 where RR is the latest message received</li> <li>It requests missing messages by sending negative acknowledgements</li> </ul>"},{"location":"7-semester/DS/04-multicast/#reliable-multicast-over-ip","title":"Reliable Multicast over IP","text":"<p>Slides from Brian Nielsen</p> <ul> <li>Each process maintains sequence numbers<ul> <li>S^p_gS^p_g -- next message to be sent</li> <li>R^q_gR^q_g (for all q \\in gq \\in g) -- latest message received from qq </li> </ul> </li> <li>On R-multicast of mm to group gg<ul> <li>attach S^p_gS^p_g and all pairs &lt;q, R^q_g&gt;&lt;q, R^q_g&gt;</li> </ul> </li> <li>R-deliver in process qq happens iff S_m = R^p_g +1S_m = R^p_g +1 <ul> <li>if $S_m &lt; R^p_g +1 $ -- process qq has seen the message before</li> <li>if S_m &gt; R^p_g +1S_m &gt; R^p_g +1 or if R_m &gt; R^p_gR_m &gt; R^p_g for some pair &lt;q, R_m&gt;&lt;q, R_m&gt; in message -- a message has been lost</li> </ul> </li> </ul> <p></p> <p>Data structures at process pp:</p> <ul> <li>S_g^pS_g^p -- sending sequence number</li> <li>R^{q}_{g}R^{q}_{g} -- sequence number of the latest message pp delivered from qq (for each qq)</li> </ul> <p>On initialization:</p> <ul> <li>S_g^p = 0S_g^p = 0</li> <li>\\bold R_g^q = -1\\bold R_g^q = -1 for all q \\in gq \\in g</li> </ul> <p>For process pp to R-multicast message mm to group gg</p> <ul> <li>IP-multicast (gg, &lt;m, S_g^p, &lt;\\bold R_g&gt;&gt;&lt;m, S_g^p, &lt;\\bold R_g&gt;&gt;)</li> <li>S_g^pS_g^p++</li> </ul> <p>On IP-deliver (&lt;m, S, &lt;\\bold R&gt;&gt;&lt;m, S, &lt;\\bold R&gt;&gt;) at qq from pp</p> <ul> <li>save mm</li> <li>if S = R_g^p + 1S = R_g^p + 1 then<ul> <li>R-deliver(mm)</li> <li>R_g^pR_g^p ++</li> <li>check hold-back queue</li> </ul> </li> <li>else if S &gt; R_g^p + 1S &gt; R_g^p + 1 then<ul> <li>store mm in hold-back queue</li> <li>request missing messages</li> <li>endif</li> </ul> </li> <li>endif</li> <li>if \\exists p.r_g^p \\in \\bold R\\exists p.r_g^p \\in \\bold R and r_g^p &gt; R_g^pr_g^p &gt; R_g^p then request missing messages -- endif</li> </ul>"},{"location":"7-semester/DS/04-multicast/#elixir-code","title":"Elixir Code","text":"<pre><code>defmodule IPReliableMulticast do\n...\ndefp loop(app, group \\\\ [], hb_q \\\\ %{}, seq \\\\ 0, r_seq \\\\ %{}) do\nrecieve do\n{:group, group} -&gt;\nnew_r_seq = for n &lt;- group, do: { n, -1 }\nloop(app, group, hb_q, seq, Enum.into(new_r_seq, %{}))  # insert new_r_seq into %{}\n\n# we got a message from application\n{:send, m} -&gt;\nudp_multicast group, {:message, self(), m, seq, r_seq}\nloop(app, group, hb_q, seq + 1, r_seq)\n\n# we are asked to respond (negative ack)\n{:nack, num, pid, sender} -&gt;\ntcp_send sender, {:message, pid, hb_q[{pid, num}], num, r_seq} # get message from hold-back queue\n\n# we got message from the network\n{:message, sender, m, s_seq, s_r_seq} -&gt;\nnew_hb_q = Map.put(hb_q, {sender, s_seq}, m) # insert m into hold-back queue\nnew_r_seq = try_deliver(app, sender, new_hb_q, r_seq, m, s_seq)\nsend_nack(sender, new_r_seq, s_r_seq)\nloop(app, group, new_hb_q, seq, new_r_seq)\n\ndefp try_deliver(app, sender, r_seq, hb_q, m, s_seq) do\nif s_seq == r_seq[sender]+1 do # if the sequence number is one more than received\n# next message from sender, tell app\nsend app, m\nn_r_seq = Map.put(r_seq, sender, s_seq) # update received sequence number from sender\n# check hold-back queue\nif Map.has_key?(hb_q, {sender, s_seq + 1}) do\ntry_deliver(app, sender, n_r_seq, hb_q, hb_q[{sender, s_seq +1}], s_seq + 1)\nelse\n# done with hold-back\n{hb_q, n_r_seq} # return\nend\nelse\n# handled elsewhere\n{ rb_q, r_seq } # return\nend\nend\n\ndefp send_nack(sender, r_seq, other_r_seq) do\nfor {pid, seq} &lt;- other_r_seq do\nif r_seq[pid] &lt; seq do\nfor m_id &lt;- r_seq[pid]..seq do\nsend sender, {:nack, m_id, pid, self()}\nend\nend\nend\nend\nend\nend\n</code></pre> <p>Integrity: Yes (IP also does checksum)</p> <p>Validity: Yes</p> <p>Agreement: ... eventually</p> <p>Two problems (exercise)</p> <p>No drops, good ordering = O(N)O(N) messages!</p>"},{"location":"7-semester/DS/04-multicast/#ordered-multicast","title":"Ordered Multicast","text":"<p>FIFO Ordered</p> <ul> <li>Messages from p_np_n are received at p_kp_k in order send by p_np_n<ul> <li>Like speaking</li> </ul> </li> </ul> <p>Total ordered</p> <ul> <li>All messages are received in same order at p_np_n and p_kp_k</li> </ul> <p>Casually Ordered</p> <ul> <li>if p_np_n receives m_1m_1 before m_2m_2, then m_1m_1 happened before m_2m_2</li> </ul>"},{"location":"7-semester/DS/04-multicast/#examples","title":"Examples","text":"<p>Imagine a bank.</p> <p>Can lead to wrong states</p> <p></p> <p>Use FIFO to fix this problem</p> <p></p> <p>If we introduce another process, it can fail again</p> <p></p> <p>Introduces total order</p> <p></p> <p>Total order can also go wrong</p> <p></p> <p>Reliable IP-Multicast is FIFO</p> <ul> <li>We respect sequence numbers of sender!</li> </ul>"},{"location":"7-semester/DS/04-multicast/#totally-ordered-multicast","title":"Totally Ordered Multicast","text":"<p>Idea</p> <ul> <li>do as FIFO but only one sequence number</li> <li>each message has a unique id/hash</li> <li>agree globally on \"next\" message<ol> <li>use global sequencer or</li> <li>use negotiation (ISIS)</li> </ol> </li> </ul>"},{"location":"7-semester/DS/04-multicast/#sequencer","title":"Sequencer","text":"<pre><code>defmodule TOSEQMulticast do\n...\ndefp loop(app, group \\\\ %{}, hb_q \\\\ %{}, l_seq \\\\ 0, g_seq \\\\ -1, seq_map \\\\ %{}) do\nreceive do\n# for setting our neighbours\n{:group, group} -&gt;\nloop(app, group, hb_q, l_seq, g_seq, seq_map)\n\n# message from application\n{:send, m} -&gt;\n# remember to make unique message ID!\nid = {self(), l_seq}\nb_multicast(group, {:message, m, id, self()})\nloop(app, group, hb_q, l_seq + 1, g_seq, seq_map)\n\n# got message from network\n{:message, m, id} -&gt;\nn_hb_q = Map.put(hb_q, id, m) # put message in HB queue\nn_g_seq = try_deliver(app, group, n_hb_q, l_seq, n_g_seq, seq_map)\nloop(app, group, n_hb_q, l_seq, n_g_seq, seq_map)\n\n# order from sequencer\n{:order, id, order} -&gt;\nn_seq_map = Map.put(seq_map, order, id) # update sequence map\nn_g_seq = try_deliver(app, group, hb_q, l_seq, n_g_seq, n_seq_map)\nloop(app, group, hb_q, l_seq, n_g_seq, n_seq_map)\n\ndefp try_deliver(app, hb_q, g_seq, seq_map) do\nif seq_map[g_seq + 1] != nil and hb_q[seq_map[g_seq + 1]] != nil do\nsend app, hb_q[seq_map[g_seq + 1]]\ntry_deliver(app, hb_q, g_seq + 1, seq_map)\nelse\ng_seq # return\nend\nend\nend\nend\nend\n\ndefmodule Sequencer do\n...\ndefp loop(group \\\\ [], seq \\\\ 0) do\nreceive do\n# for setting our neighbors\n{:group, group} -&gt; loop(group, seq)\n\n# got message from network\n{:message, _m, id} -&gt;\nb_multicast(group, {:order, id, seq})\nloop(group, seq + 1)\nend\nend\nend\n</code></pre> <p>Problems</p> <ul> <li>Sequencer is bottleneck</li> <li>Single point of failure</li> </ul> <p>Bonus</p> <ul> <li> <p>What breaks w. IP-multicast instead of B-multicast?</p> </li> <li> <p>Package loss = deadlock of process</p> </li> <li>Solution: reliable underlying multicast</li> </ul>"},{"location":"7-semester/DS/04-multicast/#isis","title":"ISIS","text":"<p>Idea: Negotiate next ID</p> <ol> <li>Process pp broadcasts message mm</li> <li>Every other process qq responds to pp with proposal</li> <li>pp picks largest proposed value, broadcasts</li> </ol> <p>The trick: </p> <ul> <li>Track \"largest proposed value\" and \"largest agreed value\" at each process</li> </ul> <p></p> <p>Good:</p> <ul> <li>Reliable crash-detection = robust<ul> <li>Sequence numbers are monotonically increasing</li> <li>Nobody will deliver \"early\"</li> </ul> </li> </ul> <p>Bad</p> <ul> <li>every broadcast requires negotiation (3 rounds)<ul> <li>sequencer has 2 rounds</li> </ul> </li> </ul>"},{"location":"7-semester/DS/04-multicast/#casually-ordered-multicast","title":"Casually Ordered Multicast","text":"<p>Idea</p> <ul> <li>order events by happened-before relationship</li> <li>use \"vectored and quircky\" lamport-clocks (Vector Clocks)</li> <li>track only \"send\" as an event</li> </ul>"},{"location":"7-semester/DS/04-multicast/#vector-clocks","title":"Vector Clocks","text":"<p>Not-quite-Lamport clocks, and they are vectors</p> <ul> <li>keep track of \"last known time\" of other processes</li> <li>\"gossip\" about \"last known time\" during communication</li> </ul> <p>Let V_iV_i be the vector of process p_i \\in \\{p_0, \\dots, p_n\\}p_i \\in \\{p_0, \\dots, p_n\\} then</p> <ul> <li>initially V_i[j] = 0V_i[j] = 0 for all j \\in 0\\dots nj \\in 0\\dots n,</li> <li>before event V_i'[i] = V_i'[i] +1V_i'[i] = V_i'[i] +1,</li> <li>attach VV to any message sent,</li> <li>on receive of V'V' we let V''[j] = \\max(V[j], V'[i])V''[j] = \\max(V[j], V'[i]) for j \\in 0 \\dots nj \\in 0 \\dots n</li> </ul> <p>Given two vectors VV and WW,</p> <ul> <li>V=WV=W if all values match<ul> <li>for all j \\in 0...n,\\quad V[j] = W[j]j \\in 0...n,\\quad V[j] = W[j]</li> </ul> </li> <li>V \\leq WV \\leq W if all values in VV are less than or equal those in WW,<ul> <li>for all j \\in 0...n,\\quad V[j] \\leq W[j]j \\in 0...n,\\quad V[j] \\leq W[j]</li> </ul> </li> <li>V \\leq WV \\leq W if all values in VV are less than or equal to WW and W \\neq VW \\neq V<ul> <li>V \\leq WV \\leq W and V \\neq WV \\neq W</li> </ul> </li> </ul> <p>Example</p> <p>Example in slides 36</p>"},{"location":"7-semester/DS/04-multicast/#algorithm","title":"Algorithm","text":"<p>Notice</p> <ul> <li>Casual order implies FIFO</li> <li>Casual order does not imply Total</li> <li>Good: No extra communication for order!</li> <li>Can be combined with total</li> <li>Reliable if using R-multicast instead of B-multicast</li> </ul>"},{"location":"7-semester/DS/05-consensus/","title":"Consensus","text":"<p>What is consensus?</p> <ul> <li>The ability for a group of processes to agree on one, and only one value</li> </ul> <p>Examples</p> <ul> <li> <p>We have already seen</p> <ul> <li>Mutex</li> <li>Leader election</li> <li>Multicast (ordering)</li> <li>Bank-accounts</li> </ul> </li> <li> <p>Practical Applications</p> <ul> <li>Redundancy<ul> <li>Space and aeronautics</li> <li>Industrial systems</li> </ul> </li> <li>Replication<ul> <li>Distributed file systems</li> <li>Ledger technology (e.g. blockchain)</li> </ul> </li> </ul> </li> </ul> <p>Big questions</p> <ul> <li>When do we agree on what we agree on?</li> <li>What do we agree on?</li> </ul> <p>Why</p> <ul> <li>Generalized consensus</li> <li>If we have consensus, everything is easy</li> <li>Feasibility depends on system model</li> </ul>"},{"location":"7-semester/DS/05-consensus/#impossibility","title":"Impossibility","text":""},{"location":"7-semester/DS/05-consensus/#multicast","title":"Multicast","text":"<p>No Failures, Easy</p> <ol> <li>B-multicast to everyone</li> <li>Wait till N messages are received</li> <li>Decide (e.g. minimum, majority, ...)</li> </ol> <p>Failures?</p> <p>We need:</p> <ul> <li>Mechanism for failure detection<ul> <li>Difficult/impossible for async systems<ul> <li>Impossible to detect if dead or slow</li> </ul> </li> </ul> </li> <li>Mechanism for failure handling</li> </ul>"},{"location":"7-semester/DS/05-consensus/#the-two-army-problem","title":"The Two Army Problem","text":"<p>Both read armies has to attack at the same time</p> <ul> <li>They can send a message, but the blue army can intercept</li> </ul> <p>Can we design a protocol to make sure that both armies attack at 6.</p> <p>If left army sends a message to right, they would not know if the message has been received.</p>"},{"location":"7-semester/DS/05-consensus/#impossibility-of-consensus-in-async-systems","title":"Impossibility of Consensus in Async Systems","text":"<p>Informally</p> <ul> <li>Communication can be \"blocked\" indefinitely<ul> <li>(which is not forever)</li> </ul> </li> </ul> <p>Reliable TO (Totally Ordered) Multicast is also impossible in async systems</p> <ul> <li>Same problem</li> </ul> <p>Quiz</p> <ul> <li>Assume we have a magic, reliable TO Multicast, can we derive a consensus algorithm?<ul> <li>Everyone takes the first message delivered.<ul> <li>Since its totally ordered everyone gets messages in the same order</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/05-consensus/#consensus-problem","title":"Consensus Problem","text":"<p>To reach consensus, every process p_i begins in undecided state and proposes a value v_iv_i from the set DD (e.g. \\{1,2,\\dots,N\\}\\{1,2,\\dots,N\\}).</p> <p>The processes communicate , exchanging values.</p> <p>Each process sets the value of a decision variable d_id_i which cant change, and enters the decided state.</p>"},{"location":"7-semester/DS/05-consensus/#system-model","title":"System Model","text":"<ul> <li>Synchronous Systems</li> <li>Reliable Communication</li> <li>Fault models<ul> <li>Crashes</li> <li>Byzantine<ul> <li>Arbitrary</li> <li>Evil</li> </ul> </li> </ul> </li> <li>No signed messages!<ul> <li>There can be \"Identity theft\"</li> </ul> </li> </ul>"},{"location":"7-semester/DS/05-consensus/#requirements","title":"Requirements","text":"<p>Given p_i \\in \\{p_0,\\dots,p_n\\}p_i \\in \\{p_0,\\dots,p_n\\} and a corresponding decision-variable d_i\\in D \\cup \\{\u22a5\\}d_i\\in D \\cup \\{\u22a5\\}</p> <ul> <li> <p>\u22a5 \\not \\in D\u22a5 \\not \\in D</p> </li> <li> <p>Termination</p> <ul> <li>Eventually a correct process sets its decision variable d_id_i</li> </ul> </li> <li>Agreement<ul> <li>The decision values of all correct processes are the same</li> </ul> </li> <li>Integrity<ul> <li>If all correct processes propose the same value, then any correct process in the decided state decided on that value</li> </ul> </li> <li>Weak Integrity<ul> <li>The agreed value must be one proposed by a correct process</li> </ul> </li> </ul> <p>Decided State</p> <p>We say that p_ip_i is decided if d_i \\not = \u22a5d_i \\not = \u22a5</p> <ul> <li>Some systems work in rounds,</li> <li>Most things are not truly async<ul> <li>\"Indefinitely\" rarely happens</li> </ul> </li> </ul> <p>Goal</p> <ul> <li>f-crash-resilient synchronous consensus algorithm</li> </ul> <p>f-resilient</p> <ul> <li>The algorithm is f-resilient if f processes may fail</li> </ul>"},{"location":"7-semester/DS/05-consensus/#algorithm","title":"Algorithm","text":"<ul> <li>Takes f+1f+1 rounds -- with timeout</li> <li>At each round less than round f+1f+1 -- b-multicast your value if it has changed</li> <li>When value is received -- set your value to it - if value received is less than your value</li> <li>At round f+1f+1 you have reached consensus<ul> <li>all processes has sent their value to all</li> </ul> </li> </ul> <p>Theorem</p> <p>Any optimal f-resilient consensus-algorithm requires f+1 rounds</p> <ul> <li> <p>Proof by pigeon hole principle</p> <ul> <li>At least one correct round</li> <li>Remember R-multicast</li> </ul> </li> <li> <p>Unclear when correct round is</p> </li> <li> <p>Weak consensus</p> <ul> <li>We can agree on a value that was not proposed on a correct process<ul> <li>Not weak integrity</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/05-consensus/#byzantine-error","title":"Byzantine Error","text":"<p>What is processes do not crash-fail but interact unpredictably?</p> <p>The term arbitrary or Byzantine failure is used to describe the worst possible failure semantics, in which any type of error may occur. For example, a process may set wrong values in its data items, or it may return a wrong value in response to an invocation.</p> <p>Byzantine failures in processes cannot be detected by seeing whether the process responds to invocations, because it might arbitrarily omit to reply.</p>"},{"location":"7-semester/DS/05-consensus/#examples","title":"Examples","text":"<ul> <li>Single Event Upset: A flipped bit</li> <li>Single Event Latchup: Hardware error</li> </ul> <p>They use 4 different computes running the same software on the space shuttle, and then voting on consensus.</p> <p></p> <p>Not only a space issue</p> <ul> <li>\"Error-Correcting code memory\" (ECC)</li> <li>Bitflips on planes</li> <li>Nuclear power plants</li> <li>...</li> </ul> <p>Systems can \"fall asleep\" and later continue from where they left off</p> <p></p>"},{"location":"7-semester/DS/05-consensus/#byzantine-consensus","title":"Byzantine Consensus","text":"<p>Requirements</p> <ul> <li>...</li> <li>Byzantine integrity<ul> <li>If all non-faulty processes start with the same value, then all non-faulty processes decide on that value</li> </ul> </li> </ul> <p>Goal</p> <ul> <li>f-byzantine-resilient synchronous consensus algorithm</li> </ul> <p>Bad news</p> <ul> <li>Impossible for f \\geq {n \\over 3}f \\geq {n \\over 3}</li> </ul> <p>Good news</p> <ul> <li>Possible otherwise</li> </ul>"},{"location":"7-semester/DS/05-consensus/#the-byzantine-generals-problem","title":"The Byzantine Generals Problem","text":"<ul> <li>If B is evil and gives different orders to A and C</li> <li>If C is evil and lies about order from B</li> <li>A cannot detect the traitor</li> </ul> <p>\\uparrow \\downarrow\\uparrow \\downarrow Proof that if 1/3 is faulty you cannot arrive at consensus</p> <p></p>"},{"location":"7-semester/DS/05-consensus/#byzantine-consensus-algorithm","title":"Byzantine Consensus Algorithm","text":"<p>f = 1f = 1</p> <p></p> <ul> <li>Works only for f=1f=1<ul> <li>Can be generalized</li> <li>O(n^{f+1})O(n^{f+1}) messages<ul> <li>O(n^2)O(n^2) messages, growing exponentially in size</li> </ul> </li> </ul> </li> <li>Integrity is violated!</li> </ul>"},{"location":"7-semester/DS/05-consensus/#kings-algorithm","title":"Kings Algorithm","text":"<p>We introduces a \"leader\"/tiebreaker</p> <ul> <li>Works only for any n &gt; 3 \\times fn &gt; 3 \\times f</li> <li>Small messages, O(n^2)O(n^2)</li> <li>(f+1) \\times 3(f+1) \\times 3 rounds</li> <li>Integrity is respected</li> </ul>"},{"location":"7-semester/DS/05-consensus/#notes-on-byzantine-algorithms","title":"Notes on Byzantine Algorithms","text":"<ul> <li>General case:<ul> <li>Requires f+1f+1 rounds</li> <li>Sends O(n^{f+1})O(n^{f+1}) messages</li> <li>Number of rounds can be exchanged for messages<ul> <li>Queen algorithm (f+1) \\times 2(f+1) \\times 2 rounds + f &lt; {n \\over 4}+ f &lt; {n \\over 4}-robust</li> <li>King algorithm (f+1) \\times 3(f+1) \\times 3 rounds</li> </ul> </li> </ul> </li> <li>Using digital signiture<ul> <li>Still f+1f+1 rounds</li> <li>O(n^2)O(n^2) messages</li> </ul> </li> </ul> <p>Note</p> <ul> <li>Costly in general form</li> <li>Often specialized solutions are cheaper</li> </ul>"},{"location":"7-semester/DS/05-consensus/#fixing-the-async-problem","title":"Fixing the Async Problem","text":""},{"location":"7-semester/DS/05-consensus/#random-solution","title":"Random Solution","text":"<p>If we allow randomness in our algorithm we can have a solution to Byzantine Generals Problem in async setting</p>"},{"location":"7-semester/DS/05-consensus/#paxos","title":"Paxos","text":"<p>A family of algorithms by L. Lamport</p> <ul> <li>No coordinator</li> <li>Async system</li> <li>Nodes may crash and recover<ul> <li>OK with up to n/2n/2 failures</li> </ul> </li> <li>Once a single process decides, all will (eventually) decide the same</li> </ul> <p>Inconceivable!</p> <ul> <li>No guaranteed termination</li> <li>... but terminates in \"reasonable environments\"</li> </ul> <p>The Paxos Algorithm</p>"},{"location":"7-semester/DS/05-consensus/#reaching-consensus-with-paxos","title":"Reaching Consensus with Paxos","text":"<ul> <li>Consensus is agreeing on one result</li> <li>Once a majority agrees on a proposal, that is the consensus</li> <li>The reached consensus can be eventually known by anyone</li> <li>The involved parties want to agree on any result, not on their proposal</li> <li>Communication channels may be faulty, that is, messages can get lost</li> </ul>"},{"location":"7-semester/DS/05-consensus/#basics","title":"Basics","text":"<ul> <li>Paxos defines three roles:<ul> <li>Proposers</li> <li>Acceptors</li> <li>Learners</li> </ul> </li> <li>Paxos nodes can take multiple roles, even all of them</li> <li>Paxos nodes must know how many acceptors a majority is<ul> <li>Two majorities will always overlap in at least one node</li> </ul> </li> <li>Paxos nodes must be persistent: they cant forget what they accepts</li> <li>A Paxos run aims at reaching a single consensus<ul> <li>Once consensus is reached, it cannot progress to another consensus</li> <li>In order to reach another consensus, a different Paxos run must happen</li> </ul> </li> </ul>"},{"location":"7-semester/DS/05-consensus/#the-paxos-algorithm","title":"The Paxos Algorithm","text":""},{"location":"7-semester/DS/05-consensus/#majority-of-promises","title":"Majority of Promises","text":""},{"location":"7-semester/DS/05-consensus/#contention","title":"Contention","text":""},{"location":"7-semester/DS/05-consensus/#majority-of-accepts","title":"Majority of Accepts","text":""},{"location":"7-semester/DS/05-consensus/#practical-example-simple-distributed-storage-system","title":"Practical Example - Simple Distributed Storage System","text":""},{"location":"7-semester/DS/06a-replication/","title":"Replication and Consistency","text":""},{"location":"7-semester/DS/06a-replication/#goals-of-replication","title":"Goals of Replication","text":"<p>Fault Tolerance</p> <ul> <li>Transparent to user</li> <li>Tolerates node/network failures</li> </ul> <p>High availability</p> <ul> <li>Service is rarely interrupted</li> </ul> <p>Performance</p> <ul> <li>Limits of horizontal scaling</li> <li>Overcome geographic/network limits</li> </ul>"},{"location":"7-semester/DS/06a-replication/#tolerance-and-availability","title":"Tolerance and Availability","text":""},{"location":"7-semester/DS/06a-replication/#performance","title":"Performance","text":"<ul> <li>Edge servers around the internet</li> </ul>"},{"location":"7-semester/DS/06a-replication/#caching","title":"Caching","text":"<p>Caching is also replication</p> <ul> <li>Local browser cache</li> <li>Prefetching for Netflix<ul> <li>fault tolerance<ul> <li>if you loose network for a second, the video keeps playing</li> </ul> </li> </ul> </li> <li>DNS registry</li> </ul>"},{"location":"7-semester/DS/06a-replication/#problems","title":"Problems","text":"<ul> <li>Consensus<ul> <li>... or consistency</li> </ul> </li> <li>Overhead in communication</li> <li>Failure detection and handling</li> </ul>"},{"location":"7-semester/DS/06a-replication/#cap-theorem","title":"CAP Theorem","text":"<p>It is impossible for a distributed computer system to simultaneously provide Consistency, Availability and Partition Tolerance.</p> <p>A distributed system can satisfy any two of these guarantees at the same time but not all three.</p>"},{"location":"7-semester/DS/06a-replication/#the-choice","title":"The Choice","text":"<p>But: If we relax our requirements we can overcome this impossibility</p>"},{"location":"7-semester/DS/06a-replication/#examples","title":"Examples","text":"<p>CP Systems</p> <ul> <li>Financial sector</li> <li>Simulation (weather forecast)</li> <li>CERN</li> </ul> <p>AP Systems</p> <ul> <li>Social Networks</li> <li>Streaming services</li> <li>Search Engines</li> <li>Emails</li> </ul> <p>CA Systems</p> <ul> <li>Single server systems</li> <li>Stable Elixir setups</li> </ul> <p>Application Dictates</p> <p>Core/critical services are often CP</p>"},{"location":"7-semester/DS/06a-replication/#assumptions","title":"Assumptions","text":"<ul> <li>Async systems</li> <li>Reliable communication</li> <li>Crash-fail</li> <li>Atomic operation </li> <li>Objects are \"state machines\"<ul> <li>no random</li> <li>no timer</li> <li>no external events</li> </ul> </li> </ul> <p>Notation</p> <p><code>o.m(v)</code> apply modifier <code>m</code> to object <code>o</code> with value <code>v</code></p> <p><code>myAccount.deposit(1000)</code></p> <p></p>"},{"location":"7-semester/DS/06a-replication/#requirements","title":"Requirements","text":"<ul> <li>Transparent for user</li> <li>Consistent in replicated objects</li> </ul> <p>Ideal</p> <p>Indistinguishable from single copy behavior</p>"},{"location":"7-semester/DS/06a-replication/#operations","title":"Operations","text":"<p>Generalized workflow</p> <ol> <li>Request</li> <li>Coordination</li> <li>Execution</li> <li>Agreement</li> <li>Response</li> </ol> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Interesting when we have multiple requests at the same time</p> <p></p>"},{"location":"7-semester/DS/06a-replication/#fault-tolerance","title":"Fault Tolerance","text":"<p>Goal</p> <ul> <li>f-resilient replication</li> <li>No downtime</li> <li>Transparent to clients</li> </ul> <p>Notice</p> <p>Transparent to clients is not yet formally defined</p>"},{"location":"7-semester/DS/06a-replication/#consistency-models","title":"Consistency Models","text":"<p>Strong consistency</p> <ul> <li>In real-time, after update A, everybody will see the modification done by A when reading</li> </ul> <p>Weak Consistency</p> <ul> <li>What is the ordering, disregarding real-time?</li> <li>\"reasonably consistent\"</li> </ul>"},{"location":"7-semester/DS/06a-replication/#inconsistency","title":"Inconsistency","text":"<p>Example on sildes 16-</p> <p></p>"},{"location":"7-semester/DS/06a-replication/#desired-temporal-consistencies","title":"Desired Temporal Consistencies","text":"<ul> <li>If I write a value, I will see that (or a newer value) on a subsequent read</li> <li>If I read twice, the value returned on the second read is at least as new as from the first read</li> <li>If data is related (questions and answers), I expect this to be reflected in a consistent manner<ul> <li>... no constraints on unrelated data!</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#linearizability-lamport","title":"Linearizability (Lamport)","text":"<p>\\bold {C_i} operations</p> <ul> <li>o_1^i, o_2^i, \\dots, o_n^io_1^i, o_2^i, \\dots, o_n^i for some operation o \\in Oo \\in O</li> </ul> <p>Timestamp</p> <ul> <li>Let T(o^i_n)T(o^i_n) be the timestamp of o^i_no^i_n.</li> </ul> <p>Linearizability</p> <ul> <li>An interleaving \\dots, o^i_5, o^j_{100}, o^i_6, \\dots\\dots, o^i_5, o^j_{100}, o^i_6, \\dots (with i \\neq ji \\neq j) is linearizable if<ul> <li>arrive at a (single) correct copy of the object (from specification)</li> <li>the order is consistent with real time<ul> <li>T(o^i_5) \\leq T(o^j_{100}) \\leq T(o^i_6)T(o^i_5) \\leq T(o^j_{100}) \\leq T(o^i_6)</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#problems_1","title":"Problems","text":"<p>Implementation</p> <ul> <li>Sync hardware clock on multiple machines</li> <li>Guess maximal network delay DD<ul> <li>keep operation in hold-back queue until age DD</li> <li>keep hold-back queue sorted</li> </ul> </li> </ul> <p>Drawbacks</p> <ul> <li>No accurate clock synchronization algorithm<ul> <li>Reasonably accurate versions exists (depends on DD)</li> </ul> </li> <li>No hard deadline in async setting</li> </ul>"},{"location":"7-semester/DS/06a-replication/#interleavings","title":"Interleavings","text":""},{"location":"7-semester/DS/06a-replication/#sequential-consistency-lamport","title":"Sequential Consistency (Lamport)","text":"<p>\\bold {C_i}\\bold {C_i} operations</p> <ul> <li>o_1^i, o_2^i, \\dots , o_n^io_1^i, o_2^i, \\dots , o_n^i for some operation o \\in Oo \\in O</li> </ul> <p>Sequential Consistency</p> <ul> <li>An interleaving \\dots, o^i_a, o^j_b, o^i_c, \\dots\\dots, o^i_a, o^j_b, o^i_c, \\dots (with i \\neq ji \\neq j) is sequentially consistent if<ul> <li>arrive at a (single) correct copy of the object (from specification)</li> <li>the order respects casuality of C_iC_i<ul> <li>a &lt; ca &lt; c, i.e. from C_i, o^i_aC_i, o^i_a was sent before o^i_co^i_c</li> </ul> </li> </ul> </li> </ul> <p>Example on slides 23</p> <p></p>"},{"location":"7-semester/DS/06a-replication/#replication-architectures-for-fault-tolerance","title":"Replication Architectures for Fault Tolerance","text":"<p>Read-only replication</p> <ul> <li>Immutable files</li> <li>Cache-servers</li> </ul> <p>Passive replication (primary/secondary)</p> <ul> <li>High consistency</li> <li>Banks?</li> </ul> <p>Active replication</p> <ul> <li>Fast failover mechanism<ul> <li>Everyone can take over if one fails</li> </ul> </li> <li>Workload distribution</li> <li>Everybody is working on equal terms</li> </ul>"},{"location":"7-semester/DS/06a-replication/#passive-replication","title":"Passive Replication","text":"<ul> <li>\"just follow primary\"</li> <li>Up to n-1n-1 crashes</li> <li>No byzantine failures</li> <li>Linearizable (with regards to clock of primary)</li> <li>Large overhead of failure<ul> <li>why?</li> </ul> </li> </ul> <p>Note</p> <p>Sacrifice linearizability =&gt; offload reads to backups!</p>"},{"location":"7-semester/DS/06a-replication/#active-replication","title":"Active Replication","text":"<ul> <li>Sequentially consistent</li> <li>RTO multicast<ul> <li>impossible in async</li> <li>expensive otherwise</li> </ul> </li> <li>\"state-machine\" objects required</li> <li>Handles byzantine nodes<ul> <li>assuming signed messages (n/2)-1(n/2)-1 failures</li> </ul> </li> <li>Failover is cheap<ul> <li>Just exclude failed from group</li> <li>\"same procedure\"</li> </ul> </li> <li>Read can be trivially distributed</li> </ul>"},{"location":"7-semester/DS/06a-replication/#availability","title":"Availability","text":"<p>Availability VS Fault Tolerance</p> <ul> <li>We care less about consistency</li> <li>Higher uptime = better</li> <li>Faster response times</li> </ul> <p>Example</p> <ul> <li>Read-only: caches</li> <li>Most web-scaled services<ul> <li>Youtube, Facebook, Stackoverflow</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#gossip-architecture","title":"Gossip Architecture","text":"<p>Operations</p> <ul> <li>Read<ul> <li>no state change</li> </ul> </li> <li>Write (update)<ul> <li>can change state of object</li> </ul> </li> </ul> <p></p> <p>Relaxed Consistency</p> <ul> <li>RR's apply operations \"eventually\" with specific order</li> <li>Client may receive outdated data<ul> <li>though newer than clients current data</li> </ul> </li> </ul> <p>Reads</p> <ul> <li>Casual ordering</li> </ul> <p>Writes</p> <ul> <li>Choice of clients<ul> <li>Causal order</li> <li>Total + Causal order (relative to relations)</li> <li>Immediate ordering</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#idea","title":"Idea","text":"<p>Vector clocks, vector clocks everywhere</p> <p>Track \u201cnumber of unique updates R_iR_i has seen of object from some frontend\u201d as a vector.</p> <ul> <li>Each entry in vector-clock corresponds to R_iR_i<ul> <li>R_iR_i updates own index in vector on update from some F_iF_i</li> <li>Keep messages from future in hold-back queue</li> <li>Avoid duplicates</li> </ul> </li> <li>Frontend keep track of \"last known\" timestamp<ul> <li>Frontend label their reads/writes with last-known timestamp</li> <li>Receive new timestamp updates from R_iR_i (or via gossip)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#phases","title":"Phases","text":"<ol> <li>Request: FFs forwards to a single RR (or more)</li> <li>Coordination: Queue request until order is respected</li> <li>Execution: Execute in correct order</li> <li>Agreement: we can do one of:<ul> <li>Wait for gossip</li> <li>Request missing data</li> </ul> </li> <li>Response<ul> <li>Read: await coordination</li> <li>Write: immediately</li> </ul> </li> </ol>"},{"location":"7-semester/DS/06a-replication/#frontend-view","title":"Frontend View","text":"<p>slides 34</p>"},{"location":"7-semester/DS/06a-replication/#replication-managers-view","title":"Replication Managers View","text":"<p>slides 35</p> <p></p> <p>slides 36</p> <p></p>"},{"location":"7-semester/DS/06a-replication/#details","title":"Details","text":"<p>Frequency of gossip</p> <ul> <li>Minutes, hours or days</li> <li>Depend on the requirement of application<ul> <li>think of git, how often are we committing?</li> </ul> </li> </ul> <p>Topology</p> <ul> <li>Random</li> <li>Deterministic: investigate known clocks</li> <li>Topological: Mesh, circle, tree</li> <li>Geographical<ul> <li>you gossip to machines geographically close to you</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06a-replication/#discussion","title":"Discussion","text":"<ul> <li>Works even with network partition<ul> <li>but may need conflict resolution</li> </ul> </li> <li>More RR's = more gossip</li> <li>Larger delays between gossip<ul> <li>larger consistency gaps</li> <li>higher latency</li> </ul> </li> <li>Good when conflicting updates are rare</li> </ul>"},{"location":"7-semester/DS/06b-transactions/","title":"Transactions","text":"<p>Transaction = A series of operations that must be executed with ACID properties</p> <p>ACID</p> <ul> <li>Atomicity \u2013 to outside world, transaction happens indivisibly</li> <li>Consistency \u2013 transaction preserves system invariants</li> <li>Isolated \u2013 transactions do not interfere with each other</li> <li>Durable \u2013 once a transaction \u201ccommits,\u201d the changes are permanent</li> </ul> <p>In \u201cconventional\u201d Databases: Protect against concurrency and crash failures of a single DB server </p> <p>Distributed Transaction: The operations are targeted at different severs.</p> <p>Book trip=TRANSACTION(Book Flight; Book Car; Book Hotel)</p> <ul> <li>Distributed: Involves 3 different services</li> </ul>"},{"location":"7-semester/DS/06b-transactions/#a-distributed-banking-transaction","title":"A Distributed Banking Transaction","text":"<pre><code>T = openTransaction\n    a.withdraw(4)\n    c.deposit(4)\n    b.withdraw(3)\n    d.deposit(3)\ncloseTransaction\n</code></pre> <ul> <li>Client opens a transaction: contacts a server that appoints a Coordinator (often itself)</li> <li>Transactions are given a globally unique ID that is appended to every operation</li> <li>Client sends operations to servers that tentatively executes them<ul> <li>(tentatively: with hesitancy or uncertainty)</li> </ul> </li> <li>When client closes the transaction: Servers coordinate to decide to globally \u201cACID\u2019LY\u201d commit or abort </li> </ul>"},{"location":"7-semester/DS/06b-transactions/#one-phase-commit-protocol","title":"One-phase Commit Protocol","text":"<ul> <li>First cut: The coordinator unilaterally communicates either commit or abort, </li> <li>Repeat until all participants (servers) all acknowledge<ul> <li>Doesn\u2019t work when a participant crashes before receiving this message (partial transaction results that were in memory are lost).</li> <li>Does not allow participant to abort the transaction, e.g., under error conditions or concurrency control.</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06b-transactions/#two-phase-commit-protocol","title":"Two-phase Commit Protocol","text":""},{"location":"7-semester/DS/06b-transactions/#assumptions","title":"Assumptions","text":"<ul> <li>Both coordinator and participant may abort</li> <li>Crash-stop failures, but we may use stable storage and let new processes recover the state, and resume the role of the failed process</li> <li>Stable storage contains a combination of<ul> <li>Check-points</li> <li>Re-do and un-do log files</li> </ul> </li> <li>Asynchronous system</li> </ul>"},{"location":"7-semester/DS/06b-transactions/#protocol","title":"Protocol","text":""},{"location":"7-semester/DS/06b-transactions/#timouts","title":"Timouts","text":""},{"location":"7-semester/DS/06b-transactions/#persistent-storage","title":"Persistent storage","text":""},{"location":"7-semester/DS/06b-transactions/#crashes","title":"Crashes","text":"<ul> <li>If coordinator crash:<ul> <li>If participant has not yet voted (or has aborted) then it aborts locally</li> <li>If participant voted \u201dYES\u201d: It must await outcome <ul> <li>If all participants are uncertain: keep waiting until coordinator is recovered (\"BLOCKING\")<ul> <li>Coordinator may be replaced if its log file is available </li> <li>Or at least one other participant knows the verdict</li> </ul> </li> </ul> </li> </ul> </li> <li>If participant crash<ul> <li>Coordinator aborts</li> <li>Ignores tardy votes</li> </ul> </li> <li>Does not solve consensus<ul> <li>Either possibly wait forever</li> <li>Mask failure by recovery and stable storage (a recovering process == a very slow process)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06b-transactions/#data-replication-with-transactions","title":"Data Replication with Transactions","text":""},{"location":"7-semester/DS/06b-transactions/#read-any-write-all-protocol","title":"Read-Any-Write-All Protocol","text":"<ul> <li>Read<ul> <li>Perform read at any one of the replicas</li> </ul> </li> <li>Write<ul> <li>Perform on all of the replicas</li> </ul> </li> <li>Sequential consistency</li> <li>Cannot cope with even a single crash (by definition)</li> </ul>"},{"location":"7-semester/DS/06b-transactions/#available-copies-protocol","title":"Available-Copies Protocol","text":"<ul> <li>Read<ul> <li>Perform on any one of the replicas</li> </ul> </li> <li>Write<ul> <li>Perform on all available replicas</li> </ul> </li> <li>Better availability</li> <li>Network partitions may give inconsistency in two sub-divided network groups.<ul> <li>Consensus Approach: Updates require majority</li> </ul> </li> </ul>"},{"location":"7-semester/DS/06b-transactions/#quorum-based-protocols","title":"Quorum-Based Protocols","text":"<p>Two quora:</p> <ol> <li>R and WW intersect, i.e. \\#R + \\#W &gt;n\\#R + \\#W &gt;n</li> <li>Writes need majority, i.e. \\#W &gt; n/2\\#W &gt; n/2</li> </ol> <p></p> <p>Read-any-write-all as special case: R=1, W = nR=1, W = n</p> <ul> <li> <p>Read</p> <ul> <li>Retrieve the read quorum</li> <li>Select the one with the latest version.<ul> <li>Note \\# R + \\# W &gt; n\\# R + \\# W &gt; n</li> </ul> </li> <li>Perform a read on it</li> </ul> </li> <li> <p>Write</p> <ul> <li>Retrieve the write quorum</li> <li>Find the latest version and increment it</li> <li>Perform a write on the entire write quorum</li> </ul> </li> <li> <p>If a sufficient number of replicas from read/write quorum fails, the operation must be aborted.</p> </li> </ul>"},{"location":"7-semester/DS/07-wireless/","title":"Wireless Sensor Networks and Internet of Things","text":""},{"location":"7-semester/DS/07-wireless/#standardized-wsn-protocols","title":"Standardized WSN Protocols","text":"<ul> <li>Traditional WiFi + IP too resource intensive for WSN</li> <li>802.15.1 (Bluetooth: cable replacement)<ul> <li>1 PAN coordinator + up to 7 slaves</li> <li>Version 1.0 ... 4.x now 5.0</li> <li>BLE aka Bluetooth SMART</li> <li>Bluetooth Mesh</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#ieee-802154","title":"IEEE 802.15.4","text":"<ul> <li>802.15.4 designed for wireless personal area networks (home automation, cars, remote metering,\u2026)<ul> <li>Monitoring and Control</li> <li>Ease of installation but no mobility</li> <li>Low power <ul> <li>protocol assumes nodes sleep most of the time</li> </ul> </li> <li>Low transmission rates (&lt; 250 kbps)</li> <li>Low range (&lt; 75m max)</li> </ul> </li> <li>802.15.4 defines Physical and MAC layer. What to run on top of it?</li> </ul>"},{"location":"7-semester/DS/07-wireless/#mac-overview","title":"MAC Overview","text":"<ul> <li>Full Function Device (\\color{darkblue}\\text{FFD})<ul> <li>Any topology</li> <li>Network coordinator capable</li> <li>Talks to any other device</li> </ul> </li> <li>Reduced Function Device \\color{darkred} \\text{RFD}\\color{darkred} \\text{RFD}<ul> <li>Limited to star topology</li> <li>Cannot become a network coordinator</li> <li>Talks only to a network coordinator</li> <li>Very simple implementation</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#mac-topology","title":"MAC Topology","text":""},{"location":"7-semester/DS/07-wireless/#csma-ca","title":"CSMA-CA","text":"<ul> <li>Carrier-Sense Multiple Access Collision Avoidance</li> <li>Backoff if carrier occupied</li> <li>WiFi: Use RTS/CTS</li> </ul>"},{"location":"7-semester/DS/07-wireless/#optional-superframe-structure","title":"Optional Superframe Structure","text":""},{"location":"7-semester/DS/07-wireless/#zigbee","title":"ZigBee","text":"<ul> <li>Defines Network layer on top of 802.15.4</li> <li>Developed by the Zigbee alliance</li> <li>Nodes can join network, get 16 bit address</li> <li>Routing algorithm for tree (and star) and mesh topologies</li> <li>Route discovery based on distance vector algorithm</li> <li>128-bit AES encryption</li> <li>Also provides an application layer framework for applications</li> </ul> <p>http://www.chiaraburatti.org/uploads/teaching/ZigBee-Libro.pdf</p>"},{"location":"7-semester/DS/07-wireless/#6lowpan","title":"6LoWPAN","text":"<ul> <li>\u201cWhy invent a new protocol when we already have IP?\u201d<ul> <li>Developers are familiar with IP</li> <li>16-bit addresses (ZigBee) not enough for IoT</li> </ul> </li> <li>Developed by IEFT: 6LowPan: IPv6 over 802.15.4</li> </ul> <ul> <li>Stacked headers<ul> <li>Basic header for small packets sent point-to-point or in star networks: 4 bytes (!)<ul> <li>802.15.4 MAC addresses are 64bit long (in the MAC frame)</li> <li>In IPv6, the lower 64bit (of 128 bits) can be the MAC\u2019s address</li> <li>\\to\\to No need to repeat address in 6LowPan header (compressed header)</li> </ul> </li> <li>Optional Fragmentation header for large packets</li> <li>Optional Mesh Networking header for mesh networks</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#lora-long-range","title":"LoRa - Long Range","text":"<ul> <li>Long-range, low-power and low-througput</li> <li>LoRa: PHY layer, developed by Semtech</li> <li>LoRaWAN MAC layer defined by LoRaAlliance</li> <li>Range<ul> <li>2-5 km in urban environments</li> <li>&gt; 15 km in open space</li> </ul> </li> <li>Throughput: 0.3 kbps to 50 kbps</li> <li>LoRaWAN MAC accepts Spreading Factor (SF) of PHY to balance data rate / range / lifetime</li> </ul>"},{"location":"7-semester/DS/07-wireless/#sigfox","title":"SigFox","text":"<ul> <li>Very long range (few km in cities, up to 40km in rural areas with directional antennas)</li> <li>Signal can reach underground objects</li> <li> <p>Sigfox deploys its antennas with the help of local telcos around the world</p> <ul> <li>Thus Sigfox itself takes care of coverage</li> <li>Device owners pay a subscription (1 Euro per device per year)</li> </ul> </li> <li> <p>Send</p> <ul> <li>up to 140 messages per day, limit of 6 msgs/hour</li> <li>Each message can be up to 12 bytes</li> </ul> </li> <li>Receive<ul> <li>up to 4 downlink msgs per day, each of which can carry payload of 8 bytes</li> </ul> </li> <li>Thus<ul> <li>SigFox is for applications that send only small and infrequent bursts of data and receive close to nothing, like alarms and meters.</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/07-wireless/#nb-iot-narrowband-internet-of-things","title":"NB-IoT - Narrowband Internet of Things","text":"<ul> <li>Narrowband Internet of Things (NB-IoT) is a secure, reliable, and efficient type of Low-Power Wide-Area (LPWA) Technology that was standardized by 3GPP and uses licensed spectrum. </li> <li>low power consumption</li> <li>low device cost</li> <li>low connectivity cost</li> <li>massive connections (tens of thousands of devices per base station)</li> <li>long range (about 5 km in dense urban areas and about 50 km in rural area)</li> <li>good signal penetration (can reach elevators inside buildings as well as basement and underground car parks)</li> </ul>"},{"location":"7-semester/DS/07-wireless/#comparison","title":"Comparison","text":"<p>https://www.polymorph.co.za/iot-connectivity-comparison-gsm-vs-lora-vs-sigfox-vs-nb-iot/</p>"},{"location":"7-semester/DS/07-wireless/#routing-in-iot-wsn","title":"Routing in IoT / WSN","text":"<ul> <li>Why routing?</li> <li>Tree routing</li> <li>Directed Diffusion</li> <li>Dynamic Source Routing</li> <li>Ad Hoc On-Demand Distance Vector Routing</li> </ul>"},{"location":"7-semester/DS/07-wireless/#what-is-routing","title":"What is Routing","text":"<ul> <li>Low power wireless links can be too short to reach destination in one hop</li> <li>Need to traverse multiple links to reach destination</li> </ul> <ul> <li>Routing = selecting (best) path for network traffic from source to destination</li> <li>Lots of criteria (metrics) to device what is best path<ul> <li>Delivery delay</li> <li>Link load</li> <li>Router load</li> <li>...</li> </ul> </li> <li>In WSN we have more metrics<ul> <li>Energy consumption</li> <li>Battery level of a node</li> <li>Loss probability</li> <li>...</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#traditional-routing","title":"Traditional Routing","text":"<ul> <li>A routing protocol sets up a routing table in routers</li> </ul> <ul> <li>A node makes a local choice depending on global topology</li> <li>What if node cannot know the global topology?</li> </ul>"},{"location":"7-semester/DS/07-wireless/#zigbee_1","title":"ZigBee","text":"<ul> <li>As described, Zigbee defines Network layer &amp; Application layer framework on top of 802.15.4.</li> </ul> <p>802.15.4 devices can be:</p> <ul> <li>Full function device (FFD)<ul> <li>PAN coordinator capable</li> <li>Talks to any other device</li> <li>Can act as router</li> </ul> </li> <li>Reduced function device (RFD)<ul> <li>Cannot become a PAN coordinator</li> <li>Talks only to a PAN coordinator</li> <li>Very simple implementation</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#zigbee-network-layer-overview","title":"ZigBee Network Layer Overview","text":"<p>When considering the network layer / ZigBee:</p> <ul> <li>Three kinds of devices<ul> <li>Coordinator (unique in network)</li> <li>Router</li> <li>End device</li> </ul> </li> <li>Three kinds of networks<ul> <li>Star</li> <li>Tree</li> <li>Mesh</li> </ul> </li> </ul> <p></p> <ul> <li>RFD must be an end device</li> </ul>"},{"location":"7-semester/DS/07-wireless/#address-assignment","title":"Address Assignment","text":"<ul> <li>In ZigBee, network addresses are assigned to devices by a distributed address assignment scheme</li> <li>ZigBee coordinator defines three network parameters<ul> <li>maximum number of children (C_mC_m) of a ZigBee router</li> <li>maximum number of child routes R_mR_m of a parent node</li> <li>depth of the network L_mL_m</li> </ul> </li> <li>A parent device utilizes C_m, R_mC_m, R_m and L_mL_m to compute a parameter C_{skip}C_{skip}<ul> <li>used to compute size of its children's address pools</li> </ul> </li> </ul>  C_{skip}(d) = \\left \\{ \\begin{array}{} 1+ C_m \\cdot (L_m - d - 1), &amp; \\text{if } R_m = 1 \\\\ \\frac {1+ C_m - R_m - C_m \\cdot R_m^{L_m-d-1}} {1- R_m}, &amp; \\text{otherwise} \\end{array}\\right.   C_{skip}(d) = \\left \\{ \\begin{array}{} 1+ C_m \\cdot (L_m - d - 1), &amp; \\text{if } R_m = 1 \\\\ \\frac {1+ C_m - R_m - C_m \\cdot R_m^{L_m-d-1}} {1- R_m}, &amp; \\text{otherwise} \\end{array}\\right.  <ul> <li>If a parent node at depth dd has an address A_{parent}A_{parent}<ul> <li>the nth child router is assigned to address A_{parent}+(n-1) \\times C_{skip}(d) +1A_{parent}+(n-1) \\times C_{skip}(d) +1</li> <li>nth child end device is assigned to address A_{parent} + R_m \\times C_{skip}(d)+nA_{parent} + R_m \\times C_{skip}(d)+n</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#zigbee-routing-protocols","title":"ZigBee Routing Protocols","text":"<ul> <li>In a star network<ul> <li>No routing</li> </ul> </li> <li>In a tree network<ul> <li>Tree routing<ul> <li>utilize the address assignment to obtain the routing paths</li> </ul> </li> </ul> </li> <li>In a mesh network, two options<ul> <li>Tree routing</li> <li>AODV, described later</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#zigbee-tree-routing","title":"ZigBee Tree Routing","text":"<ul> <li>When a device receives a packet, checks if the destination is itself or one of its child devices<ul> <li>If so, accept the packet or forward it to a child</li> <li>Otherwise, relay it along the tree 78</li> </ul> </li> </ul> <ul> <li>Example<ul> <li>38 \\to\\to 45</li> <li>38 \\to\\to 92</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#directed-diffusion","title":"Directed Diffusion","text":"<ul> <li>\"How many vehicles are there in the South West quadrant?\"<ul> <li></li> </ul> </li> <li>How can we find the sensors that have the relevant information?</li> <li>Which routes should the queries and the responses take?</li> </ul>"},{"location":"7-semester/DS/07-wireless/#1-forward-an-exploratory-interest","title":"1 - Forward an Exploratory Interest","text":"<ul> <li>Forwarding: broadcast (Flooding)</li> <li>Do not forward already resent interests</li> <li>Interests are soft state: they time out unless refreshed by the sink</li> <li>Gradient = state information for the reverse links (toward the sink)</li> </ul>"},{"location":"7-semester/DS/07-wireless/#2-send-exploratory-data-back","title":"2 - Send Exploratory Data Back","text":"<ul> <li>Nodes with the right type of data generate event instances with the highest frequency indicated among all its gradients</li> <li>Data sent unicast on every gradient</li> <li>Nodes ignore data without matching entry in the interest cache</li> <li>Nodes check their data cache to prevent loops</li> </ul>"},{"location":"7-semester/DS/07-wireless/#3-positive-enforcement","title":"3 - Positive Enforcement","text":"<ul> <li>Once the sink has received the exploratory data<ul> <li>send the original interest with the \"real\" frequency to the neighbor it (first) received the data from</li> </ul> </li> <li>When a node receives an interest from existing gradient<ul> <li>if request rate is higher than inflow, re-enforce a neighbor</li> <li>Select \"good\" neighbor (e.g. Lowest latency)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#result","title":"Result","text":"<ul> <li>A path from the sink to the source (and back) has been reinforced<ul> <li>Sources sends data in intervals of 10ms on this path</li> <li>It is the path with shortest delay</li> </ul> </li> <li>Completely local decisions! No global state</li> <li>Also works with multiple sources and multiple sinks</li> </ul>"},{"location":"7-semester/DS/07-wireless/#simulation-result","title":"Simulation Result","text":"<ul> <li>ns-2 simulation of 50-250 node networks with constant average node density, 5 sources, 5 sinks</li> <li>802.11 MAC Layer</li> <li>Compare directed diffusion to<ul> <li>flooding</li> <li>omniscient multicast (shortest-path)</li> </ul> </li> <li>Key metrics<ul> <li>Average dissipated energy<ul> <li>per node energy dissipation / number of events seen by sinks</li> </ul> </li> <li>Average packet delay<ul> <li>latency of event transmission to reception at sink</li> </ul> </li> <li>Distinct event delivery<ul> <li>number of distinct events received / number of events originally sent</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#average-dissipated-energy","title":"Average Dissipated Energy","text":"<ul> <li>Flooding is poor because of multiple paths from source to sink</li> <li>Diffusion is better than OM because duplicate data messages are suppressed</li> </ul>"},{"location":"7-semester/DS/07-wireless/#average-delay","title":"Average Delay","text":"<ul> <li>Flooding has high latency due to MAC collisions</li> <li>Diffusion finds lowest-delay path (=shortest path)</li> </ul>"},{"location":"7-semester/DS/07-wireless/#dynamic-source-routing-dsr","title":"Dynamic Source Routing (DSR)","text":"<ul> <li>When node S wants to send a packet to node D, but does not know a route to D, node S initiates a route discovery</li> <li>Source node S floods Route Request (RREQ)</li> <li>Each node appends own identifier when forwarding RREQ</li> </ul>"},{"location":"7-semester/DS/07-wireless/#route-discovery-in-dsr","title":"Route Discovery in DSR","text":"<p>Example in slides (pdf. p. 21)</p> <p></p> <p>\\Downarrow\\Downarrow</p> <p></p> <ul> <li>Destination D on receiving the first RREQ, sends a Route Reply (RREP)</li> <li>RREP is sent on a route obtained by reversing the route appended to received RREQ</li> <li>RREP includes the route from S to D on which RREQ was received by node D</li> </ul>"},{"location":"7-semester/DS/07-wireless/#route-reply-in-dsr","title":"Route Reply in DSR","text":""},{"location":"7-semester/DS/07-wireless/#routing-in-dsr","title":"Routing in DSR","text":"<ul> <li>Node S on receiving RREP, caches the route included in the RREP</li> <li>When node S sends a data packet to D, the entire route is included in the packet header<ul> <li>hence the name source routing</li> </ul> </li> <li>Intermediate nodes use the source route included in a packet to determine to whom a packet should be forwarded</li> </ul>"},{"location":"7-semester/DS/07-wireless/#data-delivery-in-dsr","title":"Data Delivery in DSR","text":""},{"location":"7-semester/DS/07-wireless/#dsr-advantages-and-disadvantages","title":"DSR Advantages and Disadvantages","text":"<ul> <li>(pro) Routes maintained only between nodes who need to communicate</li> <li>(pro) A single route discovery may yield many routes to the destination</li> <li>(con) Packet header size grows with route length due to source routing</li> <li>(con) Flood of route requests may potentially reach all nodes in the network</li> <li>(con) Potential collisions between route requests propagated by neighboring nodes<ul> <li>insertion of random delays before forwarding RREQ</li> </ul> </li> <li>(con) Increased contention if too many route replies come back due to nodes replying using their local cache<ul> <li>Route Reply Storm problem</li> </ul> </li> </ul>"},{"location":"7-semester/DS/07-wireless/#ad-hoc-on-demand-distance-vector-routing","title":"Ad Hoc On-Demand Distance Vector Routing","text":"<ul> <li>DSR includes source routes in packet headers</li> <li>Resulting large headers can sometimes degrade performance<ul> <li>particularly when data contents of a packet are small</li> </ul> </li> <li>AODV improves on DSR by maintaining routing tables at the nodes, so that data packets do not have to contain routes</li> <li>AODV retains the desirable feature of DSR that routes are maintained only between nodes which need to communicate</li> </ul>"},{"location":"7-semester/DS/07-wireless/#aodv","title":"AODV","text":"<ul> <li>Route Requests (RREQ) are forwarded in a manner similar to DSR</li> <li>When a node re-broadcasts a Route Request, it sets up a reverse path pointing towards the source<ul> <li>AODV assumes symmetric (bi-directional) links</li> </ul> </li> <li>When the intended destination receives a Route Request, it replies by sending a Route Reply (RREP)</li> <li>Route Reply travels along the reverse path set-up when Route Request is forwarded</li> </ul>"},{"location":"7-semester/DS/07-wireless/#route-request-in-aodv","title":"Route Request in AODV","text":"<p>Examples in slides (pdf. p. 34)</p> <p></p> <p>\\Downarrow\\Downarrow</p> <p></p>"},{"location":"7-semester/DS/07-wireless/#forward-path-setup-in-aodv","title":"Forward Path Setup in AODV","text":""},{"location":"7-semester/DS/07-wireless/#route-request-and-route-reply","title":"Route Request and Route Reply","text":"<ul> <li>Route Request (RREQ) includes the last known sequence number for the destination</li> <li>An intermediate node may also send a Route Reply (RREP) provided that it knows a more recent path than the one previously known to sender</li> <li>Intermediate nodes that forward the RREP, also record the next hop to destination</li> <li>A routing table entry maintaining a reverse path is purged after a timeout interval</li> <li>A routing table entry maintaining a forward path is purged if not used for a active_route_timeout interval</li> </ul>"},{"location":"7-semester/DS/07-wireless/#aodv-summary","title":"AODV Summary","text":"<ul> <li>Routes need not be included in packet headers</li> <li>Nodes maintain routing tables containing entries only for routes that are in active use</li> <li>At most one next-hop per destination maintained at each node<ul> <li>DSR may maintain several routes for a single destination</li> </ul> </li> <li>Sequence numbers are used to avoid old/broken routes</li> <li>Sequence numbers prevent formation of routing loops</li> <li>Unused routes expire even if topology does not change</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/","title":"Peer to Peer","text":""},{"location":"7-semester/DS/08-peer-to-peer/#overlay-networks","title":"Overlay Networks","text":"<ul> <li>Set of nodes and links (network)</li> <li>Built over an underlying network (e.g. the internet)</li> </ul> <p>The overlay network here is A B C D and E</p> <ul> <li>We don't care if one connection e.g. B - D has a relay node inbetween</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#why","title":"Why","text":"<ul> <li>Adds a layer to the stack to provide something the underlying network does not have without changing the underlying network<ul> <li>A service (integrated into the network) e.g. multimedia content distribution</li> <li>A routing protocol e.g. over ad-hoc network</li> <li>Other e.g. multicast integrated into the network, enhanced security</li> </ul> </li> <li>Could we do everything in the application layer?<ul> <li>Yes, but it is a mess (?)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#types-of-overlay","title":"Types of overlay","text":"Motivation Type Description Tailored for application needs Distributed hash tables Prominent class of overlay network. Offers a service mapping from keys to values across a potentially large number of nodes in a completely decentralized manner (similar to a standard hash table but in a networked environment). Peer-to-peer file sharing Overlay structures that focus on constructing tailored addressing and routing mechanisms to support the cooperative discovery and use (for example, download) of files. Content distribution networks Provides replication, caching and placement strategies to improve performance for content delivery to web users; can offer real-time performance for video streaming. Tailored for network style Wireless ad hoc networks Provides customized routing protocols for wireless ad hoc networks, including (i) proactive schemes to construct a routing topology over underlying nodes, and (ii) reactive schemes that establish routes on demand typically supported by flooding. Disruption-tolerant networks Overlays designed to operate in hostile environments that suffer significant node or link failure and potentially high delays. Offering additional features Multicast Provides access to multicast services where multicast routers are not available. Resilience Focused on improvement in robustness and availability of Internet paths. Security Overlay networks that offer enhanced security over the underling IP network, including virtual private networks."},{"location":"7-semester/DS/08-peer-to-peer/#example-pre-microsoft-skype","title":"Example: Pre-Microsoft Skype","text":""},{"location":"7-semester/DS/08-peer-to-peer/#limitation-of-the-clientserver-paradigm","title":"Limitation of the Client/Server Paradigm","text":"<ul> <li>A server offers a service</li> <li>The client finds out the address of the server</li> <li>The client starts communication with the server</li> <li>... business logic ...</li> </ul> <p>Issues</p> <ul> <li>Scalability<ul> <li>As the number of users increases, there is a higher demand for computing power, storage space, and bandwidth associated with the server-side</li> </ul> </li> <li>Reliability<ul> <li>The whole network will depend on the highly loaded server to function properly</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#peer-to-peer-paradigm","title":"Peer-to-peer Paradigm","text":"<ul> <li>A peer must find the other peer</li> <li>Both peers can initiate communication</li> <li>... business logic ...</li> </ul> <p>Advantages</p> <ul> <li>The system is based on the direct communication between peers</li> <li>No reliance on centralized services or resources</li> <li>The system can survive extreme changes in network composition</li> <li>This model is highly scalable</li> <li>Able to benefit from consumer technology<ul> <li>Instead of having servers</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#limitations-and-challenges","title":"Limitations and Challenges","text":"<p>Issues</p> <ul> <li>on/off behavior, participants churn<ul> <li>peers servicing other peers can get out of the network</li> </ul> </li> <li>need to join<ul> <li>bootstrap</li> </ul> </li> <li>need to discover other peers</li> <li>easier to misunderstand communication rules when implementing peers</li> <li>incentivize participation and reciprocation<ul> <li>you have to have many peers</li> </ul> </li> </ul> <p>Needs protocols to</p> <ul> <li>Finding peers on the network</li> <li>Finding what services a peer provides</li> <li>Obtaining status information from a peer</li> <li>Invoking a service on a peer</li> <li>Creating, joining, and leaving peer groups</li> <li>Creating data connections to peers</li> <li>Relaying messages for other peers</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#formalizing-p2p","title":"Formalizing P2P","text":"<p>A peer to peer system is a set of autonomous entities (peers) able to auto-organize and sharing a set of distributed resources in a computer network. The system exploits such resources to give a service in a complete or partial decentralized way</p> <ul> <li>A peer is a node on a P2P network that forms the fundamental processing unit of any P2P solution</li> <li>Each peer has a unique Peer ID</li> <li>Each peer belongs to one or several Peer Groups</li> <li>Each peer can communicate with other peers in its group and also those in other groups</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#types-of-p2p-applications","title":"Types of P2P Applications","text":"<p>Usually, p2p applications divided into three main categories:</p> <ul> <li>Distributed computing</li> <li>File sharing</li> <li>Collaborative applications</li> </ul> <p>Different purposes \\Rightarrow different set of requirements</p> <ul> <li>Distributed computing applications typically require the decomposition of larger problem into smaller parallel problems</li> <li>File sharing applications require efficient search across wide area networks</li> <li>Collaborative applications require update mechanisms to provide consistency in multi-user environment</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#p2p-file-sharing","title":"P2P File Sharing","text":"<p>Common Primitives</p> <ul> <li>Join: how do I begin participating?</li> <li>Publish: how do I advertise my file?</li> <li>Search: how to find a file/service?</li> <li>Fetch: how do I retrieve a file/use service? </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#centralized-p2p-networks","title":"Centralized P2P Networks","text":"<p>P2P file sharing killer application: Old Napster</p> <ul> <li>Free music over the Internet</li> </ul> <p>Key idea: share the content, storage and bandwidth of individual (home) users</p> <p></p> <p>Main Challenge</p> <ul> <li>Find where a particular file is stored</li> </ul> <p>Other challenges</p> <ul> <li>Scale: up to hundred of thousands or millions of machines</li> <li>Dynamicity: machines can come and go any time</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#napster-solution","title":"Napster Solution","text":"<ul> <li> <p>Assume a centralized index system that maps files (songs) to machines that are alive</p> </li> <li> <p>How to find a file:</p> <ul> <li>Query the index system \\to\\to return a machine that stores the required file<ul> <li>Ideally this is the closest/least-loaded machine</li> </ul> </li> <li>FTP the file</li> </ul> </li> <li>Advantages<ul> <li>Simplicity</li> <li>Easy to implement sophisticated search engines on top of the index system</li> </ul> </li> <li>Disadvantages<ul> <li>Robustness since there is a central point of failure</li> <li>Scalability since there is a central bottleneck</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#algorithm","title":"Algorithm","text":""},{"location":"7-semester/DS/08-peer-to-peer/#search-operation","title":"Search Operation","text":"<ul> <li>The client sends keywords to search with</li> <li>The server searches its list with the keywords</li> <li>The server returns a list of hosts - <code>&lt;ip_address, portnum&gt;</code> tuples - to client</li> <li>The client pings each host in the list to find transfer rates</li> <li>The client fetches file from best host</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#issues","title":"Issues","text":"<ul> <li>Centralized server a source of congestion</li> <li>Centralized server single point of failure</li> <li>No security: plaintext messages and passwords</li> <li>napster.com declared to be responsible for users\u2019 copyright violation<ul> <li>\"Indirect infringement\"</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#unstructured-p2p-networks-gnutella","title":"Unstructured P2P Networks - Gnutella","text":"<ul> <li>Peers form an overlay network</li> <li>Query Flooding:<ul> <li>Join: on startup, client contacts a few other nodes (learn from bootstrap-node); these become its \u201cneighbors\u201d</li> <li>Publish: no need</li> <li>Search: ask \u201cneighbors\u201d, who ask their neighbors, and so on... when/if found, reply to sender.</li> <li>Fetch: get the file directly from peer</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#search","title":"Search","text":"<p>Advantages:</p> <ul> <li>Totally decentralized</li> <li>Highly robust</li> </ul> <p>Disadvantages:</p> <ul> <li>Not scalable (need to contact all peers to perform a deterministic search)</li> <li>The entire network can be swamped with request<ul> <li>Each request needs a TTL (limited scope flooding)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#avoiding-excessive-traffic","title":"Avoiding Excessive Traffic","text":"<ul> <li>Query forwarded to all neighbors except peer from which received</li> <li>Each Query (identified by DescriptorID) forwarded only once<ul> <li>To avoid duplicate transmissions, each peer maintains a list of recently received messages</li> <li>Duplicates with same DescriptorID and Payload descriptor (msg type, e.g., Query) are dropped</li> </ul> </li> <li>QueryHit routed back only to peer from which Query received with same DescriptorID</li> <li>QueryHit with DescriptorID for which Query not seen is dropped</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#download","title":"Download","text":"<ul> <li> <p>Requester chooses \"best\" QueryHit responder</p> <ul> <li> <p>Initiates HTTP request directly to responder's IP+PORT</p> </li> <li> <p><code>http     GET /get/&lt;File Index&gt;/&lt;File Name&gt;/HTTP/1.0\\r\\n         Connection: Keep-Alive\\r\\n         Range: bytes=0-\\r\\n         User-Agent: Gnutella\\r\\n         \\r\\n</code></p> </li> </ul> </li> <li> <p>Usage of HTTP since it is widely used, and widely accepted by firewalls</p> </li> <li> <p>range field in the GET request to support partial file transfers.</p> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#comparison-napster-v-gnutella","title":"Comparison - Napster v Gnutella","text":"<p>Napster</p> <ul> <li>Pros<ul> <li>Simple</li> <li>Search scope is O(1)O(1)</li> </ul> </li> <li>Cons<ul> <li>Server maintains O(N)O(N) State</li> <li>Server performance bottleneck</li> <li>Single point of failure</li> </ul> </li> </ul> <p>Gnutella</p> <ul> <li>Pros<ul> <li>Simple</li> <li>Fully de-centralized</li> <li>Search cost distributed</li> </ul> </li> <li>Cons<ul> <li>Search scope is O(N)O(N)</li> <li>Search time is O(???)O(???)</li> <li>Large number of freeloaders</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#new-gnutella-protocol","title":"\"New\" Gnutella Protocol","text":"<ul> <li>Protocol originally called FastTrack</li> <li> <p>Implemented initially in Kazaa, KazaaLite, Grokster</p> <ul> <li>Then also in Gnutella</li> </ul> </li> <li> <p>Like Gnutella, but with some peers designated as supernodes</p> <ul> <li>Takes advantage of \u201chealthier\u201d participants in the system</li> <li>Contain a Napster-like directory of files</li> </ul> </li> <li> <p>\u201cSmart\u201d Query Flooding:</p> <ul> <li>Join: on startup, client contacts a \u201csupernode\u201d; may at some point become one itself</li> <li>Publish: send list of offered files to supernode</li> <li>Search: send query to supernode, supernodes flood query amongst themselves</li> <li>Fetch: get the file directly from peer(s); can fetch simultaneously from multiple peers</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/08-peer-to-peer/#discussion","title":"Discussion","text":"<ul> <li>A supernode stores a directory listing a subset of nearby (<code>&lt;filename,peer pointer&gt;</code>), similar to Napster servers</li> <li>Supernode membership changes over time</li> <li>Any peer can become (and stay) a supernode, provided it has earned enough reputation<ul> <li>Reputation of a user affected by length of periods of connectivity and total number of uploads</li> </ul> </li> <li>More sophisticated Reputation schemes invented, based on economics</li> </ul> <p>Pros</p> <ul> <li>Tries to balance between search overhead and space needs</li> <li>Tries to take into account node heterogeneity:<ul> <li>Bandwidth</li> <li>Host Computational Resources</li> </ul> </li> </ul> <p>Cons</p> <ul> <li>Still no real guarantees on search scope or search time</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#structured-p2p-network-chord","title":"Structured P2P Network - Chord","text":"<p>API based on unique GUID associated to data</p> <ul> <li><code>put(GUID, data)</code><ul> <li><code>data</code> stored in replicas at all nodes responsible for the object identified by <code>GUID</code></li> </ul> </li> <li><code>remove(GUID)</code><ul> <li>Deletes all references to GUID and the associated data</li> </ul> </li> <li><code>value = get(GUID)</code><ul> <li>data associated with GUID is retrieved from one of the responsible nodes</li> </ul> </li> </ul> <p>Alternate vision:</p> <ul> <li><code>publish(GUID)</code><ul> <li>GUID computed from the object</li> </ul> </li> <li><code>unpublished(GUID)</code><ul> <li>Makes the object corresponding to GUID inaccessible</li> </ul> </li> <li><code>sendToObj(msg, GUID, [n])</code><ul> <li>Invocation message is sent to an object<ul> <li>E.g: request to download a TCP connection for data transfer, sent to n replicas of the object</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#identifier-to-node-mapping","title":"Identifier to Node Mapping","text":""},{"location":"7-semester/DS/08-peer-to-peer/#lookup","title":"Lookup","text":"<ul> <li>Each node maintains its successor</li> <li>Route packet (ID, data) to the node responsible for ID using successor pointers</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#robustness-of-the-network","title":"Robustness of the Network","text":"<ul> <li>Each node A periodically sends a stabilize() message to its successor B</li> <li>Upon receiving a stabilize() message, node B<ul> <li>returns its predecessor B\u2019=pred(B) to A by sending a notify(B\u2019) message</li> </ul> </li> <li>Upon receiving notify(B\u2019) from B,<ul> <li>if B\u2019 is between A and B, A updates its successor to B\u2019</li> <li>otherwise, A does nothing</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#joining-operation","title":"Joining Operation","text":""},{"location":"7-semester/DS/08-peer-to-peer/#init","title":"Init","text":"<ul> <li>Node with id=50 joins the ring</li> <li>Node 50 needs to know at least one node already in the system<ul> <li>Assume known node is 15</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#find-successor","title":"Find Successor","text":"<ul> <li>Node 50: send join(50) to node 15</li> <li>Node 44: returns node 58, since it is responsible for GUID 50</li> <li>Node 50 updates its successor to 58</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#stabilize-successor","title":"Stabilize() Successor","text":"<ul> <li>Node 50: send stabilize() to node 58</li> <li>Node 58:<ul> <li>update predecessor to 50</li> <li>send notify() back to its new predecessor (50)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#predecessor-finds-you","title":"Predecessor Finds You","text":"<ul> <li>Sooner or later, node 44 sends a stabilize message to its successor, node 58</li> <li>Node 58 reply with a notify message</li> <li>Node 44 updates its successor to 50</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#predecessor-stabilize-you","title":"Predecessor stabilize() you","text":"<ul> <li>Node 44 sends stabilize message to its new successor, node 50</li> <li>Node 50 sets its predecessor to node 44</li> </ul> <p>*</p>"},{"location":"7-semester/DS/08-peer-to-peer/#achieving-efficiency-with-finger-tables","title":"Achieving Efficiency with Finger Tables","text":"<ul> <li>ith entry at peer with id n is first peer with id \\geq n+2^i (\\mod 2^m)id \\geq n+2^i (\\mod 2^m)</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#achieving-robustness","title":"Achieving Robustness","text":"<ul> <li>To improve robustness each node maintains the k (&gt; 1) immediate successors instead of only one successor</li> <li>In the notify() message, node A can send its k-1 successors to its predecessor B</li> <li>Upon receiving notify() message, B can update its successor list by concatenating the successor list received from A with A itself </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#files","title":"Files","text":"<ul> <li>GUID of files in the same namespace</li> <li>File is stored at first peer with id greater than or equal to its key</li> </ul> <ul> <li>What is into node 45<ul> <li>Data for GUID 37 or</li> <li><code>&lt;ip, port&gt;</code> for the peer offering file 37, or</li> <li>...</li> </ul> </li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#analysis","title":"Analysis","text":"<ul> <li>Search takes O(log(N))O(log(N)) time<ul> <li>Proof<ul> <li>(intuition): at each step, distance between query and peer-with-file reduces by a factor of at least 2</li> <li>(intuition): after log(N) forwardings, distance to key is at most 2^m / 2^{log(N)} = 2^m / N2^m / 2^{log(N)} = 2^m / N</li> </ul> </li> </ul> </li> </ul> <ul> <li>O(log(N))O(log(N)) search time holds for file insertions too (in general for routing to any GUID / key)<ul> <li>\u201cRouting\u201d can thus be used as a building block for<ul> <li>All operations: insert, lookup, delete</li> </ul> </li> </ul> </li> <li>Size of finger table: O(log(N))O(log(N))</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#comparative-performance","title":"Comparative Performance","text":""},{"location":"7-semester/DS/08-peer-to-peer/#structured-p2p-network-pastry","title":"Structured P2P Network - Pastry","text":"<p> Youtube Video explaining Pastry</p> <ul> <li>Assigns ids to nodes, just like Chord (using a virtual ring)</li> <li>Leaf Set - Each node knows its successor(s) and predecessor(s)</li> <li>Routing tables based on prefix matching</li> <li>Consider a peer with id <code>01110100101</code>. <ul> <li>It maintains a neighbor peer with an id matching each of the following prefixes (* = starting bit differing from this peer\u2019s corresponding bit):</li> <li><code>*</code></li> <li><code>0*</code></li> <li><code>01*</code></li> <li><code>011*</code></li> <li>... <code>0111010010*</code>\u200b</li> </ul> </li> <li>When it needs to route to a peer, say <code>01110111001</code> it starts by forwarding to a neighbor with the largest matching prefix, i.e. <code>011101*</code></li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#locality","title":"Locality","text":"<ul> <li>For each prefix, say <code>011*</code>, among all potential neighbors with the matching prefix, the neighbor with the shortest roundtrip-time is selected<ul> <li>Among the ones it knows</li> <li>Sniff over packets, looking for \u201cbetter deals\u201d</li> </ul> </li> <li>Since shorter prefixes have many more candidates (spread out throughout the Internet), the neighbors for shorter prefixes are likely to be closer than the neighbors for longer prefixes</li> <li>Thus, in the prefix routing, early hops are short and later hops are (physically, RTT) longer</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#first-four-rows-of-a-pastry-routing-table","title":"First Four Rows of a Pastry Routing Table","text":"<p>The routing table is located at a node whose GUID begins <code>65A1</code>. Digits are in hexadecimal.  The n\u2019s represent <code>[GUID, IP address]</code> pairs specifying the next hop to be taken by messages addressed to GUIDs that match each given prefix. Grey- shaded entries indicate that the prefix matches the current GUID up to the given value of p: the next row down or the leaf set should be examined to find a route. Although there are a maximum of 128 rows in the table, only \\log_{16} N\\log_{16} N rows will be populated on average in a network with NN active nodes.</p>"},{"location":"7-semester/DS/08-peer-to-peer/#routing-example","title":"Routing Example","text":"<ul> <li>Routing a message from node <code>65A1FC</code> to <code>D46A1C</code>.</li> <li>With the aid of a well-populated routing table, the message can be delivered in ~\\log_{16} (N)\\log_{16} (N) hops</li> </ul>"},{"location":"7-semester/DS/08-peer-to-peer/#tapestry","title":"Tapestry","text":"<ul> <li>Same routing of Pastry: prefix routing</li> <li> <p>DOLR interface</p> <ul> <li><code>publish(GUID)</code></li> <li><code>unpublish(GUID)</code></li> <li><code>sendToObj(msg, GUID, [n])</code></li> </ul> </li> <li> <p>Main difference: flexibility since application can place replicas close (in network distance) to frequent users of resources for:</p> <ul> <li>reduced latency</li> <li>minimized network load</li> <li>tolerance of network and host failures</li> </ul> </li> </ul> <p></p> <p>Replicas of the file Phil's Books (G=4378) are hosted at nodes 4228 and AA93.</p> <p>Node 4377 is the root node for object 4378.</p> <p>The Tapestry routings shown are some of the entries in routing tables.</p> <p>The publish paths show routes followed by the publish messages laying down cached location mappings for object 4378.</p> <p>The location mappings are subsequently used to route messages sent to 4378.</p>"},{"location":"7-semester/DS/08-peer-to-peer/#structured-vs-unstructured-peer-to-peer-systems","title":"Structured vs Unstructured Peer-to-peer Systems","text":""},{"location":"7-semester/DS/09-cluster-storage/","title":"Cluster Data Storage","text":""},{"location":"7-semester/DS/09-cluster-storage/#google-application","title":"Google Application","text":"<ul> <li>Search engine</li> <li>Cloud Applications: Gmail, Gdrive, messaging (Google Talk), Calendar, Docs, Maps, Earth, YouTube, \u2026</li> <li>PaaS</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#original-search-engine","title":"Original Search Engine","text":""},{"location":"7-semester/DS/09-cluster-storage/#applications-workload","title":"Applications / Workload","text":"<ul> <li>Offline batch jobs<ul> <li>Large datasets (PBs), bulk reads/writes (MB chunks)</li> <li>Short outages acceptable</li> <li>Web indexing, log processing, satellite imagery, etc.</li> </ul> </li> <li>Online applications<ul> <li>Smaller datasets (TBs), small reads/writes (KBs)</li> <li>Outages immediately visible to users, low latency vital</li> <li>Web search, GMail, Google Docs, etc.</li> </ul> </li> <li>Many areas:<ul> <li>Information retrieval</li> <li>Machine learning</li> <li>Image/video processing</li> <li>Natural language processing</li> <li>Machine translation</li> <li>...</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#cluster-architecture","title":"Cluster Architecture","text":"<p>http://www.google.com/about/datacenters/index.html https://www.youtube.com/watch?v=XZmGGAbHqa0</p> <ul> <li>Groups of clusters stored in different places in the world</li> </ul> <p></p>"},{"location":"7-semester/DS/09-cluster-storage/#normal-events-in-large-clusters","title":"Normal Events in Large Clusters","text":"<p>Typical first year for a new cluster:</p> <ul> <li>~0.5 overheating (power down most machines in &lt;5 mins, ~1-2 days to recover)</li> <li>~1 PDU failure (~500-1000 machines suddenly disappear, ~6 hours to come back)</li> <li>~1 rack-move (plenty of warning, ~500-1000 machines powered down, ~6 hours)</li> <li>~1 network rewiring (rolling ~5% of machines down over 2-day span)</li> <li>~20 rack failures (40-80 machines instantly disappear, 1-6 hours to get back)</li> <li>~5 racks go wonky (40-80 machines see 50% packet loss)</li> <li>~8 network maintenances (4 might cause ~30-minute random connectivity losses)</li> <li>~12 router reloads (takes out DNS and external vips for a couple minutes)</li> <li>~3 router failures (have to immediately pull traffic for an hour)</li> <li>~dozens of minor 30-second blips for dns</li> <li>~1000 individual machine failures (eg DRAM)</li> <li> <p>~thousands of hard drive failures</p> </li> <li> <p>slow disks, bad memory, mis-configured machines, flaky machines, etc.</p> </li> <li>Long distance links: wild dogs, sharks, drunken hunters, etc.</li> </ul> <p>Large variety of Software bugs, crashes</p>"},{"location":"7-semester/DS/09-cluster-storage/#original-cluster-philosophy","title":"Original Cluster Philosophy","text":"<ul> <li>Use software techniques for fault tolerance</li> <li>Use replication and parallelism for throughput and availability</li> <li>Buy HW with best price/performance ratio, not absolute performance</li> <li>\u201cUnreliable\u201d, low-performance commodity HW<ul> <li>\\Rightarrow minimize cost (incl. depreciation, operation costs) per query</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#google-infrastructure","title":"Google Infrastructure","text":""},{"location":"7-semester/DS/09-cluster-storage/#cluster-services","title":"Cluster Services","text":"<p>Jeff Dean (Google)</p>"},{"location":"7-semester/DS/09-cluster-storage/#googles-borg","title":"Google's Borg","text":"<ul> <li>Borg: Google\u2019s cluster manager<ul> <li>runs &gt;100k jobs, &gt;1k different applications, across 10k machines</li> </ul> </li> <li>Goal: high resource utilization, fast recovery time<ul> <li>uses admission control</li> <li>efficient task-packing and over-commitment</li> <li>scheduling policies that reduce the probability of correlated failures</li> <li>machine sharing with process-level performance isolation</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#gfs-a-distributed-filesystem","title":"GFS - A Distributed Filesystem","text":"<p> Youtube Video about GFS</p>"},{"location":"7-semester/DS/09-cluster-storage/#design-assumptions","title":"Design Assumptions","text":"<ul> <li>Component failures are normal</li> <li>Few very large files</li> <li>Optimized towards Google Workload (processing of bulk-data):<ul> <li>Large sequential reads, few small random reads</li> <li>Frequent (concurrent) append, rare concurrent random writes; multiple producers/single consumers of data to same file</li> <li>High sustained throughput more important than latency</li> </ul> </li> <li>Non-POSIX API:<ul> <li>create, delete, open, close, read, write</li> <li>snapshot: fast copy of a file or a directory tree</li> <li>record append: multiple clients append data to the same file<ul> <li>guaranteed consistency</li> <li>location of append not decided by the client</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#architecture","title":"Architecture","text":""},{"location":"7-semester/DS/09-cluster-storage/#passive-replication-write","title":"Passive Replication - Write","text":"<p>s</p> <ol> <li>Ask master who is primary (leasing) for chunk x</li> <li>the identity of the primary and the locations of the other (secondary) replicas.</li> <li>The client pushes the data to all the replicas in a forwarding chain</li> <li>Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary.</li> <li>The primary forwards the write request to all secondary replicas. Each secondary replica applies mutations in the same serial number order assigned by the primary.</li> <li>The secondaries all reply to the primary indicating that they have completed the operation.</li> <li>The primary replies to the client.<ul> <li>Any errors encountered at any of the replicas are reported to the client (a subset of replica\u2019s modified)</li> <li>Client retries</li> <li>File may be inconsistent</li> </ul> </li> </ol>"},{"location":"7-semester/DS/09-cluster-storage/#consistency-model","title":"Consistency Model","text":"<ul> <li> <p>File namespace mutations (e.g. file creation) are atomic (handled by master)</p> </li> <li> <p>A file region is</p> <ul> <li>\u201cConsistent\u201d if all clients see same data (from all replicas)</li> <li>\u201cDefined\u201d if consistent and clients see writes in their entirety</li> </ul> </li> <li> <p>Append: record is appended atomically at least once somewhere</p> <p></p> </li> <li> <p>Applications can handle inconsistent regions</p> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#replica-management-master","title":"Replica Management (Master)","text":"<ul> <li>Replica placement<ul> <li>Spread replicas over different racks to optimize availability and bandwidth, but at an increased cost of writes (inter-rack-communication)</li> </ul> </li> <li>New Chunk allocation:<ul> <li>consider disk utilization, number of recent allocations to same disk, and placement across racks</li> </ul> </li> <li>Re-replication<ul> <li>When too many replica\u2019s are unavailable</li> <li>Higher priority when replication factor is low</li> </ul> </li> <li>Re-balancing<ul> <li>to ensure uniform load and disk utilization</li> </ul> </li> <li>Garbage Collection<ul> <li>delete chunks with outdated version number, deleted files</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#fault-tolerance-of-master","title":"Fault Tolerance of Master","text":"<ul> <li>Master state (Operations-log and its check-points) is replicated and maintained in stable storage</li> <li>Relatively easy/fast recovery</li> <li>Shadow masters (read-only) provide read-only access</li> <li>External failure detection mechanism detects master failure, selects a new master, and restarts it.</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#performance-2003","title":"Performance (2003)","text":"<ul> <li>Micro-benchmark: performance test of basic functionality / selected aspects (in a reduced controlled setting)</li> <li>1 master (2 shadow replicas), 16 chunk servers, 16 clients, 100Mbps network cards (12.5 MB/S) ,1 Gbps link between switches (125 MB/s)</li> </ul> <p>Example results (anno 2003):</p> <p></p> <p>Behavior in real-life workload, real-life setup:</p> <p></p> <ul> <li>A for R&amp;D</li> <li>B is a production cluster</li> </ul> <p></p> <ul> <li>A\u2019s network limit is 750 MB/s</li> <li>B\u2019s network limit is 1300 MB/s</li> </ul> <p>Chunk Recovery</p> <ul> <li>When a chunk server fails or is killed, some chunks are under-replicated (not enough replica)</li> <li>1 (out of 3) chunk server with 15000 chunks (600 GB) killed<ul> <li>Restored in ~23 minutes</li> </ul> </li> <li>2 (out of 3) killed<ul> <li>Restored to 2x replication in 2 minutes</li> <li>Prioritization kicks in</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#conclusions","title":"Conclusions","text":"<ul> <li>Apparently successful DFS<ul> <li>For commodity clusters</li> <li>Dedicated to Google's workload</li> </ul> </li> <li>Key infrastructure enabling many of their services</li> <li>Interesting replica management system, but few details / policies provided</li> </ul> <p>Since 2012: Colossus file system</p> <ul> <li>\u201cH\u00f6lzle calls Colossus \"similar to GFS \u2013 but done better after ten years of experience.\u201c</li> <li>https://www.wired.com/2012/07/google-colossus/</li> <li>https://cloud.google.com/files/storage_architecture_and_challenges.pdf</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#chubby-a-distributed-lock-service","title":"Chubby - A Distributed Lock Service","text":"<ul> <li>A coarse-grained lock service and file-system</li> <li>Lock service: allows clients to synchronize their activities</li> <li>Coarse = for hours or days, and</li> <li>Reliable (but low-volume) storage</li> </ul> <p>Example: Master Election</p> <ul> <li>Nodes try to get a lock</li> <li>The nodes who wins writes result into a small file</li> </ul> <p>Filesystem: Is a well-known mechanism and interface for the programmers</p> <p>Chubby</p> <ul> <li>Intended for \u201cloosely-coupled distributed systems\u201d<ul> <li>Nodes run independently - at unpredictable speed</li> <li>Nodes may crash \u2013 difficult to detect, and recover</li> <li>Messages may be lost, delayed, reordered, but not corrupted</li> </ul> </li> <li>A coarse-grained lock service<ul> <li>Highly fault tolerant (consistent)</li> <li>Availability</li> <li>Scalability</li> <li>Throughput and performance less important (coarse!)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#examples-of-use","title":"Examples of Use","text":"<ul> <li>GFS: Elect a master</li> <li>BigTable: master election, client discovery, table service locking</li> <li>Well-known location to bootstrap larger systems</li> <li>Name Service</li> <li>Partition workloads</li> <li>Synchronization, but not fine grained locking</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#architecture_1","title":"Architecture","text":"<p>Typically</p> <ul> <li>1 cell per data center</li> <li>Serves 90000+ processors</li> <li>N=5</li> </ul> <p></p>"},{"location":"7-semester/DS/09-cluster-storage/#locks-and-files","title":"Locks and Files","text":"<ul> <li>Filesystem like interface:</li> </ul> <pre><code>fh=Open(\u201c/ls/exampleCell/gfs/master\u201d)\nsuccess=tryAcquire(fh)\nif(success)\n    write(fh,myID)\n</code></pre> <ul> <li>Either Exclusive-Write lock or Shared-Read lock</li> <li>Subdirectories and (non-inherited) ACLs supported, but not links</li> <li>Locks are advisory (you can ignore the lock)</li> <li>\u201cWhole-file\u201d R/W</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#client-to-master-communication","title":"Client to Master Communication","text":"<ul> <li>All read/write requests go through the master</li> <li>Communication via RPC (through the library)</li> <li>The other replicas only get updates from the master</li> <li>How the client finds the master:<ul> <li>Send master location request to all replicas in DNS</li> <li>Non-masters redirect to master</li> </ul> </li> <li>Client sends all requests to master until negative answer</li> <li>Master notifies clients if files modified, created, deleted, lock status changes (push</li> <li>Master notifies clients if files modified, created, deleted, lock status changes (push; saves bandwidth compared to constant polling)<ul> <li>Master is stateful</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#read-and-write","title":"Read and Write","text":"<ul> <li>Reads are handled by the master</li> <li>Write: Successful if majority of replicas acknowledge receipt of update<ul> <li>Usual Prepare \u2013 Promise \u2013 Accept \u2013 Accepted (Paxos)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#client-sessions","title":"Client Sessions","text":"<ul> <li>Sessions maintained between client and server</li> <li>Client Failure<ul> <li>Master promises service for \u201clease time\u201d</li> <li>Clients make \u201cKeep-alive\u201d RPCs to maintain session; master returns extended lease time (eg. 12 sec)</li> <li>If session is lost, server releases any client-held handles.</li> </ul> </li> <li>Master failure<ul> <li>If client does not get a renewed lease, session is in jeopardy<ul> <li>Clear local cache</li> <li>Wait for \u201cgrace period\u201d (about 45 seconds)</li> <li>Continue attempt to contact (possibly new) master</li> </ul> </li> <li>Successful attempt =&gt; ok; jeopardy over</li> <li>Failed attempt =&gt; session assumed lost</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#cache-consistency","title":"Cache Consistency","text":"<ul> <li>Clients cache all file content to reduce read traffic</li> <li>Strict consistency<ol> <li>A file-modification is blocked until all caches are invalidated</li> <li>Invalidation messages are piggybacked on keep-alive messages</li> <li>Clients flush cache, and acknowledges (piggybacked on lease-renewal)</li> </ol> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#master-re-election","title":"Master Re-Election","text":"<ul> <li> <p>If replicas lose contact with master, they wait for grace period (shorter: 4 - 6 seconds)</p> </li> <li> <p>On timeout, hold new election</p> </li> <li>The new master updates the DNS, gets a recent copy of the database, etc.</li> <li>But how do the replicas agree on one (!) new master?</li> <li>Paxos algorithm<ul> <li>Also used to propagate write updates to the replicas</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#conclusions_1","title":"Conclusions","text":"<ul> <li>An \u201ceasy-to-use\u201d file and locking service</li> <li>Integration of well-known (but advanced) techniques</li> <li>Rarely used code for fail-over contained \u201ca rich collection of interesting bugs\u201d</li> <li>Extensive verification/testing necessary</li> </ul> <p>Google testing motto:</p> <ul> <li>If it ain\u2019t broke, you are not trying hard enough!</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#bigtable-a-high-performance-storage-system","title":"BigTable - A High-Performance Storage System","text":"<p>Database used by Google</p> <p></p> <ul> <li>Distributed storage system: PBs, across 1000s of servers</li> <li>Row/Column abstraction for storing data</li> <li>Distributed Persistent multi-level sorted map</li> </ul> <p>(Keys are normally 10-100 bytes, max 64 KB)</p> <p></p> <p>(Qualifiers are used to address individual column within family)</p>"},{"location":"7-semester/DS/09-cluster-storage/#example-web-table","title":"Example: \"Web-table\"","text":"<p>Rows are lexicographically sorted: </p> <ul> <li>Webtable domain names are reversed so we group related pages. </li> <li>Efficient domain analysis: related information likely stored in same tablet!</li> </ul> <p>All row accesses are atomic!</p>"},{"location":"7-semester/DS/09-cluster-storage/#bigtable-applications-2006","title":"BigTable Applications (2006)","text":"<p>Example: Google Analytics stores information on raw clicks associated with users in one table and summarizes analyzed information in a second table.</p> <p></p> <ul> <li>Analytics: row = user session (sitename, starttime)</li> <li>Earth: row = geographical segment, column family = sources of data</li> <li>Personalized Search: row = userid, column family = type of action (search, webaccess)</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#tablets","title":"Tablets","text":"<ul> <li>Tablet = consecutive set of rows</li> <li>Size ~ 200MB</li> <li>Tablets can be split/merged if too large/small</li> <li>Each tablet is served by one Tablet Server (similar to a GFS chunkserver)</li> <li>Stored in \u201cSorted Strings Table\u201d SSTables (indexed keyvalue maps) file format in GFS<ul> <li>immutable</li> </ul> </li> <li>Row access is atomic</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#system-structure","title":"System Structure","text":"<ul> <li>Main goal of the BigTable infrastructure: (1) manage tablets and access and change associated data\u2026</li> <li>\u2026 and (2) map tablet structure into the underlying file system.</li> <li>BigTable Master is stateless: all data in Chubby!</li> <li>Live set of servers detected via Chubby.</li> <li>BigTable Master: <ul> <li>Tablet assignment: one server at a time.</li> </ul> </li> <li>Tablet Server<ul> <li>Tablet localization: Tablets stored in a B+Tree: B-tree (range of keys in each level), where stored at the leaves (only)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#tablet-localization","title":"Tablet Localization","text":"<p>System maintains B+ tree index (in BigTable!) </p> <p>Clients searches index </p> <p>Clients cache tablet locations</p> <p></p> <p></p> <p>Eg. 128MB (2^27^) Meta-data tablets (1kB=2^10^ per key) in 2 index levels addresses 2^34^ tablets (of each 128Mb= 2^61^ B)</p>"},{"location":"7-semester/DS/09-cluster-storage/#tablet-serving","title":"Tablet Serving","text":""},{"location":"7-semester/DS/09-cluster-storage/#bigtable-features","title":"BigTable Features","text":"<ul> <li>Single-row transactions: easy to do read/modify/write operations</li> <li>Locality groups: segregate columns into different SSTables</li> <li>In-memory columns: random access to small items</li> <li>Suite of compression techniques: per locality group</li> <li>Bloom filters: avoid seeks for non-existent data<ul> <li>Probabilistic set membership test: is item in set?<ul> <li>Answer: \u201cdefinitely not\u201d no need to look up!</li> <li>Answer: \u201cmaybe in set\u201d.</li> </ul> </li> </ul> </li> <li>Garbage Collection of (immutable) SSTable Files</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#performance","title":"Performance","text":"<p>Anno 2006 [Chang et al - TOCS 26(2)]</p> <p></p> <ul> <li>\u201cMem\u201d = locality group marked to be placed in-memory</li> <li>Random reads are slow because much data transferred from GFS, but little utilized, 1200 reads/s ~75MB/S<ul> <li>Random reads are slow: cannot exploit locality, much data from GFS not used.</li> <li>Reads in memory much faster.</li> </ul> </li> <li>Sequential read: better: same block hit 64 times<ul> <li>Sequential reads faster: entire block used!</li> </ul> </li> <li>Scans: use API for scanning over all values in a row range</li> <li>Good scalability for most operations, but not linear due to load imbalance</li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#status-2009","title":"Status (2009)","text":"<ul> <li>Continuous development<ul> <li>Scaling, robustness</li> <li>Replication: eventual consistency replication across data centers (user facing services)</li> </ul> </li> <li>~500 BigTable clusters</li> <li>Largest cluster:<ul> <li>70+ PB data; sustained: 10M ops/sec; 30+ GB/s I/O</li> </ul> </li> </ul>"},{"location":"7-semester/DS/09-cluster-storage/#summary","title":"Summary","text":""},{"location":"7-semester/DS/10-blockchain/","title":"Blockchain","text":""},{"location":"7-semester/DS/10-blockchain/#crypto-tools","title":"Crypto Tools","text":"<ul> <li>Hash</li> <li>Signatures</li> <li>Asymmetric crypto</li> <li>Merkle Trees</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#cryptographic-hash-function","title":"Cryptographic Hash Function","text":"H: X = \\{0,1\\}* -&gt; Y = \\{0,1\\}^L  <ul> <li> <p>with L fixed:</p> <ul> <li>Examples for L: 128/160/256/512 bits</li> </ul> </li> <li> <p>Informal property</p> <ul> <li>a small change in the input produces a completely different output</li> </ul> </li> <li>Security properties (collisions exist, but are hard to find):<ul> <li>Pre-image resistance: \\forall y \\in Y\\forall y \\in Y, it is hard to find x \\in Xx \\in X such that H(x)=yH(x)=y</li> <li>Second pre-image resistance: given a particular M \\in YM \\in Y and this h=H(M)h=H(M), it is hard to find M'M' with H(M')=hH(M')=h</li> <li>Collision-resistance: it is hard to find x_1 \\in Xx_1 \\in X and x_2 \\in Xx_2 \\in X, with x_1 \\neq x_2x_1 \\neq x_2 and H(x_1)=H(x_2)H(x_1)=H(x_2)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#case-study-rock-paper-scissors","title":"Case Study: Rock Paper Scissors","text":"<ul> <li>Let us play over the internet<ul> <li>You play your rock / paper / scissors move</li> <li>I play my move</li> <li>One wins</li> </ul> </li> <li>Ideally, we could play at the same time but my cam is not working, and there is some jitter on the audio<ul> <li>Or the rock-paper-scissors championship is today, and I have no 4g connection, so we play via email</li> </ul> </li> <li>Well, tell me your move, and you can trust I will tell you mine!!!</li> <li>Or can you do something using hash functions?</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#solution-1-3","title":"Solution 1 / 3","text":"<ul> <li>M \u2013 your move</li> <li> <p>H \u2013 Hash function</p> </li> <li> <p>You tell me H(M)</p> </li> <li>I will then tell you my move</li> </ul> <p>Does this work?</p> <ul> <li>No! You can just run rock paper and scissors through hash</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#solution-2-3","title":"Solution 2 / 3","text":"<ul> <li>M \u2013 your move</li> <li>H \u2013 Hash function</li> <li>S \u2013 random string computer by you (salt)</li> <li> <p>|| - concatenation</p> </li> <li> <p>You tell me H(M||S)</p> </li> <li>I will then tell you my move</li> </ul> <p>Does this work?</p> <ul> <li>What if I don\u2019t trust you?<ul> <li>Nor your uncle working at NSA!</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#solution-3-3","title":"Solution 3 / 3","text":"<ul> <li>M \u2013 your move</li> <li>H \u2013 Hash function</li> <li>S \u2013 random string computer by you (salt)</li> <li>|| - concatenation</li> <li> <p>T \u2013 a nonce / a timestamp / a string I send you</p> </li> <li> <p>You tell me H(T||M||S)</p> </li> <li>I will then tell you my move</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#sha-secure-hash-algorithm","title":"SHA: Secure Hash Algorithm","text":"<ul> <li>The Secure Hash Algorithm is a family of cryptographic hash functions published by the National Institute of Standards and Technology (NIST) as a U.S. Federal Information Processing Standard (FIPS)</li> </ul> <p>https://en.wikipedia.org/wiki/Secure_Hash_Algorithm</p> <p>Bad algorithms in red:</p> <p></p>"},{"location":"7-semester/DS/10-blockchain/#usage","title":"Usage","text":"<ul> <li>I want to use hash functions to sign a large data structure<ul> <li>I compute the hash hh</li> <li>I send you the hash using a secure/expensive channel</li> <li>I send you data using normal channel</li> <li>If your H(data)H(data) is not hh, you know it is bad!</li> </ul> </li> <li>You would have to ask for the whole data once again</li> <li>Ok, let\u2019s split data in chunks c_1 \\dots c_kc_1 \\dots c_k<ul> <li>I compute the hashes h_1 =H(c_1) \\dots h_k = H(c_k)h_1 =H(c_1) \\dots h_k = H(c_k)</li> <li>I send you the hashes using a secure/expensive channel</li> <li>I send you data using normal channel</li> <li>If your H(c_i)H(c_i) is not h_ih_i, you know it is bad, and I just ask for c_ic_i</li> </ul> </li> <li>All cool, but sending all the hashes is heavy<ul> <li>One per chunk!</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#lets-chain-the-hashes","title":"Lets Chain the Hashes","text":"<p>Let\u2019s split data in chunks c_1 \\dots c_kc_1 \\dots c_k</p> <ul> <li>I compute the hashes h_1 = H(c_1), h_2 = H(c_2 | h_1) \\dots h_k =H(c_k|h_{k-1})h_1 = H(c_1), h_2 = H(c_2 | h_1) \\dots h_k =H(c_k|h_{k-1})</li> <li>From time to time, you can ask me a hash, for example h_{10}h_{10} to verify the first 10 chunks (blocks). Later on, you ask me h_{20}h_{20} to verify the chunks 11 to 20</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#digital-signatures-asymmetric-cryptography","title":"Digital Signatures - Asymmetric Cryptography","text":"<p>Three algorithms: KeyGen, Sign, Verify</p> <ul> <li><code>(sk, pk) := generateKeys(keysize)</code><ul> <li><code>sk</code>: secret signing key</li> <li><code>pk</code>: public verification key</li> </ul> </li> <li><code>sig := sign(sk, message)</code><ul> <li>Computes the signature of the message using the secret key</li> </ul> </li> <li><code>isValid := verify(pk, message, sig)</code><ul> <li>Decrypts the signature using the public key and compare the result with the message, given the property<ul> <li><code>verify(pk, message, sign(sk, message)) == true</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#performance","title":"Performance","text":"<ul> <li>Algorithms using private/public keys are very slow</li> <li>Usually, the message is hashed with a known algorithm<ul> <li>known = I publicly declare which algorithm I am using</li> </ul> </li> <li>Then, I compute the signature on the hash</li> <li>The receiver will decrypt the signature using the public key, compute the hash of the message, and compare</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#in-java","title":"In Java","text":"<pre><code>import java.security.KeyPair; import java.security.KeyPairGenerator; import java.security.NoSuchAlgorithmException; import java.security.PrivateKey; import java.security.PublicKey; import javax.crypto.Cipher;\n</code></pre> <p>... and so on</p>"},{"location":"7-semester/DS/10-blockchain/#merkle-tree-hash-tree","title":"Merkle Tree - Hash Tree","text":"<p>A data structure summarizing information about a big quantity of data with the goal to check the content</p> <p>Introduced by Ralph Merkle in 1979</p> <ul> <li>Combines hash functions with binary tree structure</li> </ul> <p>Main ingredient: a complete binary tree built starting from a initial set of symbols</p> <ul> <li>exploits a hash function H (SHA1, MD5)</li> <li>leaves: H applied to the initial symbols</li> <li>internal nodes: H applied to the sons of a node</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#example","title":"Example","text":"<ul> <li>4 blocks</li> </ul> <ul> <li>Hash them</li> </ul> <ul> <li>Now concatenate them</li> </ul> <ul> <li>Hash the concatenation of the hashes</li> </ul> <ul> <li> <p>And repeat, so on and so forth</p> <p></p> </li> <li> <p>If data B is corrupted, it invalidates one whole branch of the tree</p> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#building-a-merkle-tree","title":"Building a Merkle Tree","text":"<ul> <li>Let us organize all data as leaves of the hash tree<ul> <li>Nodes at height h will depend on 2^H2^H leaf values</li> <li>Tree of height HH has N= 2^HN= 2^H leaves</li> </ul> </li> <li>Obtaining the root P requires calculating all NN leaf values plus 2^H-12^H-1 more hash function evaluations<ul> <li>Is it too much work?<ul> <li>It is 2N</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#benefits-of-a-merkle-tree","title":"Benefits of a Merkle Tree","text":"<ul> <li>Let us store the root of the hash tree somewhere!<ul> <li>If suspicious, you can ask me for all data and verify the root is right</li> </ul> </li> <li>Compute the root from all the data<ul> <li>You can cache the hashes of the \u201cwitnesses\u201d for performance</li> <li>You can hash elements \u201cas you go\u201d if data is produced slowly</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#blockchain_1","title":"Blockchain","text":"<ul> <li>A blockchain is a digitized, decentralized, public ledger of all cryptocurrency transactions. Constantly growing as \u2018mined\u2019 blocks (the most recent transactions) are recorded and added to it in chronological order, it allows market participants to keep track of digital currency transactions without central recordkeeping. (merkle tree)</li> <li>Wikipedia: \u201cA distributed database that is used to maintain a continuously growing list of records, called blocks. Each block contains a timestamp and a link to a previous block\u201d</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#hash-pointer","title":"Hash Pointer","text":"<ul> <li>A pointer to where some info is stored</li> <li>A cryptographic hash of the info</li> </ul> <p>If we have a hash pointer, we can</p> <ul> <li>ask to get the info back</li> <li>verify that it hasn\u2019t changed</li> </ul> <p>Tamper-evident data pointer = Hash Pointer (HP)</p> <p></p>"},{"location":"7-semester/DS/10-blockchain/#blockchain_2","title":"Blockchain","text":"<ul> <li>Information organized into blocks</li> <li>Each block has a hash pointer (HP) to previous block</li> <li>To verify block n, hash it and compare to HP(block n)<ul> <li>Which is contained into your block n+1</li> </ul> </li> <li>Tamper free block addition</li> </ul> <p>\"tamper-proof linked list\"</p>"},{"location":"7-semester/DS/10-blockchain/#tampering","title":"Tampering","text":"<ul> <li>If you tamper with data in block ii</li> <li>You have to tamper with hash pointer i+1i+1, hash pointer i+2i+2 and so on<ul> <li>Since  HP\\ i+2HP\\ i+2 depends on HP\\ i+1HP\\ i+1 and so on</li> </ul> </li> <li>And I will store the HP on the head somewhere safe<ul> <li>Where? Everywhere!</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#blockchain-as-a-decentralized-database","title":"Blockchain as a Decentralized Database","text":"<ul> <li>Information held on a blockchain exists as a shared \u2014 and continually reconciled \u2014 distributed database</li> <li>The blockchain database isn\u2019t stored in any single location, meaning the records it keeps are truly public and easily verifiable</li> <li>No centralized version of this information exists for a hacker to corrupt</li> <li>Hosted by millions of computers simultaneously, its data is accessible to anyone on the internet</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#blockchain-network-architecture","title":"Blockchain Network Architecture","text":"<p>Node</p> <ul> <li>A computer connected to the blockchain network using a client that performs the task of validating and relaying transactions) gets a copy of the blockchain, which gets downloaded automatically upon joining the blockchain network</li> <li>Every node is an \u201cadministrator\u201d of the blockchain, and joins the network voluntarily (in this sense, the network is decentralized)</li> </ul> <p></p>"},{"location":"7-semester/DS/10-blockchain/#double-spend-conundrum","title":"Double Spend Conundrum","text":"<p>Let us describe an example on bitcoins</p> <ul> <li>Information in ledger is the transaction<ul> <li>I write in the blockchain that I gave you $$$ in exchange for something</li> <li>You can use the information in the block to show you own \u201cmy old\u201d money</li> </ul> </li> <li>I take status A of the blockchain, I write on a block I give you 100$ and send it around<ul> <li>You receive it from the network, you believe you can spend \u201cmy old\u201d money, and provide me services</li> </ul> </li> <li>Then I take status A of the blockchain and add another transaction to your colleague<ul> <li>He thinks he has \u201cmy old\u201d money, and provides me services</li> </ul> </li> <li>Double-spending is the result of successfully spending digital money more than once</li> <li>Protects against double spending by verifying each transaction added and ensuring that the inputs for the transaction had not previously already been spent</li> <li>Need to have just one valid blockchain, always growing with all accepted transactions, and validated by means of consensus</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#consensus","title":"Consensus","text":"<p>Can we use Paxos?</p> <ul> <li>As soon as you provide me services, I create 1,000,000 fake ids (Sybil attack) and I distribute the second blockchain</li> <li>It has consensus! I can double spend my $$$!!</li> <li>The problem is that creating new identities is cheap</li> </ul> <p>Let us do something that is not so cheap</p>"},{"location":"7-semester/DS/10-blockchain/#a-blockchain-transaction","title":"A Blockchain Transaction","text":"<ul> <li>Make step (4) expensive!<ul> <li>Slow</li> <li>Lot of computation</li> <li>High computation time</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#nakamoto-consensus","title":"Nakamoto Consensus","text":"<p>YouTube video about Nakamoto Consensus</p> <p>Let us decide that all the nodes send to each other the blockchain</p> <p></p> <ul> <li>But a fork is natural in distributed systems!</li> </ul> <p>The rule: The longest blockchain has consensus!</p> <ul> <li>I consider that<ul> <li>adding a block is computationally expensive</li> <li>most nodes are honest</li> </ul> </li> <li>If I receive a blockchain that is shorter than mine, I ignore it<ul> <li>It was created later than mine</li> <li>It can be out of sync</li> </ul> </li> </ul> <p></p> <p>A transaction is \u201caccepted\u201d if it is buried deep enough</p> <p></p> <ul> <li>If I see a longer blockchain, I embrace it, and try to add my blocks to it.</li> <li>Statistically, the accepted transaction will not be eaten by a newer (shorter) transaction<ul> <li>All transactions added in the blocks are immutable</li> <li>e,.g.: no double spending</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#how-to-make-adding-a-block-expensive","title":"How to Make Adding a Block Expensive","text":"<p>Proof of Stake </p> <ul> <li>For a later class</li> </ul> <p>Proof of Work</p> <ul> <li>Provide a computational (hashing) puzzle that is<ul> <li>hard to solve when you want to add a valid block</li> <li>easy to solve when you want to verify that a block is valid</li> </ul> </li> <li>All the nodes working actively to support the blockchain (miners, more on this later) take e.g.: 7 seconds to add a block<ul> <li>You cannot start working on your fork before a transaction is accepted, which implies adding N blocks</li> <li>Your malicious computers will not be able to redo the work on your fork (adding N+1 blocks) faster than all other miners add blocks</li> </ul> </li> </ul> <p>We still have to specify 2 things</p> <ul> <li>The proof of work puzzle</li> <li>What is inside this immutable transaction data structure</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#the-puzzle","title":"The Puzzle","text":"<ul> <li>I insert a nonce in the header<ul> <li>It has to be hashed together with the rest of the header</li> </ul> </li> <li>The nonce is good when H(header) starts with n zeros<ul> <li>Need to select nonces at random until one fits the puzzle</li> <li>n defines how hard it is to add a new block</li> </ul> </li> <li>We use SHA256, I give you challenge n = 36<ul> <li>Each nonce has prob 2^{-36}2^{-36} of success</li> <li>When you succeed, only takes me one hash to check</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#the-transaction","title":"The Transaction","text":"<ul> <li>\u201cUser P1 transfers 200$ to User P2\u201d</li> <li>I can go back one (or more) blocks to verify that User P1 owned the money</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#summary","title":"Summary","text":""},{"location":"7-semester/DS/10-blockchain/#transactions","title":"Transactions","text":"<p>Are you really happy with the description of the data structures and algorithms?</p> <ul> <li>User P1?</li> <li>Verification of transactions?</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#user","title":"User","text":"<ul> <li>A user is somebody who can transfer money<ul> <li>A wallet, a user\u2019s identity, a pair (sk : private key, pk : public key)</li> </ul> </li> <li>Transaction: ([input transactions], [output identity pk, how much], signature)<ul> <li>The input transactions refer to previous transactions that transferred money to the user</li> <li>It specifies to whom transfer each fraction of the money, by means of users\u2019 public keys</li> <li>It signs the transaction with its private key</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#transactions_1","title":"Transactions","text":"<p> Short YouTube video about transactions</p> <p></p>"},{"location":"7-semester/DS/10-blockchain/#characteristics-of-the-transaction","title":"Characteristics of the Transaction","text":"<ul> <li>Since it is signed with the private key, only the owner of the identity can transfer (spend) that money<ul> <li>If it points to input transactions from different identities p1 \u2026 pk, it will sign the transaction with all the s1 \u2026 sk to prove it owns the money</li> </ul> </li> <li>All money from input transactions must be used<ul> <li>But part of the money can be transferred to the same user</li> <li>Or another public key of the same user \u2013 for privacy</li> </ul> </li> <li>Privacy: a real-life user can create one identity (sk,pk) each time it wants to receive money</li> <li>When transaction is signed it is propagated to the nodes on the network<ul> <li>It is saved in the mempool</li> </ul> </li> <li>When the transaction is added to a block onto the blockchain it is confirmed<ul> <li>1 level of confirmation per block above it</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#more-general-case-scripts","title":"More General Case - Scripts","text":""},{"location":"7-semester/DS/10-blockchain/#general-output-of-a-transaction","title":"General Output of a Transaction","text":"<ul> <li>It contains a challenge script (also called locking script or scriptPubKey) with:<ul> <li>the spending conditions under which the bitcoins associated can be spent</li> </ul> </li> </ul> <p>Usually, it requires just a valid signature. Other cases:</p> <ul> <li>It can be a script, encoded in a non-Turing complete language<ul> <li>To protect miners against DOS attacks (<code>while true {}</code>)</li> </ul> </li> <li>An m-of-n multisignature challenge script</li> <li>Temporal parameters for automatic billing over time</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#transactions-in-a-block","title":"Transactions in a Block","text":"<ul> <li>Transactions are received continuously by nodes looking to solve the puzzle</li> <li>Organized into a Merkle tree</li> <li>Root hash is part of the new block header, thus it is part of next block\u2019s hash</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#why-the-merkle-tree","title":"Why the Merkle Tree?","text":"<ul> <li>The Merkle tree can be computed as transactions are received<ul> <li>No need to recompute the hash of all the transactions after one is received</li> </ul> </li> <li>Need to have always the data of the block of the blockchain</li> <li>Anyway, possible to discard branches of the Merkle tree when all its money is spent, and keep the hash only on the disk</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#how-does-everything-add-up","title":"How Does Everything Add Up?","text":"<p>A miner will:</p> <ul> <li>Verify all the transactions by looking that input transactions are covered and properly signed</li> <li>Compute the Merkle root hash for the transactions</li> <li>Solve the puzzle on the previous block, for immutability</li> <li>Broadcast the new header</li> <li>Go on collecting new transactions for next block</li> </ul> <p></p>"},{"location":"7-semester/DS/10-blockchain/#why-be-a-miner","title":"Why Be a Miner?","text":"<ul> <li>Incentives: every new block that gets accepted provides a number of bitcoins by default to the miner who found the nonce</li> <li>Fees: for each transaction, some difference between input and output, and the difference is paid to the miner</li> <li>Anyway, what a waste!<ul> <li>Bitcoin blockchain network\u2019s miners are attempting 450 thousand trillion solutions per second in efforts to validate transactions</li> <li>Vast amounts of energy necessary to process and store transactions</li> <li>Wasted resources: energy for $15million/day</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#beyond-bitcoin","title":"Beyond Bitcoin","text":"<ul> <li>The challenge scripts could do much more than in Bitcoin</li> <li>Smart Contracts: Computer protocols that facilitate, verify, or enforce the negotiation or performance of a contract, or that make a contractual clause unnecessary</li> <li>Define the rules and penalties around an agreement in the same way that a traditional contract does, but also automatically enforce those obligations (code is law</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#ethereum","title":"Ethereum","text":""},{"location":"7-semester/DS/10-blockchain/#turing-complete-contracts-on-a-blockchain","title":"Turing Complete Contracts on a Blockchain","text":"<ul> <li>Contracts are the main building blocks of Ethereum, the second most popular blockchain</li> <li>A contract is a computer program that lives inside the distributed Ethereum network and has its own ether balance of Ether (Ethereum\u2019s cryptocurrency / cryptofuel), memory and code.</li> <li>Every time you send a transaction to a contract, it executes its code, which can store data, send transactions and interact with other contracts.</li> </ul>"},{"location":"7-semester/DS/10-blockchain/#like-a-jukebox","title":"Like a Jukebox","text":"<ul> <li> <p>Can be activated and run, by funding it with some Ether</p> <ul> <li>to run, create a transaction sending a payment of ETH to the contract, and possibly supplying some other input information</li> <li>the contract runs at most for a time dependent on how much gas (1 ETH = many many gas units) you paid</li> <li>ETH fees are for the winning miner</li> </ul> </li> <li> <p>Each miner runs the smart contract, and produces same output</p> <ul> <li>winning miner will publish the block to the rest of the network</li> <li>other miners validate that they get the same result</li> </ul> </li> </ul>"},{"location":"7-semester/DS/10-blockchain/#summary_1","title":"Summary","text":""},{"location":"7-semester/DS/10-blockchain/#five-point-test","title":"Five Point Test","text":"<p>Is blockchain for everything? </p> <ul> <li>No!</li> </ul> <p></p>"},{"location":"7-semester/DS/11-big-data-analytics/","title":"Big Data Analytics","text":"<p>With a focus on Google</p>"},{"location":"7-semester/DS/11-big-data-analytics/#big-data","title":"Big Data","text":"<p>International Data Corporation:</p> <ul> <li>In 2011, 1.8 ZB of data produced (~ 10^21^ B)</li> <li>Number likely to double every 2 year</li> </ul> <p>In contrast to traditional data:</p> <ul> <li>Data sets are often less structured (not perfectly suited for traditional data bases)</li> <li>Data require more real-time analysis</li> </ul> <p>Examples</p> <ul> <li>Google processes Petabytes of data each year</li> <li>Facebook generates logs of 10 PB per month</li> <li>Alibaba generates 10s of TB trading data per day, </li> <li>72h new YouTube content per min!</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#the-4-vs","title":"The 4 Vs","text":"<ul> <li>Volume: the large scale of data collection and processing</li> <li>Velocity: timeliness of data and analysis</li> <li>Variety: different types of data, semi-structured and unstructured (e.g., text)</li> <li>Value: huge value but low density</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#examples","title":"Examples","text":"<ul> <li>Social Media and web<ul> <li>Facebook: pictures, movies, status-updates,..</li> <li>YouTube: Videos</li> <li>Google Analytics: \u201duser clicks\u201d</li> </ul> </li> <li>Enterprise <ul> <li>Trading and product data</li> <li>Parts tracking </li> <li>Log data</li> </ul> </li> <li>Internet of things<ul> <li>today small, but expected that by 2030 the largest set (1 trillion sensors)</li> <li>smart cities based on IoT, agriculture, transportation, medical data\u2026</li> <li>sensing: either simple numerical data or multimedia (surveillance stream) </li> </ul> </li> <li>Bio-medical data<ul> <li>gene sequencing and gene diagnosis</li> <li>China national genebank: over 1 mio humans, animals and plants</li> <li>US gene bank: over 150,000 different organisms</li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#key-challenges","title":"Key Challenges","text":"<ul> <li>Data representation<ul> <li>heterogeneity in type, structure, semantics, organization, granularity, and accessibility, \u2026</li> </ul> </li> <li>Compression<ul> <li>For example, most data generated by sensor networks are highly redundant, which may be filtered and compressed at orders</li> </ul> </li> <li>Data life cycle management<ul> <li>Often only little data is relevant: which data shall be stored and which data shall be discarded</li> </ul> </li> <li>Analytical mechanism<ul> <li>Traditional RDBMSs are often not scalable and flexible</li> <li>Non-relational databases are becoming popular for processing unstructured data</li> <li>New Computation models </li> </ul> </li> <li>Privacy<ul> <li>Remove sensitive data before delivering to third party for processing</li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#new-storage-mechanisms","title":"New Storage Mechanisms","text":"<p>File systems</p> <ul> <li>E.g., Google File System (GFS): not efficient for small files (Colossus solves some of these issues)</li> <li>Derived from GFS: Hadoop Distributed File System (HDFS) for map/reduce data</li> </ul> <p>Databases</p> <ul> <li>Traditional databases do not sufficiently scale for big data and cannot deal with less structured data</li> <li>Popular paradigm NoSQL: provides eventual consistency only, much simpler and more flexible than traditional databases</li> <li>Popular non-SQL databases, e.g.:<ul> <li>Key-Value Stores: <ul> <li>Amazon Dynamo, <ul> <li>Memcachd, etc.: often based on consistent hashing (\u201c1-hop DHT\u201d)</li> </ul> </li> </ul> </li> <li>Column-oriented Databases: <ul> <li>like Google BigTable: both columns and rows can be segmented into multiple nodes, </li> <li>Cassandra, </li> <li>\u2026</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#new-programming-models","title":"New Programming Models","text":"<p>Map Reduce</p> <ul> <li>Two user defined functions (2 phases)</li> <li>Map<ul> <li>given key-value pairs, produce intermediate key-value pairs</li> <li>Combine all values of the same key and send it to reducer</li> </ul> </li> <li>Reduce: <ul> <li>further compress the value set of the same key</li> </ul> </li> </ul> <p>Pregel</p> <ul> <li>System by Google to process and analyze large graphs</li> <li>Executions in super-steps: In every superstep, vertex computations are parallel, and every vertex executes the same user-defined function to express a given algorithm logic</li> <li>Between super-steps, nodes can communicate (e.g., with neighbors)</li> <li>When all nodes inactive: done</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#zoo-of-data-analysis-tools-and-models-layered-architecture","title":"Zoo of data analysis tools and models - Layered Architecture","text":"<ul> <li>NA - Non Apache projects</li> <li>Green layers are Apache/Commercial Cloud (light) to HPC (darker) integration layers</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#map-reduce","title":"Map-Reduce","text":"<p>Programming model for processing of large data sets</p> <p>Used at Google: data mining on BigTable, graph algorithms (pagerank), indices, etc.</p> <ul> <li>Processes 20 pB/day</li> </ul> <p>Open-source implementations widely used! </p> <ul> <li>Apache Hadoop: Yahoo, Facebook, Amazon, \u2026</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#computation-need-pagerank","title":"Computation Need - PageRank","text":"<ul> <li>PageRank algorithm outputs a probability distribution that represent the likelihood that a person randomly clicking on links will arrive at any particular page.</li> <li>Initial Probability distribution: 1/N</li> <li>A nodes probability is divided among links<ul> <li>D gives 25%/3 to each of A, B, C. </li> <li>A receives 25%/1 from B, 25%/2 from C, 25%/3 from D: Pr(A)=0.458</li> </ul> </li> <li>Page rank model<ul> <li>A virtual surfer continues with a probability (damping factor) d (typically=85%)</li> <li>Picks another random page with 1-d (=15%)<ul> <li>PR(p_i) = \\frac {1-d} N + d\\ \\sum_{p_j \\in M(p_i)} \\frac {PR(p_j)} {L(p_j)}</li> </ul> </li> </ul> </li> <li>May be computed iteratively until convergence</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#mapreduce","title":"MapReduce","text":"<ul> <li>Massive parallel and distributed processing on clusters</li> <li>Inspired by functional programming</li> <li>Several frameworks and libraries that handle for you<ul> <li>Data transfer</li> <li>Distributing the load in the cluster</li> <li>Failure handling</li> <li>...</li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#idea","title":"Idea","text":"<p>Two functions</p> <ul> <li>Map: <ul> <li></li> <li>takes input data and produces (key,value) pairs<ul> <li>(k1, v1) \\to\\to list of (k2, v2)</li> </ul> </li> <li>Combine all values of the same key and send them to reducer in charge of this key (Shuffle)</li> </ul> </li> <li>Reduce<ul> <li></li> <li>takes all values with the same key and produces result<ul> <li>(k2, list(v2)) \\to\\to v3</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#classic-example-word-count","title":"Classic Example - Word Count","text":"<pre><code>map(String key, String value):\n    // key: document name\n    // value: document contents\n  for each word w in value:\n    EmitIntermediate(w, \"1\")\n\n\nreduce(String key, Iterator values):\n    // key: a word\n    // values: list of counts\n    int result = 0\n    for each v in values:\n        result += ParseInt(v)\n  Emit(key, AsString(result))\n</code></pre> <p>(*) beware: Commutative and Associative Operations</p> <ul> <li>Different reducers in charge of different keys/words.</li> <li>If same word multiple times in same document, mapper could in principle pre-aggregate those.</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#document-indexing","title":"Document Indexing","text":"<ul> <li>Input:  Set of documents D_1,\\dots, D_ND_1,\\dots, D_N</li> <li>Map<ul> <li>Parse document DD into terms T_1, \\dots, T_NT_1, \\dots, T_N</li> <li>Produces (key, value) pairs<ul> <li>(T_1, D), \\dots, (T_N, D)(T_1, D), \\dots, (T_N, D)</li> </ul> </li> </ul> </li> <li>Reduce<ul> <li>Receives list of (key, value) pairs for term TT<ul> <li>(T, D_1), \\dots , (T, D_N)(T, D_1), \\dots , (T, D_N)</li> </ul> </li> <li>Emits single (key, value) pair<ul> <li>(T, (D_1, \\dots, D_N))(T, (D_1, \\dots, D_N))</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#google-maps","title":"Google Maps","text":""},{"location":"7-semester/DS/11-big-data-analytics/#mapreduce-execution","title":"MapReduce Execution","text":"<ul> <li>One worker is the master<ul> <li>It assigns map &amp; reduce jobs to the other workers</li> <li>It stores the state of each map &amp; reduce job<ul> <li>(idle,in-progress,completed) and </li> <li>the identify of all non-idle machines</li> </ul> </li> <li>It stores the locations of the output files of the map &amp; reduce tasks</li> </ul> </li> </ul> <ul> <li>MapReduce library in user program first splits input files into pieces (~16-64MB per piece).</li> <li>Then starts up many copies of the program on cluster of machines: M map tasks, R reduce tasks, and one Master (not a worker)</li> <li>Master assigns work: picks idle workers and assigns each one a map or a reduce task.</li> <li>Mappers read input, parse key/value pairs, and passes them to user-defined map function. The intermediate key/value pairs are buffered in memory, and periodically written to local disk. </li> <li>The locations of these buffered pairs on the local disk are passed back to the master who responsible for forwarding these locations to the reduce workers.</li> <li>Reducer notified by master about key-value pair locations, uses remote procedure calls to read the buffered data from the mappers\u2019 local disks. Then sorts and groups same keys. If the amount of intermediate data is too large to fit in memory, an external sort is used.</li> <li>The reducer passes the values to the user\u2019s reduce function. The output of the reduce function is appended to a final output file for this reduce partition.</li> <li>When all map and reduce tasks have completed, the master wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code.</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Locality<ul> <li>Worker should be close to the GFS replica storing the data</li> <li></li> </ul> </li> <li>Task Granularity<ul> <li>Number of maps and reduces &gt;&gt; number of workers: <ul> <li>better load balancing, but more overhead and state info at master</li> </ul> </li> <li>E.g., M=200000, R=5000, W=2000</li> </ul> </li> <li>Stragglers<ul> <li>In large systems, nearly always some worker is slow</li> <li>Schedule backup executions of remaining in-progress tasks when a phase nears completion</li> </ul> </li> <li>User defined partitioning function</li> <li> <p>Combiners: local reduce directly after map phase</p> </li> <li> <p>Barrier synchronization / pipelining</p> <ul> <li>Can we start reducing while still mapping? </li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/11-big-data-analytics/#failure-handling","title":"Failure Handling","text":"<ul> <li>Worker Failures<ul> <li>Master periodically pings workers</li> <li>Re-execution (map and reduce op\u2019s are normally deterministic functions)</li> </ul> </li> <li>Master Failure<ul> <li>Terminate whole job</li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#effect-on-performance-stragglers-and-worker-failures","title":"Effect on Performance - Stragglers and Worker Failures","text":""},{"location":"7-semester/DS/11-big-data-analytics/#hadoop-word-count-example","title":"Hadoop - Word Count Example","text":"<pre><code>public class WordCount {\n// map &amp; reduce are implemented as classes\npublic static class Map extends MapReduceBase implements Mapper&lt;LongWritable,Text,Text,IntWritable&gt; {\nprivate final static IntWritable one = new IntWriteable(1);\nprivate Text word = new Text();\n\npublic void map(\nLongWritable key, Text value, OutputCollector&lt;Text,IntWritable&gt; output, Reporter reporter\n) throws IOException {\n\nString line = value.toString();\nStringTokenizer tokenizer = new StringTokenizer(line);\nwhile(tokenizer.hasMoreTokens()) {\nword.set(tokenizer.nextToken());\noutput.collect(word, one);\n}\n}\n}\n\npublic static Reduce extends MapReduceBase implements Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {\npublic void reduce(\nText key,\nIterator&lt;IntWritable&gt; values,\nOutputCollector&lt;Text, IntWritable&gt; output,\nReporter reporter\n) throws IOException {\n\nint sum = 0;\nwhile(values.hasNext()) {\nsum += values.next().get();\noutput.collect(key, new IntWritable(sum))\n}\n}\n}\n\npublic static void main(String[] args) throws Exception {\nJobConf conf = new JobConf(WordCount.class);\nconf.setJobName(\"wordcount\");\nconf.setOutputKeyClass(Text.class);\n// configure map and reduce for this job\nconf.setMapperClass(Map.class);\nconf.setCombinerClass(Reduce.class);\nconf.setReducerClass(Reduce.class);\n\nconf.setInputFormat(TextInputFormat.class);\nconf.setOutputFormat(TextOutputFormat.class);\nconf.setInputPath(new Path(args[0]));\nconf.setOutputPath(new Path(args[1]));\n\nJobClient.runJob(conf);\n}\n}\n</code></pre> <ul> <li>This code can be run locally or in a fully-distributed Hadoop installation!</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#overall-execution-of-a-sawzall-program","title":"Overall Execution of a Sawzall Program","text":""},{"location":"7-semester/DS/11-big-data-analytics/#conclusion","title":"Conclusion","text":"<ul> <li>Map Reduce widely used in cloud computing environments!<ul> <li>\\Rightarrow\\Rightarrow Open Source implementations available</li> </ul> </li> <li>E.g., Apache Hadoop<ul> <li>Map/reduce for clusters of commodity HW</li> <li>Main contributor (Yahoo)</li> <li>Used at Yahoo, Facebook, NY Times, Amazon<ul> <li>Serialization, RPC, HDFS, \u2026</li> <li>Packaged in various \u201cEnterprise Solutions\u201d <ul> <li>Yahoo, Cloudera, AWS Elastic MapReduce, SUN, IBM,..</li> </ul> </li> </ul> </li> </ul> </li> <li>Some new research in generalized or tuned frameworks</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#spark","title":"Spark","text":"<p>Map Reduce:</p> <ul> <li>let programmers write parallel computations using a set of high-level operators</li> <li>without having to worry about work distribution and fault tolerance</li> </ul> <p>However: no abstractions of distributed memory</p> <ul> <li>inefficient for an important class of emerging applications which reuse intermediate results across multiple computations</li> </ul> <p></p> <ul> <li> <p>Overhead in data replication ,disk I/O, serialization, ...</p> </li> <li> <p>Data reuse important: </p> <ul> <li>in iterative machine learning and graph algorithms, e.g., PageRank, K-means clustering, regression</li> <li>and interactive data mining: <ul> <li>user runs multiple adhoc queries on the same subset of data</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#rdd","title":"RDD","text":"<p>Spark relies on a new abstraction: resilient distributed datasets (RDDs)</p> <ul> <li>Immutable, partitioned collections of records (normally in RAM)</li> <li>are fault-tolerant, parallel data structures</li> <li>enable efficient data reuse in a broad range of applications</li> <li>that let users<ul> <li>explicitly persist intermediate results in memory,</li> <li>control their partitioning to optimize data placement, and</li> <li>manipulate them using a rich set of operators</li> </ul> </li> </ul> <p></p> <p>RDDs provide an interface for coarse-grained transformations</p> <ul> <li>e.g., map, filter and join</li> <li>can be applied to many data items simultaneously</li> </ul> <p>A program performs a series of transformations</p> <pre><code>lines = spark.textFile(\"hdfs://...\") \nerrors = lines.filter(_.startsWith(\"ERROR\")) \nerrors.persist() \nerrors.filter(_.contains(\"Foo\")).count() \nerrors.filter(_.contains(\"Bar\")).count()\n</code></pre> <ul> <li> <p>A program performs a series of (lazy) transformations, each resulting in a new RDD</p> </li> <li> <p>Action: launch computation and returns a value (e.g count)</p> </li> </ul> <p></p> <ul> <li> <p>An RDD does not have to be materialized all the time: </p> <ul> <li>rather, we store the \u201elineage\u201c, information about how it was derived from other datasets (operations on RDDs).</li> <li>Storing the \"lineage\" enables efficient fault tolerance:<ul> <li>if a partition of an RDD is lost, the RDD has enough information about how it was derived from other RDDs to re-compute it</li> </ul> </li> </ul> </li> <li> <p>When a partition is lost: RECOMPUTE</p> </li> </ul> <p></p> <ul> <li>Up to 20x faster than MapReduce!</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#rdd-dependencies","title":"RDD Dependencies","text":"<ul> <li>Narrow Dependencies: <ul> <li>each partition of the parent RDD is used by at most one partition of the child RDD<ul> <li>map, filter, union, etc</li> </ul> </li> </ul> </li> <li>Wide dependencies: <ul> <li>multiple child partitions may depend on a parent (may require a shuffle of keys)<ul> <li>groupByKey, reduce, etc.</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#rdd-execution-model","title":"RDD Execution Model","text":"<p>The scheduler launches tasks to compute missing partitions from each stage until it has computed the target RDD</p> <p></p>"},{"location":"7-semester/DS/11-big-data-analytics/#pregel","title":"Pregel","text":"<ul> <li>Like Spark: keeps intermediate results in memory</li> <li>However, more specific than Spark: tailored to graph computations<ul> <li>Scale: billions of vertices, trillions of edges</li> </ul> </li> <li>Computational model: Vertex-centric<ul> <li>Typically (number of vertices) &gt;&gt; (number of servers)<ul> <li>good for load-balancing, and exploiting locality!</li> </ul> </li> <li>Programs are expressed as a sequence of iterations, in each of which a vertex (Super-steps)<ul> <li>can receive messages sent in the previous iteration,</li> <li>send messages to other vertices,</li> <li>and modify its own state,</li> <li>mutate graph topology.</li> </ul> </li> </ul> </li> </ul> <p>Vertex-centric and message-passing model often a better fit for graph algorithms than Map Reduce, e.g., shortest path computations, Page Rank, \u2026!</p>"},{"location":"7-semester/DS/11-big-data-analytics/#pregel-vertex-state-machine","title":"Pregel Vertex State-machine","text":"<ul> <li>Algorithm termination is based on every vertex voting to halt<ul> <li>In super-step 0, every vertex is in the active state</li> <li>A vertex deactivates itself by voting to halt</li> <li>A message may re-activate a vertex</li> </ul> </li> </ul> <ul> <li>The algorithm as a whole terminates when all vertices are simultaneously inactive and there are no messages in transit</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#example-compute-maximum","title":"Example - Compute Maximum","text":"<ul> <li>In each super-step, any vertex that has learned a larger value from its messages sends it to all its neighbors.</li> <li>When no further vertices change in a super-step, the algorithm terminates.</li> </ul>"},{"location":"7-semester/DS/11-big-data-analytics/#implementation","title":"Implementation","text":"<ul> <li>Master-worker model<ul> <li>Executed on Google\u2019s clusters</li> <li>Persistent data on GFS or BigTable</li> </ul> </li> <li>Master<ul> <li>Monitors workers</li> <li>Partitions graph vertices to workers: eg<ul> <li><code>Hash(VertedID) % NoPartitions -&gt; PartitionID</code></li> </ul> </li> <li>More partitions per worker to balance load</li> </ul> </li> <li>Worker<ul> <li>Execute <code>compute()</code> when starting a super-step</li> <li>Buffer outgoing messages per destination worker<ul> <li>Flush&amp;Send when full, or at the end of super-step</li> </ul> </li> <li>Report number of active vertices to master at end of every super-step.</li> </ul> </li> <li>Fault-tolerance through checkpointing at every super-step</li> </ul>"},{"location":"7-semester/DS/12-soa/","title":"Service-oriented Architectures","text":"<p>SOA is a set of principles for the design, deployment and management of both applications and software infrastructure using sets of loosely coupled services that can be dynamically discovered and then communicate with each other or are coordinated through choreography to provide enhanced services</p> <p>Services become building blocks that form business flows</p> <ul> <li>Gartner 18 July 2006: SOA is entering the \u201ctrough of disillusionment\u201d</li> </ul> <p>Many different definitions</p> <ul> <li>Bad definition based on the technology used, since the principle is not just for \u201cweb-services\u201d</li> </ul> <p>Possible definitions: A service is:</p> <ul> <li>a discrete business function that operates on data</li> <li>a reusable component that can be used as a building block to form larger, more complex business-application functionality</li> </ul>"},{"location":"7-semester/DS/12-soa/#how-services-encapsulate-logic","title":"How Services Encapsulate Logic","text":""},{"location":"7-semester/DS/12-soa/#soa-manifesto","title":"SOA Manifesto","text":"<p>Made October, 2009.</p> <ul> <li>Business value is given more importance than technical strategy</li> <li>Strategic goals are given more importance than project-specific benefits</li> <li>Intrinsic inter-operability is given more importance than custom integration</li> <li>Shared services are given more importance than specific-purpose implementations</li> <li>Flexibility is given more importance than optimization</li> <li>Evolutionary refinement is given more importance than pursuit of initial perfection</li> </ul>"},{"location":"7-semester/DS/12-soa/#properties-of-services","title":"Properties of Services","text":"<p>Four properties of a service:</p> <ul> <li>It is a black box for its consumers<ul> <li>A service presents a simple interface articulated in endpoints to the requester that abstracts away the underlying complexity</li> <li>The SOA infrastructure will provide standardized access mechanisms to discover services with service-level agreements</li> </ul> </li> <li>It is self-contained (loose-coupling between services)<ul> <li>The consumer of the service is required to provide only the data stated on the interface definition, and to expect only the results specified on the interface definition</li> <li>In the context of web services, loose coupling refers to minimizing the dependencies between services in order to have a flexible underlying architecture (reducing the risk that a change in one service will have a knock-on effect on other services)</li> </ul> </li> <li>It may consist of other underlying services<ul> <li>It allow users to combine and reuse them in the production of applications</li> <li>It should be based on open standards. Open standards ensure the broadest integration compatibility opportunities</li> </ul> </li> <li>It should be stateless<ul> <li>The service does not maintain state between invocations</li> <li>If a transaction is involved, the transaction is committed and the data is saved somewhere<ul> <li>The id of the transaction can provide context (sessions)</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#what-can-we-do-with-services","title":"What can we do with services?","text":"<ul> <li>Multiple services can be composed (orchestrated) to provide the functionality of a large software application<ul> <li>Services must communicate with each other by passing data in a well-defined, shared format, or by coordinating an activity between two or more services</li> <li>Thus, need for protocols that describe how they pass and parse messages using description metadata (for both functional and nonfunctional requirements such as QoS)</li> </ul> </li> <li>Facilitated by technologies and standards that facilitate components' communication and cooperation over a network</li> </ul>"},{"location":"7-semester/DS/12-soa/#innovation","title":"Innovation","text":"<p>Service Oriented Computing</p> <p>The major innovation in SOC is the move from the object oriented paradigm to a service oriented one</p> <ul> <li>Object Oriented:<ul> <li>Object: stateful</li> </ul> </li> <li>Service Oriented:<ul> <li>Service: stateless</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#object-oriented-vs-service-oriented","title":"Object Oriented vs Service Oriented","text":"Features Object-oriented computing Service-oriented computing Methodology Application development by identifying tightly coupled classes. Application architecture is hierarchical based on the inheritance relationships. Application development by identifying loosely coupled services and composing them into executable applications. Level of abstraction and cooperation Application development is often delegated to a single team responsible for the entire life cycle of the application. Developers must have knowledge of application domain and programming. Development is delegated to three independent parties: application builder, service provider, and service broker. Application builders need to understand application logic and may not know how individual services are implemented. Service providers can program but do not have to understand the applications that use their services. Code sharing and reuse Code reuse through inheritance of class members and through library functions. Library functions have to be imported at compilation time and are platform dependent. Code reuse at the service level. Services have standard interfaces and are published on Internet repository. They are platform-independent and can be searched and remotely accessed. Service brokerage enables systematic sharing of services. Dynamic binding and recomposition Associating a name to a method at runtime. The method must have been linked to the executable code before the application is deployed. Binding a service request to a service at runtime. The services can be discovered after the application has been deployed. This feature allows an application to be recomposed at runtime. System maintenance Users need to upgrade their software regularly. The application has to be stopped to perform the upgrading. The service code resides on service providers' computers. Services can be updated without users' involvement."},{"location":"7-semester/DS/12-soa/#design-patterns","title":"Design Patterns","text":"<p>3 main roles:</p> <ul> <li>Service provider / publisher<ul> <li>Offers the service, registers it in the service broker for consumers to find</li> </ul> </li> <li>Service consumer<ul> <li>Retrieves service providers from service broker, then uses the services</li> </ul> </li> <li>Service broker / registry / repository</li> </ul> <p></p>"},{"location":"7-semester/DS/12-soa/#interoperability","title":"Interoperability","text":"<ul> <li> <p>Formal interfaces and/or contracts (e.g.: WSDL)</p> <ul> <li>Describe the interaction protocol</li> <li>Platform-independent, programming language-independent</li> </ul> </li> <li> <p>High-level programming languages (for orchestration, e.g.: BPEL) and specifications (for choreography, e.g.: WS-CDL, WSCoordination) to support the cooperation of fine-grained services into more coarse-grained business services</p> <ul> <li>Also to incorporate into workflows and business processes</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#choreography","title":"Choreography","text":"<ul> <li>Service composition where the interaction is specified from a global perspective, to describe a set of interactions, showing the behavior of each member of a set of participants</li> <li>For example: it might specify constraints on the order and the conditions in which messages are exchanged by participants</li> <li>Difference with orchestration: it is performed by the services itself<ul> <li>Orchestration is centralized</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#solid-principles","title":"SOLID Principles","text":"<p>(OOP, etc)</p> <ul> <li>Single-responsibility Principle: each component should do just one job</li> <li>Open/Closed Principle: your component should be open for extension but closed for modification</li> <li>Liskov Substitution Principle<ul> <li>if q(x) is a property provable about x of type T, q(y) should be provable for objects y of type S where S is a subtype of T</li> </ul> </li> <li>Interface Segregation Principle: clients should not be forced to depend upon interfaces that they do not use</li> <li>Dependency Inversion Principle: an interface is an abstraction between a higher and a lower level component<ul> <li>Abstractions should not depend on details. Details should depend upon abstractions</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#soa-and-solid","title":"SOA and SOLID","text":"<ul> <li>Single-responsibility Principle: each service should be specialized</li> <li>The Open/Closed Principle: service orchestration</li> <li>The Liskov Substitution Principle: clients consume services, which consume lower granularity services</li> <li>The Interface Segregation Principle: in place of using one fat service interface, we create multiple small services</li> <li>The Dependency Inversion Principle: you can replace interface implementations without changing the interface</li> </ul>"},{"location":"7-semester/DS/12-soa/#design-questions","title":"Design Questions","text":"<ul> <li>Service granularity: how do I decide how much functionality is offered by each service? Should I split it into 2 services?</li> <li>Service statelessness: how much state should I keep in the service provide<ul> <li>Since I have loose coupling, I will remove all info after service fruition</li> <li>Service session (a.k.a. consumer specific context) \u2013 but with which granularity?</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#enterprise-service-bus-esb","title":"Enterprise Service Bus - ESB","text":"<ul> <li>An infrastructure used for building compound applications</li> <li>In its simplest form:<ul> <li>An ESB delivers a message from one point to another</li> </ul> </li> <li>The ESB is a style for integrating enterprise applications in an implementation-independent fashion</li> <li>A binding component \u201cspeaks\u201d the service\u2019s protocol.</li> <li>The request gets \u201crouted\u201d to a service</li> <li>Same for intermediate (orchestrated) service requests</li> <li>\u2026 and \u2013 finally \u2013 back</li> </ul>"},{"location":"7-semester/DS/12-soa/#key-characteristics","title":"Key Characteristics","text":"<ul> <li> <p>Supports multiple binding strategies</p> </li> <li> <p>Performs data transformation</p> </li> <li> <p>Intelligent routing</p> </li> <li> <p>Real time monitoring</p> </li> <li> <p>Exception handling</p> </li> <li> <p>Service security</p> </li> <li> <p>Result:</p> <ul> <li>Loose coupling</li> <li>Location transparency</li> <li>Transport neutral</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#sample-esb","title":"Sample ESB","text":"<p>Features:</p> <ul> <li>Custom services</li> <li>Transformation services</li> <li>Orchestration</li> <li>Routing</li> <li>Application server</li> </ul> <p></p>"},{"location":"7-semester/DS/12-soa/#microservice-architecture-msa","title":"Microservice Architecture - MSA","text":"<ul> <li>MSA is a modern interpretation of SOA</li> <li>Services are still processes that communicate with each other over the network</li> <li>This style emphasizes continuous deployment and other agile practices</li> </ul>"},{"location":"7-semester/DS/12-soa/#soa-vs-msa","title":"SOA vs MSA","text":""},{"location":"7-semester/DS/12-soa/#principles","title":"Principles","text":"<p>MSA stresses more on:</p> <ul> <li>fine-grained interfaces (to independently deployable services),</li> <li>business-driven development (e.g. domain-driven design),</li> <li>services are autonomous,</li> <li>polyglot programming and persistence</li> <li>lightweight container deployment,</li> <li>decentralized continuous delivery.</li> </ul>"},{"location":"7-semester/DS/12-soa/#soa-service-types","title":"SOA Service Types","text":"<p>SOA provides 4 service types:</p> <ul> <li>Business Services:<ul> <li>Coarse-grained, define core business operations, use XML, BPEL, etc</li> </ul> </li> <li>Enterprise Services:<ul> <li>Implement the functionality defined by business services, using AS/IS</li> </ul> </li> <li>Application Services:<ul> <li>Fine-grained, confined to a specific application context.</li> </ul> </li> <li>Infrastructure Services:<ul> <li>Implement non-functional tasks such as authentication, auditing, security, and logging.</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#msa-service-types","title":"MSA Service Types","text":"<p>2 service types only:</p> <ul> <li>Functional Services:<ul> <li>Support specific business operations.</li> <li>Accessing of services is done externally and these services are not shared with other services.</li> </ul> </li> <li>Infrastructure services:<ul> <li>As in SOA, implement tasks such as auditing, security, and logging.</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#more-info","title":"More Info","text":"<p>Service Granularity:</p> <ul> <li>MSA: generally single-purpose services that do one thing really, really well</li> <li>SOA: service components can range in size. Coarse-grained to be useful to more applications</li> </ul> <p>Component Sharing:</p> <ul> <li>one of the core tenets of SOA.</li> <li>MSA tries to minimize on sharing through \u201cbounded context\u201d (coupling of a component and its data as a single unit with minimal dependencies)</li> </ul> <p>Middleware vs API layer:</p> <ul> <li>MSA provides an API layer</li> <li>SOA has a messaging middleware component (provides mediation and routing, message enhancement, message, and protocol transformation)</li> </ul> <p>Remote services:</p> <ul> <li>SOA architectures rely on messaging (AMQP, MSMQ)</li> <li>Most MSAs rely on two protocols \u2013 REST and simple messaging (JMS, MSMQ), and the protocol found in MSA is usually homogeneous.</li> </ul> <p>Heterogeneous interoperability:</p> <ul> <li>SOA promotes the propagation of multiple heterogeneous protocols through its messaging middleware component: to integrate several systems using different protocols in a heterogeneous environment</li> <li>MSA attempts to simplify the architecture pattern by reducing the number of choices for integration: all your services could be exposed and accessed through the same remote access protocol</li> </ul> SOA MSA Follows \u201cshare-as-much-as-possible\u201d architecture approach Follows \u201cshare-as-little-as-possible\u201d architecture approach Importance is on business functionality reuse Importance is on the concept of \u201cbounded context\u201d They have common governance and standards They focus on people, collaboration and freedom of other options Uses Enterprise Service bus (ESB) for communication Simple messaging system They support multiple message protocols They use lightweight protocols such as HTTP/REST etc. Multi-threaded with more overheads to handle I/O Single-threaded usually with the use of Event Loop features for non-locking I/O handling Maximizes application service reusability Focuses on decoupling Traditional Relational Databases are more often used Modern Relational Databases are more often used A systematic change requires modifying the monolith A systematic change is to create a new service DevOps / Continuous Delivery is becoming popular, but not yet mainstream Strong focus on DevOps / Continuous Delivery"},{"location":"7-semester/DS/12-soa/#bottom-line","title":"Bottom Line","text":"<ul> <li>SOA is better suited for large and complex business application environments that require integration with many heterogeneous applications using a middleware component</li> <li>Microservices are better suited for smaller and well-partitioned, web-based systems in which microservices give you much greater control as a developer</li> </ul>"},{"location":"7-semester/DS/12-soa/#technologies-for-soa","title":"Technologies for SOA","text":"<p>SOA/MSA can be implemented using many different technologies</p> <p>Common implementations:</p> <ul> <li>Web services based on WSDL and SOAP</li> <li>RESTful HTTP</li> <li>Messaging, e.g., with ActiveMQ, JMS, RabbitMQ</li> <li>OPC-UA</li> <li>RPC</li> <li>It can use more than 1 technology in one (orchestrated) service<ul> <li>Quite common with SOA, less common with MSA</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#uniform-resource-identifier-uri","title":"Uniform Resource Identifier - URI","text":"<ul> <li>URIs are a way to identify resources (and endpoints) on the Web, and other Internet resources such as electronic mailboxes</li> <li>URIs are \u2018uniform\u2019:<ul> <li>their syntax incorporates that of indefinitely many individual types of resource identifiers (that is, URI schemes), and</li> <li>there are procedures for managing the global namespace of schemes</li> </ul> </li> <li>Specializations: Uniform Resource Locator (URL), and Uniform Resource Name (URN)</li> </ul>"},{"location":"7-semester/DS/12-soa/#uniform-resource-locators-url","title":"Uniform Resource Locators - URL","text":"<ul> <li>Some URIs contain information that can be used to locate and access a resource</li> <li>Example of URL: http://www.aau.dk/<ul> <li>a web page at the given path (\u2018/\u2019) on the host www.aau.dk, and it is accessed using the HTTP protocol</li> </ul> </li> <li>Another example: mailto:mialb@cs.aau.dk<ul> <li>mailbox of user mialb at cs.aau.dk</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#uniform-resource-names-urn","title":"Uniform Resource Names - URN","text":"<ul> <li>URNs are URIs that are just pure resource names, with no locator</li> <li>URNs are not required to be associated with a particular protocol or access method, and need not be resolvable</li> <li>They are of the form <code>urn:nameSpace:nameSpace-specificName</code></li> <li>They still need to be unique and persistent<ul> <li>Most namespaces need a registration authority</li> </ul> </li> <li>Example: <code>urn:ISBN:0-201-62433-8</code><ul> <li>It is a International Standard Book Numbers identifying books that bear the name <code>0-201-62433-8</code></li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#web-service","title":"Web Service","text":"<ul> <li>HTTP request-reply protocol allows general-purpose clients (browsers)</li> <li>Web services return to a model in which an application-specific client interacts with a service with a functionally specialized interface over the Internet</li> <li>In its \u201cpure\u201d definition, a web service uses XML, SOAP, WSDL, UDDI, BPEL, \u2026<ul> <li>External data representation and marshalling of messages exchanged between clients and web services in XML</li> <li>The SOAP protocol specifies the rules for using XML to package messages, for example to support a request-reply protocol</li> </ul> </li> <li>Alternative: REST approach</li> </ul>"},{"location":"7-semester/DS/12-soa/#representational-state-transfer-rest","title":"Representational State Transfer - REST","text":"<ul> <li>REST is an approach to services with a very constrained style of operation, applying \u201cverbs\u201d to \u201cnouns\u201d<ul> <li>Nouns are the URLs that identify web resources</li> <li>Verbs are the HTTP operations GET, PUT, DELETE and POST (and lately PATCH) to manipulate resources</li> </ul> </li> <li>GET to retrieve the representation of a resource</li> <li>POST to add a new resource</li> <li>PUT to update the representation of a resource using a new one</li> <li>PATCH to change part of the representation of a resource</li> <li>DELETE to discard a resource</li> </ul>"},{"location":"7-semester/DS/12-soa/#tenets-of-rest","title":"Tenets of REST","text":"<ul> <li>Resources are identified by uniform resource identifiers (URIs)</li> <li>Resources are manipulated through their representations</li> <li>Messages are self-descriptive and stateless</li> <li>Multiple representations are accepted or sent</li> <li>Hypertext is the engine of application state</li> </ul>"},{"location":"7-semester/DS/12-soa/#rest-messages","title":"REST Messages","text":"<ul> <li>Like what we already know: HTTP, URIs, etc.</li> <li>REST can support any media type, but XML is expected to be the most popular transport for structured information.</li> <li>Unlike SOAP and XML-RPC, REST does not really require a new message format</li> </ul>"},{"location":"7-semester/DS/12-soa/#what-if-rest-is-not-enough","title":"What if REST is not enough?","text":"<ul> <li>What happens when you need application semantics that don't fit into the GET / PUT / POST / DELETE generic interfaces and representational state model?</li> <li>People tend to assume that the REST answer is:<ul> <li>If the problem doesn't fit HTTP, build another protocol</li> <li>Extend HTTP by adding new HTTP methods</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#but-in-fact","title":"But in fact:","text":"<ul> <li>There are no applications you can think of which cannot be made to fit into the GET / PUT / POST / DELETE resources / representations model of the world!</li> <li>These interfaces are sufficiently general</li> <li>Other interfaces considered harmful because they increase the costs of consuming particular services</li> </ul>"},{"location":"7-semester/DS/12-soa/#web-based-applications","title":"Web-based Applications","text":"<p>A Web-based application is a dynamically changing graph of</p> <ul> <li>possible states representations (pages)</li> <li>transitions (links) between states</li> </ul> <p>If it doesn\u2019t work like that, it may be accessible from the Web, but it\u2019s not really part of the Web</p>"},{"location":"7-semester/DS/12-soa/#two-kinds-of-state","title":"Two kinds of state","text":""},{"location":"7-semester/DS/12-soa/#application-state","title":"Application State","text":"<ul> <li>Application state is the information necessary to understand the context of an interaction<ul> <li>Authorization and authentication information are examples of application state</li> </ul> </li> <li>The \"stateless\" constraint means that all messages must include all application state as part of the content transferred from client to server back to client</li> </ul>"},{"location":"7-semester/DS/12-soa/#resource-state","title":"Resource State","text":"<p>Changes in resource state are unavoidable</p> <ul> <li>Someone has to POST new resources before others can GET them</li> </ul> <p>REST is about avoiding implicit or unnamed state; resource state is named by URIs</p>"},{"location":"7-semester/DS/12-soa/#sessions","title":"Sessions","text":"<ul> <li>Session state is also application state</li> <li>If you want a session, you need to move it back and forth between client and server</li> <li>A purchasing client could send a single HTTP request mentioning everything it wanted to purchase in one message</li> </ul>"},{"location":"7-semester/DS/12-soa/#the-purpose-of-statelessness","title":"The purpose of statelessness","text":"<ul> <li>Prevents partial failures</li> <li>Allows for substrate independence<ul> <li>Load-balancing</li> <li>Service interruptions</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#another-kind-of-state","title":"Another kind of state","text":"<ul> <li>Don\u2019t confuse REST state with state-machine state</li> <li>REST state is the representation of the values of the properties of a resource</li> <li>State machines fit into REST when the states are expressed as resources with links indicating transitions</li> </ul>"},{"location":"7-semester/DS/12-soa/#messaging","title":"Messaging","text":"<ul> <li>Until now, we have considered request / response protocols</li> <li>All requests were unicast, all responses were unicast, the identity of the server was explicit, the communication was synchronous</li> </ul>"},{"location":"7-semester/DS/12-soa/#publish-subscribe","title":"Publish Subscribe","text":"<ul> <li>The message is not sent to the recipient anymore, but instead to an entity hosted on a broker</li> <li>Example: Topic-oriented: the subscriber requests all messages related to a topic of interest<ul> <li>Subscriber sends a topic subscription to the broker</li> <li>Sender publishes (sends) a message on a topic rather than a destination</li> <li>The broker relays messages to the subscribers who subscribed to related topics</li> </ul> </li> <li>If a topic is popular, this approach implements one-to-many communication (multicast)</li> </ul>"},{"location":"7-semester/DS/12-soa/#message-oriented-middleware-for-soa","title":"Message Oriented Middleware for SOA","text":"<ul> <li>MOM is the plumbing for shipping messages between the services<ul> <li>SOA is all about using messages to connect services</li> </ul> </li> <li>Goals:<ul> <li>scalability,</li> <li>decoupling, and</li> <li>advanced communication semantics</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#scalability","title":"Scalability","text":"<ul> <li>MOM systems provide an abstraction over the identity of the subscribers (topics, etc)</li> <li>This disencumbers clients from maintaining a list of the peers that subscribed to their data</li> <li>This also allows for seamless<ul> <li>Elasticity (you can add service providers / consumers), and</li> <li>Load balancing (you can implement smart routing on the broker to split the burden)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#decoupling","title":"Decoupling","text":"<ul> <li>Space decoupling: the publisher and subscriber do not need to be aware of each other\u2019s location or identities</li> <li>Time decoupling: publisher and subscriber do not need to be online and actively collaborating in the interaction at the same time<ul> <li>Asynchronous and non-blocking message passing</li> </ul> </li> <li>Synchronization decoupling: allows asynchronous notification of subscribers by using event services callbacks</li> </ul>"},{"location":"7-semester/DS/12-soa/#advanced-communication-semantics","title":"Advanced communication semantics","text":"<ul> <li>Involves mechanisms to protect communication from message losses, message reordering of the messages caused by jitter and message duplication</li> <li>What: Usual semantics that can be requested (e.g.: by configuring the broker) are \u201cAt most once\u201d, \u201cAt least once\u201d, \u201cExactly once\u201d, \u201cIn-order delivery\u201d</li> <li>How: transport layer protocols, techniques that can merge messages (e.g., two data updates can become a single larger update in data-oriented middleware) and increase efficiency (e.g., by caching messages on intermediate servers for faster delivery when retransmission is requested)</li> </ul>"},{"location":"7-semester/DS/12-soa/#application-to-soa","title":"Application to SOA","text":"<ul> <li>By allowing a service consumer to ask for its request to be delivered to just one service provider, it is possible to let the broker decide which service provider will be used, implementing scalability, load balancing, robustness, elasticity</li> <li>By one-to-many communication, it is possible to ask to a number of service provider to act on a command, thus allowing to activate multiple service providers on the request</li> </ul>"},{"location":"7-semester/DS/12-soa/#smart-grids-encourage","title":"Smart grids - ENCOURAGE","text":"<ul> <li>Middleware for the \u201clast mile\u201d of the smart grid</li> <li>Data is collected from users\u2019 HAN, and brought up to modules in the cloud</li> <li>This lecture:<ul> <li>Middleware component</li> <li>Messaging infrastructure<ul> <li>AMQP</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#messaging-bus-configuration","title":"Messaging bus configuration","text":"<ul> <li>ENCOURAGE uses RabbitMQ messaging bus, which implements AMQP</li> <li>One of the many publish/subscribe middleware</li> </ul>"},{"location":"7-semester/DS/12-soa/#topology-of-the-exchanges-topics","title":"Topology of the exchanges / topics","text":""},{"location":"7-semester/DS/12-soa/#another-example-arrowhead","title":"Another Example - Arrowhead","text":"<ul> <li>Minimal ingredients:<ul> <li>A service producer</li> <li>A service consumer</li> <li>The Arrowhead Framework</li> </ul> </li> <li>The services are REST<ul> <li>Authorization for security</li> <li>Service Registry to make your service known</li> <li>Orchestrator to ask for service to consume</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#the-services-in-the-arrowhead-framework","title":"The services in the Arrowhead Framework","text":"<p>Service oriented approach supporting local cloud automation functionalities It offers a set of services that ease application development:</p> <ul> <li>Mandatory services:<ul> <li>Service Discovery;</li> <li>Orchestration;</li> <li>Authorization and Authentication</li> </ul> </li> <li>A set of optional support services:<ul> <li>QoS Manager</li> <li>Event Handler</li> <li>etc</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/12-soa/#tools-for-rest-services","title":"Tools for REST Services","text":""},{"location":"7-semester/DS/12-soa/#structure-of-a-rest-api","title":"Structure of a REST API","text":"<ul> <li>The service is provided at an URL</li> <li>The service allow access through a set of endpoints</li> <li>Each endpoint allows for REST verbs/operations (GET, POST, PUT, PATCH, DELETE)</li> <li>The input data can be JSON or XML</li> <li>The output is a HTTP status code, and sometimes data as JSON or XML</li> </ul>"},{"location":"7-semester/DS/12-soa/#openapi","title":"OpenAPI","text":"<p>OpenAPI Specification is an API description format for REST APIs, to describe:</p> <ul> <li>Available endpoints and operations on each endpoint</li> <li>Operation parameters Input and Output for each operation</li> <li>Authentication methods</li> <li>Contact information, license, terms of use and other information.</li> </ul> <p>An OpenAPI document itself is a JSON object, which may be represented and written either in JSON or YAML format</p> <p>We will use OpenAPI version 3 (the latest one)</p> <p>https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.3.md</p> <p>The OpenAPI document is composed by a number of parts</p> <p>Most important parts (except for the \u201cheaders\u201d <code>openapi</code>, <code>info</code> and <code>servers</code>):</p> <ul> <li><code>Paths</code></li> <li><code>Components</code></li> </ul>"},{"location":"7-semester/DS/12-soa/#paths","title":"Paths","text":"<ul> <li>A series of <code>path</code> objects</li> <li>It is the \"path\" of the resource URL, followed by the operations it accepts</li> <li>For each operation:<ul> <li>The specific of the input data</li> <li>A list of HTTP status codes, and optionally the specific of return data for each use</li> </ul> </li> </ul>"},{"location":"7-semester/DS/12-soa/#components","title":"Components","text":"<ul> <li>It contains a set of reusable objects<ul> <li><code>schemas</code></li> <li><code>responses</code></li> <li><code>parameters</code></li> <li>etc</li> </ul> </li> <li>All objects defined within the <code>components</code> object will have no effect on the API unless they are explicitly referenced</li> </ul>"},{"location":"7-semester/DS/12-soa/#example","title":"Example","text":"<pre><code>openapi: 3.0.3\ninfo: title: ping test\nversion: '1.0'\nservers:\n- url: 'http://localhost:8000'\npaths:\n/ping:\nget:\noperationId: pingGet\nresponses:\n'201':\ndescription: OK\n</code></pre>"},{"location":"7-semester/DS/12-soa/#try-openapi-out","title":"Try OpenAPI out","text":"<ul> <li>Write an OpenAPI specification</li> <li>Use openapi-generator or Swagger<ul> <li>http://api.openapi-generator.tech/index.html</li> <li>https://editor.swagger.io/</li> </ul> </li> <li>Download the generated code<ul> <li>for a server (any language you want)</li> <li>for a client (preferably, Elixir)</li> </ul> </li> <li>Implement the business logic</li> <li>Try it out: Compile, execute, etc</li> </ul>"},{"location":"7-semester/DS/exam/","title":"Exam","text":"<p>Question 1: Distributed Mutual Exclusion </p> <ul> <li>What is DME and what are the requirements to a DME algorithm?</li> <li>What are the criteria to evaluate DME algorithms?</li> <li>Explain the centralized, token ring, and Ricart and Agrawala\u2019s algorithms, and compare them. What are their advantages/disadvantages?</li> </ul> <p>Question 2: Multicast </p> <ul> <li>Why do you need multicast?</li> <li>Explain basic multicast assuming reliable 1:1 communication</li> <li>What are the requirements to reliable multicast and how do you implement it over basic multicast and IP-multicast?</li> <li>Explain the difference between FIFO, Total and Causal ordering? When is it important?</li> <li>Briefly explain the two ideas to implement TO-multicast. What can you say about reliability?</li> </ul> <p>Question 3: Replication and Consistency \u200b()</p> <ul> <li>Why do you need replication?</li> <li>Explain the challenges resulting from replication</li> <li>What consistency models exist?</li> <li>Explain the consistency model and compare them</li> <li>Present an execution which is sequentially consistent but not linearizable</li> </ul> <p>Question 4: Consensus </p> <ul> <li>Explain the consensus problem</li> <li> <p>Solution in synchronous system</p> </li> <li> <p>Explain what the Byzantine generals problem is.</p> </li> <li>Present impossibility result for 3 Byzantine generals, 1 faulty (argue carefully!)</li> <li>Present the solution for 4 Byzantine generals, 1 faulty.</li> <li>Present clearly your assumptions on system model, failures, and message signing. </li> <li>Discuss impossibility in asynchronous systems and practical workarounds</li> </ul> <p>Question 5: Clustered Storage (GFS, Chubby, BigTable) ()</p> <ul> <li>What are the design principles behind the Google Infrastructure?</li> <li>Go into depth with GFS: Explain the architecture, consistency model, replication, fault tolerance. What are its advantages and disadvantages?</li> <li>Chubby: goals, architecture.</li> <li>BigTable: goals and architecture, as difference from GFS and Chubby</li> </ul> <p>Question 6: Big Data Processing (MapReduce/Hadoop, Spark, Pregel) \u200b()\u200b</p> <ul> <li>Explain the Map Reduce paradigm and programming model</li> <li>Explain the system architecture</li> <li>Explain a concrete example application and how it is executed</li> <li>Explain how to optimize the performance and how worker failures can be handled</li> <li>Describe Spark and Pregel, as difference from Hadoop</li> </ul> <p>Question 7: Internet of Things Routing (Directed Diffusion, Tree Routing in ZigBee, AODV, DSR)  \u200b()\u200b</p> <ul> <li>Explain the characteristics and limitation of IoT</li> <li>Describe goals of IoT platforms</li> <li>Describe Directed Diffusion</li> <li>Explain the basics of 802.15.4 (ZigBee's lower layers)</li> <li>Describe Tree Routing in ZigBee</li> <li>Describe AODV and DSR as difference from the other routing approaches</li> </ul> <p>Question 8: Peer to Peer (Gnutella, Chord) \u200b()</p> <ul> <li>Explain the characteristics of peer-to-peer networks</li> <li>Describe the initial architecture of Gnutella</li> <li>Describe the novel architecture of Gnutella (with super-peers)</li> <li>Describe Chord routing approach</li> <li>Discuss Pastry/Tapestry, as differences from Chord</li> </ul> <p>Question 9: Blockchain (Tamper-free linked lists, Nakamoto Consensus, proof of work, transactions in Merkle trees) </p> <ul> <li>Explain the characteristics of the blocks in a blockchain (e.g.: immutability, linear growth)</li> <li>Explain how the crypto tools used in blockchain work (hash function, signature, merkle tree, hash pointer) and how they are used in the blockchain</li> <li>Explain why Paxos consensus is not enough for a blockchain, e.g.: to protect against the double spending conundrum</li> <li>Bitcoin: explain the structure of the transaction and how they are verified by the miner</li> </ul>"},{"location":"7-semester/DS/exam/1-distributed-mutex/","title":"Question 1 - Distributed Mutual Exclusion","text":"<ul> <li>What is DME and what are the requirements to a DME algorithm?</li> <li>What are the criteria to evaluate DME algorithms?</li> <li>Explain the centralized, token ring, and Ricart and Agrawala\u2019s algorithms, and compare them. What are their advantages/disadvantages?</li> </ul>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#what-is-dme-and-what-are-the-requirements-to-a-dme-algorithm","title":"What is DME and what are the requirements to a DME algorithm?","text":"<p>Mutual exclusion algorithms ensures that one and only one process can access a shared resource at any given time.</p> <p>Examples</p> <ul> <li>Using a printer<ul> <li>should only print one document at a time</li> </ul> </li> <li>Writing to a file</li> </ul> <p>Distributed mutual exclusion (DME) is mutual exclusion by only sending messages</p> <p>There 3 requirements to a DME Algorithm</p> <ol> <li>Safety<ul> <li>at most one at a time is given access</li> </ul> </li> <li>Liveness<ul> <li>requests for access are eventually granted</li> </ul> </li> <li>Ordering / Fairness<ul> <li>if A happens before B         then A should be granted before B</li> </ul> </li> </ol>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#what-are-the-criteria-to-evaluate-dme-algorithms","title":"What are the criteria to evaluate DME algorithms?","text":"<p>We evaluate DME algorithms using the following properties</p> <ul> <li>Fault Tolerance<ul> <li>what happens if a process crashes?</li> </ul> </li> <li>Performance<ul> <li>Message complexity<ul> <li>how many message to get mutex?</li> <li>how many messages to release?</li> </ul> </li> <li>Client delay<ul> <li>time from a request   until it is granted</li> </ul> </li> <li>Synchronization delay<ul> <li>time from a release of a mutex    until the next request is granted</li> </ul> </li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#explain-the-centralized-token-ring-and-ricart-and-agrawalas-algorithms-and-compare-them-what-are-their-advantagesdisadvantages","title":"Explain the centralized, token ring, and Ricart and Agrawala\u2019s algorithms, and compare them. What are their advantages/disadvantages?","text":""},{"location":"7-semester/DS/exam/1-distributed-mutex/#centralized","title":"Centralized","text":"<p>In the centralized algorithm we have one external coordinator</p> <ul> <li>has an ordered queue</li> </ul> <p>When a process wants mutex, it asks coordinator</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#evaluation","title":"Evaluation","text":"<p>Fulfills the safe and liveness requirements.</p> <p>But it is not ordered in an asynchronous system.</p> <p>Has entry delay of 2 messages (request + grant) and exit delay of 1 message</p> <p>The synchronization delay is also 2 (release + grant)</p> <p>If the either the coordinator or the mutex holder crashes it will lead to a deadlock</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#proscons","title":"Pros/Cons","text":"<p>It is lightweight in case of messages, but the coordinator quickly becomes a bottleneck.</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#token-ring","title":"Token Ring","text":"<p>In the Token Ring Algorithm we have a ring of processes</p> <ul> <li>Pass token around in the ring</li> </ul> <p>If a process is not using mutex it passes it to \"next\"</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#evaluation_1","title":"Evaluation","text":"<p>Also fulfils safe and liveness.</p> <p>It is still not ordered but it is ordered by ring</p> <p>Entry delay is 1/2 * n on average and n-1n-1 worst case</p> <p>Exit delay is 11</p> <p>Synchronization delay is also 1/2 * n1/2 * n on average and n-1n-1 worst case</p> <p>If any process crashes it causes a deadlock</p> <ul> <li>but if we can detect crashes, we can recover</li> </ul>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#proscons_1","title":"Pros/Cons","text":"<p>The algorithm ensures more order than the centralized, and can possibly recover from deadlock.</p> <p>However, it keeps using bandwidth even when no processes need mutex.</p> <p>It also scales badly with number of processes.</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#ricard-and-agrawalas","title":"Ricard and Agrawala's","text":"<p>In the Ricard and Agrawala's algorithm we have a shared priority queue by using Lamport Clocks</p> <ul> <li>When a process wants mutex,   it requests all and wait for all to accept</li> </ul>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#lamport-clocks","title":"Lamport clocks","text":"<ul> <li>Counts number of messages</li> <li>Piggybacked on messages</li> <li>On send -- Increment local clock</li> <li>On receive -- correct local clock and increment<ul> <li>local = \\max(local, received) + 1local = \\max(local, received) + 1</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#evaluation_2","title":"Evaluation","text":"<p>Ensures both safe, liveness and order. </p> <p>Entry delay is 1 + 1 multicast messages</p> <p>Exit delay is likewise 1 + 1 multicast messages</p> <p>Synchronization delay is 1 message</p> <p>If any process fails we have a deadlock</p>"},{"location":"7-semester/DS/exam/1-distributed-mutex/#proscons_2","title":"Pros/Cons","text":"<p>Its advantage is that it is ordered, and It has a synchronization delay of 11. </p> <p>It does however require multicast, and if there is no hardware support, it can lead to 2(n-1)2(n-1) messages for each request.</p>"},{"location":"7-semester/DS/exam/2-multicast/","title":"Question 2 - Multicast","text":"<ul> <li>Why do you need multicast?</li> <li>Explain basic multicast assuming reliable 1:1 communication</li> <li>What are the requirements to reliable multicast and how do you implement it over basic multicast and IP-multicast?</li> <li>Explain the difference between FIFO, Total and Causal ordering? When is it important?</li> <li>Briefly explain the two ideas to implement TO-multicast. What can you say about reliability?</li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#why-do-you-need-multicast","title":"Why do you need multicast?","text":"<ul> <li>Multicast is one-to-many communication</li> <li>Want to guarantee that all processes get same information</li> <li>With hardware support<ul> <li>send only one message to router</li> <li>router then takes care of sending messages to members</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#explain-basic-multicast-assuming-reliable-11-communication","title":"Explain basic multicast assuming reliable 1:1 communication","text":"<ul> <li>Each process is member of a group</li> <li>when message from application<ul> <li>send message to every member of group -- including self</li> </ul> </li> <li>when receiving message<ul> <li>send message to application -- deliver</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#what-are-the-requirements-to-reliable-multicast-and-how-do-you-implement-it-over-basic-multicast-and-ip-multicast","title":"What are the requirements to reliable multicast and how do you implement it over basic multicast and IP-multicast?","text":""},{"location":"7-semester/DS/exam/2-multicast/#reliable-multicast","title":"Reliable Multicast","text":"<p>To have reliable multicast we must satisfy 3 properties</p> <ul> <li>Integrity<ul> <li>a correct process delivers message at most once.</li> <li>no \"identity theft\"</li> </ul> </li> <li>Validity<ul> <li>If correct process multicasts a message, it eventually delivers it</li> <li>\"a process delivers to itself or crashes\"</li> </ul> </li> <li>Agreement<ul> <li>If correct process delivers, all correct processes in group deliver</li> <li>\"all deliver or none deliver\"</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#reliable-over-basic","title":"Reliable over Basic","text":"<ul> <li>First we b-multicast to group</li> <li>When we receive message<ul> <li>If we have not already delivered message<ul> <li>if message is not from self -- b-multicast message</li> <li>and deliver message</li> </ul> </li> </ul> </li> </ul> <p>Integrity -- yes</p> <ul> <li>message is only delivered once</li> </ul> <p>Validity -- yes</p> <ul> <li>message is delivered to self</li> </ul> <p>Agreement -- yes</p> <ul> <li>message is sent to all devices </li> <li>if process crashes after sending one -- message is sent from receiving process</li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#reliable-over-ip","title":"Reliable over IP","text":"<p>To implement Reliable Multicast over IP-Multicast we steal some ideas from TCP</p> <ul> <li>Sequence number<ul> <li>detect duplicates and lost messages</li> </ul> </li> <li>hold-back-queue<ul> <li>wait for re-transmission</li> <li>replicate messages</li> </ul> </li> <li>track others sequence numbers</li> <li>gossip sequence numbers</li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#implementation","title":"Implementation","text":"<ul> <li> <p>Each process maintains next sequence number S^p, and latest sequence number received from each member R^qR^q</p> </li> <li> <p>IP-multicast message to group with S^pS^p and all pairs &lt;q, R^q&gt;&lt;q, R^q&gt; (all received sequence numbers)</p> <ul> <li>and increment sequence number (S^pS^p++)</li> </ul> </li> <li>On IP-deliver at qq from pp<ul> <li>if received sequence number SS is equal to R^p + 1R^p + 1<ul> <li>R-deliver message</li> <li>Increment received sequence number (R^pR^p++)</li> <li>check hold-back queue for next message and IP-deliver it</li> </ul> </li> <li>else (S &gt; R_g^p + 1S &gt; R_g^p + 1)<ul> <li>store message in hold-back queue</li> </ul> </li> <li>request missing messages</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#explain-the-difference-between-fifo-total-and-causal-ordering-when-is-it-important","title":"Explain the difference between FIFO, Total and Causal ordering? When is it important?","text":""},{"location":"7-semester/DS/exam/2-multicast/#fifo-ordering","title":"FIFO Ordering","text":"<p>Messages from p_np_n are received at p_kp_k in the order sent by p_np_n</p> <ul> <li>like speaking</li> <li>Reliable IP-Multicast is FIFO<ul> <li>we respect sequence-numbers of sender</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#total-ordering","title":"Total Ordering","text":"<p>All messages are received in same order at p_np_n and p_kp_k</p>"},{"location":"7-semester/DS/exam/2-multicast/#casual-ordering","title":"Casual Ordering","text":"<p>if p_np_n receives m_1m_1 before m_2m_2, then m1m1 happened before m_2m_2</p>"},{"location":"7-semester/DS/exam/2-multicast/#why","title":"Why","text":"<p>Lets say we have a bank</p> <ul> <li>if messages are not received ordered -- it can lead to wrong state</li> </ul> <p></p> <ul> <li>if we use FIFO order problem is inherently fixed</li> </ul> <p></p> <ul> <li>If we introduce another sending process -- we have problem again</li> </ul> <p></p> <ul> <li>If we use total order problem fixed again</li> </ul> <p></p> <ul> <li>Can however still go wrong</li> </ul> <p></p>"},{"location":"7-semester/DS/exam/2-multicast/#briefly-explain-the-two-ideas-to-implement-to-multicast-what-can-you-say-about-reliability","title":"Briefly explain the two ideas to implement TO-multicast. What can you say about reliability?","text":"<p>The idea is to do like FIFO multicast -- but have only one sequence-number</p> <ul> <li>each message has unique id</li> <li>all processes agree on next message<ul> <li>global sequencer or</li> <li>negotiation (ISIS)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#global-sequencer","title":"Global Sequencer","text":"<ul> <li>One process works as a global sequencer</li> <li>When sequencer receives message<ul> <li>b-multicasts order message with sequence number for message id</li> <li>increments its own sequence number</li> </ul> </li> <li> <p>when order is received</p> <ul> <li>update sequence map with sequence number for message id</li> <li>try-deliver</li> </ul> </li> <li> <p>when normal process receives message</p> <ul> <li>put message in hold-back queue</li> <li>try-deliver</li> </ul> </li> <li>on try-deliver<ul> <li>check if sequence number has been received and message exists in hold-back-queue</li> <li>deliver to application</li> <li>try-deliver next message</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#reliability","title":"Reliability","text":"<ul> <li>Global Sequencer is single point of failure</li> <li>Also bottleneck</li> <li>on package loss -&gt; deadlock</li> </ul>"},{"location":"7-semester/DS/exam/2-multicast/#isis","title":"ISIS","text":"<p>Idea -- Negotiate next ID</p> <ol> <li>Process pp broadcasts message mm</li> <li>Every other process qq responds to pp with proposal</li> <li>pp picks largest proposed value, broadcasts</li> </ol> <p>Need to track \"largest proposed value\" and \"largest agreed value\" at each process</p>"},{"location":"7-semester/DS/exam/2-multicast/#reliability_1","title":"Reliability","text":"<p>If we have reliable crash-detection we have robust protocol</p> <ul> <li>sequence numbers increases</li> <li> <p>no process delivers early</p> </li> <li> <p>however</p> <ul> <li>every message requires 3 rounds for negotiation<ul> <li>(the sequencer takes 2 rounds)</li> <li>1 for proposal -- 1 for vote -- 1 for picking</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/","title":"Question 3 - Replication and Consistency","text":"<ul> <li>Why do you need replication?</li> <li>Explain the challenges resulting from replication</li> <li>What consistency models exist?</li> <li>Explain the consistency model and compare them</li> <li>Present an execution which is sequentially consistent but not linearizable</li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#why-do-you-need-replication","title":"Why do you need replication?","text":"<p>The goals of replication is Fault tolerance, high availability  and performance</p> <p>We want to tolerate node and network failures</p> <p>We want the service to be available as much as possible</p> <p>We want to be able to scale the service, as well as overcome geographic- and network limits</p> <p></p>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#explain-the-challenges-resulting-from-replication","title":"Explain the challenges resulting from replication","text":"<p>In a distributed system, it is impossible to simultaneously provide Consistency, Availability and Partition tolerance</p> <p>We can only satisfy any two of them at the same time but not all three</p> <p>This is called the CAP Theorem</p> <p></p> <p>We also want to make it transparent for the user</p> <ul> <li>They should not worry about which server to contact</li> </ul> <p>Ideally we would have it indistinguishable from single copy behavior</p> <p>Fault tolerance -- what if a process crashes</p> <ul> <li>f-resilience  -- f amounts processes can crash without stopping service</li> </ul> <p>Inconsistency</p> <p></p> <ul> <li>Inconsistent -- since what was set in replica 1 is never sent out to other replicas</li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#replication-architectures-for-fault-tolerance","title":"(Replication Architectures for Fault Tolerance)","text":"<p>Read-only replication</p> <ul> <li>Immutable files</li> <li>Cache-servers</li> </ul> <p>Passive replication (primary/secondary)</p> <ul> <li>High consistency</li> </ul> <p>Active replication</p> <ul> <li>Fast failover mechanism<ul> <li>Everyone can take over if one fails</li> </ul> </li> <li>Workload distribution</li> <li>Everybody is working on equal terms</li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#what-consistency-models-exist","title":"What consistency models exist?","text":"<p>We have two consistency models</p> <ul> <li>A strong consistency -- Linearizability<ul> <li>In real-time, after update A, everybody will see the modification done by A when reading</li> </ul> </li> <li>A weak consistency -- Sequential Consistency<ul> <li>\"reasonably consistent\"</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#explain-the-consistency-model-and-compare-them","title":"Explain the consistency model and compare them","text":""},{"location":"7-semester/DS/exam/3-replication-and-consistency/#linearizability-strong-consistency","title":"Linearizability - Strong Consistency","text":"<p>We have C_iC_i operations</p> <ul> <li>o_1^i, o_2^i, \\dots, o_n^io_1^i, o_2^i, \\dots, o_n^i for some operation o \\in Oo \\in O</li> </ul> <p>Let T(o^i_n)T(o^i_n) be the timestamp of o^i_no^i_n.</p> <p>We then say that an interleaving \\dots, o^i_5, o^j_{100}, o^i_6, \\dots\\dots, o^i_5, o^j_{100}, o^i_6, \\dots (where i \\neq ji \\neq j) is linearizable if</p> <ul> <li>we arrive at a (single) correct copy of the object (from specification)<ul> <li>the results of the client\u2019s operations make sense as they occur within the interleaving</li> </ul> </li> <li>the order is consistent with real time<ul> <li>T(o^i_5) \\leq T(o^j_{100}) \\leq T(o^i_6)T(o^i_5) \\leq T(o^j_{100}) \\leq T(o^i_6)</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#sequential-consistency-weak-consistency","title":"Sequential Consistency - Weak Consistency","text":"<p>We have C_iC_i operations</p> <ul> <li>o_1^i, o_2^i, \\dots , o_n^io_1^i, o_2^i, \\dots , o_n^i for some operation o \\in Oo \\in O</li> </ul> <p>We then say that an interleaving \\dots, o^i_5, o^j_{100}, o^i_6, \\dots\\dots, o^i_5, o^j_{100}, o^i_6, \\dots (where i \\neq ji \\neq j) is sequentially consistent if</p> <ul> <li>arrive at a (single) correct copy of the object (from specification)<ul> <li>the results of the client\u2019s operations make sense as they occur within the interleaving</li> </ul> </li> <li>the order respects causality of C_iC_i<ul> <li>a &lt; ca &lt; c, i.e. from C_i, o^i_aC_i, o^i_a was sent before o^i_co^i_c</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/3-replication-and-consistency/#present-an-execution-which-is-sequentially-consistent-but-not-linearizable","title":"Present an execution which is sequentially consistent but not linearizable","text":"<ul> <li>Since Client 1's operations are done in correct order in respect to Client 1 and</li> <li>and Client 2's operations are done in correct order in respect to Client 2<ul> <li>the execution is sequentially consistent</li> </ul> </li> <li>But since step (3) happens after step (2) -- client 2 should see 100$ in balance<ul> <li>maybe operation (2) has not reached replica 1 yet</li> <li>the execution is not linearizable</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/","title":"Question 4: Consensus","text":"<ul> <li>Explain the consensus problem</li> <li>Solution in synchronous system</li> <li>Explain what the Byzantine generals problem is.</li> <li>Present impossibility result for 3 Byzantine generals, 1 faulty (argue carefully!)</li> <li>Present the solution for 4 Byzantine generals, 1 faulty.</li> <li>Present clearly your assumptions on system model, failures, and message signing. </li> <li>Discuss impossibility in asynchronous systems and practical workarounds</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#explain-the-consensus-problem","title":"Explain the consensus problem","text":"<p>Consensus is the ability for a group of processes to agree on one, and only one value</p> <p>For example in Mutex, we have to agree on who is holding the mutex.</p> <p>We need it in redundant systems in order.</p> <ul> <li>For example in a space ship, there is a possibility of bits flipping, so we have multiple computers, that then has to agree on values.</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#definition","title":"Definition","text":"<p>We have a set of processes p_i \\in \\{p_0,\\dots,p_n\\} and each has a decision variable d_id_i</p> <ul> <li>They all start in the undecided state, and proposes a value to each other.</li> <li>Each process then has to agree on a value and set its decision variable d_id_i</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#requirements","title":"Requirements","text":"<p>A consensus algorithm has to fulfil the following requirements</p> <ul> <li>Termination<ul> <li>Eventually a correct process sets its decision variable d_id_i</li> </ul> </li> <li>Agreement<ul> <li>The decision values of all correct processes are the same</li> </ul> </li> <li>Integrity<ul> <li>If all correct processes propose the same value, then any correct process in the decided state decided on that value</li> </ul> </li> <li>Weak Integrity<ul> <li>The agreed value must be one proposed by a correct process</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#solution-in-synchronous-system","title":"Solution in synchronous system","text":"<ul> <li>Takes f+1f+1 rounds -- with timeout</li> <li>At each round less than round f+1f+1 -- b-multicast your value if it has changed</li> <li>When value is received -- set your value to it - if value received is less than your value</li> <li>At round f+1f+1 you have reached consensus<ul> <li>all processes has sent their value to all</li> </ul> </li> </ul> <p>(image not for slides)</p> <p>Not possible to make algorithm with that requires less than f+1f+1 rounds</p> <ul> <li>If ff devices fail -- there can be ff faulty rounds</li> <li>we need at least 1 correct round</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#explain-what-the-byzantine-generals-problem-is","title":"Explain what the Byzantine generals problem is.","text":"<p>In the Byzantine Generals Problem we have 3 or more generals that has to agree to attack or retreat.</p> <ul> <li>One is the commander and gives the order</li> <li>Rest are lieutenants and has to decide on Attack or Retreat </li> </ul> <p>One or more of the generals may be treacherous -- faulty</p> <ul> <li>Treacherous commander may propose attack to one and retreat to another</li> <li>Treacherous lieutenants may lie about order from commander</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#present-impossibility-result-for-3-byzantine-generals-1-faulty-argue-carefully","title":"Present impossibility result for 3 Byzantine generals, 1 faulty (argue carefully!)","text":"<p>If we have 3 generals and 1 of them is faulty, it is impossible to detect who is the faulty one.</p> <p>Lets say that B is faulty.</p> <ul> <li>B sends Attack to A -- and retreat to C</li> <li>That means A receives both attack and retreat, and will not know who is faulty</li> </ul> <p>Lets say that C is faulty</p> <ul> <li>B sends Attack to both A and C</li> <li>C sends retreat to A</li> <li>Again that means A receives both attack and retreat, and will not know who is faulty</li> </ul> <p>This can be generalized to mean that if 1/3 is faulty we cannot arrive at consensus</p> <p></p>"},{"location":"7-semester/DS/exam/4-consensus/#present-the-solution-for-4-byzantine-generals-1-faulty","title":"Present the solution for 4 Byzantine generals, 1 faulty.","text":"<p>If we have 4 generals and 1 of them is faulty, we can reach agreement.</p> <p>There are 2 cases</p> <ul> <li>A faulty lieutenant<ul> <li>in the first round the commander sends the right value to all lieutenants</li> <li>in second round lieutenants send their values to each other, but the faulty one sends different values to each</li> <li>we then take the majority value </li> </ul> </li> <li>A faulty commander<ul> <li>in the first round the commander sends different values to all lieutenants</li> <li>in second round lieutenants send their values to each other, but everyone receives 3 different values, and they therefore know that the general is faulty</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#present-clearly-your-assumptions-on-system-model-failures-and-message-signing","title":"Present clearly your assumptions on system model, failures, and message signing.","text":"<p>We assume that we have</p> <ul> <li>reliable communication</li> <li>crash failures and </li> <li>byzantine failures</li> <li>and no signed messages<ul> <li>we can have \"identity theft\"</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#discuss-impossibility-in-asynchronous-systems-and-practical-workarounds","title":"Discuss impossibility in asynchronous systems and practical workarounds","text":"<p>It has been proved by that no algorithm can guarantee consensus in an asynchronous system.</p> <p>In asynchronous systems, the communication can be \"blocked\" indefinitely</p> <ul> <li>we cannot know if a process is slow or crashed</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#two-army-problem","title":"Two Army Problem","text":"<p>An example of a consensus problem is the two army problem</p> <ul> <li>We have three armies<ul> <li>two red</li> <li>one blue</li> </ul> </li> <li>The red armies has to attack at the same time</li> <li>They can send message but blue can intercept</li> <li>It is impossible to design a protocol to make sure that both armies attack at same time</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#practical-workarounds","title":"Practical workarounds","text":"<p>Masking Faults</p> <p>We can mask failures, for example by using a checksum with messages to ensure that they are not corrupted</p> <p>We can also save sufficient data on persistent storage to be able to recover from a crash</p> <p>Failure Detection</p> <p>We cannot, by only passing messages, design a perfect failure detector.</p> <p>We can agree that if a process has not responded within a timeframe we deem it failed.</p> <ul> <li>We can then ignore the rest of its messages if it is still working -- fail-silent</li> </ul> <p>We have to be careful with the timeout</p> <ul> <li>too low and we ignore usable nodes</li> <li>too high and we potentially has to wait a long time</li> </ul> <p>Problems can arrive if we have network partition</p> <p>Randomness</p> <p>If we introduce some randomness in the process's behavior, so that the system cannot be effectively thwarted.</p>"},{"location":"7-semester/DS/exam/4-consensus/#paxos-if-it-comes-up","title":"Paxos if it comes up","text":"<ul> <li>No coordinator</li> <li>Async system</li> <li>Nodes may crash and recover<ul> <li>OK with up to n/2n/2 failures</li> </ul> </li> <li>Once a single process decides, all will (eventually) decide the same</li> </ul> <p>Inconceivable!</p> <ul> <li>No guaranteed termination</li> <li>... but terminates in \"reasonable environments\"</li> </ul> <p>The Paxos Algorithm</p>"},{"location":"7-semester/DS/exam/4-consensus/#reaching-consensus-with-paxos","title":"Reaching Consensus with Paxos","text":"<ul> <li>Once a majority agrees on a proposal, that is the consensus</li> <li>The reached consensus can be eventually known by anyone</li> <li>Processes will agree on any result -- not only own</li> <li>Communication may be faulty -- messages can get lost</li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#basics","title":"Basics","text":"<ul> <li>Paxos defines three roles:<ul> <li>Proposers</li> <li>Acceptors</li> <li>Learners</li> </ul> </li> <li>Nodes can take multiple roles</li> <li>Paxos nodes must know how many acceptors a majority is</li> <li>Paxos nodes must be persistent: they cant forget what they accepts</li> <li>A Paxos run aims at reaching a single consensus<ul> <li>Once consensus is reached, it cannot progress to another consensus</li> <li>In order to reach another consensus, a different Paxos run must happen</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/4-consensus/#the-paxos-algorithm","title":"The Paxos Algorithm","text":""},{"location":"7-semester/DS/exam/4-consensus/#majority-of-promises","title":"Majority of Promises","text":""},{"location":"7-semester/DS/exam/4-consensus/#contention","title":"Contention","text":""},{"location":"7-semester/DS/exam/4-consensus/#majority-of-accepts","title":"Majority of Accepts","text":""},{"location":"7-semester/DS/exam/4-consensus/#practical-example-simple-distributed-storage-system","title":"Practical Example - Simple Distributed Storage System","text":""},{"location":"7-semester/DS/exam/5-clustered-storage/","title":"Question 5 - Clustered Storage","text":"<ul> <li>What are the design principles behind the Google Infrastructure?</li> <li>Go into depth with GFS: Explain the architecture, consistency model, replication, fault tolerance. What are its advantages and disadvantages?</li> <li>Chubby: goals, architecture.</li> <li>BigTable: goals and architecture, as difference from GFS and Chubby</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#what-are-the-design-principles-behind-the-google-infrastructure","title":"What are the design principles behind the Google Infrastructure?","text":"<p>Key philosophy: use large number of commodity PCs</p> <ul> <li>best performance per dollar</li> <li>high risk of failure</li> </ul> <p>Use cluster architecture</p> <p></p> <ul> <li>Use software techniques for fault tolerance</li> <li>Use replication and parallelism for throughput and availability</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#go-into-depth-with-gfs-explain-the-architecture-consistency-model-replication-fault-tolerance-what-are-its-advantages-and-disadvantages","title":"Go into depth with GFS: Explain the architecture, consistency model, replication, fault tolerance. What are its advantages and disadvantages?","text":""},{"location":"7-semester/DS/exam/5-clustered-storage/#architecture","title":"Architecture","text":"<ul> <li>Master keeps track of chunk locations</li> <li>Data directly from chunk servers</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#writing","title":"Writing","text":"<ul> <li>When a client wants to write data, it asks master for primary replica for chunk (1 + 2)</li> <li>The client then pushes the data to all the replicas (3)</li> <li>When all replicas have acknowledged, client sends write request to primary (4)</li> <li>The primary forwards write requests to secondaries (5)</li> <li>When the secondaries have acknowledged to primary (6) the primary replies to client (7)</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#consistency-model","title":"Consistency Model","text":"<ul> <li>File namespace mutations such as file creation are atomic and handled by the master</li> <li>A file region is consistent if all clients see the same data from all replicas</li> <li>A file region is defined if consistent and all clients see writes in entirety </li> <li>On an append, the record is appended atomically at least once somewhere<ul> <li>leads to defined but potentially inconsistent</li> </ul> </li> <li>Inconsistent regions are handled by the applications</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#replication","title":"Replication","text":"<ul> <li>The replicas are placed across different racks to optimize availability and bandwidth</li> <li>Chunks are allocated on multiple replicas<ul> <li>based on recent allocations on disks and placement</li> </ul> </li> <li>When replicas become unavailable, chunks are re-replicated</li> <li>The master re-balances periodically to optimize disk space and load balancing</li> <li>Garbage collection to delete unused chunks</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#fault-tolerance","title":"Fault Tolerance","text":"<ul> <li>Master contains an operations log and check points in persistent storage<ul> <li>to recover from crashes</li> </ul> </li> <li>Read-only Shadow Masters</li> <li>External failure detection to select new master and restart faulty</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#proscons","title":"Pros/cons","text":"<ul> <li>High availability and throughput and works with commodity hardware</li> <li> <p>Reliable</p> <ul> <li>saved on multiple locations, and corrupted data can be recovered</li> </ul> </li> <li> <p>GFS is optimized for large file, and is thus not suitable for small files.</p> </li> <li> <p>The Master is a single point of failure, and can become a bottleneck</p> <ul> <li>somewhat solved with shadow masters</li> </ul> </li> <li>Optimized for append operations and not random writes</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#chubby-goals-architecture","title":"Chubby: goals, architecture.","text":"<p>Chubby is a coarse-grained distributed lock service.</p> <ul> <li>coarse meaning hours or days</li> </ul> <p>It is intended for \"loosely-coupled distributed systems\"</p> <ul> <li>independent nodes<ul> <li>unpredictable speed</li> </ul> </li> <li>nodes can crash, which are difficult to detect and recover</li> <li>messages can be lost -- delayed -- re-ordered -- but not corrupted</li> </ul> <p>Also has reliable but low-volume storage</p> <p>It should have</p> <ul> <li>high fault-tolerant</li> <li>high availability</li> <li> <p>high scalability</p> </li> <li> <p>and throughput and performance is less important</p> </li> </ul> <p>Examples of use</p> <ul> <li>GFS<ul> <li>master election </li> </ul> </li> <li>BigTable<ul> <li>master election</li> <li>client discovery</li> <li>table service locking</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#architecture_1","title":"Architecture","text":"<p>Chubby consists of client library and chubby cell</p> <p>Typically </p> <ul> <li>1 cell per data center</li> <li>5 replicas</li> </ul> <p>1 replica is elected as master</p> <p>Clients communicate with master via RPC</p> <ul> <li>reads and writes go through master<ul> <li>writes only acknowledged before majority has replicated</li> </ul> </li> </ul> <p>Chubby has a filesystem-like interface</p> <pre><code>fh = Open(\u201c/ls/exampleCell/gfs/master\u201d)\nsuccess = tryAcquire(fh)\nif(success) write(fh, myID)\n</code></pre> <p>Maintains session between client and server</p> <ul> <li>master promises service for \"lease time\"</li> <li>clients make \"keep-alive\" calls to maintain session</li> <li>on session loss -- server releases client-held handles</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#bigtable-goals-and-architecture-as-difference-from-gfs-and-chubby","title":"BigTable: goals and architecture, as difference from GFS and Chubby","text":"<p>BigTable is a distributed storage system</p> <ul> <li>opposed to GFS -- designed for structured data<ul> <li>stored as strings</li> <li>resembles a database</li> </ul> </li> <li>petabytes of data and thousands of machines</li> <li>random access to small items</li> </ul> <p>Its goals are</p> <ul> <li>wide applicability</li> <li>scalability</li> <li>high performance</li> <li>high availability</li> </ul>"},{"location":"7-semester/DS/exam/5-clustered-storage/#architecture_2","title":"Architecture","text":"<ul> <li>uses row/column abstraction</li> <li>contains timestamps for data</li> </ul> <pre><code>(row: String, column: String, time: int64) -&gt; String\n</code></pre> <p>A BigTable is split into tablets</p> <ul> <li>consecutive set of rows</li> <li>about ~200 MB</li> <li>can be split and merged</li> </ul> <p>Each tablet is served by one Tablet Server</p> <ul> <li>like GFS chunk-server</li> </ul> <p>Tablets are stored in SSTable (Sorted Strings Table) in GFS </p> <ul> <li>ordered and immutable map from keys to values (String, String)</li> <li>mutations not performed on SSTables -- but written to log</li> </ul> <p></p> <p></p> <ul> <li>Add some notes here </li> </ul>"},{"location":"7-semester/DS/exam/6-big-data-processing/","title":"Question 6 - Big Data Processing","text":"<ul> <li>Explain the Map Reduce paradigm and programming model</li> <li>Explain the system architecture</li> <li>Explain a concrete example application and how it is executed</li> <li>Explain how to optimize the performance and how worker failures can be handled</li> <li>Describe Spark and Pregel, as difference from Hadoop</li> </ul>"},{"location":"7-semester/DS/exam/6-big-data-processing/#explain-the-map-reduce-paradigm-and-programming-model","title":"Explain the Map Reduce paradigm and programming model","text":"<p>Map Reduce consists of 2 phases -- functions defined by user</p> <ul> <li>Map<ul> <li>given key-value pairs, produce intermediate key-value pairs</li> <li>Combine values of the same key and send it to reducer</li> </ul> </li> <li>Reduce<ul> <li>further compress the value set of the same key</li> </ul> </li> </ul> <p>Created for processing of large data sets.</p> <p>Inspired by functional programming</p>"},{"location":"7-semester/DS/exam/6-big-data-processing/#explain-the-system-architecture","title":"Explain the system architecture","text":"<p>The system consists of 1 master and several mappers and reducers.</p> <p></p> <p>The master</p> <ul> <li>assigns map and reduce jobs to other workers</li> <li>stores the state of each job</li> <li>stores the location of output files of the jobs</li> </ul> <p></p> <ul> <li>First we split the input into pieces</li> <li>Master assigns mappers and reducers</li> <li>Reducers get path of map output from master </li> </ul>"},{"location":"7-semester/DS/exam/6-big-data-processing/#explain-a-concrete-example-application-and-how-it-is-executed","title":"Explain a concrete example application and how it is executed","text":""},{"location":"7-semester/DS/exam/6-big-data-processing/#google-music-example","title":"Google Music Example","text":"<ul> <li>Chunk-servers contains analytics for music played</li> <li>We want to find the most played songs</li> </ul> <p>The master tells each chunk-server to count how many times each song has been played (map-phase)</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"7-semester/DS/exam/6-big-data-processing/#explain-how-to-optimize-the-performance-and-how-worker-failures-can-be-handled","title":"Explain how to optimize the performance and how worker failures can be handled","text":""},{"location":"7-semester/DS/exam/6-big-data-processing/#performance","title":"Performance","text":"<ul> <li> <p>Locality</p> <ul> <li>Worker should be close to the GFS replica storing the data</li> </ul> </li> <li> <p>Stragglers</p> <ul> <li>slow workers -- nearly always some worker is slow</li> <li>when program near finished<ul> <li>in progress tasks are rescheduled at backup worker</li> <li>done when either backup or original is done</li> </ul> </li> </ul> </li> <li>Barrier synchronization / pipelining<ul> <li>whether we can start reducing while mapping</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/6-big-data-processing/#fault-tolerance","title":"Fault Tolerance","text":"<ul> <li>The master sends pings to workers</li> <li>If one is idle<ul> <li>if its running map task, task is marked idle and rescheduled</li> <li>if its running reduce task two things can happen<ul> <li>if task task is in progress, its rescheduled</li> <li>if task is done -- output written to global storage -- done</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/6-big-data-processing/#describe-spark-and-pregel-as-difference-from-hadoop","title":"Describe Spark and Pregel, as difference from Hadoop","text":""},{"location":"7-semester/DS/exam/6-big-data-processing/#spark","title":"Spark","text":"<p>Map Reduce is inefficient for applications which reuse intermediate results across multiple computations</p> <p>Spark uses resilient distributed datasets (RDDs)</p> <ul> <li>Immutable, partitioned collections of records (normally in RAM)</li> <li>fault-tolerant, parallel data structures,</li> <li>efficient data reuse</li> </ul> <p>let users</p> <ul> <li>explicitly persist intermediate results in memory</li> </ul> <p>RDD does not have to be materialized all the time: </p> <ul> <li>store the \u201elineage\u201c, information about how it was derived from other datasets (operations on RDDs).<ul> <li>re-computable</li> </ul> </li> </ul> <p></p> <ul> <li>black rectangles are already in memory</li> </ul> <p></p>"},{"location":"7-semester/DS/exam/6-big-data-processing/#pregel","title":"Pregel","text":"<p>Pregel is  tailored to graph computations</p> <ul> <li>scale to billions of vertices, trillions of edges</li> </ul> <p>Keeps intermediate results like spark</p> <p>Algorithm termination is based on every vertex voting to halt</p> <ul> <li>In super-step 0, every vertex is in the active state</li> <li>A vertex deactivates itself by voting to halt</li> <li>A message may re-activate a vertex</li> </ul> <p></p> <p>Master - worker architecture</p> <ul> <li>Master monitors workers and partitions vertices to workers</li> <li>Workers execute at each super-step<ul> <li>report number of active vertices to master at end of step</li> </ul> </li> </ul> <p>Uses GFS or BigTable for persistent data</p>"},{"location":"7-semester/DS/exam/6-big-data-processing/#example","title":"Example","text":""},{"location":"7-semester/DS/exam/7-iot-routing/","title":"Question 7 - Internet of Things Routing (Directed Diffusion, Tree Routing in ZigBee, AODV, DSR)","text":"<ul> <li>Explain the characteristics and limitation of IoT</li> <li>Describe goals of IoT platforms</li> <li>Describe Directed Diffusion</li> <li>Explain the basics of 802.15.4 (ZigBee's lower layers)</li> <li>Describe Tree Routing in ZigBee</li> <li>Describe AODV and DSR as difference from the other routing approaches</li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#explain-the-characteristics-and-limitation-of-iot","title":"Explain the characteristics and limitation of IoT","text":"<p>IoT Network consists of many small devices</p> <p>Limitations in</p> <ul> <li>Power consumption<ul> <li>Turn off idle devices</li> <li>Reduce communication!</li> </ul> </li> <li>Bandwidth</li> <li>Memory, CPU</li> <li>Routing</li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#describe-goals-of-iot-platforms","title":"Describe goals of IoT platforms","text":"<p>Designed for many small devices, such as sensors or smart home devices</p> <ul> <li>The goal is to be resource efficient and dynamic</li> <li>Communication between devices</li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#describe-directed-diffusion","title":"Describe Directed Diffusion","text":"<ul> <li>Some nodes contains interests -- sinks</li> <li>System propagates interests through the system -- diffusion<ul> <li>Nodes that receives interest stores record of it -- propagates it further</li> </ul> </li> <li>gradients set up -- contains direction and value such as flow-rate</li> <li>When source node is found, application is activated -- data generated</li> <li>Explorative data sent back -- find path of minimum length with heuristic</li> <li>Path is created</li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#explain-the-basics-of-802154-zigbees-lower-layers","title":"Explain the basics of 802.15.4 (ZigBee's lower layers)","text":"<ul> <li>802.15.4 designed for wireless personal area networks (home automation, cars, remote metering,\u2026)<ul> <li>Monitoring and Control</li> <li>Ease of installation but no mobility</li> <li>Low power </li> <li>Low transmission rates (&lt; 250 kbps)</li> <li>Low range (&lt; 75m max)</li> </ul> </li> <li>802.15.4 defines Physical and MAC layer</li> <li>Devices can be one of two<ul> <li>Full Function Device (\\color{darkblue}\\text{FFD})<ul> <li>Exist in any topology<ul> <li>Star</li> <li>Tree</li> <li>Mesh</li> </ul> </li> <li>Can be coordinator</li> <li>Talk to any device</li> </ul> </li> <li>Reduced Function Device \\color{darkred} \\text{RFD}\\color{darkred} \\text{RFD}<ul> <li>Only star topology</li> <li>Cannot be coordinator</li> <li>Talk to network coordinator only</li> <li>Simple implementation</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#describe-tree-routing-in-zigbee","title":"Describe Tree Routing in ZigBee","text":""},{"location":"7-semester/DS/exam/7-iot-routing/#address-assignment","title":"Address Assignment","text":"<ul> <li>Coordinator defines 3 network parameters<ul> <li>max number of children C_mC_m of a ZigBee router</li> <li>max number of child routes R_mR_m of a parent node</li> <li>depth of the network L_mL_m</li> </ul> </li> <li>Parent device computes parameter C_{skip}C_{skip}<ul> <li>to compute size of its children's address pools</li> </ul> </li> </ul>  C_{skip}(d) = \\left \\{ \\begin{array}{} 1+ C_m \\cdot (L_m - d - 1), &amp; \\text{if } R_m = 1 \\\\ \\frac {1+ C_m - R_m - C_m \\cdot R_m^{L_m-d-1}} {1- R_m}, &amp; \\text{otherwise} \\end{array}\\right.   C_{skip}(d) = \\left \\{ \\begin{array}{} 1+ C_m \\cdot (L_m - d - 1), &amp; \\text{if } R_m = 1 \\\\ \\frac {1+ C_m - R_m - C_m \\cdot R_m^{L_m-d-1}} {1- R_m}, &amp; \\text{otherwise} \\end{array}\\right.  <p>Address then assigned by parents depth dd and address A_{parent}A_{parent}:</p> <ul> <li>for n'th child router:<ul> <li>A_{parent}+(n-1) \\times C_{skip}(d) +1A_{parent}+(n-1) \\times C_{skip}(d) +1</li> </ul> </li> <li>for n'th child end device:<ul> <li>A_{parent} + R_m \\times C_{skip}(d)+nA_{parent} + R_m \\times C_{skip}(d)+n</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/DS/exam/7-iot-routing/#tree-routing","title":"Tree Routing","text":"<p>Uses address assignment to obtain the routing paths</p> <ul> <li>Device receives package<ul> <li>check destination by checking its address range<ul> <li>for self: accept or forward to child</li> <li>otherwise: relay along tree</li> </ul> </li> </ul> </li> </ul> <p></p> <ul> <li>Example 38 \\to\\to 45<ul> <li>38 - 33 - 32 - 40 - 45</li> </ul> </li> <li>Example 38 \\to\\to 92<ul> <li>38 - 33 - 32 - 0 - 63 - 92</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#describe-aodv-and-dsr-as-difference-from-the-other-routing-approaches","title":"Describe AODV and DSR as difference from the other routing approaches","text":""},{"location":"7-semester/DS/exam/7-iot-routing/#dsr-dynamic-source-routing","title":"DSR - Dynamic Source Routing","text":"<ul> <li>Instead of being based on static addresses - route calculated dynamically</li> <li>Source node (S) sends out Route Request (RREQ)<ul> <li>Nodes append their id<ul> <li>Source routing</li> </ul> </li> </ul> </li> </ul> <ul> <li>When destination (D) receives request -- send Route Reply (RREP)<ul> <li>using reverse route of request</li> </ul> </li> </ul> <ul> <li>Routes are only maintained between nodes who need to communicate</li> <li>A single route discovery may yield many routes to the destination</li> <li>However<ul> <li>Packet header size grows with route length</li> <li>Flood of requests potentially reach all nodes</li> <li>Potential collisions between route requests (J + K \\to\\to D)<ul> <li>insert random delays before forwarding RREQ to fix</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/7-iot-routing/#aodv-ad-hoc-on-demand-distance-vector-routing","title":"AODV - Ad Hoc On-Demand Distance Vector Routing","text":"<ul> <li> <p>Works in a similar fashion to DSR</p> </li> <li> <p>Instead of including source routes in packet headers -- maintain routing tables at nodes</p> <ul> <li>Routes are still only maintained between nodes needing to communicate</li> </ul> </li> </ul> <p></p> <ul> <li>Route Request (RREQ) includes the last known sequence number for the destination<ul> <li>used to avoid old/broken routes</li> <li>prevent formation of routing loops</li> </ul> </li> <li>Intermediate nodes that forward the RREP, also record the next hop to destination</li> <li>A routing table entry maintaining a reverse path is purged after a timeout interval</li> <li>A routing table entry maintaining a forward path is purged if not used for a active_route_timeout interval</li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/","title":"Question 8 - Peer to Peer (Gnutella, Chord)","text":"<ul> <li>Explain the characteristics of peer-to-peer networks</li> <li>Describe the initial architecture of Gnutella</li> <li>Describe the novel architecture of Gnutella (with super-peers)</li> <li>Describe Chord routing approach</li> <li>Discuss Pastry/Tapestry, as differences from Chord</li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#explain-the-characteristics-of-peer-to-peer-networks","title":"Explain the characteristics of peer-to-peer networks","text":"<p>In a peer-to-peer network -- peers find each other</p> <ul> <li>Initiates communication with each other</li> <li>Direct communication between peers</li> <li>No reliance on centralized services or resources</li> <li> <p>Highly scalable</p> </li> <li> <p>peers can enter and leave the network</p> </li> </ul> <p>Formal</p> <ul> <li>A peer is a node on a P2P network forming fundamental processing unit</li> <li>Each peer has unique ID</li> <li>Each peer belong to one or several peer groups</li> <li>Each peer can communicate with other peers</li> </ul> <p>Different Purposes</p> <ul> <li>Distributed computing </li> <li>File sharing</li> <li>Collaborative applications </li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#describe-the-initial-architecture-of-gnutella","title":"Describe the initial architecture of Gnutella","text":"<ul> <li> <p>Gnutella is unstructured Peer to Peer network</p> </li> <li> <p>Peers form overlay network</p> </li> </ul> <p>(Query flooding)</p> <p>Join</p> <ul> <li>on startup -- client contacts a few other nodes (learn from bootstrap-node)<ul> <li>become its \u201cneighbors\u201d</li> </ul> </li> </ul> <p>No Publish</p> <p>Search</p> <ul> <li>ask \u201cneighbors\u201d -- who ask their neighbors -- and so on... <ul> <li>when/if found, reply to sender.</li> </ul> </li> </ul> <p>Fetch</p> <ul> <li>get the file directly from peer</li> </ul> <p></p> <ul> <li>Its totally decentralized</li> <li>Highly robust</li> <li>However<ul> <li>Not scalable -- need to contact all peers for deterministic search</li> <li>Network can be flooded<ul> <li>solved with TTL (Time-to-live)</li> </ul> </li> </ul> </li> </ul> <p>To avoid excessive traffic</p> <ul> <li>Query forwarded to all neighbors except peer from which received</li> <li>Each Query (identified by DescriptorID) forwarded only once<ul> <li>each peer maintains a list of recently received messages</li> </ul> </li> <li>QueryHit routed back only to peer from which Query received with same DescriptorID</li> </ul> <p>Download</p> <ul> <li>Choose \"best\" QueryHit responder</li> <li>Download directly with HTTP</li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#describe-the-novel-architecture-of-gnutella-with-super-peers","title":"Describe the novel architecture of Gnutella (with super-peers)","text":"<ul> <li>Protocol originally called FastTrack</li> <li>some peers designated as super-nodes<ul> <li>advantage of \u201chealthier\u201d participants in the system</li> <li>Contain a directory of files<ul> <li><code>&lt;filename,peer pointer&gt;</code></li> </ul> </li> <li>can change over time<ul> <li>decided with reputation -- affected by connectivity and uploads</li> </ul> </li> </ul> </li> </ul> <p>(Query Flooding)</p> <p>Join</p> <ul> <li>client contacts super-node</li> </ul> <p>Publish</p> <ul> <li>send list of offered files to super-node</li> </ul> <p>Search</p> <ul> <li>send query to super-node<ul> <li>super-nodes flood query among themselves</li> </ul> </li> </ul> <p>Fetch</p> <ul> <li>get file directly from peer(s)</li> </ul> <p></p>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#describe-chord-routing-approach","title":"Describe Chord routing approach","text":"<ul> <li>a structured Peer-to-Peer network</li> <li>GUID based API<ul> <li><code>put(GUID, data)</code><ul> <li>store data in replicas responsible for object based on GUID</li> </ul> </li> <li><code>remove(GUID)</code><ul> <li>delete references to GUID and data</li> </ul> </li> <li><code>value = get(GUID)</code><ul> <li>data retrieved from one responsible node</li> </ul> </li> </ul> </li> </ul> <ul> <li>Nodes maintain pointer to successor</li> <li>Node 8 responsible for GUID in [5,8]</li> <li>Node 15 for [9,15]</li> <li>Node 20 for [16, 20]</li> <li>...</li> <li>Node 4 for [59, 4]</li> </ul> <p>Lookup</p> <ul> <li>Route packet sent to the node responsible for ID using successor pointer</li> </ul> <p></p>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#robustness","title":"Robustness","text":"<ul> <li>Nodes periodically sends <code>stabilize()</code> messages to successor</li> <li>Successor returns its predecessor with <code>notify(predecessor)</code> message</li> <li>When receiving <code>notify(predecessor)</code><ul> <li>if predecessor changed update successor</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#finger-tables","title":"Finger Tables","text":"<ul> <li>Increased efficiency using Finger Tables</li> </ul> <ul> <li> <p>ith entry at peer with id n is first peer with id \\geq n+2^i (\\mod 2^m)</p> </li> <li> <p>O(log(N))O(log(N)) for lookup</p> </li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#discuss-pastrytapestry-as-differences-from-chord","title":"Discuss Pastry/Tapestry, as differences from Chord","text":"<ul> <li> <p>Assigns hexadecimal ids to nodes, just like Chord (using a virtual ring)</p> </li> <li> <p>Leaf Set - Each node knows its successor(s) and predecessor(s)</p> </li> <li>Routing tables based on prefix matching</li> </ul> <p></p> <ul> <li>Example of routing table -- GUID <code>65A1...</code></li> <li>Contains rows for each combination each combination with matching prefix</li> </ul> <p></p> <ul> <li>Message can be delivered in \\log_{16} (N)\\log_{16} (N) hops</li> </ul>"},{"location":"7-semester/DS/exam/8-peer-to-peer/#tapestry","title":"Tapestry","text":"<ul> <li>Works like Pastry</li> <li>Main difference: flexibility since application can place replicas close (in network distance) to frequent users of resources for:<ul> <li>reduced latency</li> <li>minimized network load</li> <li>tolerance of network and host failures</li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/9-blockchain/","title":"Question 9 - Blockchain (Tamper-free linked lists, Nakamoto Consensus, proof of work, transactions in Merkle trees)","text":"<ul> <li>Explain the characteristics of the blocks in a blockchain (e.g.: immutability, linear growth)</li> <li>Explain how the crypto tools used in blockchain work (hash function, signature, merkle tree, hash pointer) and how they are used in the blockchain</li> <li>Explain why Paxos consensus is not enough for a blockchain, e.g.: to protect against the double spending conundrum</li> <li>Bitcoin: explain the structure of the transaction and how they are verified by the miner</li> </ul>"},{"location":"7-semester/DS/exam/9-blockchain/#explain-the-characteristics-of-the-blocks-in-a-blockchain-eg-immutability-linear-growth","title":"Explain the characteristics of the blocks in a blockchain (e.g.: immutability, linear growth)","text":"<p>Blocks in a blockchain are immutable</p> <ul> <li>if a block is changed -- it can be detected in subsequent blocks easily</li> <li>\"tamper-proof linked list\"</li> </ul> <p>Blocks are of the same size and grows linearly</p> <ul> <li>we only have one chain</li> <li>if forks are created -- the longest chain has consensus</li> </ul>"},{"location":"7-semester/DS/exam/9-blockchain/#explain-how-the-crypto-tools-used-in-blockchain-work-hash-function-signature-merkle-tree-hash-pointer-and-how-they-are-used-in-the-blockchain","title":"Explain how the crypto tools used in blockchain work (hash function, signature, merkle tree, hash pointer) and how they are used in the blockchain","text":"<p>Cryptographic hash function is basis for the blockchain</p> <ul> <li>Function that takes input and produces fixed length output</li> <li>Small change in input -- completely different output</li> <li>Hard to find input that produces given output</li> <li>Hard to find 1 input that produces same output as given input</li> <li>Hard to find 2 inputs that produces same output</li> <li>Commonly used algorithm is SHA-256</li> <li>for example used in proof-of-work puzzle</li> </ul> <p>Block-chain built around hash-pointers</p> <p></p> <ul> <li>Contains a pointer to some data as well as hash of that data</li> <li>used to verify that data has not changed</li> <li>block-chain consists of a chain of blocks connected by hash-pointers<ul> <li>if data changes in one block it can be spotted in following blocks</li> </ul> </li> </ul> <p></p> <p>Asymmetric Cryptography used to create digital signatures</p> <ul> <li>consists of a public and private key<ul> <li>private key is kept private</li> </ul> </li> <li>signature can be created by signing message with private key<ul> <li>can then be decrypted with public key</li> </ul> </li> <li>Used by block-chain to sign transactions<ul> <li>if transaction is changed -- signature is no longer valid</li> </ul> </li> </ul> <p>Transactions in block is contained in Merkle Tree</p> <p></p> <ul> <li>Created by first hashing leaves<ul> <li>then hashing concatenation of hashes of neighboring leaves</li> <li>then hashing concatenation of those</li> <li>lastly we get Merkle Root</li> </ul> </li> <li>if leaf is corrupted -- invalidates whole branch<ul> <li>detectable at root</li> </ul> </li> <li>If I have to check a transaction in block<ul> <li>only have to calculate hashes of branch instead of all transactions</li> <li>example -- check A<ul> <li>hash A -- Hash H1 || H2 -- Hash H12 || H34</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/DS/exam/9-blockchain/#explain-why-paxos-consensus-is-not-enough-for-a-blockchain-eg-to-protect-against-the-double-spending-conundrum","title":"Explain why Paxos consensus is not enough for a blockchain, e.g.: to protect against the double spending conundrum","text":"<p>Double spend conundrum means spending money twice</p> <ul> <li>I write transaction 100$ to A in block and send to A</li> <li> <p>I write transaction 100$ to B in block and send to B</p> </li> <li> <p>We need to have only one valid block-chain</p> </li> </ul> <p>If we use Paxos we have a problem</p> <ul> <li>Paxos based on majority of acceptors</li> <li>Easy to double-spender to create many fake ids after getting product/service from first spend<ul> <li>called sybil attack</li> <li>gets majority -- distribute second block-chain -- double spend</li> </ul> </li> </ul> <p>Instead Bitcoin uses Nakamoto Consensus -- based on proof-of-work</p> <ul> <li>make it hard to add new blocks to blockchain</li> <li>proof of work puzzle<ul> <li>insert nonce into header</li> <li>need to find nonce such that hash of header starts with n zeros<ul> <li>n defines how hard puzzle is</li> </ul> </li> <li>when nonce is found new blockchain can be added</li> </ul> </li> <li>longest chain always wins</li> </ul>"},{"location":"7-semester/DS/exam/9-blockchain/#bitcoin-explain-the-structure-of-the-transaction-and-how-they-are-verified-by-the-miner","title":"Bitcoin: explain the structure of the transaction and how they are verified by the miner","text":"<p>A transaction consists of</p> <ul> <li>list of input transaction<ul> <li>previous transaction transferring money to user </li> </ul> </li> <li>list of output identity + amount</li> <li>signature<ul> <li>messaged signed with users private key</li> </ul> </li> </ul> <p>A user is a pair of private key and public key -- only public key is known</p> <p>When transaction is signed -- broadcast to network of nodes -- saved in mempool</p> <ul> <li>Miners validate transactions by checking previous transactions and verifying signature</li> <li>When miner complete puzzle -- add transactions to blockchain</li> </ul>"},{"location":"7-semester/PP/","title":"PP - Programming Paradigms","text":"<p>Moodle page:</p> <p>https://www.moodle.aau.dk/course/view.php?id=34737</p> <p></p>"},{"location":"7-semester/PP/Logic/semantics/","title":"Semantics of Datalog / Prolog","text":""},{"location":"7-semester/PP/Logic/semantics/#herbrand","title":"Herbrand","text":"<p>Lets consider an example</p> <pre><code>grandparent(X,Y) :- parent(X,Z), parent(Z,X).\nparent(magrethe, frederik).\nparent(frederik, christian).\nparent(frederik, isabella).\nparent(frederik, vincent).\nparent(frederik, josephine).\n</code></pre>"},{"location":"7-semester/PP/Logic/semantics/#herbrand-universe","title":"Herbrand Universe","text":"<p>The Herbrand Universe U_P of a logic program PP is the set consisting of all constants that appear anywhere in PP</p> <p>The Herbrand Universe of our example is the set:</p> <ul> <li><code>{magrethe, frederik, christian, isabella, vincent, josephine}</code></li> </ul>"},{"location":"7-semester/PP/Logic/semantics/#herbrand-base","title":"Herbrand Base","text":"<p>Recall that a ground atom is an atom that contains no variables. The Herbrand base B_PB_P of a logic program PP is the set consisting of ground atoms that can be built over U_PU_P using the predicates in PP using the correct arity (number of arguments)</p> <p>The Herbrand base of our example program is the set:</p> <p></p>"},{"location":"7-semester/PP/Logic/semantics/#what-is-the-herbrand-base","title":"What is the Herbrand base?","text":"<p>The Herbrand base contains three kinds of atoms:</p> <ol> <li>The immediate facts in the extensional database<ul> <li>Here, e.g: <code>parent(margrethe, frederik)</code></li> </ul> </li> <li>The derivable facts in the intensional database<ul> <li>Here, e.g.: <code>grandparent(margrethe, isabella)</code></li> </ul> </li> <li>All other facts - that cannot be derived<ul> <li>Here, e.g.: <code>parent(frederik, margrethe)</code></li> </ul> </li> </ol>"},{"location":"7-semester/PP/Logic/semantics/#interpretations","title":"Interpretations","text":"<p>An interpretation \\mathcal I\\mathcal I is a set of atoms from the Herbrand base.</p> <p>A subset of the Herbrand base.</p> <p>For instance the following is an interpretation:</p> <ul> <li><code>{parent(margrethe, frederik), grandparent(margrethe, isabella)}</code></li> </ul>"},{"location":"7-semester/PP/Logic/semantics/#truth-under-an-interpretation","title":"Truth under an interpretation","text":"<p>We define when a clause \\mathcal C\\mathcal C is true under an interpretation \\mathcal I\\mathcal I. We write $\\mathcal I \\models \\mathcal C $</p> <p>We have:</p> <ul> <li>\\mathcal I \\models p(k_1, \\dots k_n)\\mathcal I \\models p(k_1, \\dots k_n) if p(k_1, \\dots, k_n) \\in \\mathcal Ip(k_1, \\dots, k_n) \\in \\mathcal I</li> <li>\\mathcal I \\models A_0 \\Leftarrow A_1, \\dots, A_n\\mathcal I \\models A_0 \\Leftarrow A_1, \\dots, A_n if whenever \\mathcal I \\models A_i\\mathcal I \\models A_i for all 1 \\leq i \\leq n1 \\leq i \\leq n then \\mathcal I \\models A_0\\mathcal I \\models A_0</li> </ul> <p>The last condition is equivalent to requiring that either the head is true or every clause in the body is false.</p> <p>For a problem about interpretations and truth, see problem set 2, problem 1 on Moodle.</p>"},{"location":"7-semester/PP/exam/","title":"PP Exam","text":"<p>Moodle page</p>"},{"location":"7-semester/PP/exam/#scheme","title":"Scheme","text":"<p>Literature overview</p> <p>Main scheme literature</p>"},{"location":"7-semester/PP/exam/#haskell","title":"Haskell","text":"<p>Hans' self written literature about Haskell</p> <p>Haskell documentation</p>"},{"location":"7-semester/PP/exam/#datalogprolog","title":"Datalog/Prolog","text":"<p>Main datalog/prolog literature</p>"},{"location":"7-semester/PP/exam/datalog-and-prolog/","title":"Datalog and Prolog","text":""},{"location":"7-semester/PP/exam/datalog-and-prolog/#datalog","title":"Datalog","text":""},{"location":"7-semester/PP/exam/datalog-and-prolog/#semantics","title":"Semantics","text":"<p>Datalog Semantics</p>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#computing-minimal-model","title":"Computing Minimal Model","text":"<p>Problem set 2 - Problem 4</p> <p>Slides 2 - Slide 19-23</p>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#stratification","title":"Stratification","text":"<p>Slides 2 - 31-40</p> <ul> <li>If there is a rule A(\\cdots) \\Leftarrow \\cdots B(\\cdots) \\cdots there is a positive edge from B to A (mark it with a +)</li> </ul> <p></p> <ul> <li>If there is a rule A(\\cdots) \\Leftarrow \\cdots \\textbf{not } B(\\cdots) \\cdotsA(\\cdots) \\Leftarrow \\cdots \\textbf{not } B(\\cdots) \\cdots there is a negative edge from B to A (mark it with a -)</li> </ul> <p></p> <ul> <li>If there are no cycles with a negative edge, the program is stratifiable.</li> </ul> <p>Topological sort</p> <ul> <li>Start with a vertex/node with in degree 0</li> <li>Think of an edge from node1 to node2, means that node1 must be defined before node2. An edge only descirbes a relationship between the two involved nodes and nothing else</li> </ul>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#syntax","title":"Syntax","text":"<p>A Datalog program is a finite sequence of Horn clauses.</p>  \\begin{align*}     &amp;P \\in \\textbf{Program}  &amp;&amp;P ::= C_1 ... C_m\\\\     &amp;C \\in \\textbf{Clause} &amp;&amp;C ::= A_0 \\Leftarrow A_1 ... A_n\\\\ \\end{align*}   \\begin{align*}     &amp;P \\in \\textbf{Program}  &amp;&amp;P ::= C_1 ... C_m\\\\     &amp;C \\in \\textbf{Clause} &amp;&amp;C ::= A_0 \\Leftarrow A_1 ... A_n\\\\ \\end{align*}  <p>Where A_0A_0 is called the head of the clause and A_1 \\dots A_nA_1 \\dots A_n is called the body</p> <p>If n=0n=0 the clause if called a fact</p>      A \\in \\textbf{Atom}\\qquad A ::= p(t_1 ... t_n)       A \\in \\textbf{Atom}\\qquad A ::= p(t_1 ... t_n)  <p>Where pp is a predicate symbol, which is an identifier</p>      t \\in \\textbf{Term} \\qquad t ::= k \\mid x       t \\in \\textbf{Term} \\qquad t ::= k \\mid x  <p>Here kk is the set of constants (strings and numerals), while xx is the set of variables</p>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#ground-atoms-and-rules","title":"Ground Atoms and Rules","text":"<ul> <li>An atom is a ground atom if it does not contain variables<ul> <li><code>married(frederik,marie)</code> is ground, while</li> <li><code>married(frederik,X)</code> is not ground</li> </ul> </li> <li>A rule is a ground rule if it does not contain variables<ul> <li><code>royal(marie) :- married(marie,mary), royal(mary).</code> is ground, while</li> <li><code>royal(X) :- married(X,Y), royal(Y).</code> is not ground</li> </ul> </li> </ul>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#ground-instance","title":"Ground Instance","text":"<p>From artificial intelligence book </p> <p>A ground instance of a clause is obtained by uniformly substituting constants for the variables in the clause. The constants required are those appearing in the knowledge base or in the query. If there are no constants in the knowledge base or the query, one must be invented.</p> <p>Suppose the knowledge base is:</p> <p></p> <p>Then the set of all ground instances is:</p> <p></p>"},{"location":"7-semester/PP/exam/datalog-and-prolog/#datalog-vs-prolog","title":"Datalog vs Prolog","text":"<ul> <li>Datalog does not have negation while Prolog does</li> <li>Datalog does not have functions</li> <li>Datalog cannot have facts that are not ground atoms</li> <li>(maybe? Based on example exam questions) In Datalog every rule must only contain variables</li> </ul>"},{"location":"7-semester/PP/exam/haskell/","title":"Haskell","text":""},{"location":"7-semester/PP/exam/haskell/#functions","title":"Functions","text":""},{"location":"7-semester/PP/exam/haskell/#picking-function-based-on-type","title":"Picking function based on type","text":"<p>Given the type <pre><code>data Branching a = Element a | Branch ( Branching a) ( Branching a)\n</code></pre> We can design a recursive count function <pre><code>count (Branch l r) = count l + count r count (Element e)  = 1\n</code></pre> See the miniproject for more examples</p>"},{"location":"7-semester/PP/exam/haskell/#types","title":"Types","text":"<p>In <pre><code>(Eq a, Num b) =&gt; (a,a) -&gt; b\n</code></pre> we say that * <code>a</code> and <code>b</code> are type variables     * \"unknown types that we must find on the way\" * <code>Eq</code> and <code>Num</code> are type classes     * defines that every type <code>a</code> from this class has some functions defined on it         * e.g. <code>Eq a</code> -- <code>a</code> has a function <code>==</code> with type <code>a -&gt; a -&gt; Bool</code></p>"},{"location":"7-semester/PP/exam/haskell/#type-and-term-constructor","title":"Type and Term Constructor","text":"<p>Example</p> <p><pre><code>data BTree a = BLeaf a | BBranch (a,Tree a,Tree a)\n</code></pre> * <code>BTree</code> is a type constructor, since it is used to construct a type * <code>BLeaf</code> and <code>BBranch</code> are term constructors, since they are used to build a term</p>"},{"location":"7-semester/PP/exam/haskell/#polymorphism","title":"Polymorphism","text":"<ul> <li>Ad hoc-polymorphism <ul> <li>In ad hoc-polymorphism, a polymorphic function really stands for a collection of different implementations corresponding to different uses. </li> <li>This is sometimes called overloading.</li> </ul> </li> <li>Parametric polymorphism<ul> <li>In parametric polymorphism, a polymorphic function is a general implementation with a general type.</li> </ul> </li> </ul>"},{"location":"7-semester/PP/exam/haskell/#pattern-matching","title":"Pattern Matching","text":"<ul> <li><code>(x:xs)</code> (list pattern) matches a non-empty list where the first element is bound to <code>x</code> and the rest bound to <code>xs</code></li> </ul>"},{"location":"7-semester/PP/exam/haskell/#list-comprehension","title":"List Comprehension","text":"<p>Video about list comprehension</p> <p>We can generate all even numbers with: <pre><code>evens = [2 * i | i &lt;- [1..]]\n</code></pre> * The right side is called the generator (<code>i &lt;- [1..]</code>)</p> <p>List comprehensions can be nested such as:</p> <p><pre><code>pairs = [[(i,j) | i &lt;- [1,2]] | j &lt;- [1..]]\n</code></pre> * This will give the pairs <code>[[(1,1), (2,1)], [(1,2), (2,2)], ...]</code></p> <ul> <li>List comprehension = <ul> <li>ranges  (generators) +</li> <li>filters (guards)</li> </ul> </li> </ul>"},{"location":"7-semester/PP/exam/scheme/","title":"Scheme","text":""},{"location":"7-semester/PP/exam/scheme/#delayed-evaluation-and-streams","title":"Delayed Evaluation and Streams","text":"<p>Two new primitives</p> <ul> <li><code>(delay expr) =&gt; promise</code></li> <li><code>(force promise) =&gt; value</code></li> </ul>"},{"location":"7-semester/PP/exam/scheme/#stream-functions","title":"Stream Functions","text":"<ul> <li> <p><code>(cons-stream a b)</code> ~ <code>(cons a (delay b))</code></p> </li> <li> <p><code>(define head car)</code></p> <ul> <li>Gets head of stream</li> </ul> </li> <li> <p><code>(tail stream)</code></p> <ul> <li>Get tail of the stream</li> </ul> </li> <li> <p><code>(stream-section n stream)</code></p> <ul> <li>Gives the n first elements of the stream</li> </ul> </li> <li><code>(add-streams s1 s2)</code><ul> <li>Pairwise addition of the two streams</li> </ul> </li> </ul> <p>Example - Fibonacci Stream</p> <pre><code>(define fibs\n(cons-stream 0\n(cons-stream 1\n(add-streams (tail fibs) fibs))))\n</code></pre>"},{"location":"7-semester/PP/exam/scheme/#rewrite-rules","title":"Rewrite Rules","text":""},{"location":"7-semester/PP/exam/scheme/#alpha-rule","title":"Alpha Rule","text":"<p>Formal parameters of a lambda expression can be substituted by other names, which are not used as free names in the body</p> <p>Legal Conversion <pre><code>(lambda (x y) (f x y))  =&gt;  (lambda (a b) (f a b))\n</code></pre></p> <p>Illegal Conversion <pre><code>(lambda (x y) (f x y))  =/&gt; (lambda (a f) (f a f))\n</code></pre></p>"},{"location":"7-semester/PP/exam/scheme/#beta-rule","title":"Beta Rule","text":"<p>An application of a function can be substituted by the function body, in which formal parameters are substituted by the corresponding actual parameters</p> <p>Legal Conversion <pre><code>((lambda(x) (f x)) a)                    =&gt;  (f a)\n((lambda(x y) (* x (+ x y))) (+ 3 4) 5)  =&gt;  (* 7 (+ 7 5))\n((lambda(x y) (* x (+ x y))) (+ 3 4) 5)  =&gt;  (* (+ 3 4) (+ (+ 3 4) 5))\n</code></pre></p>"},{"location":"7-semester/PP/exam/scheme/#eta-rule","title":"Eta Rule","text":"<p>A function <code>f</code>, which only passes its parameters on to another function <code>e</code>, can be substituted by <code>e</code></p> <pre><code>(lambda(x) (e x)) &lt;=&gt; e provided that x is not free in the expression e\n</code></pre> <p>Legal Conversion</p> <pre><code>(lambda (x) (square x))               =&gt; square\n(lambda (x) ((lambda(y) (* y y)) x))  =&gt; (lambda(y) (* y y))\n</code></pre> <p>Illegal Conversion</p> <pre><code>(lambda(x) ((lambda(y) (f x y)) x))  =&gt; (lambda(y) (f x y))\n</code></pre>"},{"location":"7-semester/PP/exam/solutions/01-scheme/","title":"Scheme Exercises","text":"<p>Exercises 1</p> <p>Exercises 2</p> <p>Exercises 3 </p> <p>Exercises 4</p>"},{"location":"7-semester/PP/exam/solutions/02-haskell/","title":"Haskell Exercises","text":"<p>Exercises 6</p> <p>Exercises 7</p> <p>Exercises 8+9</p>"},{"location":"7-semester/PP/exam/solutions/03-datalog-prolog/","title":"Datalog and Prolog Exercises","text":"<p>Exercises 1</p> <p>Exercises 2</p> <p>Exercises 3</p>"},{"location":"7-semester/WI/","title":"WI - Web Intelligence","text":"<p>Moodle page:</p> <p>https://www.moodle.aau.dk/course/view.php?id=34715</p> <p></p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/","title":"Introduction and Crawlers","text":"<ul> <li>Book - Chapter 20</li> <li>Slides</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#what-is-the-web","title":"What is the web?","text":"<p>Simple definition:</p> <p>Hyper-linked network of web pages</p> <p></p> <p>Number of web-pages indexed by Google estimated by https://www.worldwidewebsize.com/</p> <p></p> <p>A page may contain multi-media content</p> <p>We focus on text in this course (we view web pages as documents of texts)</p> <ul> <li>Carries the most important information (in most cases)</li> <li>Techniques used for dealing with text can be adapted to dealing with other types of data (cf. \u201cvisual words\u201d in computer vision).</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#what-is-web-intelligence","title":"What is web intelligence?","text":"<p>Intelligent ways to extract information and knowledge from the web:</p> <ul> <li>I finding relevant information available on the web</li> <li>obtaining new knowledge by analyzing web data: the web itself, but also how it evolves, and how users interact on and with the web</li> </ul> <p>Some applications:</p> <ul> <li>Intelligent Search</li> <li>Recommender Systems</li> <li>Business Analytics</li> <li>Crowd Sourcing</li> <li>Not so nice ones:<ul> <li>Advertising</li> <li>Manipulation</li> <li>Surveillance </li> </ul> </li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#web-crawlers","title":"Web Crawlers","text":"<p>Before we can do anything, web data needs to be retrieved and organized:</p> <p></p> <pre><code>Crawl(URL set: seeds):\n    frontier = seeds\n    while frontier != \u00d8 do\n        url = get_url(frontier) // select next URL from frontier\n        doc = fetch(url)        // pages returned as html source text docs\n        index(doc)                          // send doc to indexer\n        frontier.add(extract_urls(doc))\n  end\n</code></pre> <p>Key design issue</p> <ul> <li>the frontier of URLs to be processed</li> <li>selection strategy implementing <code>get_url</code></li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#two-simplistic-solutions","title":"Two simplistic solutions","text":"<ul> <li>frontier as stack<ul> <li>leads to depth-first seach</li> <li>Problem<ul> <li>can get quickly stuck in \"dead end\" remote corners of the web</li> </ul> </li> </ul> </li> <li>frontier as queue<ul> <li>leads to breadth-first seach</li> <li>Problem<ul> <li>slow progress, lacking politeness</li> </ul> </li> </ul> </li> </ul> <p>Both are too simple because</p> <ul> <li>a pure sequential, single thread architecture will get stuck once a host does not respond (quickly) to a fetch(url) request</li> <li>crawler must implement robustness<ul> <li>not get stuck in spider traps, i.e., large, dead-end (uninteresting) web components<ul> <li>spider traps \"... are generators of web pages that mislead crawlers into getting stuck fetching an infinite number of pages in a particular domain. Crawlers must be designed to be resilient to such traps. Not all such traps are malicious; some are the inadvertent side-effect of faulty website development.\" Chapter 20</li> </ul> </li> </ul> </li> <li>crawler must implement politeness<ul> <li>not overload a single web server with requests</li> </ul> </li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#crawler-types-and-prioritization","title":"Crawler Types and Prioritization","text":"<p>Crawlers can have different purposes:</p> <ul> <li>Periodic<ul> <li>maintain an up-to-date general picture of the web<ul> <li>the same pages (URLs) should be revisited periodically</li> </ul> </li> </ul> </li> <li>Focused<ul> <li>map a part of the web pertaining to a particular topic</li> </ul> </li> </ul> <p>Implemented by</p> <ul> <li><code>index(doc)</code><ul> <li>maybe not every fetched document needs to be added to the index</li> </ul> </li> <li>frontier.add(extract_urls(doc))<ul> <li>extracted URLs may be added to the frontier with different priorities<ul> <li>URLs that have already been recently visited have a lower priority (periodic crawling)</li> <li>URLs that are less likely to refer to relevant pages have a lower priority (focused crawling)</li> <li>...</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#politeness","title":"Politeness","text":"<ul> <li>Minimum time delay between two request to one host</li> <li>Obey <code>robots.txt</code> file</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#robottxt","title":"robot.txt","text":"<p>Text file at top level of domain: <code>http://domain.com/robots.txt</code>. Provides instructions to crawlers.</p> <p>Don\u2019t allow any crawlers to go to <code>/private/</code> directory: </p> <pre><code>User-agent: * \nDisallow: /private/\n</code></pre> <p>Allow all crawlers all access, except <code>googlebot</code> is not allowed in <code>/tmp/</code>:</p> <pre><code>User-agent: *\nDisallow:\nUser-agent: googlebot\nDisallow: /tmp/\n</code></pre> <p>Non-standard extension of <code>robots.txt</code>: request delay between successive visits:</p> <pre><code>User-agent: bingbot\nCrawl-delay: 5\n</code></pre> <p>The interpretation of the delay values can be crawler specific</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#mercator-frontier","title":"Mercator Frontier","text":"<p>Heydon, A., &amp; Najork, M. (1999). Mercator: A scalable, extensible web crawler. World Wide Web, 2(4), 219-229.</p> <p></p> <p>Front queues: for prioritization</p> <p>Back queues: for politeness</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#mercator-front-queues","title":"Mercator Front Queues","text":"<p>Fixed number of K FIFO queues:</p> <p></p> <ul> <li>Incoming URLs are assigned a priority value between 1 and K, and enqueued in the corresponding front queue.</li> <li>URLs are extracted by<ul> <li>Selecting (e.g. randomized) one of the front queues; higher priority queues are more likely to be selected</li> <li>Dequeuing the head element from the selected queue</li> </ul> </li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#mercator-back-queues","title":"Mercator Back Queues","text":"<p>Fixed number of B FIFO queues:</p> <p></p> <ul> <li>Each back queue contains URLs from only one host</li> <li>Each queue/host has an entry in a priority queue (heap) that determines from which back queue the next URL will be extracted</li> <li>Priority value: time stamp at which next request to host can be made at the earliest (following politeness policy)</li> </ul> <p>Getting the next URL:</p> <ul> <li>Determine highest priority host</li> <li>Dequeue head element from corresponding queue</li> <li>Update priority value of host</li> </ul> <p>If queue of selected host becomes empty, refill back-queues from front queues as follows</p> <ul> <li>Get the next URL url from front queues</li> <li>If url's host already has a back queue: enqueue there<ul> <li>otherwise<ul> <li>enqueue url in the empty queue</li> <li>update heap and host dictionary</li> </ul> </li> </ul> </li> <li>Reapeat until queue non-empty</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#distributed-crawling","title":"Distributed Crawling","text":"<p>In practice: use multiple crawlers</p> <ul> <li>Each crawler has its own URL frontier</li> <li>URLs are distributed over crawlers according to host: each crawler is responsible for a certain set of hosts (e.g. defined by a hash function, or geographically)</li> <li>The <code>frontier.add(extract_urls(doc))</code> operation must add URLs to the frontier of the relevant crawler</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#duplicate-identification","title":"Duplicate Identification","text":"<p>Many web-pages are duplicates or near-duplicates of other pages:</p> <ul> <li>Mirrors</li> <li>Identical product descriptions, user manuals, etc. contained on diverse web sites</li> <li>...</li> </ul> <p>Estimate: as many as 40% of pages have duplicates [Manning et al., 2009]</p> <ul> <li>May not want to include all duplicates in index</li> <li>The <code>index(doc)</code> operation may include a prior test whether <code>doc</code> is a (near-)duplicate of an already indexed page</li> </ul> <p>We only consider the texts of the pages!</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#fingerprints","title":"Fingerprints","text":"<p>If we wanted to detect identical texts, things would be relatively easy: construct a hash code</p>  text \\to \\text{64bit intergers}   text \\to \\text{64bit intergers}  <p>such that non-identical texts are unlikely to be mapped to the same integer (1.8\\cdot 10^{19}1.8\\cdot 10^{19} codes vs ~10^{11}10^{11} web documents).</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#shingles","title":"Shingles","text":"<p>k-shingles or k-grams</p> <p>We view text as a set of consecutive sequences of kk words:</p> <pre><code>we view text as a sequence of words\nwe view text as\n     view text as a\n                text as a sequence\n                         as a sequence of\n                                a sequence of words\n</code></pre> <p>4-shingle representation:</p> <p>{ as a sequence of, a sequence of words, text as a sequence, view text as a, we view text as }</p> <ul> <li>Order of occurrence of shingles is not included in representation</li> <li>Number of occurrences of a shingle is not included in representation</li> <li>Some pre-processing of raw html text before shingling (e.g.: ignore case, remove html tags)</li> </ul> <p>Assuming a fixed vocabulary of size NN there are N^4N^4 different 4-shingles, and we can identify them with the integers 0,\\dots,N^4 - 10,\\dots,N^4 - 1</p> <p>[Broder, Andrei Z., et al. \"Syntactic clustering of the web.\" Computer networks and ISDN systems 29.8-13 (1997): 1157-1166.]</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#jaccard-coefficient","title":"Jaccard Coefficient","text":"<p>For any two finite sets A, B, define</p>  J(A,B):=\\frac {|A\\cap B|} {|A \\cup B|}   J(A,B):=\\frac {|A\\cap B|} {|A \\cup B|}  <p>J(A,B)J(A,B) measures the overlap relative to the total size of the sets</p> <p></p> <p>We measure the similarity of text documents d_1, d_2d_1, d_2 by the Jaccard Coefficient of their shingle sets S(d_1), S(d_2)S(d_1), S(d_2)</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#sketches","title":"Sketches","text":"<p>Estimating J(S(d_1), S(d_2)):J(S(d_1), S(d_2)):</p> <ul> <li>Let \\pi\\pi be a random permutation of the integers 0,\\dots,N^4 -10,\\dots,N^4 -1</li> <li>For j=1,2j=1,2: let x_j^\\pi:=\\min \\{\\pi(x):x\\in S(d_j\\}x_j^\\pi:=\\min \\{\\pi(x):x\\in S(d_j\\}<ul> <li>Then:</li> </ul> </li> </ul>  J(S(d:_1), S(d_2)) = P(x_1^\\pi = x_2^\\pi)   J(S(d:_1), S(d_2)) = P(x_1^\\pi = x_2^\\pi)  <p>where PP is the probability over the selection of a random permutation \\pi\\pi</p> <p></p> <p>P(x_1^\\pi = x_2^\\pi)P(x_1^\\pi = x_2^\\pi) = probability that the minimum value \\min \\pi(S(d_1)\\cup S(d_2))\\min \\pi(S(d_1)\\cup S(d_2)) falls inside S(d_1)\\cap S(d_2)= J(S(d_1), S(d_2))S(d_1)\\cap S(d_2)= J(S(d_1), S(d_2))</p> <p>One random permutation does not tell us much, so we take many, e.g. \\pi_1,\\pi_2,\\dots,\\pi_{200}\\pi_1,\\pi_2,\\dots,\\pi_{200}</p> <p>Then characterize every document d_hd_h by its feature vector</p>  \\psi(d_h):=(x_h^{\\pi_1},\\dots,x_h^{\\pi_{200}}),   \\psi(d_h):=(x_h^{\\pi_1},\\dots,x_h^{\\pi_{200}}),  <p>called the sketch of d_hd_h:</p> <p></p> <p>Now we can approximately estimate the Jaccard Coefficient:</p> <p></p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#clustering-documents","title":"Clustering Documents","text":"<p>Given a collection of documents</p> <p></p> <p>Group documents into clusters, so that near-duplicates are in one cluster</p> <p>Supports: </p> <p>(from google)</p> <p></p> <ul> <li>Caution: this does not mean that all documents in a cluster are near-duplicates!</li> <li>Will give useful results only if there are no long near-duplicate paths leading from one document to a totally different one</li> </ul>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#naive-algorithm","title":"Na\u00efve Algorithm","text":"<p>Na\u00efve agglomerative single-link clustering using a union-find data structure:</p> <p></p> <ul> <li>line 3: can be approximated using sketches</li> <li>line 4: two find and (at most) one union operation</li> </ul> <p>Complexity is \\Theta(N^2)\\Theta(N^2) which is already infeasible!</p> <p>Basic strategy: filter out pairs d_i,d_jd_i,d_j for which J(S(d_i), S(d_j)) &gt;tJ(S(d_i), S(d_j)) &gt;t surely will not hold</p>"},{"location":"7-semester/WI/01-introduction-and-crawlers/#filtering-with-sketches","title":"Filtering with Sketches","text":"<p>Generate pairs of documents whose sketches have at least one component in common:</p> <p></p> <ul> <li>Not counting line 5, the complexity is O(N \\log N)O(N \\log N)</li> <li>Line 5 can stile generate a large number of pairs (think of rather common shingles, e.g. \"this is not a\")</li> <li>The same pair (d_h,d_{h'}d_h,d_{h'}) may be returned for different values of kk</li> </ul> <p>From sketches to super-shingles (shingling shingles):</p> <p></p> <p>Documents with large sketch overlap are likely to have super-shingles in common</p> <p>Filtering based on super-shingles:</p> <ul> <li>Generate list of \\langle \\textit{super-shingle, document} \\rangle\\langle \\textit{super-shingle, document} \\rangle</li> <li>Sort on first component, return pairs of second components</li> </ul> <p>This is quite heuristic!</p>"},{"location":"7-semester/WI/02-index-construction/","title":"Index Construction","text":"<ul> <li>Slides</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#text-preprocessing","title":"Text Preprocessing","text":"<p>How to construct the index?</p> <ul> <li>Depends on: what type of search (and: analytics) do we want to support?</li> </ul> <p>For now:  think about Boolean queries over single search terms:</p> <ul> <li>(Corona OR Covid) AND vaccination</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#from-byte-stream-to-index-terms","title":"From Byte Stream to Index Terms","text":""},{"location":"7-semester/WI/02-index-construction/#tokenization","title":"Tokenization","text":"<p>Initial heuristic for English (or Danish, German, ...):</p> <ul> <li>split on whitespace</li> <li>delete punctuation characters</li> </ul> <p>But:</p> <ul> <li> <p>some things should perhaps not be split:</p> <p> </p> </li> <li> <p>May also need to split where there is no white space:</p> <p></p> </li> </ul> <p>No golden bullet! Lots of language or domain-specific rules and heuristics.</p>"},{"location":"7-semester/WI/02-index-construction/#normalization","title":"Normalization","text":"<p>Transform distinct \u2019equivalent\u2019 tokens into one normalized form. E.g.:</p> <ul> <li>write all in lower case: <code>This</code> \\to <code>this</code></li> <li>use non-hyphenated forms: <code>anti-discriminatory</code> \\to\\to <code>antidiscriminatory</code></li> <li>delete periods: <code>U.S.A</code> \\to\\to <code>USA</code> (or <code>usa</code>)</li> </ul> <p>Have to balance:</p> <ul> <li>more normalization:<ul> <li>smaller index</li> <li>more permissive search: user searching for \u2019U.S.A\u2019 also receives results containing \u2019usa\u2019</li> </ul> </li> <li>less normalization:<ul> <li>supports more specific search: users searching for \u2019C.A.T.\u2019 don\u2019t receive results for \u2019cat\u2019. (try Google vs. Bing on this one!)</li> </ul> </li> </ul>"},{"location":"7-semester/WI/02-index-construction/#stop-word-removal","title":"Stop word removal","text":"<p>Stop words: very frequent words that are not semantically descriptive:</p> <ul> <li>the, a, this, and, of, that, ...</li> </ul> <p>Stop list:  list of stop words that are removed. E.g. containing 15-200 stop words.</p> <p>Problem: stop words may become important as part of an expression:</p> <ul> <li>\u201cTo be or not to be\u201d</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#stemming","title":"Stemming","text":"<p>Similar to normalization: reduce different grammatical variants to their common underlying word \u201cstem\u201d:</p> <p>Inflectional Forms:</p> <ul> <li>learn, learns, learned \\to\\to learn</li> </ul> <p>Word types:</p> <ul> <li>organize, organizer, organization \\to\\to organ</li> </ul> <p>but also</p> <ul> <li>organ, organizer, organic \\to\\to organ</li> </ul> <p>Term</p> <p>The strings that result from stemming are the terms that will be included in the index</p>"},{"location":"7-semester/WI/02-index-construction/#porters-stemming-algorithm","title":"Porters Stemming Algorithm","text":"<p>https://tartarus.org/martin/PorterStemmer/</p> <p>Set of rules for iteratively reducing/removing suffixes of words. E.g.</p> <p></p> <p>Only the most specific (longest suffix) rule is applied. Other applicable rules are ignored</p> <ul> <li>rule SS \\to\\to SS is not redundant!</li> </ul> <p>Rules may be conditioned on what comes before the suffix: $$ (m&gt;1)\\ \\text{EMENT} \\to $$ only applies if the part before suffix EMENT has more than 1 syllable</p>"},{"location":"7-semester/WI/02-index-construction/#putting-it-all-together","title":"Putting it all together","text":"<p>Putting things together, a text is trandformed into a sequence of terms:</p> <p></p> <p>Corpus and Vocabulary</p> <p>Corpus: collection of documents (e.g., all web-pages that have been crawled)</p> <p>Vocabulary: all terms that appear in the corpus</p> <ul> <li>We now want to build an index that allows to retrieve documents in the corpus according to (search-) terms in the vocabulary.</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#inverted-index","title":"Inverted Index","text":""},{"location":"7-semester/WI/02-index-construction/#term-document-incidence-matrix","title":"Term-document incidence matrix","text":"<p>The occurrence/absence of terms in documents can be represented by a term-document incidence matrix:</p> <p></p> <p>0: term does not appear in document </p> <p>1: term appears in document</p>"},{"location":"7-semester/WI/02-index-construction/#inverted-index_1","title":"Inverted Index","text":"<p>Putting the terms in the rows, and reducing incidence (bit-)vectors to sorted lists of postings (= IDs or references of documents):</p> <p></p> <ul> <li>This is really just an index; nothing \u201cinverted\u201d about it</li> <li>This is only a schematic picture; the actual implementation will be a dictionary data structure with terms as keys</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#boolean-retrieval","title":"Boolean Retrieval","text":""},{"location":"7-semester/WI/02-index-construction/#simple-boolean-queries","title":"Simple Boolean Queries","text":"<p>Single Word Search</p> <p>Search \"Education\"</p> <ul> <li>Apply normalization and stemming: Education \\to\\to educ</li> <li>Retrieve postings for key \u201ceduc\u201d from inverted index:<ul> <li>2, 15, 7529, 43875, 884903</li> </ul> </li> </ul> <p>Boolean AND</p> <p>Search: \u201cEducation AND Book\u201d</p> <ul> <li>Retrieve postings for \u201ceduc\u201d and \u201cbook\u201d</li> <li>Construct intersection using the merge algorithm</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#merge-algorithm","title":"Merge Algorithm","text":"<p>WI 2 Slides p. 17</p>"},{"location":"7-semester/WI/02-index-construction/#other-boolean-operators","title":"Other Boolean Operators","text":"<p>OR</p> <p>term_1 OR term_2</p> <p>Variation of merge algorithm: </p> <ul> <li>append all postings from two lists to output, without duplicates (very similar to merge step in merge sort).</li> </ul> <p>NOT</p> <p>NOT term</p> <p>In principle simple: </p> <ul> <li>construct sorted list of document keys that are not in the list of term. But: output intractably large</li> </ul> <p>AND NOT</p> <p>term_1 AND NOT term_2</p> <p>Variation of merge algorithm:</p> <ul> <li>append to output all postings from term_1 list that are not found in term_2 list</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#phrase-queries","title":"Phrase Queries","text":"<p>Most users don\u2019t want to bother with properly constructed Boolean queries. More popular are phrase queries:</p> <p>\u200b   \"Graduation ceremony at Aalborg University\"</p> <p>After pre-processing (but no stopword removal!):</p> <p>\u200b   \"graduat ceremoni at aalborg univers\"</p>"},{"location":"7-semester/WI/02-index-construction/#n-gram-index","title":"N-gram Index","text":"<ul> <li>Create dictionary over N-grams of terms instead of dictionary over terms (e.g. N=2 or N=3)</li> <li>Search for<ul> <li>graduat ceremoni AND ceremoni at AND at aalborg AND aalborg univers</li> </ul> </li> <li>Can give false positives</li> </ul>"},{"location":"7-semester/WI/02-index-construction/#positional-index","title":"Positional Index","text":"<p>Augment the inverted index with</p> <ul> <li>for each term: {\\color{blue}{\\text{document frequency}}}{\\color{blue}{\\text{document frequency}}} (=length of posting list for the term)</li> <li>for each posting: {\\color{red}{\\text{number}}}{\\color{red}{\\text{number}}} and {\\color{green}{\\text{list}}}{\\color{green}{\\text{list}}} of positions at which term appears in document</li> </ul> <p></p> <p>Size</p> <ul> <li>TT: total number of terms (stop words removed) in the corpus</li> <li>KK: average number of occurrences of a given term in a document</li> </ul> <p>Then:</p> <ul> <li>space for positional index: \\Theta(T)\\Theta(T)</li> <li>space for non-positional index: \\Theta(T/K)\\Theta(T/K)</li> </ul> <p>In practice: positional index has 30% to 50% the size of the raw corpus</p>"},{"location":"7-semester/WI/02-index-construction/#answering-phrase-queries","title":"Answering Phrase Queries","text":"<p>Query: graduat ceremoni at</p> <p>Step 1</p> <p>retrieve documents for Boolean query graduat AND ceremoni AND at (can be optimized by merging posting lists with low document frequency count first)</p> <ul> <li>obtain for each retrieved document the position lists (e.g. document 5):</li> </ul> <p></p> <p>Step 2</p> <p>apply variation of merge algorithm to find consecutive occurrences of the terms</p> <p></p> <ul> <li>Can also be adjusted to deal with proximity queries:</li> </ul> <p>Graduate /5 Ceremony</p> <p>The two terms are required to occur within 5 positions of each other (any order)</p>"},{"location":"7-semester/WI/03-content-based-ranking/","title":"Content-based Ranking","text":"<ul> <li>Slides</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#content-based-ranking_1","title":"Content-based Ranking","text":""},{"location":"7-semester/WI/03-content-based-ranking/#from-matching-to-ranking","title":"From Matching to Ranking","text":"<p>For Boolean or Phrase queries:</p> <ul> <li>a document matches or does not match a query</li> <li>no preference among documents that match the query</li> <li>good results depend on well designed queries</li> </ul> <p>Now we aim for:</p> <ul> <li> <p>ranking of how well a document matches a query</p> </li> <li> <p>\u201csoft\u201d matching: no longer a yes/no decision</p> </li> <li> <p>robust performance with loosely formulated queries</p> <ul> <li> <p>instead of</p> <ul> <li>Graduation AND ceremony AND Aalbog AND University or</li> <li>\u201cGraduation ceremony at Aalborg University\u201d</li> </ul> </li> <li> <p>Just write a free text query</p> <ul> <li>Graduation ceremony at Aalborg University</li> </ul> <p>and retrieve also pages that only contain \u201cGraduation ceremony\u201d and \u201cAalborg\u201d, but not \u201cUniversity\u201d</p> </li> </ul> </li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#text-similarity","title":"Text Similarity","text":"<p>Ideas:</p> <ul> <li>Documents and queries are both text documents</li> <li>Find documents that are most similar to query</li> </ul> <p></p> <p>Need:</p> <ul> <li>(Feature) representation of documents</li> <li>Similarity measure for query Q and document D:<ul> <li>S(Q,D)</li> </ul> </li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#jaccard-revisited","title":"Jaccard Revisited","text":"<p>For near-duplicate identification, we measured the similarity of documents with the Jaccard coefficient:</p>  S(Q,D)=J(S(Q),S(D))   S(Q,D)=J(S(Q),S(D))  <p>k-shingles (k &gt; 1)(k &gt; 1) do not make much sense for queries (word order in query can be quite arbitrary). When S(Q), S(D)S(Q), S(D) are just the sets of terms (\u201c1-shingles\u201d), we can write the Jaccard coefficient as:</p>  J(Q,D) = \\sum_{t\\in \\textit{Vocabulary}} I[Q,t] \\cdot I[D,t] \\  / \\  | Q \\cup D |   J(Q,D) = \\sum_{t\\in \\textit{Vocabulary}} I[Q,t] \\cdot I[D,t] \\  / \\  | Q \\cup D |  <p>where II is the term-document incidence matrix extended with a row for the query.</p> <p>Problem: J(Q,D)J(Q,D) will be higher for smaller documents</p>"},{"location":"7-semester/WI/03-content-based-ranking/#near-duplicates-vs-similarity-for-relevance","title":"Near Duplicates vs Similarity for Relevance","text":"<p>Different requirements for text similarity measure:</p> Near duplicate identification Similarity for relevance \u201cD_1D_1 and D_2D_2 are near duplicates\u201d is a symmetric relation \u201cDD is highly relevant for QQ\u201d is not fully symmetric Need to measure similarity on a common scale for all pairs of documents S(Q, D)S(Q, D) only needs to be a relative measure for different D, for any fixed Q (no need to compare S(Q_1, D)S(Q_1, D) vs. S(Q_2, D)S(Q_2, D))"},{"location":"7-semester/WI/03-content-based-ranking/#relevance-score-v01","title":"Relevance Score v0.1","text":"<p>Omit the normalization from the Jaccard coefficient:</p>  S_{v0.1}(d,q):=\\sum_{t\\in \\textit{Vocabulary}} I[q,t] \\cdot I[d,t]   S_{v0.1}(d,q):=\\sum_{t\\in \\textit{Vocabulary}} I[q,t] \\cdot I[d,t]  <p>(= number of query terms contained in dd)</p> <p>Problem</p> <ul> <li>No difference whether documents contain a query term only once, or many times.</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#bag-of-words","title":"Bag of Words","text":"<p>Replace the term-document incidence matrix with a term-document frequency matrix FF:</p> <p></p> <p>Entries in the matrix: F[d,t]F[d,t]: frequency of term tt in document dd </p> <ul> <li>(IR book notation: \\text{tf}_{t,d}\\text{tf}_{t,d})</li> </ul> <p>Modeling a document by the counts of occurrences of words (terms) is known as the bag of words model.</p>"},{"location":"7-semester/WI/03-content-based-ranking/#relevance-score-v05","title":"Relevance Score v0.5","text":"S_{v0.5}(q,d):= \\sum_{t \\in \\textit{Vocabulary}} I[q,t] \\cdot F[d,t]   S_{v0.5}(q,d):= \\sum_{t \\in \\textit{Vocabulary}} I[q,t] \\cdot F[d,t]  <ul> <li>Queries usually contain terms only once. Therefore, no difference whether we write I[q,t]I[q,t] or F[q,t]F[q,t]</li> </ul> <p>Advantage</p> <ul> <li>Documents that contain query terms many times are probably more relevant, and score higher</li> </ul> <p>Problem</p> <ul> <li>Consider query  Siamese cats for sale.</li> </ul> <p>Relevant part of the FF matrix for three documents (assuming for removed as stop word):</p> <p></p> <p>Then</p> <ul> <li>S_{v0.5}(q,d_3) &gt; S_{v0.5}(q,d_1) &gt; S_{v0.5}(q, d_4) &gt; S_{v0.5}(q,d_2)S_{v0.5}(q,d_3) &gt; S_{v0.5}(q,d_1) &gt; S_{v0.5}(q, d_4) &gt; S_{v0.5}(q,d_2)</li> </ul> <p>Is that what we want?</p>"},{"location":"7-semester/WI/03-content-based-ranking/#term-relevance","title":"Term Relevance","text":"<p>Idea:</p> <ul> <li>terms that are more informative should contribute more to the relevance score</li> <li>very common terms are not very informative</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#collection-frequency-and-document-frequency","title":"Collection Frequency and Document Frequency","text":"\\begin{align*} &amp;\\text{Collection frequency:} &amp; \\text{cf}(t) &amp;= \\sum_{d\\in \\textit{Corpus} } F[d,t] \\\\ &amp;\\text{Document frequency:}     &amp; \\text{df}(t) &amp;= \\sum_{d\\in \\textit{Corpus} } I[d,t] \\end{align*}   \\begin{align*} &amp;\\text{Collection frequency:} &amp; \\text{cf}(t) &amp;= \\sum_{d\\in \\textit{Corpus} } F[d,t] \\\\ &amp;\\text{Document frequency:}     &amp; \\text{df}(t) &amp;= \\sum_{d\\in \\textit{Corpus} } I[d,t] \\end{align*}  <p>What to use?</p> <p></p> <p>Is cat or sale more informative/relevant?</p> <ul> <li>Lower df value means higher \"selectivity\" at the document level. We want to select documents, so we use df rather than cf!</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#from-df-to-idf","title":"From df to idf","text":"<p>N:N: size of corpus</p> <p>Then:</p> <ul> <li>df(t) \\over Ndf(t) \\over N:  fraction of documents containing NN</li> <li>N \\over df(t)N \\over df(t): inverse fraction: less common terms score higher</li> <li>\"dampening\" by taking logarithm</li> </ul>  \\text{idf}(t) = \\log \\frac{N}{\\text{df}(t)}   \\text{idf}(t) = \\log \\frac{N}{\\text{df}(t)}"},{"location":"7-semester/WI/03-content-based-ranking/#example-reuters","title":"Example: Reuters","text":"<p>Numbers from Reuters corpus of 806,791 documents (news articles):</p> <p></p>"},{"location":"7-semester/WI/03-content-based-ranking/#relevance-score-tf-idf","title":"Relevance Score: tf-idf","text":"<p>Adding term relevance to S_{v0.5}:S_{v0.5}:</p> <p>tf-idf score $$ S_{\\text{tf-idf}}(q,d) = \\sum_{t \\in \\textit{Vocabulary}} I[q,t] \\cdot F[d,t] \\cdot \\text{idf}(t) $$</p>"},{"location":"7-semester/WI/03-content-based-ranking/#example","title":"Example","text":"<p>q = Siamese cats for sale</p> <p></p> <ul> <li>relative order has not changed in this example ...</li> </ul> <p>Problem</p> <ul> <li>Longer documents will still get a higher score</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#vector-space-model","title":"Vector Space Model","text":"<p>MM: size of the vocabulary</p> <p>Our representations of documents and queries can be seen as M-dimensional, numeric vectors:</p> <p>Example: Vocabulary = { cat, sale }, M = 2:</p> <p></p> <p></p> <p></p>"},{"location":"7-semester/WI/03-content-based-ranking/#dot-product","title":"Dot Product","text":"<p>Two vectors in n-dimensional space:</p> <ul> <li>\\bold x = (x_1, \\dots, x_n)\\bold x = (x_1, \\dots, x_n)</li> <li>\\bold y = (y_1, \\dots, y_n)\\bold y = (y_1, \\dots, y_n)</li> </ul> <p>Their dot product:</p> <ul> <li>\\bold x \\cdot \\bold y = \\sum_{i=1}^n x_iy_i\\bold x \\cdot \\bold y = \\sum_{i=1}^n x_iy_i</li> </ul> <p>Geometric interpretation: length of projection of one vector onto the other:</p> <p></p> <p>Relationship with cosine:</p> <p></p> <ul> <li>even if \\bold x, \\bold y\\bold x, \\bold y are vectors in a high-dimensional space: two vectors always lie in a 2-d common space</li> <li>the pictures on this and previous slide also cover the high-dimensional case</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#cosine-similarity","title":"Cosine Similarity","text":"<p>Back to document vectors:</p> <p></p> <p>(d_3d_3 is the concatenation of two copies of d_2d_2).</p> <p>With similarity as dot products we get:</p>  S_{dot}(q,d_3) &gt; S_{dot}(q,d_2) &gt; S_{dot}(q,d_1)   S_{dot}(q,d_3) &gt; S_{dot}(q,d_2) &gt; S_{dot}(q,d_1)  <p>With cosine similarity</p>  S_{cosine}(q,d) = \\frac {q \\cdot d} { || q || \\cdot || d ||}   S_{cosine}(q,d) = \\frac {q \\cdot d} { || q || \\cdot || d ||}   S_{cosine}(q,d_1) &gt; S_{cosine}(q,d_2) &gt; S_{cosine}(q,d_3)   S_{cosine}(q,d_1) &gt; S_{cosine}(q,d_2) &gt; S_{cosine}(q,d_3)  <p>Intuition: </p> <ul> <li>only the \u201cmix\u201d of terms in documents counts, not the total amount.</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#normalization","title":"Normalization","text":"<p>Cosine similarity still is a plain dot product between vector representations, now including a normalization:</p> <p></p> <p>Example</p> <p></p>"},{"location":"7-semester/WI/03-content-based-ranking/#smart-notation","title":"SMART Notation","text":"<p>Document (query) vector representation: </p> <ul> <li>select a combination of term-document, term, and document features. </li> <li>Notation: concatenation of one-letter acronyms for each feature. </li> <li>Then<ul> <li>Multiply component-wise the M-dimensional term-document and term feature vectors.<ul> <li>Result: \\tilde V(d)\\tilde V(d)</li> </ul> </li> <li>Multiply \\tilde V(d)\\tilde V(d) with document feature value to get document vector V(d)V(d)</li> </ul> </li> </ul> <p>Query-Document similarity: $$ S(q,d) = V(q) \\cdot V(d) $$ Notation:</p> <ul> <li>ddd.qqq<ul> <li>where ddd, qqq are the feature combination for the document and query.</li> </ul> </li> </ul> <p>Examples:</p> <ul> <li>S_{v0.1}:S_{v0.1}: bnn.bnn</li> <li>S_{v0.5}:S_{v0.5}: nnn.bnn</li> <li>S_{\\text{tf-idf}}:S_{\\text{tf-idf}}: ntn.bnn (or nnn.btn)</li> <li>cosine or tf-idf: ntc.bnc (or nnc.btc)</li> </ul>"},{"location":"7-semester/WI/03-content-based-ranking/#computing-scores","title":"Computing Scores","text":"<p>Observation</p> <p>All term-document features f[d, t]f[d, t] are 0 if I[d, t] = 0I[d, t] = 0. Therefore</p> <p></p> <p>Skeleton Algorithm</p> <p>Retrieving top-scoring documents, for any ddd.qqq score (cf. Figure 6.14 in [Manning et al.]):</p> <p></p> <ul> <li>Line 9 can be implemented using a priority queue for the documents</li> <li>The scores array can be a bit wasteful: only documents showing up in some posting list in line 4 ever get a score update</li> <li>Line 5:<ul> <li>the postings could directly store the V(d)[t]V(d)[t] values. <ul> <li>Better: store the 3 features separately (integers instead of floats in posting lists; faster update of term feature values when documents are added to the corpus)</li> </ul> </li> <li>instead of calculating full V(d)[t]V(d)[t]: only calculate here the product of the term feature and term-document feature; multiply score(d) with the document feature once after line 8.</li> </ul> </li> </ul> <p></p>"},{"location":"7-semester/WI/04-structure-based-ranking/","title":"Structure-based Ranking","text":"<ul> <li>Slides</li> <li>Exercises</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#the-value-of-links","title":"The Value of Links","text":"<p>A tiny web:</p> <p></p> <p>Two pages with the same content. Which one is more relevant?</p> <ul> <li>Number 1, since it has more pages referencing it.</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#centrality-and-prestige","title":"Centrality and Prestige","text":"<p>Basic Graph-theory</p>"},{"location":"7-semester/WI/04-structure-based-ranking/#degree-of-a-node","title":"Degree of a node","text":""},{"location":"7-semester/WI/04-structure-based-ranking/#degree-centrality","title":"Degree Centrality","text":"<p>For undirected graphs:</p> <p></p> <p>In a graph with n nodes:</p> <ul> <li>C_D(v)= {d(v) \\over n-1}C_D(v)= {d(v) \\over n-1}</li> <li>Example:<ul> <li>C_D(a)=C_D(b)= {6\\over 27}C_D(a)=C_D(b)= {6\\over 27}</li> <li>C_D(c)= {3 \\over 27}C_D(c)= {3 \\over 27}</li> </ul> </li> </ul> <p>C_DC_D is a local measure: only depends on local neighborhood of nodes</p>"},{"location":"7-semester/WI/04-structure-based-ranking/#closeness-centrality","title":"Closeness Centrality","text":"<ul> <li>d(v,u)d(v,u): distance (= number of links on shortest connection) between vv and uu</li> <li>C_C(v)= {n-1 \\over \\sum_{u\\in V} d(v,u)}C_C(v)= {n-1 \\over \\sum_{u\\in V} d(v,u)}</li> <li>Example:<ul> <li>C_C(a)= {26 \\over 54}C_C(a)= {26 \\over 54}</li> <li>C_C(b) = {26\\over 80}C_C(b) = {26\\over 80}</li> </ul> </li> </ul> <p>C_CC_C is a global measure: depends on the whole network</p> <p>Case of disconnected networks needs special treatment</p> <p>Caution: when large networks have a small diameter (small world phenomenon), then C_CC_C values will be very similar for almost all nodes</p> <ul> <li>Social network problem, everyone is connected to everyone in a relatively small path</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#degree-prestige-in-degree-centrality","title":"Degree Prestige (In-degree Centrality)","text":"<p>For directed graphs</p> <p></p> <ul> <li>P_D(v) = {d_i(v) \\over n-1}P_D(v) = {d_i(v) \\over n-1}</li> <li>Example<ul> <li>P_D(a) = P_D(b) = {5 \\over 23}P_D(a) = P_D(b) = {5 \\over 23}</li> </ul> </li> <li>P_DP_D is another local measure</li> </ul> <p>Local measures can easily manipulated by link spamming:</p> <p></p> <ul> <li>More difficult (but still possible) to manipulate global measures</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#page-rank","title":"Page Rank","text":"<p>First reported in: Brin, S., &amp; Page, L. (1998). The anatomy of a large-scale hypertextual web search engine.</p> <ul> <li>PageRank originally defined for ranking we pages</li> <li>Inspired by earlier works in link analysis (web and citation analysis)</li> <li>The ideas/principles of PageRank have been adpoted to measure node centrality/importance in many contexts</li> </ul> <p></p> <ul> <li>aa and bb have the same degree prestige</li> <li>The pages linking to aa have a higher prestige than the pages linking to bb</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#rank-prestige","title":"Rank Prestige","text":"P_R(v)= \\sum_{u:u\\to v} P_R(u)   P_R(v)= \\sum_{u:u\\to v} P_R(u)  <ul> <li>This does not directly define P_RP_R</li> <li>Only defines mutual relationships between P_RP_R values</li> <li>Can we find and compute a P_RP_R measure that satisfies these relationships?</li> </ul> <p>Web surfer: slides 13-</p> <p>Example: 10.000 random web surfers:</p> <p></p> <p></p> <p>PageRank idea: the rank (prestige) of a web-page is proportional to</p> <ul> <li>the proportion of random web-surfers that will be visiting the page at a given point in time</li> <li>= the probability that a random web-surfer is at this page at any point in time</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#markov-chain-model","title":"Markov Chain Model","text":"<p>The random surfer is described by</p> <ul> <li> <p>a probability distribution</p> <ul> <li>\\bold q^{(0)}=(q_1^{(0)}, \\dots, q_n^{(0)})\\bold q^{(0)}=(q_1^{(0)}, \\dots, q_n^{(0)})</li> </ul> <p>over all web-pages. q_i^{(0)}q_i^{(0)} : probability of starting to surf on page ii</p> </li> <li> <p>a transition probability matrix</p> <p>P_{i,j}P_{i,j} : probability of moving to page jj given we are currently on page ii: =0=0 if there is no link from ii to jj, otherwise </p> </li> </ul>  P_{i,j}= {1 \\over d_O(i)}   P_{i,j}= {1 \\over d_O(i)}  <p>\u200b   compactly:</p>  \\bold P = D_O^{-1}A   \\bold P = D_O^{-1}A  <p>\u200b   with D_OD_O: diagonal out-degree matrix, AA: adjacency matrix</p>"},{"location":"7-semester/WI/04-structure-based-ranking/#example","title":"Example","text":"<p>For a random surfer starting at page 1:</p> <p></p> <ul> <li>\\bold q^{(t)} = (q_1^{(t)}, \\dots, q_n^{(t)})\\bold q^{(t)} = (q_1^{(t)}, \\dots, q_n^{(t)}) probability distribution over web pages at time tt</li> </ul> <p></p> <p>Collected for all j, in matrix notation:</p> <p></p> <p></p> <p></p> <p></p>"},{"location":"7-semester/WI/04-structure-based-ranking/#stationary-distribution","title":"Stationary Distribution","text":"<ul> <li>\\bold q\\bold q is stationary if <ul> <li>\\bold q = \\bold q \\bold P\\bold q = \\bold q \\bold P</li> <li>I.e.: \\bold q\\bold q is eigenvector of \\bold P\\bold P with eigenvalue 1</li> </ul> </li> </ul> <p>Under some conditions* </p> <ul> <li>a Markov chain has a unique stationary distribution \\bold q ^*\\bold q ^*</li> <li>for any \\bold q^{(0)}\\bold q^{(0)}</li> </ul> <p></p>"},{"location":"7-semester/WI/04-structure-based-ranking/#example_1","title":"Example","text":"<ul> <li>We get the same vector back again</li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#irreducibility","title":"Irreducibility","text":"<p>*First condition.</p> <p>Not irreducible:</p> <p></p> <ul> <li>the limiting distribution depends on the initial distribution (starting point)</li> </ul> <p>A Markov chain is irreducible if every state is reachable from every other state</p>"},{"location":"7-semester/WI/04-structure-based-ranking/#aperiodicity","title":"Aperiodicity","text":"<p>*Second condition</p> <p>Not aperiodic:</p> <p></p> <ul> <li> <p>A state ii in a Markov chain is periodic if starting from one ii one can only return to ii in      $$     k,2k,3k,\\dots,nk, (n+1)k,\\dots     $$     many steps, where k&gt;1k&gt;1</p> </li> <li> <p>Above: all states periodic with k=3k=3</p> </li> <li> <p>A Markov chain is aperiodic if it has no periodic states</p> </li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#summary","title":"Summary","text":"<p>If a Markov chain is irreducible and aperiodic, then it</p> <ul> <li>has a unique stationary distribution \\bold q^*\\bold q^*</li> <li>for any \\bold q^{(0)}\\bold q^{(0)}:<ul> <li>\\lim_{t\\to \\infty} \\bold q(t)=\\bold q^*\\lim_{t\\to \\infty} \\bold q(t)=\\bold q^*</li> </ul> </li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#problems","title":"Problems","text":"<p>A small web:</p> <p></p> <p>Transition matrix:</p> <p></p> <p>Problem 1</p> <ul> <li>No proper transition matrix, because dangling pages (ex: page 5) have no defined transitions</li> </ul> <p>Solution 1</p> <ul> <li>Add transitions from dangling pages to all other pages:</li> </ul> <p></p> <ul> <li> <p>\"random restart\" of the web searching if ending up at dangling edge</p> </li> <li> <p>Transition matrix</p> <p></p> </li> </ul> <p>Problem 2</p> <ul> <li>Markov chain not irreducible (and maybe not aperiodic)</li> </ul> <p>Solution 2</p> <ul> <li> <p>Add additional transitions from all states to all other states, so that total probability of these extra transitions is 1- d1- d</p> </li> <li> <p>New transition matrix:</p> <ul> <li> <p>\\bold P_{PR}=\\bold P_{PR}=</p> <p></p> </li> </ul> </li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#pagerank-defined","title":"PageRank Defined","text":"<p>The page rank of webpage ii is </p>  n \\cdot q_i^*,   n \\cdot q_i^*,  <p>where \\bold q^*\\bold q^* is the limit distribution of the Markov chain defined by \\bold P_{PR}\\bold P_{PR}</p> <p>It is computed (approximately) by iterating</p> <p></p> <p>until \\bold q^{(t)}\\bold q^{(t)} does not change very much</p>"},{"location":"7-semester/WI/04-structure-based-ranking/#the-undirected-case","title":"The Undirected Case","text":"<p>Let</p> <ul> <li>GG an undirected graph, \\bold d = (d(1), \\dots, d(n))\\bold d = (d(1), \\dots, d(n)) degree vector</li> <li>d := \\sum_{i=1}^n d(i)d := \\sum_{i=1}^n d(i)</li> <li>q_i := d(i) / dq_i := d(i) / d</li> </ul> <p>Then</p> <ul> <li>\\bold q = (q_1,\\dots,q_n)\\bold q = (q_1,\\dots,q_n) is a stationary distribution of the random walk on GG</li> </ul> <p>Proof</p> <p></p> <p></p>"},{"location":"7-semester/WI/04-structure-based-ranking/#hits-algorithm","title":"HITS Algorithm","text":"<p>J. Kleinberg: Authoritative Sources in a Hyperlinked Environment. J. of the ACM, 1999</p> <p>Alternative to PageRank</p> <p></p> <p>2 different types of important nodes</p> <ul> <li>Hubs (red): Web pages pointing to many (relevant) pages<ul> <li>Example: Business listings (yellow pages)</li> </ul> </li> <li>Authorities (blue): Web pages linked to by many other pages<ul> <li>Example: Important company homepages</li> </ul> </li> </ul>"},{"location":"7-semester/WI/04-structure-based-ranking/#algorithm","title":"Algorithm","text":"<p>Step 1</p> <p>Retrieve top tt of webpages for query (mostly content-based):</p> <p></p> <ul> <li>Result: the root set</li> </ul> <p>Step 2</p> <p>Add all neighbors (up to a maximum number) of the pages in the root set:</p> <p></p> <ul> <li>Result: the base set</li> </ul> <p>Step 3</p> <p>Compute the hub and authority scores for all pages vv in the base set, implicitly defined by:</p> <p></p> <p>In matrix notation:</p> <p></p> <p>where \\bold L\\bold L: link matrix.</p> <p>Alternatively (separating \\bold a\\bold a and \\bold h\\bold h):</p> <p></p> <ul> <li> <p>Solutions  \\bold a\\bold a, \\bold h\\bold h are found by the same iterative approximation as used for q \u2217 computation (slide 26)</p> </li> <li> <p>Since \\bold L^T \\bold L\\bold L^T \\bold L and \\bold {LL}^T\\bold {LL}^T are not irreducible, aperiodic Markov chains, solutions  \\bold a\\bold a, \\bold h\\bold h need not be unique</p> </li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/","title":"Recommender Systems","text":"<ul> <li>Slides</li> <li>Exercises</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#data-scenarios","title":"Data Scenarios","text":"<ul> <li>Rich user data</li> <li>Rich item data</li> <li>Explicit rating data</li> </ul> <ul> <li>Rich item data</li> <li>Explicit rating data</li> </ul> <ul> <li>Explicit rating data</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#problem-dimensions","title":"Problem Dimensions","text":"<p>Problem Settings</p> <ul> <li>Users<ul> <li>with/without features<ul> <li>context information</li> <li>attributes</li> <li>metadata</li> <li>...</li> </ul> </li> </ul> </li> <li>Items<ul> <li>with/without features<ul> <li>context information</li> <li>attributes</li> <li>metadata</li> <li>...</li> </ul> </li> </ul> </li> <li>Interaction<ul> <li>Explicit feedback (ratings)</li> <li>Implicit feedback (positive only)</li> </ul> </li> </ul> <p>Problem Statement</p> <p>Given a user u, what new items ii (not previously rated, bought, seen, ... by uu) should be recommended to uu, so that uu is likely to interact (buy, view, rate, ...) with ii</p>"},{"location":"7-semester/WI/05-recommender-systems/#challenges","title":"Challenges","text":""},{"location":"7-semester/WI/05-recommender-systems/#cold-start","title":"Cold Start","text":"<ul> <li>User cold start<ul> <li>what to recommend to a new user, for whom there is no (feature, feedback) data?</li> </ul> </li> <li>Item cold start<ul> <li>to whom to recommend a new item that no one has bought before?</li> </ul> </li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#serendipity","title":"Serendipity","text":"<p>From Oxford English Dictionary:</p> <p>The faculty of making happy and unexpected discoveries by accident. Also, the fact or an instance of such a discovery</p> <p>Example Usage:</p> <p>\u201dColumbus and Cabot..(by the greatest serendipity of history) discovered America instead of reaching the Indies.\u201d</p> <p>It is hard for recommender systems to recommend something unexpected</p>"},{"location":"7-semester/WI/05-recommender-systems/#problem-boring-recommendations","title":"Problem: Boring Recommendations","text":""},{"location":"7-semester/WI/05-recommender-systems/#problem-information-filter-bubbles","title":"Problem: Information Filter Bubbles","text":"<p>Wikipedia:</p> <p>A filter bubble [...] is a state of intellectual isolation that allegedly can result from personalized searches when a website algorithm selectively guesses what information a user would like to see based on information about the user, such as location, past click-behavior and search history. As a result, users become separated from information that disagrees with their viewpoints, effectively isolating them in their own cultural or ideological bubbles. . . .</p> <p></p> <p>From https://en.wikipedia.org/wiki/Filter_bubble</p>"},{"location":"7-semester/WI/05-recommender-systems/#netflix-prize","title":"Netflix Prize","text":"<p>https://www.netflixprize.com/rules.html</p> <ul> <li>A big driver for research in recommender technology</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#content-based-recommendation","title":"Content-based Recommendation","text":"<p>We assume that we have some content</p> <ul> <li>Here on items</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#item-content-explicit-feedback","title":"Item Content, Explicit Feedback","text":"<p>Scenario:</p> <ul> <li>Item features available</li> <li>No user features</li> <li>Explicit feedback</li> </ul> <p>Note: picture only shows one user; there still are many users, but we treat them one at at time!</p>"},{"location":"7-semester/WI/05-recommender-systems/#user-classifier","title":"User Classifier","text":"<p>Items rated by user uu described by feature vectors:</p> <p></p> <p>Recommendation: predict ratings of new items based on the item feature vector.</p> <ul> <li>Standard machine learning regression (numeric label) or classification (categorical label) task</li> <li>Can build standard prediction model (Naive Bayes, Decision tree, ...) for each user</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#naive-bayes-classifier","title":"Naive Bayes Classifier","text":""},{"location":"7-semester/WI/05-recommender-systems/#notation","title":"Notation","text":"<ul> <li>Assume qualitative rating labels: rating of user user uu for item ii: r_{u,i} \\in \\{+,-\\}r_{u,i} \\in \\{+,-\\}</li> <li>f_if_i denotes the feature vector of item ii, and \\bold f\\bold f a particular value for this feature vector</li> </ul> <p>In example from previous table:</p> <p></p>"},{"location":"7-semester/WI/05-recommender-systems/#bayesian-classification","title":"Bayesian Classification","text":"<p>Bayes Rule:</p> <p></p> <p>Same for P_u(r_{u,i}= - \\mid f_i=\\bold f)P_u(r_{u,i}= - \\mid f_i=\\bold f)</p> <p>Both conditional probabilities have the factor 1/P_u(f_i=\\bold f)1/P_u(f_i=\\bold f) in common</p> <ul> <li>For classification can ignore this factor and can write:</li> </ul> <p></p> <p>(\u201c==\u201d in equation (4.6) in Ch.4 of Rec.Sys. Handbook should also be \u201c\\approx\\approx\u201d)</p> <p>Key Question</p> <p>What is:</p> <p></p> <p>Naive Bayes assumption:</p> <p></p> <p>where MM is the number of components in f_if_i</p> <p>Example</p> <p></p> <ul> <li>Large number of term feature factors (= size of vocabulary) may dominate this product</li> <li>mitigated by: for most terms t: P_u(t=0 \\mid r_{u,i}=+)t: P_u(t=0 \\mid r_{u,i}=+) and P_u(t=0 \\mid r_{u,i}=-)P_u(t=0 \\mid r_{u,i}=-) will be very similar, and therefore have little impact on P_u(t=\\bold f \\mid r_{u,i}=+)/P_u(t= \\bold f \\mid r_{u,i}=-)P_u(t=\\bold f \\mid r_{u,i}=+)/P_u(t= \\bold f \\mid r_{u,i}=-)</li> <li>May need to make some adjustments to handle \"hybrid\" item feature data as in this example</li> </ul> <p>Still to determine</p> <p>For a single term tt what is:</p> <p></p> <p>Bernouli model</p> <ul> <li>Use term occurrence features: k \\in \\{0,1\\}k \\in \\{0,1\\}</li> <li>P_u(\\text{t}=1 \\mid r_{u,i} = +)P_u(\\text{t}=1 \\mid r_{u,i} = +): probability that term t occurs in the text (review) for an item ii that uu has rated positively<ul> <li>= relative document frequency of term t in the \"corpus\" of items rated positively by u (cf. slide 3.9)</li> </ul> </li> </ul> <p>Multinomial model</p> <ul> <li>Use term frequency features (bag of words): k= F[i,t] \\in \\Nk= F[i,t] \\in \\N</li> <li>P_u(t=k \\mid r_{u,i} = +) = P_u(t \\mid r_{u,i} = +)^kP_u(t=k \\mid r_{u,i} = +) = P_u(t \\mid r_{u,i} = +)^k, where<ul> <li>P_u(t \\mid r_{u,i} = +)P_u(t \\mid r_{u,i} = +) is the relative frequency of the term t in items rated positively by uu.<ul> <li>= relative collection frequency of term t in the \"corpus\" of items rated positively by uu (cf. slide 3.9)</li> </ul> </li> </ul> </li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#user-classifier-pros-and-cons","title":"User Classifier Pros and Cons","text":"<p>Pros</p> <ul> <li>Makes use of item features</li> <li>Can handle item cold start (assuming features of new items known)</li> </ul> <p>Cons</p> <ul> <li>Requires explicit feedback</li> <li>Does not handle user cold start<ul> <li>... or even users with relatively small data set</li> </ul> </li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#item-content-implicit-feedback","title":"Item Content, Implicit Feedback","text":"<p>Scenario</p> <ul> <li>Item features available</li> <li>No user features</li> <li>Implicit feedback</li> </ul> <p>A partial analogy to Information Retrieval (IR):</p> <p></p>"},{"location":"7-semester/WI/05-recommender-systems/#user-profile","title":"User Profile","text":"<p>Idea</p> <p>Represent user by a vector in the same space as the item feature vectors by summarizing the feature vectors of items for which there is implicit feedback.</p> <p>Example</p> <p></p> <p>Then: rank candidate items according to similarity with user profile. Similarity can be defined as (weighted) sum of component-specific similarity measures:</p> <p></p> <p>Illustration</p> <p></p> <p>All items</p> <p></p> <p>Items with implicit rating by user uu</p> <p></p> <p>User profile of uu (= item prototype)</p> <p></p> <p>Ranking of new (gray) items for recommendation</p>"},{"location":"7-semester/WI/05-recommender-systems/#evaluation","title":"Evaluation","text":"<p>How good is the recommender we have designed?</p>"},{"location":"7-semester/WI/05-recommender-systems/#explicit-feedback","title":"Explicit Feedback","text":"<ul> <li>Split data into training and test set:</li> </ul> <ul> <li>Design/learn/configure recommender using the training data</li> <li>Compare true and predicted ratings on test cases:</li> </ul> <p>Quantify performance using e.g. \\text{accuracy}:{\\text{#correct predictions} \\over \\text{#all predictions}}\\text{accuracy}:{\\text{#correct predictions} \\over \\text{#all predictions}} (or root mean squared error RMSE for numeric predictions).</p>"},{"location":"7-semester/WI/05-recommender-systems/#implicit-feedback","title":"Implicit Feedback","text":"<ul> <li>Split data into training and test set:</li> </ul> <ul> <li>Build/learn/configure recommender using the training data</li> <li>Determine positions of test items in ranked list of all items (or: test items plus random selection of some other items):</li> </ul> <ul> <li>Quantify performance</li> </ul> <p>Mean reciprocal rank:</p> <p></p> <p>where KK: number of test items; rank(i)rank(i): the rank of the iith test item.</p> <p></p> <ul> <li>All metrics make the implicit assumption that non-test items are not relevant for the user</li> <li>To go beyond the limitations of this implicit assumption: need user studies</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#collaborative-filtering","title":"Collaborative Filtering","text":"<p>Pure interaction data</p> <p></p> <p></p> <ul> <li>Very sparse matrices</li> </ul> <p>Some key techniques</p> <ul> <li>Neighborhood methods (this session)</li> <li>Random walk based (next session)</li> <li>Matrix factorization (next session)</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#neighborhood-methods","title":"Neighborhood Methods","text":"<p>Scenario</p> <ul> <li>No item features</li> <li>No user features</li> <li>Explicit feedback</li> </ul> <p>Example</p> <p></p> <p>Here: explicit numeric feedback; could also be explicit categorical (+, \u2212) feedback</p>"},{"location":"7-semester/WI/05-recommender-systems/#user-based","title":"User Based","text":"<p>To predict Eric's rating for Titanic:</p> <ul> <li>Find users similar to Eric who have rated Titanic</li> <li>Predict by taking average of similar users\u2019 ratings</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#item-based","title":"Item Based","text":"<p>To predict Eric's rating for Titanic:</p> <ul> <li>Find items that Eric has rated which are similar to Titanic</li> <li>Predict by taking average of Eric\u2019s ratings for similar items</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#user-vs-item-based","title":"User vs Item Based","text":"<p>User- and item-based completely analogous: just transpose the matrix.</p> <p>Differences due to rating distribution in matrix:</p> <p>User cold start:  for a user uu with very few ratings (suppose exactly one rating):</p> <ul> <li>User-based<ul> <li>Many equally (and highly similar) other users.</li> <li>Prediction for r_{u,i}r_{u,i} for item ii close to global average of ratings for ii</li> </ul> </li> <li>Item-based<ul> <li>Only one candidate similar item.</li> <li>Prediction for r_{u,i}r_{u,i} for item ii equal to the only previous rating of uu</li> </ul> </li> </ul> <p>Similarly for item cold start (everything transposed ...)</p>"},{"location":"7-semester/WI/05-recommender-systems/#normalization","title":"Normalization","text":"<p>Suppose</p> <p></p> <p>are user vectors.</p> <p>Two different users may use somewhat different semantics for their ratings: user 1 gives 5 stars whenever he likes a movie, user 2 gives 5 stars only once in a lifetime.</p>"},{"location":"7-semester/WI/05-recommender-systems/#mean-centering","title":"Mean Centering","text":"<p>Let \\overline r_u\\overline r_u denote the mean value of all ratings of user uu.</p> <p>Define the user mean centered ratings as</p>  h(r_{u,i})=r_{u,i} - \\overline r_u   h(r_{u,i})=r_{u,i} - \\overline r_u  <p>Example:</p> <ul> <li>\\overline r_u = 3, \\quad \\overline r_v = 2.25\\overline r_u = 3, \\quad \\overline r_v = 2.25</li> </ul> <p></p> <p>(note the 0s!)</p>"},{"location":"7-semester/WI/05-recommender-systems/#similarity","title":"Similarity","text":"<p>Problem: measure similarity between two partial integer vectors:</p> <p></p> <ul> <li>these can be either a user (column) or item (row) vectors.</li> <li>in a sparse vector, the \u201cblank\u201d entries would be equal to 0.</li> </ul> <p>Only consider the components that are present in both vectors:</p> <p></p> <ul> <li>(1, 5, 4, 3, 2) \\quad (1, 4, 4, 1, 1)(1, 5, 4, 3, 2) \\quad (1, 4, 4, 1, 1)</li> </ul> <p>Then what...</p> <ul> <li>Dot product?</li> <li>Cosine similarity?</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#user-user-similarity","title":"User-User Similarity","text":"<ul> <li>Center full user vectors</li> </ul> <ul> <li>Calculate similarity w_{u,v}w_{u,v} as the cosine of the sub-vectors of commonly rated items:</li> </ul>  \\cos((\u22122, 2, 1, 0, \u22121), (\u22121.25, 1.75, 1.75, \u22121.25, \u22121.25))   \\cos((\u22122, 2, 1, 0, \u22121), (\u22121.25, 1.75, 1.75, \u22121.25, \u22121.25))  <p>(this is equivalent to Equation (2.19) in Rec. Sys. Handbook, Ch. 2)</p>"},{"location":"7-semester/WI/05-recommender-systems/#significance","title":"Significance","text":"<p>Problem with w_{u,v}w_{u,v}: may obtain large similarity values from very small sets of common ratings:</p> <ul> <li>\\cos((1),(1)) = 1\\cos((1),(1)) = 1</li> <li>\\cos((1, \u22121, 0, 2, 2, 0, \u22121, \u22122), (1, \u22121, 0, 1, 2, 0, \u22121, \u22122)) &lt; 1\\cos((1, \u22121, 0, 2, 2, 0, \u22121, \u22122), (1, \u22121, 0, 1, 2, 0, \u22121, \u22122)) &lt; 1</li> </ul> <p>We can apply a penalty for 'short vectors':</p>  w'_{u,v} = \\frac {\\min(\\text{#common ratings}, \\gamma)} {\\gamma} w_{u,v}   w'_{u,v} = \\frac {\\min(\\text{#common ratings}, \\gamma)} {\\gamma} w_{u,v}  <ul> <li>e.g. \\gamma =25\\gamma =25</li> </ul>"},{"location":"7-semester/WI/05-recommender-systems/#putting-things-together","title":"Putting Things Together","text":"<p>User-based prediction of r_{u,i}r_{u,i}:</p> <ul> <li>Let \\mathcal N_i\\mathcal N_i be the set of users that have rated ii</li> <li>Predict</li> </ul> <p></p> <ul> <li>Or use w'_{u,v}w'_{u,v}</li> <li>Instead of summing over all users in \\mathcal N_i\\mathcal N_i, may only sum over the kk users that are most similar to uu denoted \\mathcal N_i(u)\\mathcal N_i(u)</li> </ul>"},{"location":"7-semester/WI/06-recommender-systems-2/","title":"Recommender Systems 2","text":"<ul> <li>Slides</li> </ul>"},{"location":"7-semester/WI/06-recommender-systems-2/#random-walk-methods","title":"Random Walk Methods","text":"<p>Scenario</p> <ul> <li>No item features</li> <li>No user features</li> <li>Implicit feedback</li> </ul> <p></p> <p>Idea</p> <ul> <li>users similar to u and items liked by uu are more likely to be encountered on the random walk</li> </ul> <p>Problem</p> <ul> <li>in the long run the starting point will have little influence on the random walk</li> </ul> <p>See random walker example on slides 2-</p>"},{"location":"7-semester/WI/06-recommender-systems-2/#random-walk-teleportation-reboot","title":"Random Walk Teleportation (Reboot)","text":"<p>Teleport to user-of-interest node</p> <p>Example on slides 3-</p> <ul> <li>Leads to irreducible and aperiodic Markov chain (assuming connected graph)</li> </ul> <p>Use stationary probabilities of users and items as measure for:</p> <ul> <li>similarity of users</li> <li>relevance of items</li> </ul> <p>Transitivity</p> <ul> <li>A user ww can be (more or less) similar to uu, even if uu and ww do no have any common ratings/interactions</li> </ul> <p>Is called Personalized PageRank</p>"},{"location":"7-semester/WI/06-recommender-systems-2/#personalized-pagerank","title":"Personalized PageRank","text":"<p>Let KK users be index 1,\\dots,K1,\\dots,K, and LL items K+1, \\dots , K+LK+1, \\dots , K+L</p> <p>Then construct (K+L) \\times (K+L)(K+L) \\times (K+L) transition matrix:</p>  P_{RW}=(1-\\alpha)P_G + \\alpha P_T   P_{RW}=(1-\\alpha)P_G + \\alpha P_T  <p>where </p> <ul> <li>P_GP_G is the graph transition matrix<ul> <li>for any user or item node, make a uniform random choice over the incident edges</li> </ul> </li> <li>P_TP_T is the teleportation matrix<ul> <li>move to user node uu with probability 1</li> </ul> </li> <li>a&lt;1a&lt;1 teleportation probability</li> </ul> <p>The stationary probabilities (of user and item nodes) define a Personalized PageRank.</p> <p>It is personalized for user uu</p>"},{"location":"7-semester/WI/06-recommender-systems-2/#user-and-item-rankings","title":"User and Item Rankings","text":"<p>The computed personalized PageRanks define a ranking of users and items (\\alpha = 0.1)(\\alpha = 0.1)</p> <p></p> <p>Use:</p> <ul> <li>Use user rankings to find similar users and proceed as in neighborhood method</li> <li>Use item ranking directly to recommend items</li> </ul>"},{"location":"7-semester/WI/06-recommender-systems-2/#itemrank","title":"Itemrank","text":"<p>From slides</p>"},{"location":"7-semester/WI/06-recommender-systems-2/#matrix-factorization","title":"Matrix Factorization","text":"<p>Slides (pdfpage 29-)</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/","title":"Network Structure and Communities","text":"<p>Networks of very different types have many things in common:</p> <ul> <li>the mathematical graph model</li> <li>typical structural properties</li> <li>fundamental network (data) analysis problems, e.g.:</li> <li>community detection</li> <li>node classification and link prediction</li> </ul> <p>Network science investigates modeling and analysis problems for networks in general</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#degree-distribution","title":"Degree distribution","text":"<p>A small network and its degree distribution:</p> <p></p> <p>Degree distribution in Movielens user-movie rating graph (user nodes only):</p> <p></p> <p>Citation Network</p> <p>Source: Stanford Large Network Dataset Collection: http://snap.stanford.edu/data/index.html</p> <p>Nodes: 34546 papers in the Arxiv High Energy Physics category</p> <p>Edges: 421578 citation links between the papers (directed)</p> <p></p> <p>More examples on slides 12-</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#power-law","title":"Power Law","text":"<p>Observation: in many real networks there is a linear relationship</p> <p></p> <p>between the logarithms of the degree d, and its relative frequency f (d)f (d). Thus:</p> <p></p> <p>\\sim\\sim : proportional</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#erdos-renyi-random-graph-model","title":"Erd\u00f6s-R\u00e9nyi random graph model","text":"<p>For all pairs of nodes, v,wv,w: edge v\\to wv\\to w is included in the graph with probability pp (same for all pairs)</p> <p>Degree distribution in an ER-random graph:</p> <p></p> <ul> <li>Not like the Power Law</li> <li>Real networks evolve by more complex mechanisms than represented by ER model</li> </ul>"},{"location":"7-semester/WI/07-network-structure-and-communities/#diameters-and-distances","title":"Diameters and Distances","text":"<p>Milgram's Experiment</p> <ul> <li>How many links via personal acquaintance are needed to connect a random pair of US citizens?</li> <li>Approximate measurement by passing a message from random starting persons in Omaha, Nebraska to target person in Boston, Massachusetts.</li> <li>Total number of initiated chains: 160. No. of completed chains: 44.</li> </ul> <p></p> <p>S. Milgram: The small-world problem. Psychology Today, 1967</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#diameter-and-distance","title":"Diameter and Distance","text":"<ul> <li>dist(u,v)dist(u,v) length (number of edges) of shortest path connecting uu and vv</li> <li>diameter of graph \\max_{u,v\\in G}dist(u,v)\\max_{u,v\\in G}dist(u,v)</li> </ul> <p>Distance statistics in some real networks, collected from Stanford Large Network Dataset Collection http://snap.stanford.edu:</p> <p></p> <ul> <li>90'th percentile effective diameter:</li> <li>90 percent of pairs of nodes are connected with a dist of this.</li> <li>says parameter on the figure which is a mistake</li> </ul>"},{"location":"7-semester/WI/07-network-structure-and-communities/#clustering-coefficients","title":"Clustering Coefficients","text":"<p>Two graphs with 20 nodes and 35 edges:</p> <p></p> <p>Intuition/empirical observation: </p> <ul> <li>real networks exhibit significant clustering:<ul> <li>two acquaintances of mine are more likely to know each other than two random people.</li> </ul> </li> </ul> <p>How to measure the amount of clustering?</p> <p>Consider G=(V,E)G=(V,E) undirected.  For v \\in Vv \\in V with d(v) \\geq 2d(v) \\geq 2:</p> <ul> <li>\\tau_3(v):= \\frac{d(v)(d(v)-1)}{2}\\tau_3(v):= \\frac{d(v)(d(v)-1)}{2} <ul> <li>number of pairs of neighbors of vv</li> </ul> </li> <li>\\tau_\\triangle := |\\{\\{u,w\\}:\\{u,v\\}, \\{w,v\\},\\{u,w\\} \\in E\\}|\\tau_\\triangle := |\\{\\{u,w\\}:\\{u,v\\}, \\{w,v\\},\\{u,w\\} \\in E\\}|<ul> <li>number of triangles containing vv</li> </ul> </li> </ul> <p></p> <p>Local clustering coefficient:</p> <ul> <li>cl(v):= {\\tau_\\triangle(v) \\over \\tau_3(v)}cl(v):= {\\tau_\\triangle(v) \\over \\tau_3(v)} (for vv with degree(v) \\geq 2degree(v) \\geq 2)</li> </ul> <p>Global clustering coefficient:</p> <ul> <li>cl(G):= {1\\over|V'|} \\sum_{v\\in V'} cl(v)cl(G):= {1\\over|V'|} \\sum_{v\\in V'} cl(v), where V':= \\{v \\in V(G) | d(v) \\geq 2\\}V':= \\{v \\in V(G) | d(v) \\geq 2\\}</li> </ul> <p>Clustering coefficients and comparison with</p> <p></p> <p></p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#communities","title":"Communities","text":"<p>Zachary Karate Club</p> <p>Nodes: members of a karate club at a U.S. university. </p> <p>Edges: social interactions outside the club.</p> <p>How the network looked at some point in time:</p> <p></p> <p>Eventually, the club broke up into two. Membership in new clubs indicated by color.</p> <p></p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#what-are-communities","title":"What are Communities","text":"<p>Intuitive</p> <p>Informally, a community in a network is a group of nodes with greater ties internally than to the rest of the network. [Parathasarathy et al., 2011]</p> <p>The actors in a network tend to form groups of closely-knit connections. The groups are also called communities, clusters, cohesive subgroups or modules in different context. Roughly speaking, individuals interact more frequently within a group than between groups. [Tang et al., 2010]</p> <p>Communities and Clustering Coefficient</p> <ul> <li>Large value of cl(v): v is embedded in a closely connected neighborhood</li> <li>Large value of cl(G): most nodes lie within a closely connected component</li> </ul> <p></p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#graph-clustering","title":"Graph Clustering","text":"<p>A clustering of G= (V,E)G= (V,E) is a partitioning \\mathcal C = \\{C_1, \\dots, C_k\\}\\mathcal C = \\{C_1, \\dots, C_k\\} of VV</p> <p>Method Skeleton</p> <ul> <li>Pick a quality measure for clusterings</li> <li>Find an algorithm to (approximately) determine the clustering with optimal quality</li> </ul>"},{"location":"7-semester/WI/07-network-structure-and-communities/#cut","title":"Cut","text":"<p>Quality of a 2-clustering (aka. a cut):</p> <ul> <li>number of edges that connects vertices in different clusters<ul> <li>generalizes to weighted edges, and k-clusterings</li> </ul> </li> </ul> <p></p> <p>Minimum weight cuts can be computed efficiently (but not for the more general k &gt; 2k &gt; 2 case)</p> <p>Problem: optimal clusterings may contain very small clusters:</p> <p></p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#quality-measure-kernighan-lin-1970","title":"Quality Measure - Kernighan, Lin 1970","text":"<p>Quality Measure: Cut weight, subject to size constraints n_1 \u2264|C_i |\u2264 n_2n_1 \u2264|C_i |\u2264 n_2 for all ii.</p> <p>Algorithmic paradigm: greedy optimization, based on local modification operations (\u201cshifting method\u201d [Brandes et al., Ch.8]):</p> <p></p> <p>Kernighan, Lin local modifications:</p> <p></p> <p>Swap cluster membership of pairs of nodes. Gain (decrease in cut weight) from swapping u, v:</p> <ul> <li>(2-1) + (3-2)=2(2-1) + (3-2)=2</li> </ul> <p>Swaps maintain size constraints</p> <p>B.W. Kernighan, S. Lin: An efficient heuristic procedure for partitioning graphs. Bell System Tech. J., 1970</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#quality-measure-newman-girvan-2004","title":"Quality Measure - Newman, Girvan 2004","text":"<p>Quality Measure: Modularity (see below). No strong link between quality measure and algorithmic approach.</p> <p>Algorithmic paradigm: divisive hierarchical clustering</p> <p></p> <p>Newman, Girvan:</p> <ul> <li>Division in line 3 is effected by sequence of edge deletions</li> <li>Not only internal edges of C_iC_i will be deleted.</li> </ul> <p>M.E.J. Newman and M. Girvan: Finding and evaluating community structure in networks. Physical Review, 2004</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#edge-betweenness","title":"Edge Betweenness","text":"<p>Intuition: edges connecting communities will be used on many shortest paths connecting nodes:</p> <p></p> <p>Many more shortest path traverse edge e_1e_1 than e_2e_2</p> <p>Shortest path betweenness:</p>  \\beta(e):= \\sum_{e,v \\in V} \\frac {\\text{# shortest path connecting } u,v \\text{ going through } e} {\\text{# shortest paths connecting } u,v}   \\beta(e):= \\sum_{e,v \\in V} \\frac {\\text{# shortest path connecting } u,v \\text{ going through } e} {\\text{# shortest paths connecting } u,v}  <p>Other formalizations of \"betweenness\": random walk betweenness, current-flow betweenness.</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#newman-girvan-algorithm","title":"Newman-Girvan Algorithm","text":"<p>Line 11 can be implemented in time O(mn)O(mn) (modification of standard shortest path computations by breadth first search)</p> <p>Total time: O(m^2n)O(m^2n)</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#modularity","title":"Modularity","text":"<p>Newman-Girvan algorithm produces a hierarchy of nn clusterings. Which one is most meaningful?</p> <p></p> <ul> <li>e_{i,j} = e_{j,i}e_{i,j} = e_{j,i}: proportion of edges that connect nodes in clusters ii and jj<ul> <li>Example: e_{1,3} = 2/24,\\quad e_{1,1}=6/24e_{1,3} = 2/24,\\quad e_{1,1}=6/24</li> </ul> </li> <li>a_i := e_{i,i} + \\sum_{j \\neq i} e_{i,j}/2a_i := e_{i,i} + \\sum_{j \\neq i} e_{i,j}/2<ul> <li>\\sum_i a_i = 1\\sum_i a_i = 1</li> <li>Example: a_1 = 6/24 + 1/48 + 2/48a_1 = 6/24 + 1/48 + 2/48</li> </ul> </li> </ul> <p>In matrix form with marginal sums:</p> <p></p> <p>a_ia_i: normalized sum of degrees of nodes in cluster ii</p>"},{"location":"7-semester/WI/07-network-structure-and-communities/#modularity-random-graph-model","title":"Modularity Random Graph Model","text":"<p>Given:</p> <ul> <li>nn nodes partitioned into kk clusters C_1, \\dots, C_kC_1, \\dots, C_k</li> <li>Number mm of edges</li> <li>Probabilities a_1,\\dots a_ka_1,\\dots a_k (or degrees d_1,\\dots, d_nd_1,\\dots, d_n of all nodes)</li> </ul> <p>construct random graph by selecting for each of the mm edges randomly start and end node by </p> <ul> <li>randomly picking a cluster C_iC_i according to probability a_ia_i, and then select a node in C_iC_i with uniform probability distribution</li> </ul> <p>or</p> <ul> <li>randomly pick a node with a probability proportional to the degree of the node</li> </ul> <p>Either way: the expected proportion of edges inside cluster C_iC_i is a_i^2a_i^2</p> <ul> <li>Note: multiple edges possible; cf. PA model</li> </ul> <p>The modularity score compares the actual proportion of intra-cluster edges with the expected number under the random graph model:</p>  Q(C_1, \\dots, C_k) := \\sum_i (e_{i,i} - a_i^2)   Q(C_1, \\dots, C_k) := \\sum_i (e_{i,i} - a_i^2)"},{"location":"7-semester/WI/07-network-structure-and-communities/#newman-girvan-zachary-result","title":"Newman-Girvan Zachary Result","text":""},{"location":"7-semester/WI/07-network-structure-and-communities/#modularity-optimization","title":"Modularity Optimization","text":"<p>Can one try to optimize modularity directly?</p> <ul> <li>Exact solution: NP Hard</li> <li>Approximation heuristics: greedy agglomerative hierarchical clustering (no quality of approximation guarantees)</li> </ul> <p>Modularity optimal clustering of Zachary (Q = 0.419):</p> <p></p> <p>[U. Brandes et al.: On Modularity Clustering. IEEE Transactions on Knowledge and Data Engineering, 2008.]</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/","title":"Communities and Information Diffusion","text":"<ul> <li>Slides</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#latent-space-embeddings","title":"Latent Space Embeddings","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#graph-drawing","title":"Graph Drawing","text":"<p>Graph drawing/layout algorithms: map vertices to (x, y)-coordinates, so that graph plotted with nodes at coordinates \u201clooks nice\u201d, \u201creveals structure\u201d, etc.</p> <p></p> <p>A standard clustering algorithm (e.g. kmeans) applied to the x, y-coordinates of the nodes will return clusters that correlate with communities</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#problem-transformations","title":"Problem Transformations","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#from-graph-clustering-to-euclidean-clustering","title":"From Graph Clustering to Euclidean Clustering","text":"<p>Given graph G,</p> <ul> <li>find embedding of nodes in d-dimensional Euclidean Space \\R^d\\R^d</li> <li>apply clustering algorithm for \\R^d\\R^d-data</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#from-any-clustering-to-graph-clustering","title":"From Any Clustering to Graph Clustering","text":"<p>Given data points x_1, \\dots, x_Nx_1, \\dots, x_N (any data space),</p> <ul> <li>define a distance measure d(x_i, x_j)d(x_i, x_j) between data points</li> <li>construct distance matrix D=(d(x_i, x_j))_{i,j}D=(d(x_i, x_j))_{i,j} or some variant</li> <li>graph-cluster DD (possibly via embedding in Euclidian space: Spectral Clustering)</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#from-graph-clustering-to-distance-based-clustering","title":"From Graph Clustering to Distance-based clustering","text":"<p>Given graph GG,</p> <ul> <li>Define a graph-distance measure d(v_i , v_j)d(v_i , v_j) between vertices</li> <li>Apply any clustering algorithm that operates on a distance matrix (e.g., hierarchical clustering)</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#clustering-by-matrix-factorization","title":"Clustering by Matrix Factorization","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#adjacency-matrix","title":"Adjacency Matrix","text":"A=(a_{i,j})_{i,j}\\quad \\text{where } a_{i,j} = \\left\\{ \\begin{array}\\ 1 &amp; \\text{if } (v_i, v_j) \\in E\\\\ 0 &amp; \\text{if } (v_i, v_j) \\notin E \\end{array} \\right.   A=(a_{i,j})_{i,j}\\quad \\text{where } a_{i,j} = \\left\\{ \\begin{array}\\ 1 &amp; \\text{if } (v_i, v_j) \\in E\\\\ 0 &amp; \\text{if } (v_i, v_j) \\notin E \\end{array} \\right.  <ul> <li>GG is directed or undirected.</li> <li>AA symmetric if GG undirected.</li> </ul> <p>Interpretation as linear mapping:</p>  A: \\R^n \\to \\R^n   A: \\R^n \\to \\R^n  <p>A (column) vector \\bold x \\in \\R^n\\bold x \\in \\R^n can be interpreted as a potential or weight function on nodes. The mapping A: \\bold x \\mapsto A \\bold xA: \\bold x \\mapsto A \\bold x transforms the potential: $$ (A\\bold x)i = \\sum {j:(i,j) \\in E} x_j $$</p> <p>Alternatively for row vector \\bold x^T\\bold x^T:</p>  (\\bold x^TA)_i = \\sum_{j:(j,i) \\in E} x_j   (\\bold x^TA)_i = \\sum_{j:(j,i) \\in E} x_j"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#illustration","title":"Illustration","text":"<p>Potentials (non-negative) represented by colored boxes:</p> <p></p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#eigenvectors-and-eigenvalues","title":"Eigenvectors and Eigenvalues","text":"<p>\\bold x\\bold x is eigenvector with eigenvalue \\lambda\\lambda if A\\bold x = \\lambda \\bold xA\\bold x = \\lambda \\bold x</p> <p>Example</p> <p>Eigenvectors and -values for triangle graph:</p> <p></p> <p>Example</p> <p>Collection of cliques:</p> <p></p> <p></p> <ul> <li>The largest eigenvalue is the size (degree) of the largest clique minus one. The corresponding eigenvector is the indicator vector for the clique.</li> <li>Indicator vectors for other cliques are eigenvectors with eigenvalues equal to the size of the cliques minus one.</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#laplacian-matrix","title":"Laplacian Matrix","text":"<p>The Graph Laplacian</p> <ul> <li>AA: adjacency matrix of undirected graph</li> <li>DD: diagonal degree matrix: d_{i,i} = \\sum_{j=1}^n a_{i,j}d_{i,i} = \\sum_{j=1}^n a_{i,j}</li> </ul> <p>the (unnormalized) Laplacian is</p>  L = D - A   L = D - A  <p>Properties</p> <ul> <li> <p>LL is symmetric, and \\sum_{j=1}^n l_{i,j} = \\sum_{j=1}^n l_{j,i} = 0\\sum_{j=1}^n l_{i,j} = \\sum_{j=1}^n l_{j,i} = 0</p> </li> <li> <p>The constant vector \\bold e = (1,\\dots,1)\\bold e = (1,\\dots,1) is an eigenvector of LL with eigenvalue 0.</p> </li> <li> <p>If V' \\subset VV' \\subset V is a connected component, then the  indicator vector for V'V'</p> <ul> <li>(\\bold e_{V'})_i = \\left\\{ \\begin{array}\\ 1 &amp; \\text{if } v_i \\in V' \\\\ 0 &amp; \\text{if } v_i \\notin V' \\end{array} \\right .(\\bold e_{V'})_i = \\left\\{ \\begin{array}\\ 1 &amp; \\text{if } v_i \\in V' \\\\ 0 &amp; \\text{if } v_i \\notin V' \\end{array} \\right .</li> </ul> <p>is an eigenvector of LL with eigenvalue 0</p> </li> <li> <p>LL is positive semi-definite</p> </li> </ul> <p>[U. von Luxburg: A tutorial on spectral clustering. Stat. Comput., 2007 ]</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#connected-components","title":"Connected Components","text":"<p>Connected components and eigenvectors:</p> <p></p> <ul> <li>LL: Laplacian, arranged so that connected components are contiguous blocks</li> <li>\\bold e_{V'}\\bold e_{V'}: indicator vector of \"middle\" component</li> <li>\\bold 0\\bold 0: 0-vector</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#svd-for-l","title":"SVD for L","text":"<p>SVD for Laplacian matrix (special case for quadratic, symmetric, positive semi-definite matrices):</p> <p></p> <ul> <li>VV: matrix of orthogonal eigenvectors</li> <li>DD: diagonal, containing non-negative eigenvalues (in increasing order)</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#zachary-example-laplacian","title":"Zachary Example: Laplacian","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#zachary-example-adjacency","title":"Zachary Example: Adjacency","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#information-diffusion","title":"Information Diffusion","text":"<p>Information diffusion in a (social) network:</p> <p></p> <p>Network: possibly heterogeneous with web page nodes, user nodes, . . .</p> <p>Information:</p> <ul> <li>retweets</li> <li>hashtags</li> <li>internet rumours</li> </ul> <p>Some assumptions:</p> <ul> <li>can identify the \u201csame piece of information\u201d being adopted/shared/propagated across the network</li> <li>information \u201cspawned\u201d at one or several nodes, and then propagated along links</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#prediction-problems","title":"Prediction Problems","text":"<p>Given the trace of an information cascade so far: </p> <p></p> <p>How far is this going to spread?</p> <p>[Cheng, Justin, Lada Adamic, P. Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. \"Can cascades be predicted?.\" In Proceedings of the 23rd international conference on World wide web, pp. 925-936. 2014.]</p> <p></p> <p>Which are the most effective spawning nodes for spreading a piece of information?</p> <p>[Kempe, David, Jon Kleinberg, and \u00c9va Tardos. \"Maximizing the spread of influence through a social network.\" In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 137-146. 2003.]</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#cascade-prediction","title":"Cascade Prediction","text":"<p>This section based on:</p> <p>Cheng, Justin, Lada Adamic, P. Alex Dow, Jon Michael Kleinberg, and Jure Leskovec. \"Can cascades be predicted?.\" In Proceedings of the 23rd international conference on World wide web, pp. 925-936. 2014.</p> <p>Data</p> <p>From Facebook: \u201cSharing cascades\u201d of images observed over a 28 day period in 2013</p> <ul> <li>at least 5 reshares for each photo</li> <li>initial node can be either:<ul> <li>\"page\" (81%): company etc. accounts</li> <li>\"user\" (19%): individual users</li> </ul> </li> </ul> <p>One cascade:</p> <p></p> <p>Image source: [Cheng et al., 2014]</p> <ul> <li>\\hat G\\hat G: cascade graph - nodes and edges along which information was transmitted</li> <li>G'G':  induced sub-graph \u2013 same nodes as \\hat G\\hat G, but also including the edges on which information was not transmitted.</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#wiener-index","title":"Wiener Index","text":"<p>For any graph G = (V,E)G = (V,E) with |V|=n|V|=n</p>  d_w(G) = {2 \\over n(n-1)} \\sum _{u,v \\in V} d(u,v) \\quad \\text{(average node distance)}   d_w(G) = {2 \\over n(n-1)} \\sum _{u,v \\in V} d(u,v) \\quad \\text{(average node distance)}  <p></p> <p>Image source: [Cheng et al., 2014]</p> <p>Interpretation: higher Wiener index \u223c more viral cascade (passes across different communities)</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#data-statistics","title":"Data Statistics","text":"<p>Complementary cumulative distribution functions for size and Wiener index of cascades:</p> <p></p> <p>Image source: [Cheng et al., 2014]</p> <p>$CCDF(x) = $ fraction of cases (=cascades) that have a value (of Cascade size, Wiener index) above xx.</p> <ul> <li>We observe power laws for both distributions</li> <li>I Page induced cascades are larger but less viral than user induced cascades.</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#predicting-cascade-growth","title":"Predicting Cascade Growth","text":"<p>Given</p> <ul> <li>the observation of a cascade of current size kk</li> </ul> <p>Question</p> <ul> <li> <p>how big will it grow?</p> </li> <li> <p>Problem: default answer \u201cnot much bigger than it is now\u201d has high accuracy</p> </li> </ul> <p>Question Adapted</p> <ul> <li>Will it reach size 2k2k? (about half of cascades of size kk will reach size 2k2k.)</li> </ul> <p>Approach</p> <ul> <li>Define a number of features f_1, f_2, \\dots, f_mf_1, f_2, \\dots, f_m describing the currently observed size kk cascade</li> <li>Use standard logistic regression model to predict \u2265 2k\u2265 2k target</li> <li>Separate prediction model for each kk</li> </ul> <p>Logistic Regression</p> <p>Learn weights w_0, \\dots, w_mw_0, \\dots, w_m, and predict \\geq 2k\\geq 2k to be true for cascade CC if </p> <ul> <li> <p>w_0 + w_1f_1(C) + \\dots + w_mf_m(C) &gt; 0w_0 + w_1f_1(C) + \\dots + w_mf_m(C) &gt; 0</p> </li> <li> <p>the absolute values of the weights are a measure for the importance of the features.</p> </li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#image-features","title":"Image Features","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#poster-features","title":"Poster Features","text":"<ul> <li>Page vs. user poster</li> <li>Number of friends</li> <li>Demographic info and Facebook use statistics</li> <li>...</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#resharer-features","title":"Resharer Features","text":"<p>Similar features for the re-sharers up to now</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#cascade-structure","title":"Cascade Structure","text":"<ul> <li>Out-degree of iith re-sharer in cascade graph \\hat G(i=1, \\dots, k)\\hat G(i=1, \\dots, k)</li> <li>Out-degree of iith re-sharer in induced graph G'(i=1, \\dots, k)G'(i=1, \\dots, k)</li> <li>Number of edges in G'G'</li> <li>...</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#temporal-features","title":"Temporal Features","text":"<ul> <li>Various features derived from the time stamps of the first kk re-shares</li> </ul> <p>All features only depend on the observed cascade, not the network structure beyond the cascade.</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#results-predicting-size","title":"Results - Predicting Size","text":"<p>Results with logistic regression for k = 5k = 5 using different feature sets:</p> <p></p> <ul> <li>Temporal features most informative</li> </ul> <p>Further results:</p> <ul> <li>Accuracies improve (slightly) for larger k</li> <li>For larger k, relevance of cascade features increases, relevance of content/user features decreases.</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#results-predicting-wiener-index","title":"Results - Predicting Wiener Index","text":"<p>Task </p> <ul> <li>given cascade of size k = 5, predict whether Wiener index of final cascade is above the median value</li> </ul> <p>Results</p> <ul> <li>Obtained accuracy of 0.7250.725</li> <li>Temporal and structural features most informative</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#influence-maximization","title":"Influence Maximization","text":""},{"location":"7-semester/WI/08-communities-and-information-diffusion/#diffusion-models","title":"Diffusion Models","text":"<p>Model-based analysis:</p> <ul> <li>Define (realistic) stochastic model for the diffusion of information in a network</li> <li>Formulate precise objective</li> <li>Optimize objective under the assumptions of the model</li> </ul> <p>Terminology:</p> <ul> <li>Distinguish active and inactive users</li> <li>In the diffusion process, inactive graph neighbors of active nodes can become active</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#linear-threshold-model","title":"Linear Threshold Model","text":"<ul> <li>Assume: edges u \\to vu \\to v are associated with weights b_{u,v}b_{u,v}, such that for all vv</li> </ul> <ul> <li>Edge weights indicated by grayscale values in picture.</li> </ul> <ul> <li>At time t = 0 an initial set A0 of nodes is active<ul> <li>indicated by blue colors</li> </ul> </li> </ul> <ul> <li> <p>Every node vv randomly chooses a threshold \u03b8_v\u03b8_v uniformly from the interval [0,1][0,1]. </p> <ul> <li>Thresholds indicated by red-scale values in picture</li> </ul> </li> <li> <p>For t = 1, 2, \\dots&gt;:t = 1, 2, \\dots&gt;: the set of nodes active at time tt is</p> </li> </ul> <p></p> <p></p> <p></p> <p></p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#independent-cascade-model","title":"Independent Cascade Model","text":"<ul> <li>Assume: edges u\\to vu\\to v are associated with probabilities p_{u,v} \\leq 1p_{u,v} \\leq 1. <ul> <li>Edge probabilities indicated by grayscale values in picture.</li> </ul> </li> </ul> <ul> <li>At time t=0t=0 an initial set A_0A_0 of nodes is active</li> <li>For t=1,2,\\dotst=1,2,\\dots: each node u\\in A_{t-1} \\backslash A_{t_2}u\\in A_{t-1} \\backslash A_{t_2} (but not A_{T_2}A_{T_2}) activated at time t-1t-1 activates its inactive neighbors with probability p_{u,v}p_{u,v} A_t=A_{t-1} \\cup \\{v : v \\text{activated at time } t\\}A_t=A_{t-1} \\cup \\{v : v \\text{activated at time } t\\} </li> </ul> <ul> <li>Nodes cannot \"keep trying\" to activate nodes</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#similarities-and-differences","title":"Similarities and Differences","text":"<p>Edge Parameters</p> <ul> <li>Both models assume weights/probabilities on the edges</li> <li>These numbers will not be explicitly given by the network, but can potentially be learned from observations of information cascades<ul> <li>E.g. in social network, no-one has labeled edges with numbers<ul> <li>Facebook or Twitter would know, e.g. how much a user retweets from another user</li> </ul> </li> </ul> </li> <li>Otherwise, run the models with default parameters</li> </ul> <p>Activating the neighbors</p> <ul> <li>Independent cascade: one-shot opportunity of a newly activated node to also activate its neighbors<ul> <li>The more of your neighbors get active, the higher the chance of you becoming active</li> </ul> </li> <li>Linear threshold: a node can always contribute to the activation of neighbors if sufficiently many other nodes become active.</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#influence","title":"Influence","text":"<p>Both diffusion models lead to a final set of activated nodes at the time t where:</p>  A_{final}:=A_t=A_{t-1}   A_{final}:=A_t=A_{t-1}  <p>Each seed set A induces a probability distribution over A_{final}A_{final} sets obtained in random cascades:</p> <ul> <li>Linear Threshold: randomness induced by random choice of thresholds (new in every run)</li> <li>Independent Cascade: randomness induced by random propagation according to edge probabilities</li> </ul> <p>For any diffusion model:</p> <p>Influence: Definition</p> <p>For seed set A\\subset VA\\subset V define influence \\sigma(A)\\sigma(A) as the expected size of A_{final}A_{final} in cascade started with A_0=AA_0=A</p> <p>Influence: Computation</p> <p>For a given AA, \\sigma(A)\\sigma(A) can be hard to compute. </p> <ul> <li>Typically approximate by simulations.</li> </ul> <p>Influence: Optimization</p> <p>The influence maximization problem: find the set A_{opt}A_{opt} with |A_{opt}|=k|A_{opt}|=k, such that \\sigma(A_{opt})\\sigma(A_{opt}) is maximal among all size kk sets</p> <ul> <li>Inputs:<ul> <li>Graph (V,E)(V,E),</li> <li>Edge weights/probabilities</li> <li>kk</li> </ul> </li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#influence-maximization-problem","title":"Influence Maximization Problem","text":"<p>The influence maximization problem for the independent cascade model is NP-hard.</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#set-cover-problem","title":"Set Cover Problem","text":"<p>The Set Cover problem is a known NP-complete problem: given </p> <ul> <li>a set UU of size nn</li> <li>a collection of mm subsets S_1, \\dots, S_mS_1, \\dots, S_m of UU</li> <li>a number k\\leq mk\\leq m</li> </ul> <p>do there exist kk of the subsets S_iS_i such that their union is UU?</p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#reduction","title":"Reduction","text":"<p>The Set Cover problem can be reduced to influence maximization: given an instance of the Set Cover problem, construct bipartite graph</p> <p></p> <p>Edges directed from sets S_iS_i to elements of UU they contain. All probabilities set to p_{u,v}p_{u,v} = 1.</p> <p>Then: exists size kk set cover, if and only if \\sigma(A_{opt})=n+k\\sigma(A_{opt})=n+k</p> <ul> <li>Similar result for linear threshold model</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#greedy-optimization","title":"Greedy Optimization","text":"<p>Heuristic approximation technique (either linear threshold or independent cascade):</p> <p></p>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#approximation-guarantee","title":"Approximation Guarantee","text":"<p>The influence value \\sigma(A_{greedy})\\sigma(A_{greedy}) obtained via greedy optimization is at least:</p> <p></p> <ul> <li>General guarantee for optimization of submodular functions:<ul> <li>if A \\subset A'A \\subset A' then for all uu:</li> </ul> </li> </ul> <p></p> <ul> <li>(\"law of diminishing returns\")</li> </ul>"},{"location":"7-semester/WI/08-communities-and-information-diffusion/#an-experiment","title":"An Experiment","text":"<p>Data: collaboration network (arXiv high energy physics): 10748 nodes, 53000 edges)</p> <p>Comparing values \u03c3(A) in linear threshold model obtained by greedy optimization vs. simpler alternatives:</p> <p></p> <ul> <li>high degree: select nodes with highest out-degree </li> <li>central: select nodes according to minimal average distance to other nodes </li> <li>random: random</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/","title":"Node Classification","text":""},{"location":"7-semester/WI/09%2B10-node-classification/#node-classification_1","title":"Node Classification","text":"<p>Things we can (try to) predict in networks:</p> <p>Node Classification</p> <ul> <li>Is a user in a social network going to vote democrat or republican?</li> <li>Is a sensor in a sensor network going to fail within the next 30 days?</li> <li>Has a computer in a computer network been hacked?</li> <li>Is a poster a person or a robot?</li> </ul> <p>Link Prediction</p> <ul> <li>Are two proteins interacting?</li> <li>Will customer A buy product B?</li> <li>Is user A going to become a follower of user B?</li> </ul> <p>Network Classification</p> <ul> <li>Is a molecule a mutagen?</li> </ul> <p>We focus on node classification now.</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#node-attributes","title":"Node Attributes","text":"<p>Graph with node attributes:</p>  G=(V,E,\\bold A)  <p>where \\bold A = (A_1, \\dots, A_m)\\bold A = (A_1, \\dots, A_m) are node attributes</p> <p>Example - Lazega Lawyers</p> <p></p> <p>Attributes:</p> <ul> <li>A_1A_1: status \u2208 { partner, associate } </li> <li>A_2A_2: gender \u2208 { male, female } </li> <li>A_3A_3: office \u2208 { Boston, Hartford, Providence } </li> <li>A_4A_4: years with firm \u2208 \\R\\R </li> <li>A_5A_5: age \u2208 \\R\\R </li> <li>A_6A_6: practice \u2208 { litigation, corporate } </li> <li>A_7A_7: law school \u2208 { Harvard, Yale, Ucon, Other }</li> </ul> <p>Example - User-Product Network</p> <p></p> <p>Attributes</p> <ul> <li>A_1A_1: type \u2208 { user, product } </li> <li>A_2A_2: gender \u2208 { male, female } </li> <li>A_3A_3: category \u2208 { Tools, Cooking, Drink, . . . } </li> <li>A_4A_4: weight \u2208 \\R\\R </li> <li>A_5A_5: avg. rating \u2208 \\R\\R </li> <li>A_6A_6: reviews \u2208 text\u2217<ul> <li>All reviews as a sequence of text</li> </ul> </li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#class-label","title":"Class Label","text":"<p>Not all attributes have known values for all nodes. One incompletely known attribute is the designated class label Y. We can write:</p>  G=((V_l, V_u), E, \\bold A, Y)   G=((V_l, V_u), E, \\bold A, Y)  <p>with</p> <ul> <li>V_lV_l: the labeled nodes (value of Y known)</li> <li>V_uV_u: the unlabeled nodes (value of Y unknown)</li> </ul> <p>We want to predict the value of Y for the unlabeled nodes.</p> <p>Schematic picture:</p> <p></p> <ul> <li>Attributes: blue,red,green \u2208 { light,dark }</li> <li>Class: Y \u2208 { white, black }</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#transductive-vs-inductive","title":"Transductive vs Inductive","text":""},{"location":"7-semester/WI/09%2B10-node-classification/#transductive","title":"Transductive","text":"<ul> <li>The graph ((V_l, V_u), E, \\bold A, Y)((V_l, V_u), E, \\bold A, Y) is fixed, and the same when learning and predicting<ul> <li>all nodes V_uV_u that need to be classified already known when learning the classifier</li> </ul> </li> <li>Examples: techniques based on matrix factorization</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#inductive","title":"Inductive","text":"<ul> <li>Graph G = ((V_l, V_u), E, \\bold A, Y)G = ((V_l, V_u), E, \\bold A, Y) used for training (possibly V_u = \u2205V_u = \u2205, as in figure).</li> <li>Nodes that are classified can be new nodes added to G, or even nodes in a different graph G'</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#independent-vs-collective","title":"Independent vs Collective","text":"<p>Independent Classification</p> <ul> <li>The classification of v \\in V_uv \\in V_u is independent of the classification of other nodes v' \\in V_uv' \\in V_u</li> <li>This corresponds to the standard classification scenario in machine learning</li> </ul> <p>Collective Classification</p> <ul> <li>All nodes in V_uV_u are classified jointly: the classification of v \\in V_uv \\in V_u may depend on the classification of v' \\in V_uv' \\in V_u</li> <li>Specific for classification in network (or other \"inter-connected\") data</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#homophily","title":"Homophily","text":"<p>Homophily, also known informally as \u201cbirds of a feather\u201d, is when a link between individuals (such as friendship or other social connection) is correlated with those individuals being similar in nature. For example, friends often tend to be similar in characteristics like age, social background, and education level.</p> <p>[S. Bhagat, G. Cormode, S. Muthukrishnan: Node Classification in Social Networks]</p> <p>Mechanisms leading to homophily:</p> <ul> <li>Social influence: This indicates that people tend to follow the behaviors of their friends. The social influence effect leads people to adopt behaviors exhibited by their neighbors</li> <li>Selection: This indicates that people tend to create relationships with other people who are already similar to them;</li> <li>Confounding variables: Other unknown variables exist, which may cause friends to behave similarly with one another.</li> </ul> <p>[J. Sun and J. Tang: A Survey of Models and Algorithms for Social Influence Analysis]</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#homophily-in-lazega-network","title":"Homophily in Lazega Network","text":"<p>Collaborating lawyers are more likely to have the same Practice:</p> <p></p> <p>Image from: E.D. Kolaczyk: Statistical Analysis of Network Data</p> <p>Prediction</p>  Practice(i) = mode\\{Practice(j) \\mid j : Collaborate(i,j)\\}   Practice(i) = mode\\{Practice(j) \\mid j : Collaborate(i,j)\\}  <p>only makes 5/34 errors assuming that when predicting Practice(i), the Practice of all other nodes j is known.</p> <ul> <li>Class memberships of nodes u \u2208 V_lu \u2208 V_l can be a strong predictor for class membership of v \u2208 V_uv \u2208 V_u</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#independent-classification","title":"Independent Classification","text":""},{"location":"7-semester/WI/09%2B10-node-classification/#a-generic-approach","title":"A generic approach","text":"<ul> <li>Define a set of node features X_1, \\dots , X_kX_1, \\dots , X_k</li> <li>For each node v \\in V_lv \\in V_l, construct the training example<ul> <li>(\\bold X(v), Y(v)) = (X_1(v), \\dots, X_k(v), Y(v))(\\bold X(v), Y(v)) = (X_1(v), \\dots, X_k(v), Y(v))</li> </ul> </li> <li>Use standard machine learning approach to lean a classifier from the training examples.</li> <li>For nodes u \\in V_uu \\in V_u: calculate feature vector \\bold X(u)\\bold X(u), and predict Y(u)Y(u)</li> </ul> <p>Essentially inductive, but could also be used in a transductive situation.</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#node-feature-constructions","title":"Node feature constructions","text":"<p>Some ways to construct node features:</p> <ul> <li>X(v)=A(v)X(v)=A(v) with AA a node attribute.<ul> <li>E.g. X = locationX = location</li> </ul> </li> <li>X(v) = d(v)X(v) = d(v) (in/out degree)</li> <li>X(v) = aggr\\{A(u) \\mid u: (v,u) \\in E\\}X(v) = aggr\\{A(u) \\mid u: (v,u) \\in E\\}<ul> <li>Aggregate of attribute values of linked nodes.</li> <li>E.g. Most frequent practice type among collaborating colleagues (aggr=mode); average age of collaborating colleagues (aggr=average)</li> </ul> </li> <li>X(v)X(v): Boolean function for a property of graph neigborhood<ul> <li>E.g. At most 2 friendship links away, there is a node uu with location(u)=\\text{Hartford}location(u)=\\text{Hartford}</li> </ul> </li> <li>X(v)= PageRank(v)X(v)= PageRank(v) (in transductive setting)</li> <li>X(v) =X(v) = coefficient of v in vectors of SVD (in transductive setting)</li> <li>... infinitely many possibilities!</li> </ul> <p>Some node attributes may be unknown (especially class label). This may lead to undefined or inaccurate feature values.</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#collective-classification","title":"Collective Classification","text":"<p>Nodes with class label black or white (no further attributes):</p> <p></p> <ul> <li>Looking only at node a, predict it to be black or white?</li> <li>Looking only at node b, predict it to be black or white?</li> <li>Looking at all unlabeled nodes together, which color to predict?</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#iterative-independent-classification","title":"Iterative Independent Classification","text":"<p>We assume a transductive scenario</p> <p>Given</p> <ul> <li>((V_l, V_u), \\bold A, Y): \\bold A((V_l, V_u), \\bold A, Y): \\bold A observed for all nodes, class label Y observed for nodes in V_lV_l</li> <li>Set of node features \\bold X_i\\bold X_i<ul> <li>May include features dependent on Y</li> </ul> </li> <li>Classifier for predicting Y(v)Y(v) given \\bold X(v)\\bold X(v)</li> </ul> <p></p> <ul> <li>We use \\hat Y(v)\\hat Y(v) to denote the predicted value for the true but unknown value Y(v)\\quad (v\\in V_u)Y(v)\\quad (v\\in V_u)</li> <li>The iterative method only makes sense if the features \\bold X(v)\\bold X(v) include features dependent on labels Y(u)Y(u) for some nodes u \\neq vu \\neq v</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#example","title":"Example","text":"<ul> <li>\\bold E = (Collaborate),\\quad \\bold A = \\empty,\\quad Y = Practice\\bold E = (Collaborate),\\quad \\bold A = \\empty,\\quad Y = Practice</li> <li>X(v)X(v): fraction of vv's neighbors with Practice=corporatePractice=corporate (undefined if PracticePractice unknown for all neighbors).</li> <li>Prediction model</li> </ul>  \\hat Y(v) = \\left\\{  \\begin{array}{} corporate  &amp; \\text{if } X(v) \\geq 0.5 \\\\ litigation &amp; \\text{if } X(v) &lt; 0.5 \\\\ ?                    &amp; \\text{if } X(v) \\text{ undefined} \\end{array} \\right.   \\hat Y(v) = \\left\\{  \\begin{array}{} corporate  &amp; \\text{if } X(v) \\geq 0.5 \\\\ litigation &amp; \\text{if } X(v) &lt; 0.5 \\\\ ?                    &amp; \\text{if } X(v) \\text{ undefined} \\end{array} \\right.  <p>\\color{darkblue} \\text{Blue}\\color{darkblue} \\text{Blue}: Practice=corporate, </p> <p>\\color{darkgreen}\\text{Green}\\color{darkgreen}\\text{Green}: Practice=litigation</p> <p>White: Practice=?, </p> <p>Red border: node in V_uV_u.</p> <p></p> <p></p>"},{"location":"7-semester/WI/09%2B10-node-classification/#adding-learning-to-the-loop","title":"Adding Learning to the Loop","text":"<p>Given</p> <ul> <li>((V_l, V_u), \\bold A, Y)((V_l, V_u), \\bold A, Y): \\bold A\\bold A observed for all nodes, class label YY observed for nodes in V_lV_l</li> <li>Set of node features \\bold X_i\\bold X_i.<ul> <li>May include features dependent on YY</li> </ul> </li> <li>Learnable prediction model for class Y(v)Y(v) given \\bold X(v)\\bold X(v)</li> </ul> <p></p> <p>Example</p> <p>Example on slides 10.7</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#label-propagation","title":"Label Propagation","text":"<p>Similar to iterative independent classification based on neighbor majority vote. </p> <p>Difference:</p> <ul> <li>maintain predictions as probability distribution over all class label values</li> </ul> <p>Probability distribution over labels for unlabeled nodes:</p> <p></p> <p>[S. Bhagat, G. Cormode, S. Muthukrishnan: Node Classification in Social Networks, in: C.C. Aggarwal Ed.: Social Network Data Analytics, 2011.]</p> <p>[S.A. Macskassy, F. Provost: A Simple Relational Classifier. Workshop on Multi-Relational Data Mining (MRDM-2003)]</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#algorithm","title":"Algorithm","text":"<p>Choose indexing where V_l = \\{1, \\dots, n_0\\}V_l = \\{1, \\dots, n_0\\} and V_u=\\{n_0+1, \\dots, n\\}V_u=\\{n_0+1, \\dots, n\\}</p> <p>Define n_0 \\times kn_0 \\times k label matrix Y_lY_l:</p>  Y_l[i,j] = \\left \\{  \\begin{array}{} 1 &amp; \\text{if } Y(i) = y_j \\\\ 0 &amp; \\text{if } Y(i) \\neq y_j \\end{array} \\right .   Y_l[i,j] = \\left \\{  \\begin{array}{} 1 &amp; \\text{if } Y(i) = y_j \\\\ 0 &amp; \\text{if } Y(i) \\neq y_j \\end{array} \\right .  <p>Iterative Formulation</p> <p>For each node v \\in V_uv \\in V_u, maintain a probability distribution Q(v)Q(v) over the set \\mathcal y = {y_1, \\dots, y_k}\\mathcal y = {y_1, \\dots, y_k} of different possible class label values Y(v)Y(v):</p> <ul> <li>Q^0(v) = \\frac {1} {|V_l|} \\sum_{u\\in V_l} Y_l[u, \\bullet]Q^0(v) = \\frac {1} {|V_l|} \\sum_{u\\in V_l} Y_l[u, \\bullet] (\"class prior\")</li> <li>Iteratively update Q(v)Q(v):</li> </ul>  Q^{t+1}(v) = \\frac {1} {|N_v|} \\left( \\sum_{u\\in N_v \\cap V_l} Y_l[y, \\bullet] + \\sum_{u\\in N_v \\cap V_u} Q^t(u) \\right)   Q^{t+1}(v) = \\frac {1} {|N_v|} \\left( \\sum_{u\\in N_v \\cap V_l} Y_l[y, \\bullet] + \\sum_{u\\in N_v \\cap V_u} Q^t(u) \\right)  <p>N_vN_v: set of graph neighbors of vv.</p> <ul> <li>Prediction: most probable label according to Q^\\infty(v)Q^\\infty(v) (assuming convergence)</li> </ul> <p>Example</p> <p>Example on slides 10.10</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#random-walk","title":"Random Walk","text":"<p>Define a random walk on the graph:</p> <ul> <li>from any unlabeled node, randomly chose a neighbor</li> <li>at labeled nodes: stay at node with probability 1 (labeled nodes are sink nodes) .</li> </ul> <p>The transition matrix then can be written as:</p>  P= \\begin{pmatrix}  l        &amp; 0 \\\\ P_{ul} &amp; P_{uu} \\end{pmatrix}   P= \\begin{pmatrix}  l        &amp; 0 \\\\ P_{ul} &amp; P_{uu} \\end{pmatrix}  <p>where </p> <ul> <li>ll is n_0 \\times n_0n_0 \\times n_0 identity matrix</li> <li>P_{ul}P_{ul} is (n-n_0) \\times n_0(n-n_0) \\times n_0</li> <li>P_{uu}P_{uu} is (n-n_0) \\times (n-n_0)(n-n_0) \\times (n-n_0)</li> </ul> <p>k-step transition probabilities: P^k = P \\cdot P^{k-1}P^k = P \\cdot P^{k-1} in the limit:</p>  P^\\infty = \\begin{pmatrix} l                       &amp; 0\\\\ P^\\infty_{ul} &amp; P^\\infty_{uu} \\end{pmatrix}   P^\\infty = \\begin{pmatrix} l                       &amp; 0\\\\ P^\\infty_{ul} &amp; P^\\infty_{uu} \\end{pmatrix}  <p>Assuming that from every unlabeled node, a labeled node is reachable: P^\\infty_{uu}=0P^\\infty_{uu}=0</p> <p>For P^\\infty_{ul}P^\\infty_{ul} we have: $$ P^\\infty_{ul} = P_{ul} + P_{uu}P_{ul}^\\infty \\Rightarrow P_{ul}^\\infty = (1- P_{uu})^{-1}P_{ul} $$</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#from-random-walk-to-label-distribution","title":"From Random Walk to Label Distribution","text":"<p>The P_{ul}^\\inftyP_{ul}^\\infty distribution defines a (probabilistic) labeling of the unlabeled nodes $$ Q^{RW} = P_{ul}^\\infty \\cdot Y_l $$ where Q^{RW}Q^{RW} is a (n-n_0) \\times k(n-n_0) \\times k matrix</p> <ul> <li>Q^{RW}[h,j]Q^{RW}[h,j] = probability that random walk started at unlabeled node n_0 + hn_0 + h ends at labeled node with label y_jy_j.</li> </ul>"},{"location":"7-semester/WI/09%2B10-node-classification/#example_1","title":"Example","text":""},{"location":"7-semester/WI/09%2B10-node-classification/#equivalence","title":"Equivalence","text":"<p>The iterative and random walk distributions are the same: $$ Q^\\infty = Q^{RW} $$ This can be seen as follows: $$ \\begin{align} Q^\\infty  &amp;= P_{ul}Y_l + P_{uu}Q^\\infty \\ &amp;= P_{ul}Y_l + P_{uu}P_{ul}Y_l + P^2{uu} Q^\\infty \\ &amp;\\vdots \\ &amp;= \\Sigma^\\infty_{i=0} P^i_{uu} P_{ul} Y_l + P_{uu}^\\infty Q^\\infty \\ &amp;= \\Sigma^\\infty_{i=0} P^i_{uu} P_{ul} Y_l \\ &amp;= P^\\infty_{ul} Y_l \\ &amp;= Q^{RW} \\end{align} $$</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#word-embeddings","title":"Word Embeddings","text":"<p>Embeddings so far:</p> <ul> <li>Texts \\to\\to vector space model (observable features: tf, idf)</li> <li>User/products:<ul> <li>\\to\\to (product) feature space</li> <li>\\to\\to latent space (latent features: SVD)</li> </ul> </li> <li>(Social) network nodes \\to\\to latent space (SVD)</li> </ul> <p>Embeddings to come:</p> <ul> <li>Word embeddings: word2vec</li> <li>Node embeddings: node2vec</li> </ul> <p>Literature: Mikolov, Tomas, et al. \"Distributed representations of words and phrases and their compositionality.\" Advances in neural information processing systems. 2013.</p> <p>A word embedding maps the words of a vocabulary (or dictionary) into n-dimensional space of reals:</p>  e: \\textit{Vocabulary} \\to \\R^n   e: \\textit{Vocabulary} \\to \\R^n  <p>E.g. n=100n=100 or n=1000n=1000</p> <p>Goal: embedding encodes semantic meanings and relationships and supports multiple applications in natural language processing.</p>"},{"location":"7-semester/WI/09%2B10-node-classification/#example_2","title":"Example","text":"<p>2-d projection of 1000 dimensional embeddings of countries and capitals:</p> <p></p> <p>Source: [Mikolov et al., 2013]</p>  e(Berlin)- e(Germany) \\approx e(Paris) - e(France)   e(Berlin)- e(Germany) \\approx e(Paris) - e(France)  <p>Application for analogical reasoning: to answer \u201cBerlin is for Germany what ??? is for France\u201d, compute:</p>  e(Berlin) - e(Germany) + e(France)   e(Berlin) - e(Germany) + e(France)  <p>and find the nearest word to this vector</p>"},{"location":"7-semester/WI/exam/","title":"WI Exam","text":"<p>January 4-6, 2021</p> <ul> <li>You will get access to the assignment by the start of the exam (January 4, 2021 at 9.00)</li> <li>Your paper must be uploaded by the end of the exam (January 6, 2021 at 23.59)</li> <li>In case of errors in the assignment, please contact your semester secretary (9940 8854/ulla@cs.aau.dk)</li> </ul>"},{"location":"7-semester/WI/exam/#topics","title":"Topics","text":"<ol> <li>Web crawling. Frontier, robustness, politeness, Mercator frontier, duplicate identification, Shingles</li> <li>Index construction. Text preprocessing, inverted index, Boolean retrieval, merge algorithm, positional index</li> <li>Content-based Ranking. TF-IDF, vector space model, cosine similarity, SMART notation</li> <li>Structure based Ranking. Centrality, prestige, PageRank, random walks and Markov chains (exclude: HITS)</li> <li>Recommendation: basics and content-based. Cold start problem, serendipity, explicit/implicit feedback, evaluation measures, content-based recommendation, naive Bayes, content based recommendation with implicit feedback.</li> <li>Recommendation: basics and collaborative. Cold start problem, serendipity, explicit/implicit feedback, evaluation measures, neighborhood methods, personalized PageRank (exclude: Itemrank), matrix factorization from error function minimization perspective (exclude: matrix theory behind SVD).</li> <li>Community Detection: basics and classics: network characteristics, degree distribution, power law, diameter, clustering coefficient, Kernighan-Lin algorithm, Newman-Girvan algorithm, modularity</li> <li>Community Detection: basics and latent: network characteristics, degree distribution, power law, diameter, clustering coefficient, matrix factorization techniques, adjacency matrix, Laplacian matrix</li> <li>Node classification: inductive, transductive, homophily, node features, independent classification,  collective classification, iterative independent classification, label propagation</li> </ol>"},{"location":"7-semester/WI/exam/#procedure","title":"Procedure","text":"<p>You will receive via Digital Exam an assignment on Jan. 4, for which you have to submit a written solution on Jan. 6. </p> <p>Everyone receives a randomly allocated assignment from among these 9 different ones. For each assignment, there will be the option to solve the assignment in one of the two 'modes':</p> <ul> <li>Theoretical<ul> <li>Your solution of the assignment consists of explanations, examples, discussion, figures, etc. that are based on the lecture slides and background literature. No Python programming required.</li> </ul> </li> <li>Experimental<ul> <li>Your solution will still require some explanations, discussions etc., but is otherwise largely based on implementation and experimentation. Python code developed in the self-study exercises can often be a basis for this type of solution to the assignment.</li> </ul> </li> </ul> <p>Obviously, solutions to the assignments must be prepared strictly individually, and no collaboration between students with the same assignments is allowed. Python code developed with other students in the self studies can be freely used, however.</p>"},{"location":"8-semester/","title":"Indhold","text":"<p>Kurser:</p> <ul> <li>MDLS</li> <li>mHCI</li> <li>sP</li> </ul> <p></p>"},{"location":"8-semester/MDLS/01-introduction/","title":"Introduction","text":""},{"location":"8-semester/MDLS/01-introduction/#what-is-mobile-computing","title":"What is Mobile Computing?","text":"<ul> <li>Technology that allows transmission of data, voice and video via a computer or any other wireless enabled device without having to be connected to a fixed physical link. </li> </ul>"},{"location":"8-semester/mHCI/01-introduction/","title":"mHCI Introduction","text":""},{"location":"8-semester/mHCI/01-introduction/#what-is-hci","title":"What is HCI?","text":"<ul> <li>Human Computer Interaction</li> </ul> <p>Deals with the design and use of computers.</p> <p>HCI Researchers and practitioners observe how people interact with computers and design technologies that allow humans to interact with computers.</p> <p>HCI Research mainly produces/uses methods:</p> <ul> <li>for designing computer interfaces</li> <li>for developing interfaces</li> <li>for evaluating and comparing interfaces with respect to their usability and other desirable properties</li> <li>for studying their use and ther sociocultural implications</li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#history","title":"History","text":""},{"location":"8-semester/mHCI/01-introduction/#the-mainframe-era","title":"The Mainframe Era","text":"<p>1960</p> <ul> <li>Diffucult/impossible for normal people to use computers</li> <li>Must be effective to use, and small amount of errors</li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#personal-era","title":"Personal Era","text":"<p>1980</p> <ul> <li>Computers move into houses</li> <li>We use computers in other ways<ul> <li>Gaming consoles</li> <li>Entertainment</li> </ul> </li> <li>Computers should be easy to learn</li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#design-is-not-trivial","title":"Design is not Trivial","text":"<ul> <li>It is important how buttons are placed</li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#computers-are-evolving","title":"Computers are Evolving","text":"<ul> <li>In every use-case there is a context</li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#where-are-we-heading","title":"Where are we Heading?","text":"<ul> <li>Tangible interaction<ul> <li>We can touch the interfaces</li> </ul> </li> <li>Synthetic HCI<ul> <li>\"Human Robot Interaction\"</li> <li>How do we design robot interfaces</li> </ul> </li> <li>Ubiquitious Interaction<ul> <li>Computers are everywhere</li> </ul> </li> <li>Connected</li> <li>Wearable Computing<ul> <li>In Mobile HCI it is important</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/01-introduction/#what-is-mobilehci","title":"What is MobileHCI?","text":"<p>Three eras of interaction</p> <p></p>"},{"location":"8-semester/mHCI/01-introduction/#what-are-we-designing-for","title":"What are we designing for?","text":"<p>Different devices</p> <p></p>"},{"location":"8-semester/mHCI/01-introduction/#mobile-phones-timeline","title":"Mobile Phones Timeline","text":""},{"location":"8-semester/mHCI/01-introduction/#wearables-timeline","title":"Wearables Timeline","text":""},{"location":"8-semester/mHCI/01-introduction/#why-mobiles","title":"Why Mobiles","text":"<ul> <li>People bring their mobile devices with them<ul> <li>Easy to notify them through your design</li> <li>E.g. Google Maps asking how you trip was</li> </ul> </li> <li>Designing for Mobile devices can offer more personal experiences<ul> <li>Deliver more personal information to people</li> </ul> </li> <li>Mobile devices holds most of the features that other devices also have (and even perform better in some cases)<ul> <li>More sensors</li> </ul> </li> <li>People spend more time in front of their smartphones than other personal devices</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/","title":"MCHI Concepts and Understanding Context","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#characterising-mobile-computing","title":"Characterising Mobile Computing","text":"<ul> <li>Portability</li> <li>Miniturization</li> <li>Connectivity</li> <li>Convergence</li> <li>Divergence</li> <li>Apps</li> <li>Digital Ecosystems</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#portability","title":"Portability","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#miniturization","title":"Miniturization","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#connectivity","title":"Connectivity","text":"<ul> <li>Devices are getting connected</li> <li>Phone network</li> <li>Bluetooth and infrared</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#convergence","title":"Convergence","text":"<ul> <li>Not just a phone or computer any more</li> <li>You can now play and do spreadsheets on the phone (Nokia 9000)</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#divergence","title":"Divergence","text":"<ul> <li>Doing one thing well</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#apps","title":"Apps","text":"<ul> <li>In the beginning, only the manifactures made apps<ul> <li>limited selection</li> </ul> </li> <li>Then came Developing kits and app stores</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#digital-ecosystems","title":"Digital Ecosystems","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#defining-the-context-for-our-design","title":"Defining the Context for our Design","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#establishing-requirements-understanding-the-context","title":"Establishing Requirements (understanding the context)","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#what-is-important-for-your-users","title":"What is important for your users?","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#calculator-non-calculator","title":"Calculator / Non Calculator?","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#who-are-your-users-and-what-is-the-context-of-use","title":"Who are your users and what is the context of use?","text":""},{"location":"8-semester/mHCI/02-concepts-and-context/#context-c-and-context-c","title":"Context (C) and context (c)","text":"<p>The intent is to define the circumstances, or thetoric, of how communicate and understand ideas.</p> <p>-Mobile Design and Development</p>"},{"location":"8-semester/mHCI/02-concepts-and-context/#context-big-c","title":"Context (big C)","text":"<p>\"Context enables us to better understand a person, a place, a thing, a situation, or even an idea by adding information to it\"</p> <p>-Mobile Design and Development</p> <p>The Problem</p> <ul> <li>What problems are you trying to design a solution for?</li> <li>What value do you want to bring for your users?</li> </ul> <p>Users and their situation</p> <ul> <li>Who are your users and what do you know about them?</li> <li>How are they able to or how will they interact with your design?</li> </ul> <p>Location</p> <ul> <li>What and where is it happening?</li> </ul> <p>Markets</p> <ul> <li>How is your idea different from other design already available?</li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#example-car-next-door","title":"Example - Car Next Door","text":"<p>The problem:</p> <ul> <li>Little utilisation of private car park</li> </ul> <p>The Users:</p> <ul> <li>Car owners, non-car owners</li> </ul> <p>Location:</p> <ul> <li>Private cars scattered around town, same with users often on the go</li> </ul> <p>Other markets:</p> <ul> <li>B2C car sharing<ul> <li>often more expensive</li> </ul> </li> </ul> <p>The idea: A mobile P2P platform for sharing privately owned cars</p>"},{"location":"8-semester/mHCI/02-concepts-and-context/#context-small-c","title":"Context (small c)","text":"<p>\"The mode, medium, or environment in which we perform a task or the circumstances of understanding\"</p> <p>-Mobile Design and Development</p> <p>Which requirements / constraints lies in the context?</p> <p>Physical and spatial considerations</p> <ul> <li>Are there any restrictions in the physical environment or the location?<ul> <li>(e.g will I be able to use the design all the time)</li> </ul> </li> </ul> <p>Technological considerations</p> <ul> <li>How are different devices present in different situations?<ul> <li>(e.g. why smart watches might be better than smartphones when running or swimming)</li> </ul> </li> </ul> <p>Psycological/demographical considerations</p> <ul> <li>Does users mental models and prerequisites for interacting with certain devices<ul> <li>(e.g. knowledge, common conceptions in the community)</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/02-concepts-and-context/#example-car-next-door_1","title":"Example - Car Next Door","text":"<p>The Idea: A mobile P2P platform for sharing privately owned cars safely. Instantly through wireless locks, and at a low price, compared to B2C solutions</p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/","title":"Introduction to Quantitative Studies","text":"<p>Where are we in the Process?</p> <p></p> <p></p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#data-collection","title":"Data Collection","text":"<p>Typically takes place in a laboratory</p> <ul> <li>Able to control everything</li> </ul> <p>Typed of collected data:</p> <ul> <li>Anything that can be understood as a number<ul> <li>Time </li> <li>Performance metrics</li> <li>Success rates</li> <li>Answers to questionnaires</li> </ul> </li> <li>The difference is that data is structured and we usually collected them in order to answer a question!</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#examples-of-interesting-questions-across-different-fields","title":"Examples of interesting questions across different fields","text":"<ul> <li>Why sometimes people behave like idiots? (psychology)</li> <li>What\u2019s the difference between Denmark and Germany in relation to racism (sociology/anthropology)</li> <li>What is the effect of smart phone usage to eye-sight? (medicine)</li> <li>What is the relation between sleep and athletic performance (sports studies)</li> <li>Which platform is fastest and why? (software)</li> <li>How can we make more money out of product X? (business)</li> <li>Why prototype A is better than prototype B? (Interaction Design)</li> <li>Why people like Donald Trump? (political science)</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#how-do-we-often-get-answers-to-our-questions","title":"How do we often get answers to our questions?","text":"<p>Case 1: We use our Intuition</p> <p>Or the \u201ccommon sense\u201d: We make general conclusions about the world around us based on anecdotal evidence (for example our own experiences/our cultural background).</p> <ul> <li>\u201cSamsung is better than Apple\u201d</li> <li>\u201cAll Arabs are terrorists\u201d</li> </ul> <p>More stuff (optional): </p> <ul> <li>List of cognitive biases</li> </ul> <p>Case 2: We trust Authority</p> <p>We tend to believe people or organizations because we assume they are credible.</p> <ul> <li>\u201cDanes do not care about refuges\u201d (European media?)</li> <li>\u201cGay couples are terrible parents\u201d (Church?)</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#examples-of-wrong-answers-intuition","title":"Examples of wrong answers - Intuition","text":"<ul> <li>\u201cSince the first appearance of Rihanna, bacon sales have increased\u201d \\to Listeners of Rihanna eat bacon</li> <li>\u201cSince Kill Bill, yellow uniform sales have increased drastically\u201d \\to\\to More people want to look like Uma Thurman</li> <li>\"If the Redskins win their last home game before the election, the party that won the previous election wins the next election and that if the Redskins lose, the challenging party's candidate wins.\u201d \\to\\to Fulfilled in 17 our of 19 US presidential elections since 1937</li> </ul> <p>More stuff (optional):</p> <ul> <li>Lying with statistics</li> <li>Correlation does not imply causation</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#examples-of-wrong-answers-authority","title":"Examples of wrong answers - Authority","text":""},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#how-do-we-get-valid-answers-to-our-questions","title":"How do we get valid answers to our questions?","text":"<ul> <li>We use the Scientific Approach<ul> <li>Intuition and/or authority are used to generate ideas about a phenomenon/behavior</li> <li>Skepticism: ideas must be evaluated on the basis of careful logic and results from scientific investigations</li> <li>Empiricism: knowledge is based on observations and the study of reality</li> </ul> </li> </ul> <p>Example</p> <ul> <li>We believe mobile application X is more usable than Z</li> <li>we need to run an experiment in order to observe representative user\u2019s and acquire scientific knowledge</li> <li>Even if we prove we are wrong, this knowledge is useful (falsifiability)</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#questions-and-answers-opinions-and-claims","title":"Questions and answers, opinions and claims","text":"<ul> <li> <p>Which questions are scientific?</p> <ul> <li>The ones that can be tested by collecting and analyzing quantitative data!</li> </ul> </li> <li> <p>Which answers are evidence based and not opinions? </p> <ul> <li>The ones that emerged by applying the Scientific approach!</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#how-are-all-these-related-to-hci-and-mhci","title":"How are all these related to HCI and mHCI?","text":"<ul> <li>Because HCI and mHCI is about studying users\u2019 behaviors/feelings/emotions when they interact with technological artifacts.</li> <li>We study Interactions to:<ul> <li>Describe users\u2019 behaviors</li> <li>Predict their behavior in the future</li> <li>Determine the cause of their behaviors</li> <li>Explain their behavior</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#quantitative-methods-in-mhci","title":"Quantitative methods in mHCI","text":"<p>Quantitative methods emphasize objective measurements and the statistical, mathematical, or numerical analysis of data collected through polls, questionnaires, surveys, or logfiles, using computational techniques. </p> <p>Quantitative research focuses on gathering numerical data and generalizing it across groups of people, or to explain a particular phenomenon</p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#quantitative-research-methods-in-mhci","title":"Quantitative Research Methods in mHCI","text":"<p>Case studies</p> <ul> <li>Intensive empirical investigations of contemporary phenomena within small size entities such as groups, organizations, individuals, systems or tools in real-life context with the researcher distinct from the phenomena being studied.</li> </ul> <p>Field studies</p> <ul> <li>Characterized by taking place in \u201cthe real world\u201d covering a range of quantitative approaches in which a number of independent variables are manipulated.</li> </ul> <p>Usage Studies</p> <ul> <li>Large-scale log-file based test-scenario in which a newly designed system is exposed to its target users in order to test its resilience under real-use conditions, and if and how it is employed for the tasks for which it was intended.<ul> <li>A/B testing</li> </ul> </li> </ul> <p>Lab experiments/studies</p> <ul> <li>Characterized by taking place in a controlled environment created for the purpose of research or in dedicated laboratories allowing a detailed focus on specific phenomena of interest with a large degree of experimental control.</li> </ul> <p>Surveys</p> <ul> <li>Informs research gathers large amounts of data through various techniques such as questionnaires and interviews from a known sample of selected respondents assumed to be independent of their environment.</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#quantitative-research-methods-purposes-in-mhci","title":"Quantitative Research Methods Purposes in mHCI","text":"<p>Understanding</p> <ul> <li>The purpose of research focusing on finding the meaning of studied phenomena through, for example, frameworks or theories developed from collected data.</li> </ul> <p>Engineering</p> <ul> <li>The purpose of research focused towards developing new systems or parts of systems, for example an interaction technique for a mobile device, or a mobile application or device.</li> </ul> <p>Re-engineering</p> <ul> <li>The purpose of research focusing on improving existing systems by redeveloping them such as, for example, adapting a web browser to a small display</li> </ul> <p>Evaluating </p> <ul> <li>The purpose of research assessing or validating products, theories or methods, for example, the usability or user experience of a specific application, or a theory of interaction.</li> </ul> <p>Describing</p> <ul> <li>The purpose of research focusing on defining desirable properties of products, for example, a mobile guide system.</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#quantitative-research-process","title":"Quantitative Research Process","text":"<ol> <li>Theory </li> <li>Hypothesis</li> <li>Research Design</li> <li>Devise measures</li> <li>Select research sites</li> <li>Select research subjects</li> <li>Collect Data</li> <li>Prepare and Process Data</li> <li>Analyze Data</li> <li>Derive Findings</li> <li>Write up findings</li> <li>Go back to 1</li> </ol>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#initial-steps","title":"Initial Steps","text":"<p>Theory:</p> <ul> <li>An explanation of a situation/phenomenon</li> </ul> <p>Research Question</p> <ul> <li>A description of the broad topic of study</li> </ul> <p>Hypothesis</p> <ul> <li>A specific idea or question which can be tested through empirical investigation (using the scientific approach)</li> </ul> <p>Prediction</p> <ul> <li>A deliberate guess to answer the Hypothesis</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#example","title":"Example","text":"<p>Theory</p> <ul> <li>\u201cThere are differences among groups of people on how they perceive the mobile Facebook Interface\u201d</li> </ul> <p>Research Question</p> <ul> <li>\u201cAre there any differences among groups of people on how they perceive the mobile Facebook Interface?\"</li> </ul> <p>Hypothesis</p> <ul> <li>\u201cMales perceive the mobile Facebook Interface as more usable than Females\u201d</li> </ul> <p>Prediction</p> <ul> <li>\u201cMales are more likely to perceive the mobile Facebook Interface as more usable\u201d</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#research-question-vs-hypotheses","title":"Research Question vs Hypotheses","text":"<p>Research Question: \u201cAre there any differences among groups of people on how they perceive the Facebook Interface?\"</p> <ul> <li>Hypothesis A: \u201cMales perceive the mobile Facebook Interface than as more usable than Females\u201d</li> <li>Hypothesis B: \u201cRich perceive the mobile Facebook Interface as more usable than Poor\u201d</li> <li>Hypothesis C: \u201cEuropeans perceive the mobile Facebook Interface as more usable than Asians\u201d</li> <li>Hypothesis D: \u201cExperts perceive the mobile Facebook Interface as more usable than Novices\u201d</li> <li>...</li> <li>Hypothesis N: ...</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#null-and-alternative-hypothesis","title":"Null and Alternative Hypothesis","text":"<ul> <li>Null hypothesis: There is no difference between the conditions</li> <li>Alternative hypothesis: There is difference between the conditions</li> <li>They have to be mutually exclusive</li> </ul> <p>Example</p> <ul> <li> <p>Null hypothesis \u201c H~0~: Males do not perceive the mobile Facebook Interface as more usable than Females\u201d</p> </li> <li> <p>Alternative hypothesis \u201cH~1~: Males perceive the mobile Facebook Interface as more usable than Females\u201d</p> </li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#why-do-we-have-null-and-alternative-hypothesis","title":"Why do we have null and alternative hypothesis?","text":"<ul> <li>Long tradition in experimental research</li> <li>In statistics we do not test if two conditions are different</li> <li>We do test if there are the same!</li> </ul> <p>Example</p> <p>We take a random sample of mobile Facebook users. We assume there is no difference between sexes in relation to usability (null hypothesis, H~0~, is true).</p> <p>Through a statistical test we check if there are significant differences between sexes.</p> <p>If there are no statistically significant differences, then we accept the H~0~ as true.</p> <p>If there are differences then we reject H~0~, and we can conclude that the alternative hypothesis (H~1~) is true.</p> <p>Significance: there is a very low probability that the result is occurring by chance</p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#variables","title":"Variables","text":"<p>H~1~: \u201cMales perceive the mobile Facebook Interface as more usable than Females\u201d</p> <ul> <li>In order to test our hypothesis we need to measure or manipulate something. All the things we can measure or manipulate are called variables.</li> <li>Any variable must have more than two levels</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#operational-definitions","title":"Operational Definitions","text":"<p>For every variable we need a defined procedure to measure or manipulate it.</p> <p>If there are many options, we need to select one. The selected procedure is called the operational definition of the variable</p> <p>Example: Aggression</p> <ul> <li>The number of times a kid hits a toy</li> <li>The number of times a kid fights with another kid</li> <li>A score on a aggression questionnaire</li> <li>The number of times a kid cursed, etc.</li> </ul> <p>Example: Usability</p> <ul> <li>Perceived usability</li> <li>Task completion times/rates, etc.</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#adequacy-of-our-operational-definitions-types-of-construct-validity","title":"Adequacy of our Operational Definitions: Types of Construct Validity","text":"<ul> <li>Construct Validity: The adequacy of our operational definition<ul> <li>Content Validity: The content of our measure is linked to the true meaning of the variable</li> <li>Convergent Validity: Scores of our measure are related to other measures of the same construct</li> <li>Discriminant Validity: Scores of our measure are not related to other measures that are theoretically different</li> <li>Other types: face validity, predictive validity, concurrent validity</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#measuring","title":"Measuring","text":"<ul> <li>Every time we measure a variable there is an error</li> <li>The smaller the error, the better (obviously!)</li> <li>Standard units of measurement ensure the error is minimal</li> </ul> <ul> <li>Any examples of standard units of measurement? What about within software?</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#reliability","title":"Reliability","text":"<ul> <li>Refers to the consistency or stability of a measure</li> <li>If I measure the same thing twice I should have the same results</li> <li>The measurement error of a reliable measurement tool has less variability than an unreliable one</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#assessing-reliability","title":"Assessing Reliability","text":"<ul> <li>Test-retest reliability</li> <li>We measure the same thing twice and the results should be correlated (usually correlation coefficient &gt;0.80)</li> <li>Internal consistency reliability. Used when multiple items are measuring the same variable (i.e. questionnaire)</li> <li>Split-half reliability<ul> <li>We split the data randomly into two halves. The correlation of total score on a half of a measure should be high with the other half (Spearman-Brown split-half reliability coefficient)</li> </ul> </li> <li>Cronbach\u2019a alpha (\u03b1), the correlation of each item on the measure with every other item on the measure</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#correlation-coefficient","title":"Correlation Coefficient","text":"<ul> <li>A numerical index of the strength of relationships between variables</li> <li>Most common: Pearson product-moment correlation coefficient (r)</li> <li>-1.00 \\to 0.00 \\to +1.00-1.00 \\to 0.00 \\to +1.00</li> <li>00 = no relation at all</li> <li>++ = positive linear</li> <li>-- = negative lnear</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#types-of-relationships-between-variables","title":"Types of relationships between variables","text":"<ul> <li>Education has an effect on IQ level</li> </ul> <p>Positive Linear and Negative Linear</p> <p></p> <p>No relationship</p> <p></p> <p>Curvilinear</p> <p></p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#types-of-variables","title":"Types of Variables","text":""},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#categorical","title":"Categorical","text":"<ul> <li>Nominal Variable</li> <li>The levels do not hae any meaningful numerical, quantitative properties.</li> <li>Example: eye color, university degree, marital status, sex</li> <li>If there are only two levels its called a binary or dichotomous variable</li> <li>Ordinal variable</li> <li>Levels do have meaningful, quantitative properties, usually ordered</li> <li>Example: Exam grades, athlete placement on podium</li> <li>Usually distance among levels is not equal</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#continuous","title":"Continuous","text":"<ul> <li>Interval variable</li> <li>Different between levels are equal in size</li> <li>Thus, difference between 1 and 2 have same meaning as 6 and 7</li> <li>Example: Example, strongly agree/strongly disagree question, time, age</li> <li>Ratio variable</li> <li>Same as above, but 0 indicate absence of variable</li> </ul> <p>Tricky part</p> <ul> <li>Continuous variables can be sometimes discrete, depending on the level of precision.</li> <li>We cannot answer on a questionnaire the value 4.32, but we assume that there is a continuum that the scale is following.</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#categorizing-a-variable","title":"Categorizing a Variable","text":""},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#making-studies","title":"Making Studies","text":"<ul> <li>Non experimental methods</li> <li>Descriptive investigations (Usage studies, surveys, etc.)</li> <li>Relational investigations (Case studies)</li> <li>Experimental methods</li> <li>Lab experiments</li> <li>Field experiments</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#nonexperimental-methods","title":"Nonexperimental Methods","text":"<p>Often called correlational methods</p> <ul> <li>We make observations, or measures of the variables of interest in natural settings</li> <li>By asking people to describe their behaviour</li> <li>By making direct observations</li> <li>By recording log files, physiological reponses</li> <li>By examining public records</li> <li>...</li> <li>Characteristics</li> <li>We can have data that two variables are correlated (or covary - they vary together) with each other</li> <li>We do not know which one is the cause or the effect</li> <li>Very good for having an initial understanding of a domain</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#experimental-methods","title":"Experimental Methods","text":"<ul> <li>We basically make experiments</li> <li>They help us reducing the ambiguity of the results</li> <li>They help us deal with the directionality and confounding variable problem</li> </ul> <p>When we are certain that there is an uncontrolled external (or extraneous) variable, then it is called a confounding variable</p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#mhci-example","title":"mHCI Example","text":"<p>Directionality Problem</p> <p></p> <p>Third variable Problem</p> <p></p>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#characteristics","title":"Characteristics","text":"<ul> <li>We manipulate a variable to measure its effect on another one</li> <li>We try to create situations (or treatments or conditions) where the proposed cause is present or absent</li> <li>We try to keep constant all the confounding variables across all the conditions (experiment control)</li> <li>We randomize the participants and other variables in order to minimize the influence of other possible external variables that might affect the results</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#independent-and-dependent-variables","title":"Independent and Dependent Variables","text":"<ul> <li>Independent variable</li> <li>Variable we think is the cause</li> <li>Variable that is independent of a participant\u2019s behavior</li> <li>Variable that we manipulate in our experiment</li> <li>Dependent variable</li> <li>Variable we think is the effect, as it depends on the cause</li> <li>Variable that is dependent on a participant\u2019s behavior</li> <li>The variable that we measure in our experiment</li> <li>Examples</li> <li></li> <li>Sex has an effect on perceived usability</li> <li>Income has an effect on happiness</li> <li>Education has an effect on IQ level</li> <li>Input devices have an effect on efficiency</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#descriptive-statistics-univariate-analysis","title":"Descriptive Statistics Univariate Analysis","text":"<ul> <li>Descriptive Statistics - numbers that describe our data</li> <li>Univariate analysis - the process of analysing one variable</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#frequency-distribution","title":"Frequency Distribution","text":"<ul> <li>A plot that shows how many times each value occurs</li> <li>Usually we have the values on the horizontal axes and the times it occurred on the vertical one</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#normal-distribution","title":"Normal Distribution","text":"<ul> <li>In an ideal world our data should be distributed symmetrically around the center of all scores. </li> <li>If we draw a line in the center, the distribution should look the same on both sides</li> <li>Kurtosis, skew = 0</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#ways-a-distribution-can-deviate-from-normal","title":"Ways a distribution can deviate from normal","text":"<ul> <li>Skew - lack of symmetry (most scores are clustered at one end of the scale)</li> <li>Positively skewed distribution - it has a long tail to the right side</li> <li>Negatively skewed distribution - it has a long tail to the left side</li> <li>Kurtosis - pointiness</li> <li>Positive kurtosis (leptokurtic) - very pointy</li> <li>Negative kurtosis (platykurtic) - flatter than normal</li> </ul>"},{"location":"8-semester/mHCI/08-introduction-to-quantitive-studies/#measures-of-central-tendency","title":"Measures of central tendency","text":"<ul> <li>Mode - the score that occurs the most</li> <li>It is the tallest bar in the distribution - we can have multimodal distributions</li> <li>Median - the middle score of a distribution</li> <li>We order the scores and we get the middle one (the one in position (n+1)/2(n+1)/2) if not integer, we average the neighboring ones</li> <li>Mean - the average score</li> <li>We sum all the scores and divide by the number of scores</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/","title":"Lab Experiments","text":""},{"location":"8-semester/mHCI/09-lab-experiments/#basic-experiment","title":"Basic Experiment","text":"<p>Our case: H~1~: \"The screen size of a mobile phone has an effect on the perceived usability of mobile Facebook Interface\"</p> <p></p> <p>Manipulating the independent variable</p> <p>Defining the levels/conditions/groups/treatments</p> <p></p>"},{"location":"8-semester/mHCI/09-lab-experiments/#narrowing-down-the-number-of-levels","title":"Narrowing down the number of levels","text":"<ul> <li>We select the extreme cases - in our example 2.4\u2019\u2019 and 5.5\u2019\u2019</li> <li>We select most common conditions with the largest possible distance - in our example 4.0\" and 5.5\"</li> <li>We group the cases into two categories - in our example small screens and large screens</li> <li>Other ways that are meaningful in the context of our experiment</li> </ul> <p>Using THE RULE</p> <ul> <li>The two conditions must differ only in relation to the independent variable</li> </ul> <p></p>"},{"location":"8-semester/mHCI/09-lab-experiments/#selecting-participants","title":"Selecting participants","text":"<ul> <li>We need to select a sample that will participate in our experiment that is representative of the population</li> <li>The population is defined as all the individuals of interest</li> <li>With proper sampling we assume the results we will get from the sample will also apply to the population</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#sampling-techniques","title":"Sampling Techniques","text":"<ul> <li>Probability sampling</li> <li>Each member of the population has a specifiable probability of being chosen to participate in our experiment</li> <li>Nonprobability sampling</li> <li>The probability of any particular member of the population to be chosen is unknown</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#assigning-participants-to-conditions","title":"Assigning Participants to Conditions","text":""},{"location":"8-semester/mHCI/09-lab-experiments/#within-group-designs","title":"Within-group designs","text":"<ul> <li>The same participants experience both conditions</li> <li>Often called repeated measures design</li> </ul> <p>Advantages</p> <ul> <li>We need less participants</li> <li>The systematic error caused by the participants will be the same in both conditions - easier to get better results</li> </ul> <p>Disadvantages</p> <ul> <li>Hard to control the practice, order, and fatigue effects</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#counterbalancing","title":"Counterbalancing","text":"<ul> <li>All possible orders of conditions are included in the experiment</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#between-group-designs","title":"Between-group designs","text":"<ul> <li>Different participants experience the conditions</li> <li>Often called independent groups design</li> </ul> <p>Advantages</p> <ul> <li>Easier to control the practice, order, and fatigue effects - often do not exist</li> </ul> <p>Disadvantages</p> <ul> <li>We need many participants</li> <li>The systematic error caused by the participants' characteristics is more difficult to control</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#statistical-technique","title":"Statistical Technique","text":"<ul> <li>Within-group design =&gt; Paired samples t-tes</li> </ul> <ul> <li>Between-group design =&gt; Independent t-test</li> </ul> <p>Reporting</p> <p>We conducted an independent samples t-test to locate possible interaction effects.</p> <p>Results showed a statistically significant different in the perceived usability scores for the participants that used the large phone (M=XX, SD=XX) and the ones that used the small one (M=XX, SD=XX).</p> <p>t(58)=1.329,\\quad p=.013</p> <p>The rule for every statistical test</p> <ul> <li>Make sure you follow the test's assumptions!</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#what-if-we-have-more-than-two-conditions","title":"What if we have more than two conditions?","text":"<p>Which statistical technique to use?</p> <ul> <li>More than two conditions</li> <li>One categorical independent variable</li> <li>One continuous dependent one</li> </ul> <p></p> <p>Reporting</p> <p>In order to test if the three groups were affected in their perceptions on usability by the screen size, we conducted oneway independent ANOVA </p> <p>Having one independent variable (screen size) and one dependent variable (perceived usability). </p> <p>No significant effects were observed: F(2,57)=1.532,\\quad p=.225F(2,57)=1.532,\\quad p=.225.</p>"},{"location":"8-semester/mHCI/09-lab-experiments/#complex-experiment","title":"Complex experiment","text":"<p>...</p>"},{"location":"8-semester/mHCI/09-lab-experiments/#interpretation-of-factorial-designs","title":"Interpretation of Factorial Designs","text":"<ul> <li>We can have two types of results</li> <li>Results about the effect of each independent variable on the dependent variable (main effect)<ul> <li>The effect of the independent variable on the dependent by itself</li> </ul> </li> <li>Results about the interaction between the two independent variables (the effect of one independent variable depends on the particular level of the other one)</li> </ul> <p>Result</p> <p></p> <p>Possible outcomes of experiment</p> <ul> <li>There may or may not be a significant main effect for screen size</li> <li>There may or may not be a significant main effect for weight</li> <li>There may or may not be a significant interaction between screen size and weight</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#assigning-participants-in-factorial-designs","title":"Assigning Participants in Factorial Designs","text":"<ul> <li>All participants are different in each condition</li> <li>Independent groups (between-subjects) factorial design</li> <li>The same subjects participate in all conditions</li> <li>repeated measures (within-subjects) factorial design</li> <li>Combinations of the above</li> <li>mixed factorial design</li> </ul> <p>Example</p> <p>Independent variable A (two levels A1, A2), Independent Variable B (B1, B2) have an effect on a Dependent Variable</p> <p></p>"},{"location":"8-semester/mHCI/09-lab-experiments/#which-statistical-technique-to-use","title":"Which statistical technique to use?","text":"<p>More than 2 experimental conditions, more than 2 categorical independent variables, one continuous dependent one</p> <p></p>"},{"location":"8-semester/mHCI/09-lab-experiments/#normality-test","title":"Normality Test","text":"<ul> <li> <p>We check whether our distribution deviates from a normal distribution</p> </li> <li> <p>H1: \u201cOur distribution is different from a normal distribution\u201d</p> </li> <li> <p>H0: \u201cOur distribution is the same as a normal distribution\u201d</p> </li> <li> <p>Two tests:</p> </li> <li>Kolmogorov-Smirnov, and</li> <li> <p>Shapiro-Wilk</p> </li> <li> <p>Analyze \\to\\to Descriptive Statistics \\to\\to Explore</p> </li> <li>If the tests are significant p&lt;0.05p&lt;0.05 then our distribution is significantly different from a normal distribution</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#tests-for-homogeneity-of-variance","title":"Tests for homogeneity of variance","text":"<ul> <li>H1: \u201cOur variances are not equal among the groups\u201d</li> <li>H0: \u201cOur variances are equal among the groups\u201d</li> <li>A typically used test:</li> <li>Lavene\u2019s Test</li> <li>Analyze \\to\\to Descriptive Statistics \\to\\to Explore</li> <li>If the test is significant p&lt;0.05p&lt;0.05 then our variances are significantly different in the different groups.</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#reducing-the-bias","title":"Reducing the bias","text":"<ul> <li>Trimming the data</li> <li>Winsorizing</li> <li>Bootstrapping (too advanced for this course)</li> <li>Transforming the data</li> </ul> <p>OR</p> <ul> <li>We select an advanced technique that does not assume normality of the data (way too advanced for this course)</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#trimming-data","title":"Trimming Data","text":"<ul> <li>We delete some scores from the extremes/outliers</li> <li>Only when we have good reasons to do so</li> <li>We use two rules</li> <li>We trim a percentage from each end of the ordered scores (i.e. 5%)</li> <li>We trim data above a certain number of standard deviations (usually 3)</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#spotting-outliers","title":"Spotting Outliers","text":""},{"location":"8-semester/mHCI/09-lab-experiments/#winsorizing","title":"Winsorizing","text":"<ul> <li>We replace outliers with:</li> <li>The highest score that is not an outlier</li> <li>Or we replace extreme scores with</li> <li>A score three standard deviations from the mean</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#transforming-the-data","title":"Transforming the Data","text":"<ul> <li>If we are looking the relationships between two or more variables, we can transform only the problematic one</li> <li>If we are looking for differences with one variable (i.e. a change in a variable over time) then we need to transform all of them in order to have the same units of measurement</li> <li>When we transform the data we basically change our hypothesis and we address a different variable than the originally measured</li> <li>The consequences for applying the \u2018wrong\u2019 transformation can be worst than analyzing the original ones</li> </ul>"},{"location":"8-semester/mHCI/09-lab-experiments/#choosing-transformation","title":"Choosing Transformation","text":""},{"location":"8-semester/mHCI/10-field-experiments/","title":"Field Experiments","text":"<p>What is the Field?</p> <ul> <li>We refer to as Field studies the studies that occur in natural settings</li> <li>They started as long-term studies of people mainly within the fields of anthropology and health</li> <li>Often, they are called in the wild studies</li> <li>Contrary to the lab settings where we want almost everything under our control, in the field we need things to be out of control, natural, authentic</li> <li>We often collect both quantitative and qualitative data</li> </ul> <p>Why?</p> <ul> <li>We need to get info about interactions that we wouldn\u2019t be able to get otherwise </li> <li>e.g. some of the participants might not even realize what they are doing</li> <li>To see how our product/prototype fits users\u2019 \u2019natural habitat\u2019</li> <li>To understand the complex practices of our users in general</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#three-axes-of-field-work","title":"Three Axes of Field Work","text":"<ul> <li>Time! - How much time will we spend to study a phenomenon/situation?</li> <li>Engagement! - How much will we interfere?</li> <li>Purpose! - What is our purpose with the study? </li> <li>All three are interconnected and we can have different combinations</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#time","title":"Time","text":"<p>In other domains, field studies are extensive (ethnography). Within HCI and mHCI we usually have narrower time frames</p> <p></p>"},{"location":"8-semester/mHCI/10-field-experiments/#engagement","title":"Engagement","text":"<p>How much are we willing to interfere?</p> <p></p>"},{"location":"8-semester/mHCI/10-field-experiments/#purpose","title":"Purpose","text":"<p>Why are we doing this?</p> <p></p>"},{"location":"8-semester/mHCI/10-field-experiments/#some-challenges-in-conducting-field-work","title":"Some challenges in conducting field work","text":"<ul> <li>Challenge 1: How can we collect data of what is going on all the time?</li> <li>Challenge 2: How can we make people talk/reflect, even if we are not there?</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#challenge-1-collect-data-all-the-time","title":"Challenge 1 - Collect data all the time","text":"<p>We need to find innovative ways for collecting data</p> <ul> <li>When the situation unfolds (real time)</li> <li>Without interfering too much (unobtrusively)</li> <li>In ways that allow us to find out what is going on (informatively)</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#an-example-how-do-people-use-smartwatches-and-why","title":"An example: How do people use smartwatches and why?","text":"<p>Stefania Pizza, Barry Brown, Donald McMillan, and Airi Lampinen. 2016. Smartwatch in vivo. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI \u201916). Association for Computing Machinery, 5456\u20135469. https://doi.org/10.1145/2858036.2858522</p> <p>Research Area:  \u201cYet it is not clear how smartwatches are used and integrated into everyday life differently from mobile phones\u201d </p> <p>Method:  \u201cWe used wearable cameras to record twelve participants\u2019 daily use of smartwatches, collecting and analysing incidents where watches were used from over 34 days of user recording\u201d</p> <p>Some of the research questions</p> <ul> <li>For example, what does a wrist worn technology support in contrast to the screen of a mobile phone?</li> <li>How does the stream of notifications received on a smartwatch and mobile phone compare in this regard? (distraction) </li> <li>How are these functions [Health tracking] actually used and in what way do they integrate themselves with daily practice? </li> <li>What limitations and possibilities can we identify from closely studying smartwatches [...] for future design and innovation?</li> </ul> <p>Data collection</p> <p>We had participants wear multiple portable wearable cameras that recorded their actions relatively unobtrusively, while allowing us to see and understand smartwatch use in vivo. We made a small \u2018sensor bag\u2019 which contained two cameras with long-life batteries that allowed them to record for eight hours each. One of the cameras was directed to record the scene around the participant (pointing forward).</p> <p>The second camera was connected to a small \u2018stalk\u2019 camera that was mounted at the shoulder of the participant (looking downwards), so as to capture the participant\u2019s body and wrist.This angle captured interactions with the watch.</p> <p></p> <p>Data analysis</p> <ul> <li>Our analysis started by watching the video and extracting clips where there was any interaction around or with the watch. </li> <li>All authors collectively watched all \u2018watch use event\u2019 clips, around 8 hours of video in total</li> <li>We selected for closer analysis clips that were particularly revealing of smartwatch use</li> <li>This smaller corpus of 110 clips was used for a more lengthy analysis of the interaction around the watch to examine patterns of talk, device, and bodily interaction</li> </ul> <p>What was a smartphone used for?</p> <ul> <li>Time</li> <li>Notifications</li> <li>Activity tracking</li> <li>Talking to the Watch</li> <li>Other Interactions</li> </ul> <p>What can the smartwatch be used for in the future?</p> <ul> <li>Distractions</li> <li>The watch may simply reduce the need, or temptation, to take the phone out.</li> <li>Time and sociality</li> <li>The watch can serve as a way of reducing time spent on the phone, and to also balance availability to others with one\u2019s own concerns and demands</li> <li>Design and smartwatch:</li> <li>Similarly, we might think about applications that allow for retrospection. A simple application might, for example, record times spent in different places, or time spent in different activities (such as conversation)</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#challenge-2-making-people-talkreflect-even-if-we-are-not-there","title":"Challenge 2 - Making people talk/reflect, even if we are not there?","text":"<p>We need to find ways for collecting data:</p> <ul> <li>When the situation unfolds (real time)</li> <li>In ways were people will want to provide us with their knowledge (engagement)</li> <li>In ways that allow us to find out what is going on (informatively)</li> </ul>"},{"location":"8-semester/mHCI/10-field-experiments/#an-example-engaging-tools-for-data-collection","title":"An example: Engaging tools for data collection","text":"<p>Interaction Research Studio (2019) ProbeTools: Unconventional Cameras and Audio Devices for User Research. Interactions, March-April 2019. https://interactions.acm.org/archive/view/march-april2019/probetools</p> <ul> <li>ProbeTools are fully self-contained digital devices robust enough to be used in the field. Each one offers a unique and engaging way for people to tell you about themselves and their everyday lives</li> <li>They can be used in a variety of settings to allow us to have access in data from the field</li> <li>They can be combined with other data collection techniques , such as questionnaires, log data, etc.</li> </ul> <p>What kind of ProbeTools are available?</p> <ul> <li>TaskCam lets people take pictures in response to prompts (tasks) displayed on a small screen on the back of the camera. Participants can scroll through tasks, select one, and take a picture in response.</li> <li>VisionCam captures time-lapse images when it is activated, using computer vision to retain only contour animations\u2014 similar to line drawings\u2014to protect privacy and enhance aesthetic interest. It is designed to be a non-invasive way to record events over time at home or in public spaces.</li> <li>Interviewer asks people questions that you record, then pauses for a short time to record their answers. Digital audio processing is used to change both the questions and the answers to anonymize voices</li> </ul> <p>What can we get out of ProbeTools?</p> <p>There are no right answers when it comes to probes. They are designed to be empirically grounded, yet open to interpretation. They rely on imagination and provisional speculations. Their purpose is not to produce validated, detailed accounts of participants\u2019 lives, but rather hints and clues that can be a starting point for design</p>"},{"location":"8-semester/mHCI/99-exam/","title":"Exam Questions","text":""},{"location":"8-semester/mHCI/99-exam/#question-1","title":"Question 1","text":"<ul> <li>How can we define and characterize mobile computing? </li> <li> <p>Give examples of the different eras. </p> </li> <li> <p>What is context and why is important for mobile computing? </p> </li> <li>What is Big C and Small C? </li> <li>How can we communicate context to others?</li> </ul> <p>Mobile computing</p> <ul> <li> <p>Mobile computing can be divided into a number of eras, or waves, each characterized by a particular technological focus, interaction design trends, and by leading to fundamental changes in the design and use of mobile devices</p> </li> <li> <p>Divided into eras - characterized by</p> </li> <li> <p>particular technological focus</p> </li> <li>interaction design trends</li> <li> <p>by leading to fundamental changes in design and use of mobile devices</p> </li> <li> <p>Eras</p> </li> <li> <p>Portability</p> <ul> <li></li> </ul> </li> <li> <p>Miniturization</p> <ul> <li></li> </ul> </li> <li> <p>Connectivity</p> <ul> <li></li> </ul> </li> <li> <p>Convergence</p> <ul> <li>\"doing many things\"</li> <li>Not just phone or computer anymore</li> <li>You can now play and do spreadsheets on the phone (Nokia 9000)</li> <li></li> </ul> </li> <li> <p>Divergence</p> <ul> <li>\"Doing one thing well\"</li> </ul> <p></p> </li> <li> <p>Apps</p> <ul> <li>In the beginning, only the manifactures made apps</li> <li>limited selection</li> <li>Then came Developing kits and app stores</li> <li>Google Play - Apple App Store</li> </ul> </li> <li> <p>Digital Ecosystems</p> <ul> <li></li> </ul> </li> </ul> <p>Context</p> <ul> <li>Everything about how something is used, who uses it, where, when and how</li> <li>What is important to the users, which can depend on different external factors</li> <li>The circumstances that form the setting for an event, statement, or idea, and in terms of which it can be fully understood</li> <li>Context is important for mobile computing</li> <li>The context can easily change because of mobility</li> <li>Car vs train vs at home<ul> <li>Example - Spotify Car Mode</li> </ul> </li> <li>Context can be defined in two ways</li> <li>Big C - Context</li> <li>Small c - context</li> </ul> <p>Big C - Context</p> <ul> <li>\u201cContext enables us to better understand a person, a place, a thing, a situation, or even an idea by adding information to it\u201d</li> <li>\"How the users will derive value from something they are currently doing\" / \"the understanding of circumstance\"</li> <li>\"standing in front of Berlin Wall and reading about it on Wiki\" =&gt; adding Context to task</li> <li>\"This information is providing me Context or better understanding of what this moment in time means to me\"</li> <li>Some Questions</li> <li>The Problem<ul> <li>What problems are you trying to design a solution for?</li> <li>What value do you want to bring for your users?</li> </ul> </li> <li>Users and their situation<ul> <li>Who are your users and what do you know about them?</li> <li>How are they able to or how will they interact with your design?</li> </ul> </li> <li>Location<ul> <li>What and where is it happening?</li> </ul> </li> <li>Markets<ul> <li>How is your idea different from other designs already available?</li> </ul> </li> </ul> <p>Small c - context</p> <ul> <li>\"the mode, medium, or environment in which we perform a task\" / \"the circumstances of understanding\"</li> <li>Using phone in car    =&gt; more private information, but restricted because driving</li> <li>Using phone in train =&gt; less private information, but not restricted</li> <li>Understanding how the location changes a users behavior and what they want from their device</li> <li>Which requirements / constraints lies in the context</li> <li>Physical and spatial considerations<ul> <li>Are there any restrictions in the physical environment or the location?</li> <li>e.g. will I be able to use the design all the time?</li> </ul> </li> <li>Technological considerations<ul> <li>How are different devices present in different situations?</li> <li>e.g. why smart watches might be better than smartphones when running or swimming</li> </ul> </li> <li>Psycological/demographical considerations<ul> <li>Users mental models and prerequisites for interacting with certain devices</li> <li>e.g. knowledge, common conceptions in community etc.</li> </ul> </li> </ul> <p>Communicate Context:</p> <ul> <li>Personas</li> <li>Helps maintain perspective of users</li> <li>Fictional - created based on research - never of assumptions</li> <li>Represent different user types</li> <li>Helps understand users\u2019 needs, experiences, behaviors and goals.</li> <li>4 types</li> <li>Goal oriented<ul> <li>Users' goals - workflow, contexts, attiturdes</li> <li>Based in in-depth ethnographic research</li> <li>Provides focused design and communication tool to finish discussions </li> </ul> </li> <li>Role based<ul> <li>Users roles in organization </li> <li>data-driven - incorporate data from both qualitative and quantitative sources</li> <li>efficient design tool - our cognitive ability to use fragmented and incomplete knowledge to form complete vision of people who surround us</li> </ul> </li> <li>Engaging<ul> <li>Designers seeing users as stereotypes -&gt; actively involved in the lives of personas</li> <li>Requires broad knowledge of users</li> <li>Data should include information about - social background, psychological characteristics, emotional relationship with the focus area.</li> </ul> </li> <li>Fiction based<ul> <li>To explore and design - generate discussion and insights</li> <li>Based on intuition and experience</li> <li>Creates an empathetic focus in the design process</li> <li>Originate from brainstorming and workshops - participation from company</li> </ul> </li> <li>How - 11 steps</li> <li>Collect extensive data on target users.</li> <li>Determine the qualities of and differences between users.</li> <li>Develop a hypothesis from the research, determining the qualities of and differences between users.</li> <li>Ensure stakeholders agree on the hypothesis about the users.</li> <li>Determine a number of personas \u2013 more than one per project, but focus especially on one</li> <li>Name and describe each persona in 1-2 pages, including:<ul> <li>A picture.</li> <li>(CONTEXT): User\u2019s values, interests, education, lifestyle, needs, attitudes, desires, limitations, goals and behavior patterns.</li> <li>Extra details about the persona (e.g., interests) \u2013 anything to make him/her more real and relevant and help build empathy. A written story is better than bullet points.</li> </ul> </li> <li>Describe several situations/scenarios prompting the persona to use your product \u2013 put him/her in contexts with problems to overcome.</li> <li>Include everyone involved in the project so they\u2019ll accept the persona or advise revisions.</li> <li>Send them the persona to use in their work</li> <li>Ensure everyone develops scenarios \u2013 these should expose the persona optimally to potential use cases</li> <li>Make continuous adjustments \u2013 revisit the persona; add new features; add required new personas; discard outdated personas.</li> </ul> <p></p>"},{"location":"8-semester/mHCI/99-exam/#question-2","title":"\u200bQuestion 2","text":"<ul> <li>How can we collect data about the context of our idea? </li> <li>Give examples of the different ways of communicating your idea to other team members/costumers/users?</li> </ul> <p>Collect data:</p> <ul> <li>Contextual Inquiry</li> <li>Interviews (deep)<ul> <li>Structured - almost questionare - Replicable - lacks richness</li> <li>Semi-structured - loose script - balance between richness and replicability</li> <li>Unstructured - no script - rich - not replicable</li> <li>Focus groups - group interview</li> <li></li> <li>Interview tips</li> <li>Open questions</li> <li>Avoid Leading questions that make assumptions</li> <li>Learn the participants language</li> <li>Use probe questions<ul> <li>Tell me more about...You said \u201cdesperate.\u201d What do you mean by that?</li> </ul> </li> <li>Accept awkwardness (pregnant pauses)</li> </ul> </li> <li>Questionaries (general)</li> <li>Inspection - Observation</li> <li>Roles:<ul> <li>Observer Participant - fly on the wall</li> <li>Participant Observer - field worker is full participant in activities studied</li> </ul> </li> <li>Technology Tours<ul> <li>What to Observe:</li> <li>Space - physical space - actors: names and relavant details of people involved</li> <li>Activities - what are actors doing and why?</li> <li>Objects - physical objects present (eg. furniture) - Acts: specific individual actions</li> <li>Events - Observing part of special event?</li> <li>Time - Sequence of events</li> <li>Goals - Actors trying to accomplish?</li> <li>Feelings - Mood of group and individuals</li> </ul> </li> <li>The challenge - what people say and what they do are not the same.</li> <li>Combine interview and observation - triangulation</li> </ul> <p>Communicate idea:</p> <ul> <li>Storyboard</li> <li>\"A storyboard communicates a story through images displayed in a sequence of panels that chronologically maps the story\u2019s main events.\"</li> <li>Used to gain common ground</li> <li>Research and usability</li> <li>Parts<ol> <li>Scenario</li> <li>Who is persona?</li> <li>Short text describing scenario<ul> <li>E.g. Corporate buyer, James, needs to replenish office supplies</li> </ul> </li> <li>Visuals</li> <li>Each step in scenario is represented visually in a sequence - sketches, illustrations, photos</li> <li>Include details relevant to the story<ul> <li>what the users environment looks like</li> <li>speech bubbles with quoutes from the user</li> <li>sketch of the screen user is interacting with</li> </ul> </li> <li></li> <li>Captions</li> <li>Each visual has corresponding caption</li> <li>Caption describes user's actions, environment, emotional state, device, and so on</li> <li>Captions are concise and dont typically exceed two bullet points</li> </ol> </li> <li>Steps<ol> <li>Gather your data (ie. interviews)</li> <li>Choose fidelity level (ie. sketches, photos)</li> <li>Define basicsx (persona and scenario)</li> <li>Plan out steps (which steps will storyboard contain)</li> <li>Create visuals and add captions (create you storyboard - stick figures are okay)</li> <li>Distribute and Iterate (ie. to audience, stakeholders)</li> </ol> </li> <li>Wireframes</li> <li>Wireframes are used early in the development process to establish the basic structure of a page before visual design and content is added</li> <li>Demonstrates key elements of a design</li> <li>Demonstrates key structure of a page/app</li> <li>Low-fidelity: Quicker and cheaper to make changes to</li> <li>Mock-ups</li> <li>Mock-ups are used by designers mainly to acquire feedback from users about designs and design ideas early in the design process. Mock-ups are 'very early prototypes' made of cardboard or otherwise low-fidelity materials.</li> <li>Visualises the key elements of a design</li> <li>Still not final design, but conveys more design than wireframes</li> <li>Low-fidelity: made quicker and dirty - easy to make changes to<ul> <li>Example in cardboard</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-3","title":"Question 3","text":"<ul> <li>What is a digital ecosystem? </li> <li> <p>How can we classify interaction with multiple mobile devices in a digital ecosystem? </p> </li> <li> <p>Give short examples of the four categories of interaction (Collaboration, Communality, Complementarity, Continuity)</p> </li> </ul> <p>Digital Ecosystem</p> <ul> <li>Theoretical Framing</li> <li>A network of nodes interacting - consists of users and digital artifacts, bound dynamically by the users' actions</li> <li>When a user interacts with not just one, but multiple devices at once</li> <li>or multiple users interact with a single device</li> <li>Example:</li> <li>Google Cast</li> <li>Apple's announced Universal Control - move cursor from Mac to iPad</li> </ul> <p>Classify interaction with multiple mobile devices in ecosystem</p> <p>With a focus on interaction 4 structures emerges - like a database</p> <p></p> <ul> <li>The interesting structures are the three with either many users or many artifacts</li> <li>We can further divide interactions with several artifacts into two</li> <li>Sequential - users first interact with one device - then continues with another device<ul> <li>Example: Checking emails on phone - then moving to desktop to read specific one or answer</li> </ul> </li> <li>Simultanious - users uses several devices at once<ul> <li>Example: Overview of calendar on large screen while sending meeting invitation from phone</li> </ul> </li> <li>This leads us to the 4C Framework</li> <li>Combines the structural relationships of many users and many artifacts with the differentiation between sequential or simultaneous in a 2x2 matrix</li> </ul> <p></p> <p>4 Categories of interaction</p> <ul> <li>Communality</li> <li>Artifacts are shared between users, but only one user interacts at a time</li> <li>Subcategories<ul> <li>Personalization - relationship between users and artifacts are individual and tailored to each person </li> <li>Example: Accounts on social media on shared tablet</li> <li>Generalization - relationship is same for everyone</li> <li>Example: Ticket booth at train station - automatic passport photobooth</li> </ul> </li> <li>Might seem trivial - but decision can have great impact on system<ul> <li>Eg. login can be irrelevant</li> </ul> </li> <li>Collaboration</li> <li>Simultaneous interaction by many users</li> <li>Subcategories<ul> <li>Division - interaction with artifact is split between users</li> <li>Indiviual parallel points of attention</li> <li>Example: Split-screen gaming</li> <li>Can also be done by other means such as different sound channels</li> <li>Merging - several users's simultaneous interaction with an artifact</li> <li>Example: multi-user board games on single tablet - mixing desk</li> </ul> </li> <li>Continuity</li> <li>Sequential interaction with several artifacts</li> <li>Interaction starts on one device and continues on another</li> <li>Subcategories<ul> <li>Synchronization - data and data structures is kept consistent across all devices</li> <li>When artifact synchronizes with ecosystem - content and its organization is replicated</li> <li>Example: Cloud based storage (Dropbox, Google Drive, etc.) - email and calendar services</li> <li>Migration - users switch between artifacts by transfering state of their activity - partially or completely</li> <li>Example: Amazon Kindle - continue reading,  Google Cast - continue playback on large screen</li> </ul> </li> <li>Complementarity</li> <li>Simultaneous interaction with multiple arifacts</li> <li>Interaction with one artifact adds to the interaction with another<ul> <li>Jointly makes up a larger whole</li> </ul> </li> <li>Subcategories<ul> <li>Extension - One digital artifact directly adds to another</li> <li>Example: Using several smartphones and tables to create large display</li> <li>Example: Companion apps - Adobe Nav - Digitizer app</li> <li>Remote control - One digital artifact controls another</li> <li>Examples: TV Remote apps - Home automation</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-4","title":"\u200bQuestion 4","text":"<ul> <li>Why is it important for designers know the difference between devices and platforms when we design for them? </li> <li>What is skeuomorphism? </li> <li>How do we ensure that our design will fit into the mobile platform that we design for (e.g., Android, iOS)? </li> </ul> <p>Different devices and platforms</p> <ul> <li>Different things are possible on different platforms</li> <li>Performance, screen size, operating system</li> <li>Different contexts</li> <li>Smartphones can show more details than smartwatches</li> <li>Following the design guidelines makes the app familiar</li> <li>Using same icons lets users know what buttons do<ul> <li>Example: share icon is different on iOS and Android</li> </ul> </li> <li>We can take advantage of platform features - such as widgets<ul> <li>Notification actions on Android</li> </ul> </li> <li>Devices says something about the users</li> <li>People using Android may be \"more powerusers\"</li> <li>Linux vs Mac/Windows</li> </ul> <p>Skeuomorphism</p> <ul> <li>Interface objects that mimics their real-world counterparts<ul> <li>Recycle bin - floppy disk - toggles - buttons - dials</li> <li>sounds - animations</li> <li>Volume icon where the speaker outputs more or less sound</li> </ul> </li> <li>Makes users know what they can do with interfaces<ul> <li>Example: Folders in a file system - users know they can put files into it even though its a new concept</li> </ul> </li> </ul> <p>Design Guidelines</p> <ul> <li>Follow design guidelines provided by platforms - Apple - Google</li> <li>iPhone - purpose<ul> <li>Clarity - Functionality motivates design</li> <li>Deference - Content fills the entire screen</li> <li>Depth - Go into depth with content</li> </ul> </li> <li> <p>iOS - guidelines</p> <ol> <li>Aesthetic Integrity<ul> <li>How appearance and behavior integrate with its functions<ul> <li>Productivity vs Fun/Gaming</li> </ul> </li> </ul> </li> <li>Consistency<ul> <li>Familiar standards and paradigms<ul> <li>system provided interface elements</li> <li>well-known icons</li> <li>standard text styles</li> <li>uniform terminology</li> </ul> </li> <li>Example: pull down to refresh</li> </ul> </li> <li>Direct Manipulation<ul> <li>Rotating device - using gestures to affect content</li> <li>Example: pinch to zoom - swiping</li> </ul> </li> <li>Feedback<ul> <li>acknowledges actions and shows results</li> <li>Example: Shutter sound - vibration</li> </ul> </li> <li>Metaphors<ul> <li>metaphors for familiar experiences - either rooted in real world or digital world</li> </ul> </li> <li>User Control<ul> <li>People - not apps - are in control</li> <li>Apps suggest course of action or warn about dangerous consequences</li> </ul> </li> </ol> </li> <li> <p>Apple watch - purpose</p> <ul> <li>Lightweight interactions - short interaction time</li> <li>Holistic design - not just on screen interaction<ul> <li>\"Holistic design takes into account the person, the device, the moment, the ethnographic environment, the physical space as well as human behavior and psychology...\"</li> </ul> </li> <li>Personal communication - Meant to be worn</li> </ul> </li> <li>watchOS - guidelines<ol> <li>Glanceable<ul> <li>Interactions occur over short periods of time</li> <li>apps must convey most important information up front - clearly and without distraction</li> </ul> </li> <li>Actionable<ul> <li>anticipates user's needs - ensuring onscreen is always current and relavant</li> <li>custom notification interface include custom actions without opening app</li> </ul> </li> <li>Responsive<ul> <li>interactions should be quick</li> <li>responds to user interaction with immediate feedback<ul> <li>what the app is gonna do</li> </ul> </li> <li>notifications to deliver progress updates later</li> </ul> </li> </ol> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-5","title":"\u200bQuestion 5","text":"<ul> <li>What is a prototype? <ul> <li>When in the design process do, we introduce prototypes? </li> <li>Give examples of the different prototypes and their strengths and weaknesses.</li> </ul> </li> </ul> <p>Prototype</p> <ul> <li>simple experimental model of proposed solution</li> <li>used to test or validate ideas, design assumptions and other aspects of conceptualization</li> <li> <p>cheap and quick</p> </li> <li> <p>Why?</p> <ul> <li>reveal assumptions and biases</li> <li>uncover insights about users</li> </ul> </li> <li>Attention points:<ul> <li>People - those whom you are testing and observers</li> <li>Objects - static and interactive - prototype and objects people and/or prototype interacts with</li> <li>Location - places and environments </li> <li>Interactions - Digital or physical - between people, objects and location</li> </ul> </li> </ul> <p>Prototypes - When</p> <p></p> <p>...</p> <p>Different Prototypes</p> <ul> <li> <p>Low fidelity</p> <ul> <li>Medium unlike final medium - e.g. paper, cardboard</li> <li>Quick, cheap, easily changed</li> <li>Examples:<ul> <li>Sketches of screens</li> <li>task sequences</li> <li>post-its</li> <li>storyboards</li> <li>Wizard of Oz<ul> <li>Simulating actual functionality - combine different tools - tablets, email systems, PowerPoint with human intervention</li> </ul> </li> </ul> </li> <li>Pros<ul> <li>quick, inexpensive</li> <li>instant changes and new iterations</li> <li>disposable/throw-away</li> <li>minimal time and effort</li> <li>Available to all</li> <li>Encourages and fosters design thinking</li> </ul> </li> <li>Cons<ul> <li>lack of realism<ul> <li>results may lack validity</li> </ul> </li> <li>may not be appropriate for intended users</li> <li>removes control from the user</li> </ul> </li> </ul> </li> <li> <p>High fidelity</p> </li> <li>Materials expected to be in final product</li> <li>Looks more like final product</li> <li>Example - software prototyping</li> <li>Pros<ul> <li>Engaging - stakeholders see vision realised</li> <li>can judge how it meets expectations, wants, and needs</li> <li>User testing - high validity and applicability</li> </ul> </li> <li>Cons<ul> <li>Takes time to produce</li> <li>Test users more inclined to focus and comment on superficial characteristics</li> <li>Designers often are often loathed to make changes</li> <li>Gives test users a false impression</li> <li>Making changes can take long time - delaying project</li> </ul> </li> <li>low-fi during early stages - high-fi during later stages</li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-6","title":"Question 6","text":"<ul> <li>What kind of data can we collect in mHCI evaluations and how? </li> <li>Why do we collect such data, what is our purpose? </li> <li>Are there any differences between conducting evaluations in a lab and the field? </li> </ul> <p>Data</p> <ul> <li>Qualitative data</li> <li>What<ul> <li>Audio and video recordings</li> <li>Notes</li> <li>Materials produced by participants - sketches, drawings, pictures, etc.</li> <li>Usage data</li> <li>Online comments and articles</li> <li>...</li> </ul> </li> <li>How<ul> <li>Interviews and focus groups</li> <li>Observations</li> <li>Photo/Video/Voice Elicitation</li> <li>Diaries/journaling</li> <li>Participants write down while working - can be talked about later</li> <li>Re-enactment Videos</li> <li>Cultural/Mobile Probes</li> <li></li> <li>Online videos (e.g.Youtube)</li> </ul> </li> <li>Why<ul> <li>Explores attitudes, behaviors, and context in-depth</li> <li>Encourages discussion</li> <li>More opportunities for asking - people can explain answers</li> </ul> </li> <li>Quantitative data</li> <li>What<ul> <li>Anything that can be understood as a number</li> <li>Time</li> <li>Performance metrics</li> <li>Success rates</li> <li>Answers to questionnaires</li> <li>Data is structured</li> </ul> </li> <li>How - scientific approach<ul> <li>Intuition and/or authority to generate ideas about phenomenon/behavior</li> <li>Skepticism: ideas must be evaluated on the basis of careful logic and results from scientific investigations</li> <li>Empiricism: knowledge is based on observations and the study of reality</li> <li>Methods</li> <li>Case studies<ul> <li>Intensive empirical investigations of contemporary phenomena within small size entities such as groups, organizations, individuals, systems or tools in real-life context with the researcher distinct from the phenomena being studied.</li> </ul> </li> <li>Field studies<ul> <li>taking place in \u201cthe real world\u201d covering a range of quantitative approaches in which a number of independent variables are manipulated.</li> </ul> </li> <li>Usage studies<ul> <li>Large-scale log-file based test-scenario in which a newly designed system is exposed to its target users in order to test its resilience under real-use conditions, and if and how it is employed for the tasks for which it was intended.</li> </ul> </li> <li>Lab experiments/studies<ul> <li>taking place in a controlled environment created for the purpose of research or in dedicated laboratories allowing a detailed focus on specific phenomena of interest with a large degree of experimental control.</li> </ul> </li> <li>Surveys<ul> <li>Informs research gathers large amounts of data through various techniques such as questionnaires and interviews from a known sample of selected respondents assumed to be independent of their environment.</li> </ul> </li> </ul> </li> <li>Why<ul> <li>Understanding -  finding the meaning of studied phenomena</li> <li>ex: frameworks or theories developed from collected data</li> <li>Engineering - developing new systems or parts of systems</li> <li>ex: an interaction technique for a mobile device, or a mobile application or device</li> <li>Re-engineering - improving existing systems by redeveloping them</li> <li>ex: adapting a web browser to a small display</li> <li>Evaluating - assessing or validating products, theories or methods</li> <li>ex: the usability or user experience of a specific application, or a theory of interaction</li> <li>Describing - defining desirable properties of products</li> <li>ex: a mobile guide system</li> </ul> </li> </ul> <p>Lab vs Field</p> <ul> <li>Field takes place in the wild - lab is a controlled environment</li> <li>Field is more natural but we cannot control everything</li> <li>In field we can get results that we cant get otherwise<ul> <li>Some participants might \"realize\" what they are doing</li> </ul> </li> <li>We can see how our product/prototype fits users\u2019 \u2019natural habitat\u2019</li> <li>In the field we often collect both quantitative and qualitative data</li> <li>Field is harder to conduct</li> <li>Example: mounted camera - from lecture 10</li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-7","title":"\u200bQuestion 7","text":"<ul> <li>Assume you have collected qualitative data. </li> <li>What is the process that you need to follow to conduct an analysis of this data? </li> <li>What are the two approaches for coding qualitative data, and what are their differences? </li> </ul> <p>Qualitative data analysis</p> <ul> <li>Transform unstructured data into something meaningful/useful for design</li> <li>To gain deep/detailed knowledge of a situation/problem</li> <li>To know how our prototype/product is embedded into everyday life</li> </ul> <p>Process</p> <p></p> <ol> <li>Define the dataset</li> <li>Where do we collect data?</li> <li>Clean the dataset</li> <li>Is everything relevant?</li> <li>Code the dataset</li> <li>Assigning categories and descriptors to blocks of text - qualitative data in general</li> <li>2 approaches:<ul> <li>Emergent coding</li> <li>Extract structure of data from dataset</li> <li>No preconceptions exist</li> <li>Objectivity is important</li> <li>Often combined with grounded theory<ul> <li>objective is to create a theory</li> </ul> </li> <li>Process<ol> <li>Code data</li> <li>Develop concepts</li> <li>Group concepts into categories</li> <li>Produce a theory</li> </ol> </li> <li></li> <li>A priori coding</li> <li>Apply existing theory (taxonomy/framework) to structure data</li> <li>Some preconceptions on what we will identify</li> <li>Again, objectivity is important</li> <li></li> <li>Process<ol> <li>Identify a relevant theory/taxonomy</li> <li>Code the data (a priori coding)</li> <li>Identify how much theory explains situation</li> <li>If necessary, feed back to theory</li> </ol> </li> </ul> </li> <li>How to code:<ul> <li>Look for key items</li> <li>Assign codes</li> <li>Reflect and (redesign) codes - iteratively</li> <li>Reflect on the relationship between the codes</li> <li>Afterwards, may compare with:</li> <li>similar studies/evaluations</li> <li>results of previous version of product/prototype</li> <li>different target groups</li> </ul> </li> <li>Extract Findings</li> </ol>"},{"location":"8-semester/mHCI/99-exam/#question-8","title":"\u200bQuestion 8","text":"<ul> <li>What is a research hypothesis, and are there different types? </li> <li>What is the difference between independent and dependent variables?</li> <li>What is the operational definition of a variable?</li> <li>How can we assess the quality of operational definitions?</li> </ul> <p>Research Hypothesis</p> <ul> <li>A specific idea or question which can be tested through empirical investigation (using the scientific approach)</li> <li>Null hypothesis - \"no difference between conditions\"</li> <li>Alternative hypothesis - \" is difference between the conditions\"</li> <li>They have to be mutually exclusive</li> <li>Why null and alternative?</li> <li>Long tradition in experimental research</li> <li>In statistics we do not test if two conditions are different<ul> <li>We do test if there are the same!</li> </ul> </li> </ul> <p>Variables</p> <ul> <li>All the things we can measure or manipulate are called variables.</li> <li>must have more than 2 levels</li> <li>Independent vs Dependent</li> <li>Independent variable<ul> <li>Variable we think is the cause</li> <li>Variable that is independent of a participant\u2019s behavior</li> <li>Variable that we manipulate in our experiment</li> </ul> </li> <li>Dependent variable<ul> <li>Variable we think is the effect, as it depends on the cause</li> <li>Variable that is dependent on a participant\u2019s behavior</li> <li>The variable that we measure in our experiment</li> </ul> </li> <li> <p>Examples</p> <ul> <li></li> <li>Sex has an effect on perceived usability</li> <li>Income has an effect on happiness</li> <li>Education has an effect on IQ level</li> <li>Input devices have an effect on efficiency</li> </ul> </li> <li> <p>Operational definition</p> </li> <li>defined procedure to measure or manipulate variable</li> <li>If many options, we select one</li> <li>selected procedure is called the operational definition of the variable</li> <li>Example - Aggression<ul> <li>number of times a kid hits a toy</li> <li>score on a aggression questionnaire</li> <li>number of times a kid cursed, etc.</li> </ul> </li> <li>Adequacy<ul> <li>Construct validity - adequacy of operational definition</li> <li>Content Validity - content of measure is linked to true meaning of variable</li> <li>Convergent Validity - scores of measure are related to other measures of the same construct</li> <li>Discriminant Validity - scores of measure are not related to other measures that are theoretically different</li> <li>Other types<ul> <li>face validity - it \"looks like\" it is going to measure what it is supposed to measure</li> <li>predictive validity -</li> <li>concurrent validity - how well a new test compares to an well-established test.</li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-9","title":"Question 9","text":"<ul> <li>What can be the sources of systematic errors in an experiment?</li> <li>What can we do in order to minimize/eliminate them?</li> <li>Why is it important to pilot test?</li> </ul> <p>Systematic Errors</p> <ul> <li>THE rule in experiments</li> <li>All confounding/external variables that may have an effect on our conditions must be controlled<ul> <li>Either through randomization</li> <li>Or by keeping them constant</li> </ul> </li> <li>THE RULE<ul> <li>Our aim is that all the conditions differ only on the independent variable and nothing else</li> </ul> </li> <li>If we are successful, our experiment has high internal validity</li> <li>Systematic error - due to confounding/external variables that covary with our independent variable</li> <li>Strong negative effect on internal validity</li> <li>Usually systematic errors push the true scores at the same direction</li> <li>Sources of systematic errors</li> <li>Participants<ul> <li>carry their own experiences and expectations, and have different characteristics</li> <li>get tired if kept a long time - fatigue effect</li> <li>Tips</li> <li>Select participants that fit target group - representative of the population</li> <li>Track, based on experience and literature, all the characteristics that can influence experiment</li> <li>Try to minimize the fatigue effect either by having breaks or by introducing fun, irrelevant activities <ul> <li>(i.e. ask them to play a game for a while)</li> </ul> </li> <li>Keep participants blind regarding experiments purpose - manipulate them</li> </ul> </li> <li>Researchers<ul> <li>We can influence by simply being there</li> <li>By commenting on participants' performance</li> <li>Tips </li> <li>Same researcher always communicates with the participants</li> <li>Same instructions provided to all - video good solution</li> <li>Never comment on their behaviour</li> <li>Always be prepared and polite</li> <li>Always have a talk after the experiment - debriefing session</li> <li>Often we keep the moderator blind for the purpose of our experiment - double blind experiment</li> </ul> </li> <li>Digital artifacts<ul> <li>Digital artifacts might have characteristics that can influence the experiment </li> <li>screen sizes, keyboards, brands, etc.</li> <li>Tips</li> <li>Carefully select digital artifacts participants will interact with and try to remove any influential characteristics</li> <li>Keep same digital artifacts throughout experiment</li> </ul> </li> <li>Environment<ul> <li>Pysical environment can influence experiment</li> <li>Tips</li> <li>Prepare a nice (suitable) environment</li> <li>Never change the physical conditions <ul> <li>(i.e. keep the noise at the same level, have the lights always on, etc.)</li> </ul> </li> <li>Never change the position/placement of the participants <ul> <li>(i.e. ask them all to sit the same way)</li> </ul> </li> </ul> </li> <li>Procedure<ul> <li>Framing of tasks can influence results</li> <li>Order of tasks influences results - order effect</li> <li>Practice gained in one task will influence the rest - practice effect</li> <li>Experience they will have from a task will influence the rest - carryover effect</li> <li>Tips</li> <li>Meaningful and clear tasks</li> <li>Always randomize the sequence of the tasks</li> </ul> </li> <li>Measurement tools<ul> <li>Tools used to measure dependent variable will influence result</li> <li>Tips</li> <li>Always use measurement tools that are reliable</li> <li>Always test their performance</li> <li>Never change measurement tools during the experiment </li> </ul> </li> </ul> <p>Pilot test</p> <ul> <li>It is is important to pilot test to</li> <li>make sure that everything is working as expected</li> <li>make sure that the participants are influenced only by the independent variable among the conditions</li> <li>have preliminary findings that will tell us if we need more conditions, or a different setup</li> <li>check the tasks we have designed for:<ul> <li>Ceiling effect: too easy tasks and all the participants reach the maximum performance</li> <li>Floor effect: too difficult tasks and hardly anyone performs well</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#question-10","title":"\u200bQuestion 10","text":"<ul> <li>What is the difference between basic and complex experiments in terms of number of variables and used statistical techniques?</li> <li>What are the differences between between-subjects and within-subjects designs?</li> <li>What are their advantages and disadvantages? </li> </ul> <p>Basic vs Complex experiments</p> <ul> <li>Basic (simple)</li> <li> <p>Only 1 independent variable</p> </li> <li> <p>The independent variable has minimum two levels - leads to minimum two conditions, treatments, or groups</p> </li> <li> <p>If we have two conditions we use t-test</p> <ul> <li>Within-group design =&gt; Paired samples t-tes</li> </ul> <p></p> <ul> <li>Between-group design =&gt; Independent t-test</li> </ul> <p></p> </li> <li> <p>If we have more than two conditions we use ANOVA</p> <ul> <li>Between-group design =&gt; One-way independent ANOVA</li> <li>Within-group design =&gt; One-way repeated measures ANOVA</li> </ul> </li> <li> <p>Complex</p> </li> <li>More than two independent variables</li> <li>The independent variables have minimum two levels</li> <li>Often callled factorial designs - we have more than one indpendent variable (factors)<ul> <li>Simplest factorial design is known as 2x2</li> <li>Two independent variables, each with two levels</li> <li>Number of lvels of first IV    x    Number of levels of second IV     x     Number of levels of third IV</li> </ul> </li> <li>Statistical Technique - Factorial ANOVA<ul> <li>Between-subjects design =&gt; Independent factorial ANOVA</li> <li>Within-subject design =&gt; Repeated measures factorial ANOVA</li> <li>Mixed design =&gt; Mixed factorial ANOVA</li> </ul> </li> </ul>"},{"location":"8-semester/mHCI/99-exam/#within-group-designs","title":"Within-group designs","text":"<ul> <li>The same participants experience both conditions</li> <li>Often called repeated measures design</li> </ul> <p>Advantages</p> <ul> <li>We need less participants</li> <li>The systematic error caused by the participants will be the same in both conditions - easier to get better results</li> </ul> <p>Disadvantages</p> <ul> <li>Hard to control the practice, order, and fatigue effects</li> </ul>"},{"location":"8-semester/mHCI/99-exam/#counterbalancing","title":"Counterbalancing","text":"<ul> <li>All possible orders of conditions are included in the experiment</li> </ul>"},{"location":"8-semester/mHCI/99-exam/#between-group-designs","title":"Between-group designs","text":"<ul> <li>Different participants experience the conditions</li> <li>Often called independent groups design</li> </ul> <p>Advantages</p> <ul> <li>Easier to control the practice, order, and fatigue effects - often do not exist</li> </ul> <p>Disadvantages</p> <ul> <li>We need many participants</li> <li>The systematic error caused by the participants' characteristics is more difficult to control</li> </ul>"},{"location":"8-semester/sP/01-introduction/","title":"Introduction","text":"<ul> <li> <p>Goal of C++:</p> <ul> <li>Programs almost as efficient as assembler/machine code, but as elegantly abstract as one wishes</li> <li>Stroustrup: \u201cC++ is a language for developing and using elegant and efficient abstractions\u201d</li> </ul> </li> <li> <p>C++ is core C++ plus standard library developed in C++</p> </li> <li> <p>Defining a new type is the most fundamental programming activity in C++</p> <ul> <li>A well-designed new type differs from a build in type only in the way it is defined, not in the way it is used!</li> <li>Library \u2013 a collection of user defined types</li> </ul> </li> </ul>"},{"location":"8-semester/sP/01-introduction/#types-of-memory","title":"Types of Memory","text":"<p>Three fundamental types of memory:</p> <ul> <li>Static memory<ul> <li>Pre-allocated when program is loaded<ul> <li>In global scope ore given with <code>static</code> keyword</li> </ul> </li> </ul> </li> <li>Stack - in local or statement scope<ul> <li>small/cheap</li> <li>deallocated when goes out of scope</li> </ul> </li> <li>Dynamic memory (free store)<ul> <li>large/more expensive</li> <li>Allocated and deallocated with <code>new</code> and <code>delete</code> operators</li> </ul> </li> </ul> <pre><code>int c_arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\nint main()\n{\nvector&lt;int&gt; vec = {1, 2, 3, 4, 5, 6, 7, 8, 9};\nvector&lt;int&gt;* vecd = new vector&lt;int&gt;{1, 2, 3, 4, 5, 6, 7, 8};\n...\nfor (auto i : c_arr) cout &lt;&lt; i &lt;&lt; \" \";\n\u2026\ndelete vecd;\nreturn 0;\n}\n</code></pre> <pre><code>int main()\n{\nstatic int c_arr[] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10};\nvector&lt;int&gt; vec = {1, 2, 3, 4, 5, 6, 7, 8, 9};\nvector&lt;int&gt;* vecd = new vector&lt;int&gt;{1, 2, 3, 4, 5, 6, 7, 8};\n...\nfor (auto i : c_arr) cout &lt;&lt; i &lt;&lt; \" \";\n\u2026\ndelete vecd;\nreturn 0;\n}\n</code></pre>"},{"location":"8-semester/sP/01-introduction/#pointers-and-references","title":"Pointers and References","text":"<ul> <li>A pointer <code>*</code>  can point to any object in memory or have a special value <code>nullptr</code><ul> <li>Typed or <code>void*</code></li> <li>If typed, defines pointer arithmetic and can be dereferenced</li> </ul> </li> <li>In C, function parameters are passed by value, but pointers can be used</li> <li>C++ reference <code>&amp;</code><ul> <li>A different name for an object, must be initialized</li> </ul> </li> </ul>"},{"location":"8-semester/sP/01-introduction/#c-arrays","title":"C Arrays","text":"<ul> <li>Indexed from 0 to n-1</li> <li>A name of the array is a (constant) pointer to the first element<ul> <li><code>a[j]==*(&amp;a[0] + j) == *(a + j)</code></li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/","title":"Fundamentals","text":""},{"location":"8-semester/sP/02-fundamentals/#fundamental-types","title":"Fundamental Types","text":"<ul> <li><code>void</code></li> <li><code>bool</code></li> <li>Character types, most important <code>char</code></li> <li>Integer types: <code>short</code>, <code>int</code>,<code>long</code>,<code>long long</code><ul> <li><code>signed</code> and <code>unsigned</code> variants</li> </ul> </li> <li>Floating point types: <code>float</code>, <code>double</code>, <code>long double</code></li> <li>Enumeration types</li> <li>Pointer types<ul> <li>Including function pointers</li> </ul> </li> <li>Array types</li> <li>Reference types</li> <li><code>struct</code>, <code>union</code>, and <code>class</code></li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#bool","title":"Bool","text":"<ul> <li><code>true</code> and <code>false</code> are keywords</li> <li>Relation to other fundamental types:<ul> <li>Boolean values are converted implicitly to integers in arithmetic and logical expressions: <code>false</code> to 0 and <code>true</code> to 1.</li> <li>Integers can be converted implicitly to booleans: 0 to <code>false</code>, other values to <code>true</code>.</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#structs","title":"Structs","text":"<ul> <li>The same as struct in C, but: <ul> <li>In C++ it is possible to refer to <code>struct S {...}</code> by just <code>S</code>, not necessarily <code>struct S</code>. </li> </ul> </li> <li>C++ structs in relation to classes:<ul> <li>A struct is a class where all members are public by default</li> <li>A struct is typcically used for aggregating public data </li> <li>Both structs and classes can make use of inheritance</li> <li>Are usually used, when no member functions are defined.</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#enums","title":"Enums","text":"<ul> <li>There are plain old C enums:<ul> <li><code>enum Color {red, green, blue};</code></li> <li>Problem: <code>red, green</code> and <code>blue</code> pollutes the whole scope</li> <li>Potential problem: automatically converts to int</li> </ul> </li> <li>New enum class:<ul> <li>No implicit conversion to int</li> <li>It is scoped</li> <li>Implementation type (as well as individual type) can be suggested</li> </ul> </li> </ul> <pre><code>enum class Color:char {red = 1, green = 2, blue = 3};\n\nColor c = red;                  // Error !! no \u201cred\u201d in scope\nColor cc = 1;                       // Error !! no conversion from int or char\nchar ch = Color::red;       // Error !! no conversion to char or int\nColor ccc = Color::red; // OK\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#declarations-and-definitions","title":"Declarations and Definitions","text":"<ul> <li>Declaration<ul> <li>Introduces names \u2013 for the benefit of the compiler.</li> <li>Several declarations of the same name are allowed \u2013 must agree on the types involved.</li> <li><code>extern</code> keyword may be used to distinguish from definition.</li> </ul> </li> <li>Definition<ul> <li>A declaration that also defines an entity<ul> <li>A location in memory</li> <li>A function with a body</li> <li>A fully-specified type</li> </ul> </li> <li>An initialization or a function body signifies a definition</li> <li>There must be precisely one definition of a named entity.<ul> <li>This is a bit relaxed for the benefit of multiple includes:<ul> <li>A class, inline functions and variables, or templates may be defined more than once (if they appear in different translation units and if they are token-fortoken identical)</li> </ul> </li> </ul> </li> </ul> </li> </ul> <pre><code>/* \u2193 DEFINITIONS  */\nstring s;\nint i = 5;\n\nstruct Date {\nint d, m, y;\n};\n\nint f(int i) {\nreturn i + 1;\n}\n/* \u2191 DEFINITIONS */\n\n/* \u2193 DECLARATIONS  */\nextern string t;\nextern int j;\nstruct DateWithWeekday;\nint g(int i);\n\nDateWithWeekday h(Date, int);\n/* \u2191 DECLARATIONS */\n\n/* \u2193 DEFINITIONS  */\nstruct DateWithWeekday {\nDate wd;\nint weekday;\n};\n/* \u2191 DEFINITIONS */\n</code></pre> <pre><code>string s;\nstring s = \u201cququ\u201d;      // Error!! Double definition\nint f(int i) {\nreturn i + 1;\n}\n\nint f(int j) {              // Error!! Double definition\nreturn j + 1;\n}\n\ndouble f(double j) {    // OK. Overload\nreturn j \u2013 1;\n}\n\nint g(int i);               // Declarations\nstruct Date;\n\nint f() {                       // Another overload\nDate d;                         // Error!! Incomplete type\nf(1);\ng(2);                           // OK. Enough info for compiler\n}\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#the-structure-of-a-declaration","title":"The Structure of a Declaration","text":"<ul> <li>A declaration of a single entity consists of a four parts:<ul> <li>Base type including const and volatile qualifiers</li> <li>Declarator<ul> <li>The name being declared</li> <li>Optional declarator operators (<code>*, &amp;, &amp;&amp;, []</code>)\u2013 often mimics their use as operators in expressions</li> </ul> </li> <li>[Specifier] (prefix and suffix):<ul> <li><code>auto, extern</code></li> <li>Storage class: <code>mutable, static, virtual</code></li> </ul> </li> <li>[Initializer]<ul> <li>Different styles are possible</li> </ul> </li> </ul> </li> </ul> <pre><code>unsigned int i = 7;\nconst double d = 5.7;\nchar* str[] = {\"This\", \"is\", \"a\", \"c-string\", \"array\"};\nextern short int ei;\nbool is_even(int a);\nPoint p1(1,2);\nPair q1 = {3,4};\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#declaring-several-names-together","title":"Declaring Several Names Together","text":"<ul> <li>Several comma-separated declarators, with associated initializers, may share the same base-type and specifier..<ul> <li>May lead to confusions, better avoided:</li> </ul> </li> </ul> <pre><code>unsigned int i = 7, j[3], *k = &amp;i;\n\nchar ch0;\nchar* ch1, ch2; // Misleading notation but OK. Only ch1 is a char pointer!\nchar *ch3, ch4; // A little bit better, but better avoided all together!\n\nconst double d = 5.7, pi = 3.14159, &amp;dr = d;\nchar *str[4], ch = 'a';\nbool    is_even(int a),\nis_odd(int a);\n\nPoint p1(1,2), p2;\n\nPair    q1 = {3,4},\nq2 = {5,6};\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#objects-and-lvalues","title":"Objects and lvalues","text":"<ul> <li>An object is a contiguous region of storage - \"something in memory\"<ul> <li>A more general concept than an OOP (object)</li> </ul> </li> <li>An lvalue is an expression that refers to an object.<ul> <li>Named after expressions that can occur at the left-hand side of an assignment, but is more general than that</li> <li>Usually they are modifiable but can also be declared constant.</li> <li>They have identity.<ul> <li>Not some temporary result of computation.</li> </ul> </li> </ul> </li> </ul> <pre><code>var = 7;\ntab1[3] = 8;\n*(tab2 + 4) = 9\ntab3[0].x = 2.0;\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#rvalues","title":"Rvalues","text":"<ul> <li>An rvalue e is an expression that is not an lvalue \u2013 an expression whose value does not have an identifiable position in memory, such as a temporary object<ul> <li>Expressions that can appear at the right side of the assignment</li> <li>It does not make sense to take the address of an rvalue expression</li> </ul> </li> </ul> <pre><code>double e    = 3.14;\ndouble d    = f(5, e);\nint i       = 5, k = i + 8;\nbool b      = Point{1,2} == Point{3,4};\n\ndouble *pe  = &amp;3.14;        // error: Cannot take the address of a 3.14\ndouble *pd  = &amp;f(5, e);     // error: Cannot take the address of a f(5, e)\nint *pi         = &amp;(i + 8);         // error: Cannot take the address of (i + 8)\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#references","title":"References","text":"<ul> <li>Best way to think about a reference is that it is an alias, an alternative name.<ul> <li>Used with the same syntax as the original name</li> </ul> </li> <li>Why references in C++?<ul> <li>An implementation of call-by-reference parameters - instead of relying on pointers passed by value</li> <li>An optimization of large call-by-value parameters - by means of const references (read: \u201creferences to constants\u201d)<ul> <li>Name binding to temporary objects</li> </ul> </li> <li>Essential for programming parameters of copy constructors and assignment operator overloads</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#rules-for-references","title":"Rules for References","text":"<ul> <li>A reference must be initialized when declared</li> <li>A reference is constant by nature<ul> <li>Once established the reference can never be set to reference something else</li> </ul> </li> <li>No operator operates on a reference as such - only the object referenced</li> <li>There is no null reference (in the sense that there is a nullptr)</li> <li>Pointers to references and arrays of references do not exist<ul> <li>But references to pointers and references to arrays can exist</li> </ul> </li> </ul> <p>references1.cpp : operations on references vs. operations on pointers references3.cpp : references to local variables</p>"},{"location":"8-semester/sP/02-fundamentals/#constant-references","title":"Constant References","text":"<ul> <li>The use of <code>const</code> in a declaration of a reference (argument) means that we do not want to change the referenced object<ul> <li>...and we ask the compiler to enforce that</li> </ul> </li> <li>Replaces passing-by-value of large arguments </li> <li>\u201cAn initializer for <code>const T&amp;</code> does not need to be an lvalue, or even of type <code>T</code>\u201d<ul> <li><code>const T&amp; var = expression;</code></li> <li>Initialization of var - a reference to T:<ul> <li>Implicit conversation from the type of expression to <code>T</code> is performed</li> <li>The result is placed in a temporary variable of type <code>T</code></li> <li><code>var</code> is bound to the teporary variable, which cannot be mutated</li> </ul> </li> </ul> </li> </ul> <p>references2.cpp : const references and references for output parameters</p>"},{"location":"8-semester/sP/02-fundamentals/#lvalue-references-vs-pointers","title":"Lvalue References vs Pointers","text":"<ul> <li>The notational overhead (use of <code>&amp;</code> and <code>*</code>) is less for use of references than for pointers<ul> <li>The reason is that it is not possible to manipulate the reference as such</li> </ul> </li> <li>The mental models are different<ul> <li>Pointers: Establish a pointer to an object, follow the pointer to the object for lhs/rhs access.<ul> <li>The pointer itself may be changed.</li> </ul> </li> <li>References: Establish an alternative name to an existing object (an alias).</li> <li>Once established the reference can never be changed.</li> </ul> </li> <li>Pointer is lower-level (closer to hardware) concept, reference is a higher level, language concept.<ul> <li>But: new returns a pointer! Then use smart pointers from STL (more later\u2026)</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#three-kinds-of-references","title":"Three Kinds of References","text":"<ul> <li>Lvalue references<ul> <li>Refers to values we want to change</li> <li>Useful alternatives for C-style 'call-by-reference' parameters (using pointers)</li> </ul> </li> <li>const Lvalue references<ul> <li>Refers to constants - values that we do not want to change</li> <li>Useful alternative for 'call-by-value' parameters in many contexts</li> </ul> </li> <li>Rvalue references  (we will return to them later)<ul> <li>Refer values that we do not want to preserve after we have used it</li> <li>Useful in the context of value return from a function<ul> <li>Values that we intend to 'move from'</li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#readingwriting-complex-types","title":"Reading/Writing Complex Types","text":"<ul> <li>Unary operators are right-associative<ul> <li>It helps reading complex type constructs from right to left</li> <li><code>[]</code> and <code>()</code> take precedence over <code>*</code> and <code>&amp;</code></li> </ul> </li> </ul> <pre><code>const double* a[];              // an array of pointers to const doubles\nconst double (*a)[];            // a pointer to an array of const doubles\nconst double* const a;      // a const pointer to a const double\nconst double* const *a;     // a pointer to a const pointer to a const double\n</code></pre> <ul> <li>Terminology sometimes can be ambiguous<ul> <li>What do \u201cconst reference\u201d and \u201cconst pointer\u201d mean?</li> </ul> </li> <li>Type aliases \u2013 synonyms for complex types:</li> </ul> <pre><code>using cpdouble  = const double* const;\nusing pf                = int (*)(double);\n</code></pre>"},{"location":"8-semester/sP/02-fundamentals/#functionoperator-overloading","title":"Function/Operator Overloading","text":"<ul> <li>The same name, but different formal parameters<ul> <li>Overloading is resolved at compile time<ul> <li>Finds the best match, or reports ambiguity</li> </ul> </li> <li>The function return types do not take part in overload resolution</li> </ul> </li> <li>Complex rules for what is the best match. <ul> <li>For each pair of actual and formal parameters:<ul> <li>Exact match</li> <li>Match using promotions:<ul> <li>bool to int, char to int, short to int, float to double, \u2026</li> </ul> </li> <li>Match using standard conversions<ul> <li>int to double, double to int, ...</li> </ul> </li> <li>Match using user defined conversions<ul> <li>Conversion operators and constructors</li> </ul> </li> <li>Match using the ellipsis (\u2026)<ul> <li>Unspecified number of parameters</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>overloading1.cpp : ambiguous overloading overloading2.cpp : overloading with two parameters</p>"},{"location":"8-semester/sP/02-fundamentals/#physical-program-organization","title":"Physical Program Organization","text":"<ul> <li>Source files with <code>#include</code> directives</li> <li>A translation unit is the result of preprocessing a source file.</li> <li>preprocessing \\to compilation \\to\\to (archiving) \\to\\to linking</li> <li>source files \\to\\to object files \\to\\to (libraries) \\to\\to executables</li> <li><code>.h</code> file<ul> <li>Includes an interface \u2013 adds some definitions of types and declarations of static data and some functions to some namespace </li> </ul> </li> <li><code>.cpp</code> file<ul> <li>Includes definitions (implementations) of functions/methods and definitions of static data: <ul> <li>implement an interface defined in a header... </li> <li>...or are internal to the compilation unit</li> </ul> </li> </ul> </li> <li>External linkage:<ul> <li>A name that can be used in other translation units than the one where it is defined</li> </ul> </li> <li>Internal linkage:<ul> <li>A name that only can be used in the translation unit where it is defined</li> <li>Declared as static in C programs and older C++ programs</li> <li>Use an unnamed namespace for internal linkage in C++ programs</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#examples","title":"Examples","text":"<ul> <li>point.h</li> <li>point.cpp</li> <li>tripple.h</li> <li>tripple.cpp</li> <li>main.cpp</li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#logical-program-organization","title":"Logical Program Organization","text":"<ul> <li>Namespace is a named scope</li> <li>Use of names requires namespace qualification, with use of the scope resolution operator <code>::</code><ul> <li><code>namespace::name_in_it</code></li> </ul> </li> <li>A <code>using</code> declaration can be used to add a name (an alias) to a local scope (such as a function) from a namespace:<ul> <li><code>using N::name;</code></li> <li>name is declared as a local synonym to <code>N::name</code></li> </ul> </li> <li>A <code>using</code> directive allows convinient access to names from a given namespace:<ul> <li><code>using  namespace N;</code></li> <li>Preferably used locally, in a function for instance</li> </ul> </li> </ul>"},{"location":"8-semester/sP/02-fundamentals/#namespaces","title":"Namespaces","text":"<ul> <li>A namespace is open:<ul> <li>A single namespace N can span several source files</li> <li>For instance namespace <code>N {...}</code> forms in two or more header files</li> </ul> </li> <li>Namespaces can be nested</li> <li>There is a global namespace<ul> <li>Access to name in the global namespace: <code>::name</code></li> </ul> </li> <li>Unnamed namespaces<ul> <li>Used in C++ to make names local to a compilation unit (internal linkage)</li> </ul> </li> </ul>"},{"location":"8-semester/sP/03-initialization/","title":"Initialization","text":"<pre><code>T v1 = v;   // C style initialization.\nT v2 = {v}; // C style List initialization.\nT v3(v);        // Constructor style initialization.\nT v4{v};        // Universal initialization, without narrowing. Preferred.\nT v5();         // C++\u2019s most vexing parse: A function declaration, not a variable definition!\nT v6{};         // Default initialization. For user-defined types, use parameterless constructor.\nint i{10};  // OK.\nchar ch{i}; // Warning: narrowing\n</code></pre> <p>Assignment style:</p> <ul> <li>Confusion with assignment (can be different for user defined types)</li> </ul> <pre><code>T v1 = v; // T\u2019s copy constructor is called\nv1 = w; // T\u2019s assignment operator is called \n</code></pre> <p>Constructor-call style ()</p> <ul> <li>Confusion with function declaration</li> <li>Not possible for class members in the definition of a class</li> </ul> <p>Universal initialization - with <code>{}</code></p> <ul> <li> <p>Can bee used (almost) everywhere</p> </li> <li> <p>Warns about narrowing</p> </li> <li> <p>Generalizes the notation used for initialization of arrays and structs in C</p> </li> <li> <p>Can aso be used for passing parameters to constructors</p> </li> <li> <p>Although sometimes with some abiguities, forcing the use of old-style initialization!</p> </li> <li> <p><code>c++     std::vector&lt;int&gt; v(10, 2); // Create a vector with 10 elements all initialized to 2.     std::vector&lt;int&gt; v{10, 2}; // Create a vector with two elements: 10 and 2.</code></p> </li> <li> <p>This happens when there is a constructor of a class with a parameter of a special STL type <code>std::initializer_list&lt;T&gt;</code>. When writing your classes, consider avoiding such constructors.</p> </li> <li> <p><code>{}</code> results in default initialization, also fo the built-in types</p> </li> </ul>"},{"location":"8-semester/sP/03-initialization/#auto","title":"Auto","text":"<ul> <li> <p><code>auto</code> - the compiler infers the type&amp;&amp;)</p> </li> <li> <p>Can be decorated with <code>const</code>and <code>&amp;(&amp;&amp;)</code> or <code>*</code></p> </li> <li> <p>Good idea to use if often (AAA rule = Almost Always Auto)</p> <ol> <li>Forces to initialize</li> <li>Makes code more general and easier to refactor</li> <li>Avoids subtle errors and perfomance penalties (unexpected temporaries)</li> <li> <p>Helps when the type is known only to the compiler (e.g. lambdas)</p> </li> <li> <p>Have to be careful to avoid pitfalls (related to type inference or assuming too much about the type)</p> </li> </ol> </li> </ul> <pre><code>auto i = 10;\nauto l = 10l;\nauto s = \"Hello\"s; // std::string object! User-defined suffixes for user-defined types are possible.\nconst auto&amp; ii = i;\nauto a {10}; // Creates an integer, starting from C++17\nauto b = {10}; // But: creates an std::initializer_list object with one member!!\n\nif (i == b) // Does not compile!\ncout &lt;&lt; \"Equal\" &lt;&lt; endl;\nelse cout &lt;&lt; \"Oops\" &lt;&lt; endl;\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#lambdas","title":"Lambdas","text":"<pre><code>int m{5}, n{6};\n\nauto f1 = [](int x)-&gt;int{return x + 1;};    // a function that returns x + 1.\nauto f2 = [m](int x){return x + m;};            // can read m from local scope.\nauto f3 = [=](int x){return x + m + n;};    // can read all local variables.\nauto f4 = [&amp;m](){++m;};                                     // access to m by reference - can write.\nauto f5 = [&amp;](){++m; n--;};                             // access to all local variables by reference.\nauto f6 = [&amp;]{++m;};                                            // empty parameter list implicit.\n</code></pre> <p>Consists of</p> <ul> <li>Capture list <code>[...]</code> - the lambda introducer</li> <li><code>[]</code>: captures nothing (as for regular functions)</li> <li><code>[&amp;]</code>: all local names can be used (accessed by reference)</li> <li><code>[=]</code>: all local names can be used (their const copies are available)</li> <li> <p><code>[capture-list]</code> specific captured names are given</p> </li> <li> <p>Formal parameter list (optional) <code>(parameters)</code></p> </li> <li>Return type declaration (optional) <code>-&gt; Type</code></li> <li>If not given, deduced the same way as for auto</li> <li>Body as for any other function <code>{...}</code></li> </ul> <p>Lambdas are often used as arguments of STL (or your...) generic algorithms</p> <pre><code>int c{10};\nvector&lt;int&gt; v{1, 3, 20, 6, 4};\n\n// multiplies all numbers by a constant\nfor_each(begin(v), end(v), [c](int&amp; i){ i *= c; });\n\n// checks some condition for all numbers\nif (find_if(cbegin(v), cend(v), [](const auto&amp; i){ return i &lt; 0 || i &gt; 100; }) != cend(v))\ncout &lt;&lt; \"There is a value outside the range [0, 100]\" &lt;&lt; endl;\n\n// prints all numbers: 10, 30, 200, 60, 40,\nfor_each(cbegin(v), cend(v), [](const auto&amp; i){ cout &lt;&lt; i &lt;&lt; \", \"; });\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#class-basics","title":"Class Basics","text":"<ul> <li>In C++, class design can be emphasized by seperating class definition (in .h) from member definition (in .cpp)</li> <li>But not neccesarily for all member functions (and not at all for template classes)</li> </ul> <p>Class definition</p> <ul> <li>Public part:</li> <li>Constructors</li> <li>Copy/Move constructors</li> <li>Member functions (including operator overloads)</li> <li>Destructor</li> <li>Private part:</li> <li>Data members</li> <li>Helper functions</li> </ul> <p>Examples</p> <p>Point definition</p> <p>Point implementation</p>"},{"location":"8-semester/sP/03-initialization/#constructors","title":"Constructors","text":"<ul> <li>Constructors in C++ are in many ways similar to constructors in C# and Java</li> </ul> <pre><code>classname(formal parameters): member1{init1}, member2{init2}, member3{init3}\n{\nbody\n};\n</code></pre> <ul> <li>Initialization of class data members with member initializers</li> <li>Special syntax for initialization of data members and bases (super class parts)</li> <li>Emphasizing uniform use of <code>{}</code> notation</li> <li>Place between the constructor header and body</li> <li>Initializes the data members from the formal parameters of the constructor</li> <li>If constructor(s) with parameters are given, no default constructor is generated!</li> <li>Constructor chaining (example rectangle class)</li> </ul>"},{"location":"8-semester/sP/03-initialization/#destructors","title":"Destructors","text":"<ul> <li>Destructors are essential for resource management</li> <li>Usually called implicitly:</li> <li>When an automatic (local) variable of class type goes out of scope<ul> <li>Because of normal termination</li> <li>Because of exceptional termination: stack unwinding</li> </ul> </li> <li>When a dynamically allocated object is explicitly deleted from the free store (the heap)<ul> <li>With <code>delete</code> or <code>delete[]</code></li> </ul> </li> <li>Example: Alternative Point Class</li> </ul>"},{"location":"8-semester/sP/03-initialization/#move-semantics","title":"Move Semantics","text":""},{"location":"8-semester/sP/03-initialization/#rvalues","title":"Rvalues","text":"<ul> <li>An rvalue is an expression that is not an lvalue - an expression whose value does not have an identifiable (with a name!) position in memory, such as a temporary object</li> <li>Expressions that can appear at the right side of the assignment</li> <li>It does not make sense to take the address of an rvalue expression</li> </ul> <pre><code>double e    = 3.14;\ndouble d    = f(5, e);\nint i       = 5, k = i + 8;\nbool b      = Point{1,2} == Point{3,4};\n\ndouble *pe  = &amp;3.14;            // error: Cannot take the address of a 3.14\ndouble *pd  = &amp;f(5, e);     // error: Cannot take the address of a f(5, e)\nint *pi         = &amp;(i + 8);     // error: Cannot take the address of (i + 8)\n\nint&amp; fun();\nfun()   = 42;                       // ok, fun() is an lvalue\nint* p1 = &amp;fun();               // ok, fun() is an lvalue\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#references","title":"References","text":"<ul> <li>An rvalue reference is a reference to a tepmporary object (soon to dissapear) from which we can steal som constituents in order to avoid an expensive copy operation</li> <li>Binds to an rvalue, such as the returned value of many functions</li> <li>Used for \"destructive read\" that would otherwise have required a copy</li> <li>We want to overload some functions on Rvalue references in order to avoid expensive copy operations</li> <li>Intimately connected to move constructors</li> </ul> <pre><code>Shape&amp; Shape::operator=(Shape&amp;&amp; from) { \u2026 return *this; }\n\nShape a;\na = compute_shape();\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#copying-vs-moving-constructors","title":"Copying vs Moving Constructors","text":"<ul> <li>Moving</li> <li>Giving away details of an object instead of copying the dtails - \"destructive read\"<ul> <li>object is left in undefined (but valid!) state</li> <li>For example, it should be possible to assign to it (if the <code>operator=</code> is defined)</li> </ul> </li> <li>A move constructor <code>C(C&amp;&amp; a)</code> moves <code>a</code> into the current object</li> <li>A move constructor does not allocate resources - and should not throw any exception<ul> <li>In contrast to a copy constructor</li> </ul> </li> <li>If moving should take place, and if no move constructor exist, use the copy constructor (and pay the price)</li> </ul>"},{"location":"8-semester/sP/03-initialization/#a-class-with-everything","title":"A Class with Everything","text":"<pre><code>class MyClass\n{\nMyClass();                                        // default constructor\nMyClass(somearguments);           // constructor from arguments (type conversion, if one argument)\nMyClass(const MyClass&amp; a);        // copy constructor\nMyClass(MyClass&amp;&amp; a);                 // move constructor\nMyClass&amp; operator=(const MyClass&amp; a); // copy assignment: clean up target and copy\nMyClass&amp; operator=(MyClass&amp;&amp; a);          // move assignment: clean up target and move\n~MyClass();                                   // destructor: clean up\n// ...\n};\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#forcing-the-move-semantics","title":"Forcing the Move Semantics","text":"<ul> <li>A \"function\" <code>std::move</code> can be used to convert into an rvalue type, thus causing the move semantics</li> </ul> <pre><code>template &lt;class T&gt;\nvoid swap (T&amp; a, T&amp; b) {\nT c{std::move(a)};\na = std::move(b);\nb = std::move(c);\n}\n</code></pre>"},{"location":"8-semester/sP/03-initialization/#passing-arguments-summary","title":"Passing Arguments: Summary","text":"<ul> <li>Ignoring pointers, the possible agreements between the caller and the function regarding an argumentz</li> <li>\"Get a copy and do whatever you want with it\"</li> <li>Pass by value: <code>void fun(MyClass x);</code></li> <li>\"Work on it and give me back\"</li> <li>Pass by lvalue reference: <code>void fun(MyClass&amp; x);</code></li> <li>\"Just look at it, no touching\"</li> <li>Pass by const lvalue reference: <code>void fun(const MyClass&amp; x);</code></li> <li> <p>Note: the function may end up working on a temporary copy (if some type conversion had to be done)!</p> </li> <li> <p>\"Use it, but give me back a box\"</p> </li> <li>Pass by rvalue reference: <code>void fun(MyClass&amp;&amp; x);</code></li> </ul>"},{"location":"8-semester/sP/04-raii/","title":"Classes Continued","text":""},{"location":"8-semester/sP/04-raii/#rule-of-fivethreezero","title":"Rule of Five/Three/Zero","text":"<p>Rule of Three</p> <ul> <li>If a class requires user-defined destructor, a user-defined copy constructor, or a user-defined copy assignment operator, it almost certainly requires all three.<ul> <li>Corollary: if you delete one them, you most likely want to delete all three</li> </ul> </li> </ul> <p>Rule of Five</p> <ul> <li>If you want move semantics, you have to provide all five special functions.</li> <li>If you forget move constructor and move assignment operator - missed optimization opportunity </li> </ul> <p>Rule of Zero</p> <ul> <li>If you build things out of standard library components to manage your resources, you don\u2019t have to provide any of the special functions.<ul> <li>The same bare-bones graph, but with <code>std::vector</code>: rule0.cpp</li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#more-about-special-methods","title":"More About Special Methods","text":"<ul> <li>Deleting with <code>= delete</code><ul> <li>It is possible to delete a constructor (or any other function) that has been generated automatically</li> <li>For instance deleting a copy constructor, such that an object cannot be copied</li> </ul> </li> <li>Defaulting with <code>= default</code><ul> <li>It is possible to emphasize that we actually want to have an automatically generated function, for instance, to document that the automatically generated move constructor/assignment operator exists </li> </ul> </li> <li>Rule of five still applies...</li> </ul>"},{"location":"8-semester/sP/04-raii/#raii-principle","title":"RAII Principle","text":"<ul> <li> <p>Video about RAII</p> </li> <li> <p>Resources Acquisition is Initialization Principle</p> <ul> <li>There is no automatic memory management in C++</li> <li>Therefore it is attractive to attach resource management to construction and destruction of stack-allocated objects</li> <li>The resource is encapsulated in a class together with allocation and release member functions</li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#smart-pointers","title":"Smart Pointers","text":"<ul> <li><code>std::unique_ptr</code> \u2013 for unique ownership</li> <li><code>std::shared_ptr</code> \u2013 for shared ownership</li> <li><code>std::weak_ptr</code> \u2013 for temporary ownership (with possibility for safely dangling) </li> </ul> <p>The first two:</p> <ul> <li>provides overloads for <code>operator*</code> and <code>operator-&gt;</code></li> <li>can be null</li> <li>custom deleters are possible (but handle differently...)</li> <li>smart_pointers.cpp</li> </ul>"},{"location":"8-semester/sP/04-raii/#type-conversion","title":"Type Conversion","text":""},{"location":"8-semester/sP/04-raii/#explicit-type-conversion","title":"Explicit Type Conversion","text":"<p>Explicit conversions to type <code>T</code> (casts):</p> <ul> <li><code>static_cast&lt;T&gt;(expr)</code> from a related type<ul> <li>Can activate built-in or user-defined type conversion, conversion operators, and implicit/explicit constructors.</li> </ul> </li> <li><code>reinterpret_cast&lt;T&gt;(expr)</code> from an unrelated type - \"dangerous\"<ul> <li>Can cast between pointer types, and between integer and pointer types</li> <li>Provides a value of new type that has the same bit pattern as its argument.</li> </ul> </li> <li><code>dynamic_cast&lt;T*&gt;(expr)</code> from a related polymorphic type (pointer or reference types only)</li> <li><code>const_cast&lt;T&gt;(expr)</code> from a closely related type (add or remove const qualifier)</li> <li>C-style type casts: <code>(T)expr</code> or <code>T(expr)</code> using early C++ notation</li> </ul> <p>Stackoverflow: About casting</p> <p>\"If you are doing a lot of explicit conversions, you are doing something wrong...\"</p>"},{"location":"8-semester/sP/04-raii/#const-member-functions","title":"Const Member Functions","text":"<ul> <li> <p>A constant member function is not allowed to change the state of the object.</p> <ul> <li>On a constant object, only constant member functions can be called.</li> <li>A const member function cannot call other member functions which are not constant!</li> <li>Point class</li> </ul> </li> <li> <p>Difference between logical constness and physical constness</p> <ul> <li>For example, for efficiency, I may cash results of some expensive computations.</li> <li>mutable data members can always be updated, even if they belong to a const object</li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#inline-member-functions","title":"Inline Member Functions","text":"<ul> <li>Given by the <code>inline</code> keyword and member functions defined inside class definitions are implicitly marked as inlined</li> <li>An efficiency concern - eliminates a call<ul> <li>A plea to the compiler - not a requirement</li> <li>Inline functions must be defined in every translation unit where they are used, thus they are usually defined in header files</li> <li>Some functions cannot easily be inlined<ul> <li>recursive functions</li> </ul> </li> </ul> </li> <li>Two ways to specify them<ul> <li>Write a body in the class definition (only if it is very brief)</li> <li>Provide the definition of the member function in the same header file</li> </ul> </li> </ul> <pre><code>class Counter {\nprivate:\nint what;\nint&amp; counter;\npublic:\nCounter(int value, int&amp; cnt): what{value}, counter{cnt} {}\nvoid operator() (int item);\n};\n\ninline void Counter::operator() (int item) {\nif (item == what) counter++;\n}\n</code></pre>"},{"location":"8-semester/sP/04-raii/#friendship","title":"Friendship","text":"<ul> <li>Friendship is provided by the class that encapsulates members with access limitations<ul> <li>Friendship cannot be taken by a class or function that wants access!</li> </ul> </li> <li>Friendship can be granted to:<ul> <li>an ordinary function, or to an overloaded operator<ul> <li>\u200b <code>f(x,y)</code> versus <code>x.f(y)</code> call syntax</li> </ul> </li> <li>a member function in another class</li> <li>all members of another class</li> </ul> </li> <li>Friendship is not transitive, and it is not inherited</li> </ul> <p>Example: operators <code>&lt;&lt;</code> and <code>&gt;&gt;</code> : header, cpp</p>"},{"location":"8-semester/sP/04-raii/#operator-overloading","title":"Operator Overloading","text":"<p>Restrictions:</p> <ul> <li>It is not possible to invent new operator symbols.</li> <li>The associativity and precedence of the predefined rules of predefined operators apply.</li> <li>Cannot be overloaded: <code>::</code>, <code>.</code> , <code>.*</code> , <code>?:</code> , <code>sizeof</code> , <code>typeid</code></li> <li>At least one operand must be of a user-defined type.</li> <li>If the left operand is of user-defined type, the operator may be defined as a member function</li> <li>If the left operand is of predefined type, the operator must be a non-member function</li> </ul> <p>Example: point3.h, point3.cpp</p> <p>Example of <code>operator(), operator int()</code>: functor.cpp</p> <ul> <li>Implementing lambda through function objects</li> </ul>"},{"location":"8-semester/sP/04-raii/#stl-string","title":"STL: string","text":"<ul> <li><code>string</code> is an alias for a <code>basic_string</code> parameterized by <code>char</code></li> <li>As everything in STL, strings have value semantics<ul> <li>Copied in and out of functions - or passed by reference</li> </ul> </li> <li>Characters in strings can be accessed in checked mode and unchecked mode<ul> <li>Checked mode: <code>s.at(i)</code></li> <li>Unchecked mode: <code>s[i]</code></li> </ul> </li> <li>A string is mutable</li> <li>Strings can be copy constructed based on a C-style string<ul> <li><code>string s{\"Peter\"};</code></li> <li><code>string s(\"Peter\");</code></li> <li><code>string s = \"Peter\";</code></li> </ul> </li> <li>Short string optimization<ul> <li>Short strings are allocated in the string object itself (not on the free store)</li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#stl-vector","title":"STL: vector","text":"<ul> <li>A template class - type parameterized</li> <li>Not of fixed size like an array \u2013 the number of elements may be adjusted dynamically</li> <li>Size and capacity:<ul> <li>Size: the actual number of elements in the vector</li> <li>Capacity: the maximum number of elements before resizing is needed.</li> </ul> </li> <li>With or without range checking.</li> <li>Obeys value semantics and stores values <ul> <li>It wraps a pointer to a heap storage</li> </ul> </li> <li>Traversed with use of iterators. Iterators can be used in a similar way as pointers, via overloading of operators<ul> <li><code>*iterator</code>, <code>iterator++</code>, <code>iterator + n</code>, <code>iterator1 - iterator2</code></li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#stdostream-and-stdistream","title":"std::ostream and std::istream","text":"<p>Considerations about IO in C++:</p> <ul> <li>IO functions must apply uniformly to pre-defined types and user-defined types<ul> <li>The C-style <code>printf</code> and <code>scanf</code> are not easy to generalize to user-defined functions</li> <li>In addition, <code>printf</code> and <code>scanf</code> are not type safe</li> </ul> </li> <li>Use of overloaded operators seems attractive<ul> <li>Shorter, and easier to spot: <code>s &lt;&lt; d1 &lt;&lt; d2 &lt;&lt; d3</code></li> <li>The relative low priority of <code>&lt;&lt;</code> is practical when values of expressions must be printed.<ul> <li><code>cout &lt;&lt; x + y * z</code> and not <code>cout &lt;&lt; (x + y * z)</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/sP/04-raii/#standard-streams-and-files","title":"Standard Streams and Files","text":"<ul> <li><code>cin</code>:  Standard character input \u2013 typically defaulted to a keyboard</li> <li><code>cout</code>: Standard character output \u2013 typically defaulted to a screen</li> <li><code>cerr</code>: Standard character error output \u2013 unbuffered</li> <li><code>clog</code>: Standard character error output \u2013 buffered </li> </ul> <p>Manipulators:</p> <pre><code>cout    &lt;&lt; 17   &lt;&lt; endl &lt;&lt; showbase\n&lt;&lt; hex  &lt;&lt; 17       &lt;&lt; endl\n&lt;&lt; oct    &lt;&lt; 17       &lt;&lt; endl;\n</code></pre>"},{"location":"8-semester/sP/05-pimpl/","title":"PIMPL Idiom and Dynamic Polymorphism","text":""},{"location":"8-semester/sP/05-pimpl/#pimpl-idiom","title":"PIMPL Idiom","text":"<p>C++ relies on compiler performing a lot of work</p> <ul> <li>Compilation can get pretty slow if many headers are included</li> <li>Clients may need to be recompiled whenever private/protected implementation details change in the header...</li> </ul> <p>PIMPL Idiom:</p> <ol> <li>Collect implementation details in an implementation class</li> <li>Only forward declare it in the header, move its definition to the cpp file.</li> <li>In the main(interface) class have a (smart) pointer to an implementation object</li> <li>Have all the definitions of the methods, that access the implementation object, in the cpp file</li> </ol> <p>timeseries_pimpl.h timeseries_pimpl.cpp</p>"},{"location":"8-semester/sP/05-pimpl/#issues","title":"Issues","text":"<ul> <li>Propagation of const<ul> <li>A pimpl pointer that is constant, but is not a \"const pointer\"!</li> <li>Solution: use accessor methods everywhere instead of a direct pimpl pointer</li> </ul> </li> </ul> <pre><code>private:\nclass TimeSeriesImpl;  // Just a declaration\n\nconst TimeSeriesImpl* Pimpl() const { return pimpl.get(); }\nTimeSeriesImpl* Pimpl()             { return pimpl.get(); }\n\nstd::unique_ptr&lt;TimeSeriesImpl&gt; pimpl;\n</code></pre>"},{"location":"8-semester/sP/05-pimpl/#inheritance-in-c","title":"Inheritance in C++","text":"<ul> <li>Multiple inheritance<ul> <li>But no concept of interfaces (as in Java and C#): fully compensated by multiple inheritance and abstract classes</li> </ul> </li> <li>Polymorphism (dynamic binding) is not automatic<ul> <li>Methods should be declared virtual</li> <li>Objects should be accessed via pointers or references </li> </ul> </li> <li>Shared or replicated base classes<ul> <li>Shared base classes are called virtual base classes</li> </ul> </li> <li>Access control to base classes<ul> <li>private, protected, and public base classes </li> <li>Related to interface and implementation inheritance.</li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#constructors-and-destructors","title":"Constructors and Destructors","text":"<p>Some rules for constructors and destructors</p> <ul> <li>A subclass constructor invokes the superclass constructors \u2013 implicitly or explicitly<ul> <li>Constructors with parameters must be invoked explicitly</li> <li>Default constructors can be invoked implicitly</li> </ul> </li> <li>Bottom-up construction and top-down destruction:<ul> <li>First base class constructors, then derived class constructors</li> <li>Multiple base classes are constructed in their declaration order</li> </ul> </li> <li>C++ allows for inheritance of constructors<ul> <li>Makes sense if a derived class does not add data members.</li> </ul> </li> </ul> <p>Example of constructors/destructors in a hierarchy</p>"},{"location":"8-semester/sP/05-pimpl/#polymorphism-virtual-functions","title":"Polymorphism: Virtual Functions","text":"<ul> <li>If a member is virtual, the dynamic type of the object controls which function to call \u2013 true OOP<ul> <li>Destructors may also be virtual.</li> </ul> </li> <li>Conditions for getting polymophic behavior in C++:<ul> <li>A virtual member function f must be called</li> <li>The object must be accessed via a (smart) pointer or a reference:<ul> <li><code>o-&gt;f()</code></li> </ul> </li> </ul> </li> <li> <p>Avoiding polymorphic behavior with a virtual function f:</p> <ul> <li>Activate f with a scope resolution operation: <code>o-&gt;A::f()</code></li> </ul> </li> <li> <p><code>std::unique_ptr&lt;A&gt; o = std::make_unique&lt;B&gt;();</code></p> <ul> <li>A \\to B</li> </ul> </li> </ul> <p>Example with virtual functions</p> <p>What to remember when doing OOP with virtual functions in C++:</p> <ul> <li>The function in the base class must be virtual</li> <li>The base class function and the derived class functions must have the same name</li> <li>Their parameters must be identical</li> <li>Their constness must be the same</li> <li>Their return types must be compatible</li> <li>The object must be accessed via a pointer or a reference<ul> <li>Recommendation: use (a container of) smart pointers</li> <li>For example: <code>std::vector&lt;std::unique_ptr&lt;Point&gt;&gt;</code></li> </ul> </li> </ul> <p>It is recommended to use the (contextual) keyword override to state your intension of overriding a virtual member function</p> <ul> <li>Not using override + one of the above errors = a silent overload in the derived class</li> </ul>"},{"location":"8-semester/sP/05-pimpl/#virtual-destructors","title":"Virtual Destructors","text":"<ul> <li>A class with virtual functions should always have a virtual destructor</li> </ul> <pre><code>using namespace std;\nclass Data {\nint id;\npublic:\nData(int i): id{i} {};\nvirtual ~Data()\n{ cout &lt;&lt; \"Data destructor\" &lt;&lt; endl; }\n};\n</code></pre> <pre><code>class TimeSeries : public Data {\nint *ts;\npublic:\nTimeSeries(int i, int sz) : Data{i}, ts(new int[sz]) {};\n~TimeSeries() {\ncout &lt;&lt; \"Timeseries destructor\" &lt;&lt; endl;\ndelete[] ts;\n}\n};\n\nint main() {\nTimeSeries t{1, 10};\nData *d = new TimeSeries{2, 20};\ndelete d;\n}\n</code></pre>"},{"location":"8-semester/sP/05-pimpl/#abstract-classes","title":"Abstract Classes","text":"<ul> <li>Pure virtual functions<ul> <li>Marked with <code>= 0</code></li> </ul> </li> <li>A class is abstract if it has one or more pure virtual functions<ul> <li>No objects can be created from an abstract class</li> <li>Used as a base class in a hierarchy</li> <li>Corresponds to interfaces in Java and C#</li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#multiple-inheritance","title":"Multiple Inheritance","text":"<p>Concrete problem:</p> <ul> <li>If <code>ac</code> is an object of <code>C</code>, which <code>x</code> does <code>ac.x</code> refer to?</li> </ul> <p>In general</p> <ul> <li>Replication: Is there one or two x pieces in C?<ul> <li>There are two x variables in a C object</li> </ul> </li> <li>Name clash: Does <code>x</code> in <code>C</code> refer to the <code>x</code> in <code>A</code> or <code>x</code> in <code>B</code>? Do we have means to select one or another?<ul> <li>Use the scope resolution operator: <code>A::x</code> or <code>B::x</code></li> </ul> </li> <li>Combination: Can <code>x</code> in <code>A</code> and <code>x</code> in <code>B</code> be combined to a single <code>x</code> in <code>C</code>?<ul> <li>No - but some control is possible via virtual bases</li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#replicated-base-class","title":"Replicated Base Class","text":"<ul> <li>There are two copies of A!</li> <li>If <code>d</code> is an object of <code>D</code>, <code>d.x</code> is ambiguous<ul> <li>But there are <code>d.B::x</code> and <code>d.C::x</code></li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#virtual-base-classes","title":"Virtual Base Classes","text":"<ul> <li>It is also possible to share a base (usual case)<ul> <li>The constructor of A is called only once</li> </ul> </li> </ul> <pre><code>class B : public virtual A\n{ /* */ };\nclass C : public virtual A\n{ /* */ };\nclass D : public B, public C\n{ /* */ };\n</code></pre>"},{"location":"8-semester/sP/05-pimpl/#member-access-control","title":"Member Access Control","text":"<ul> <li><code>public</code>, <code>private</code>, and <code>protected</code><ul> <li>Similar to other object-oriented programming languages</li> <li>Access control is applied uniformly to names:<ul> <li>Functions</li> <li>Variables</li> <li>Types</li> <li>and others</li> </ul> </li> </ul> </li> <li>Access control via private/public/protected can be augmented with use of friends</li> </ul>"},{"location":"8-semester/sP/05-pimpl/#base-class-access-control","title":"Base-class Access Control","text":"<ul> <li>A base class can be defined either public, private, or protected.</li> <li>Idea: restrict access to inherited members (with private and protected base classes)</li> <li>When is more restricted access control to base classes useful?<ul> <li><code>A</code> is used internally in <code>B</code> and <code>A</code> should not affect the interface of <code>B</code><ul> <li><code>B</code> is implemented in terms of <code>A</code></li> <li><code>B</code> is not an <code>A</code></li> </ul> </li> </ul> </li> </ul> <p>Rules</p> <ul> <li><code>class B: private A</code><ul> <li>Public and protected members in A become private in B</li> <li>The default case for classes!</li> </ul> </li> <li><code>class B: protected A</code><ul> <li>Public members in A become protected in B</li> </ul> </li> <li><code>class B: public A</code><ul> <li>Public members in A will also be public in B</li> <li>The \"normal\" case - but not the default.<ul> <li>Default for structs!</li> </ul> </li> <li>Only in this case implicit up-casting works:</li> </ul> </li> </ul> <pre><code>B  b;\nA&amp; a = b;\n</code></pre>"},{"location":"8-semester/sP/05-pimpl/#interfaceimplementation-inheritance","title":"Interface/implementation Inheritance","text":"<p>Multiple inheritance and the inheritance access modifiers are useful when inheritance is used for different purposes:</p> <ul> <li>Inheriting implementation details, which we may want to hide (private)<ul> <li>Possibly hide just from the outside, but not from the derived classes (protected)</li> <li>Another option is to aggregate implementation details (PIMPL idiom) </li> </ul> </li> <li>Implementing an interface, by inheriting from an (abstract) class (public).<ul> <li>Derived class \u201cis a\u201d Base class </li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#navigating-the-hierarchy","title":"Navigating the Hierarchy","text":"<ul> <li>Given a pointer to a base class you want to check if this is a pointer to an instance of some derived class</li> <li><code>dynamic_cast&lt;T*&gt;(a)</code><ul> <li>Returns a pointer of type <code>T*</code> if <code>a</code> points to an object of type <code>T</code> or a type derived from <code>T</code>. Otherwise returns <code>nullptr</code></li> </ul> </li> <li><code>dynamic_cast&lt;T&amp;&gt;(a)</code><ul> <li>Analogous, but throws exception if not successful.</li> </ul> </li> <li>Example</li> <li>Can also be used to navigate to siblings in the hierarchy:<ul> <li><code>class ElectricGuitar: public MusicInstrument, public ElectronicDevice</code></li> <li>Then, for each member of a vector of <code>MusicInstruments</code>, try to see which can be casted to <code>ElectronicDevice</code></li> </ul> </li> </ul>"},{"location":"8-semester/sP/05-pimpl/#smart-pointers-and-hierarchy","title":"Smart Pointers and Hierarchy","text":"<ul> <li>Downcasting:<ul> <li>Obviously, it is not possible to created a downcasted copy of <code>unique_ptr</code></li> </ul> </li> </ul> <pre><code>void do_something(shared_ptr&lt;Measurement&gt; m) {\nauto stock_m = dynamic_pointer_cast&lt;StockMeasurement&gt;(m);\n// ...\n}\nvoid take_ownership(unique_ptr&lt;Measurement&gt;&amp;&amp; m) {  // special case: taking ownership of m\nif (dynamic_cast&lt;StockMeasurement*&gt;(m.get())) {     // check if we can really do this\nauto sm = unique_ptr&lt;StockMeasurement&gt;{dynamic_cast&lt;StockMeasurement*&gt;(m.release())};\n// ...\n}\n}\n</code></pre> <ul> <li>Advice: use <code>unique_ptr</code> as much as possible as well as passing by reference.</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/","title":"Double Dispatch","text":"<p>Not a good idea to define virtual operator overloads</p> <ul> <li><code>virtual MathObject* operator+(const MathObject&amp; b) const;</code><ul> <li><code>C = *A + *B</code></li> </ul> </li> <li>First, inconvenient: have to work with pointers, rather than values (or a mix of pointers and references to values...)</li> <li>Second, the operation performed is determined only by the type of the first argument (<code>*this</code>)<ul> <li>... and no dynamic polymorphism at all if defined outside the class (e.g. <code>operator&lt;&lt;</code>)</li> </ul> </li> </ul> <p>Double dispatch addresses the second point:</p> <ul> <li>The operation performed is determined by the types of both arguments</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#visitor-pattern","title":"Visitor Pattern","text":"<ul> <li>Double dispatch can be achieved:<ul> <li>One virtual function, chosen according to the type of <code>*this</code>, (first argument) delegates to another virtual function called on the second argument of the \u201coperation.\u201d</li> </ul> </li> <li>Used by the classical visitor pattern<ul> <li>What is performed by the visit operation depends on the type of the object visited and the type of the visitor.</li> </ul> </li> </ul> <p>shapes.h visitors.h main.cpp</p> <p></p>"},{"location":"8-semester/sP/06-double-dispatch/#copying-an-object-into-a-member","title":"Copying an Object into a Member","text":"<ul> <li>How to copy a (large) object into a class member?<ol> <li>Accept as const lvalue reference parameter </li> <li>Add an overload for rvalue reference parameter (optional, for performance)</li> <li>Have a template method (pass by universal reference)</li> <li>Pass by value (and then moving)!</li> </ol> </li> <li>Cost of it:<ul> <li>First: argument is copied/moved</li> <li>Then: the parameter is moved</li> <li>In total: copy+move for lvalues and move+move for rvalues</li> </ul> </li> <li>When to doo:<ul> <li>If cheap to move (e.g. std::array - not cheap to move)</li> <li>If always copied (the first copy/move is done before the call - should not be wasted)</li> </ul> </li> <li>See solution to exercise 5.2 (constructors of class Simple)</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#returning-from-functionsmethods","title":"Returning from Functions/Methods","text":"<ul> <li>Possible return types of functions?<ul> <li>Value: <code>Type f()</code><ul> <li>Standard/preferred. </li> <li>Use out parameter ( <code>f(Type&amp; out)</code> ) if the Type is large and expensive to move and copy elision/(N)RVO does not help or you want to reuse the same object (see <code>std::getline(std::istream&amp; , std::string&amp;)</code>)</li> </ul> </li> <li>Pointer: <code>Type* f()</code><ul> <li>Only to indicate position in a long-lived object. </li> <li>Never as a memory resource handle. </li> <li>Danger of a dangling pointer.</li> </ul> </li> <li>(const) Lvalue reference: <code>const Type&amp; f(\u2026)</code><ul> <li>If the function selects among alternatives: <code>Type&amp; f(Type&amp; op1, Type&amp; op2)</code></li> <li>As a return type of a getter/accessor method in a class (or should it return by value?)</li> </ul> </li> <li>Rvalue reference: almost never</li> <li>Smart pointer: <code>std::unique_ptr f()</code><ul> <li>Return ownership of a newly created object on a heap </li> </ul> </li> </ul> </li> <li>Returning several values<ul> <li>The code is more intuitive if <code>std::pair</code>, <code>std::tuple</code>, or your own structure is returned.</li> <li>Use structured bindings on the caller side:<ul> <li>structured_binding.cpp</li> </ul> </li> </ul> </li> <li>When returning a special null/invalid/void is an option:<ul> <li>Use: <code>std::optional&lt;Type&gt; f()</code></li> <li>Can have <code>std::nullopt</code> value</li> <li>It stores the value directly inside<ul> <li>optional.cpp</li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#stl","title":"STL","text":""},{"location":"8-semester/sP/06-double-dispatch/#stdstring-and-stdstring_view","title":"std::string and std::string_view","text":"<ul> <li><code>std::string</code> wraps good old <code>char*</code>:<ul> <li>Provides ownership</li> <li>Rich manipulation API</li> </ul> </li> <li>But could be expensive if we need to construct many temporary strings (just for read)<ul> <li>Example: stringviews.cpp</li> </ul> </li> <li><code>std::string_view</code> gives a lightweight, non-owning, read-only view into a string: just a pointer and a size<ul> <li>Rich interface</li> <li>Passed by value</li> <li>Can be converted from <code>std::string</code>s and C strings</li> </ul> </li> <li>Caution:<ul> <li>Returning an <code>std::string_view</code> - similar dangers to returning a raw pointer!</li> <li>As a constructor parameter to initialize a field of an object? - No!</li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#types-of-data-objects","title":"Types of Data Objects","text":"<ul> <li>Objects with value semantics (deep copy)<ul> <li>On the heap (cheap to move) e.g. <code>std::vector</code>, long <code>std::string</code></li> <li>In-place (move=copy) e.g. <code>std::array</code>, <code>std::string</code> with SSO</li> </ul> </li> <li>\"Pointer-like\" objects (shallow copy): <code>std::string_view</code>, <code>std::initializer_list</code><ul> <li>Small and passed by value</li> </ul> </li> <li>\"Handles\" to heap allocated memory (shallow/no copy): smart pointers<ul> <li>Own the object pointed to</li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#iterators","title":"Iterators","text":"<p>Iterators are generalized pointers</p> <ul> <li>The main role is to connect algorithms and containers</li> <li>Most important operators:<ul> <li>Access to the current element: <code>*</code> and <code>-&gt;</code></li> <li>Go to the next element: <code>++</code></li> <li>Equality and inequality: <code>==</code> and <code>!=</code></li> </ul> </li> <li>The start of a sequence <code>s</code>: <code>s.begin()</code></li> <li>The end of a sequence <code>s</code>: <code>s.end()</code><ul> <li>Designates a non-existing one past the last element</li> </ul> </li> </ul> <p>For range-for loop, the compiler automatically looks for iterators <code>vd.begin()</code> and <code>vd.end()</code>, or <code>begin(vd)</code> and <code>end(vd)</code>.</p> <ul> <li> <p>Defined in multiple versions in <code>&lt;iterator&gt;</code></p> </li> <li> <p>One of very few places where language depends on the standard library!</p> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#categories-of-iterators","title":"Categories of Iterators","text":"<p>C++ iterators are classified in a number of different dimensions:</p> <ul> <li>Const and non-const iterators<ul> <li>Use constant iterators, whenever possible</li> </ul> </li> <li>Reverse and forward iterators<ul> <li>For a reverse iterator, <code>++</code> moves backward.</li> </ul> </li> <li>Insert iterators<ul> <li>Inserting, instead of overwriting, elements in a container</li> </ul> </li> <li>Input, output, forward, bidirectional, random-access iterators<ul> <li>Input and output iterators have relatively few operators defined</li> <li>Random access iterators have many operators defined</li> <li>Looks like a class hierarchy, but it is not:<ul> <li>Instead use generic programming techniques supported by iterator tags \u2013 the so-called tag dispatch technique is used to implement compile-time polymorphism.</li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#operations","title":"Operations","text":"<ul> <li>All iterators: <code>++</code>, <code>*</code></li> <li>Input iterator <code>p</code><ul> <li>Single read (<code>x = *p</code>), no write, <code>==</code>, <code>!=</code></li> </ul> </li> <li>Output iterator <code>p</code><ul> <li>Single write (<code>*p = x</code>), no read</li> </ul> </li> <li>Forward iterator <ul> <li>Like input and output iterator, but can read and write repeatedly</li> </ul> </li> <li>Bidirectional<ul> <li>Like forward iterator, with an addition of <code>--</code></li> </ul> </li> <li>Random-access<ul> <li>Like bidirectional iterator, but can add and subtract integers to/from iterators</li> <li>Can compare iterators with <code>&lt;</code> , <code>&lt;=</code> , <code>&gt;</code>, and <code>&gt;=</code></li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#insert-iterators","title":"Insert Iterators","text":"<ul> <li>Insertion is normally done by the container operations <code>push_back()</code>, <code>push_front()</code>, and <code>insert()</code></li> <li>What if I want to make my algorithm independent of of the underlying container?</li> <li>Insert iterators a special type of output iterators that can be created by the template factory functions <code>back_inserter</code>, <code>front_inserter</code>, and <code>inserter</code>.</li> <li>Example</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#containers","title":"Containers","text":"<p>Three most important types of containers:</p> <ul> <li>Sequences:<ul> <li><code>vector</code>, <code>list</code>, <code>forward_list</code>, <code>dequeue</code></li> <li><code>stack</code>,<code>queue</code>, <code>priority_queue</code> via adapters on other sequences - restricting interfaces</li> </ul> </li> <li>Associative containers<ul> <li>Based on balanced trees: <code>map</code>, <code>multimap</code>, <code>set</code>, <code>multiset</code></li> <li>Based on hash tables: <code>unordered_map</code>, <code>unordered_multimap</code>, <code>unordered_set</code>, <code>unordered_multiset</code></li> </ul> </li> <li>Almost containers<ul> <li><code>string</code>, <code>valarray</code>, <code>bitset</code></li> <li><code>array</code>: Contains it elements directly (not a handle to its elements), fixed size - the size is a constant expression. Move is not more efficient than copy</li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#properties-of-containers","title":"Properties of Containers","text":"<ul> <li>No common base class for the standard containers<ul> <li>However, each container provides standard operations with standard names and semantics</li> </ul> </li> <li>Non-intrusive containers<ul> <li>Elements of containers do no need to be instances of certain classes</li> <li>An object is not aware of being an element of a particular container</li> <li>Values of built-in types can be elements in a container</li> </ul> </li> <li> <p>Standard containers rely heavily on templates, operator overloads</p> </li> <li> <p>Small example: using map</p> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#digression-exceptions","title":"Digression: Exceptions","text":"<p>Every STL operation provides one of the three guarantees:</p> <ul> <li>Basic guarantee: Basic invariants of objects are maintained (i.e., objects remain in valid state) and no resources are leaked.</li> <li>Strong guarantee: Basic guarantee + either the operation succeeds, or it has no effect. <ul> <li>For example <code>push_back()</code> provides it.</li> </ul> </li> <li>Nothrow guarantee: Basic guarantee + not throwing an exception.</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#noexcept","title":"noexcept","text":"<p>Let\u2019s look at <code>std::vector</code>\u2019s <code>push_back()</code> providing the strong guarantee.</p> <ul> <li>What happens when the vector has to be expanded, by relocating and copying it to a new space?</li> <li>For efficiency the copying can be replaced by moving, but only if the moves do not emit exceptions</li> <li>That is why it is important to declare your move operations noexcept (as well as other operations, you can guarantee not to throw exceptions)</li> </ul> <pre><code>TimeSeriesH(TimeSeriesH&amp;&amp; tsh)                      noexcept = default;\nTimeSeriesH&amp; operator=(TimeSeriesH&amp;&amp; tsh) noexcept = default;\n</code></pre>"},{"location":"8-semester/sP/06-double-dispatch/#container-member-types","title":"Container Member Types","text":"<p>Each standard container defines a number of types - via <code>using</code> type aliases. For example:</p> <ul> <li><code>value_type</code> </li> <li><code>iterator</code>, <code>const_iterator</code>, <code>reverse_iterator</code>, <code>const_reverse_iterator</code></li> <li><code>size_type</code>, <code>difference_type</code></li> <li><code>pointer</code>, <code>const_pointer</code></li> <li><code>reference</code>, <code>const_reference</code></li> </ul> <p>It is often possible to avoid use of container member type names - because auto can be used instead</p>"},{"location":"8-semester/sP/06-double-dispatch/#algorithms","title":"Algorithms","text":"<p>The advantages of using STL algorithms:</p> <ul> <li>Raise the level of abstraction \u2013 code is easier to read and maintain! </li> <li>Avoid common mistakes:<ul> <li>Off-by-one errors</li> <li>Special cases (like empty collection)</li> </ul> </li> <li>High quality implementations</li> <li>Best algorithmic complexity:<ul> <li>For example: <code>std::nth_element</code> in <code>O(n)</code> time.</li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#overview","title":"Overview","text":"<p>Wide variety of algorithms \u2013 simple building blocks: (see Fluent C++ blog for an alternative classification into 7 categories)</p> <ul> <li>Non-modifying sequence algorithms<ul> <li><code>for-each()</code>: Applies a function on each element of a sequence</li> <li><code>find()</code>: Find the first element that compares equal to a given value. Return iterator to element</li> <li><code>find_if()</code>: Find the first element that satisfies a given predicate. Return iterator to element</li> </ul> </li> <li> <p>Modifying sequence algorithms</p> <ul> <li><code>transform()</code>: Applies a function on each element, and writes the result into another container.</li> <li><code>replace()</code>: Replace elements that satisfies a predicate with a another value</li> </ul> </li> <li> <p>Sorting and searching algorithms (on sequences):</p> <ul> <li><code>sort</code></li> <li><code>binary_search</code></li> </ul> </li> <li>Set algorithms<ul> <li><code>set_union</code>, <code>set_intersection</code>, <code>set_difference</code></li> </ul> </li> <li>Heap algorithms<ul> <li><code>make_heap</code>, <code>push_heap</code>, and <code>pop_heap</code></li> </ul> </li> <li>Min and max algorithms<ul> <li><code>min</code> and <code>max</code> for pairs of elements</li> <li><code>max_element</code> and <code>min_element</code>: generalization to sequences of elements</li> </ul> </li> <li>Permutation algorithms<ul> <li><code>next_permutation</code> and <code>prev_permutation</code>: systematic creation of permutations of a sequence</li> </ul> </li> <li>Numeric algorithms</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#principles","title":"Principles","text":"<ul> <li>Generalization by function parameters<ul> <li>Pointers to functions, function objects, or lambda expressions</li> <li>Function object is an object for which an application operator, <code>operator()</code>, has been defined </li> </ul> </li> <li>A sequence is defined by two iterators<ul> <li>Beginning at the first element</li> <li>Ended by the one-beyond-the-last element</li> </ul> </li> <li>Failure to find an element in a sequence:<ul> <li>Return the (off by one) end-of-sequence iterator</li> </ul> </li> <li>The time complexities of the algorithms are specified by the C++ standard</li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#for_each-example","title":"for_each Example","text":"<ul> <li>Let's find out if a sequence is sorted<ul> <li>Note that <code>for_each</code> returns its third parameter: the function (object)</li> <li>Example<ul> <li>Use of objects as functions via an overload of the application operator</li> <li>A function surrounded by private, mutable state</li> </ul> </li> </ul> </li> <li>A Stroustrup advice: \u201cbefore using <code>for_each()</code>, consider if there is a more specialized algorithm that would do more for you\u201d<ul> <li>Such as <code>accumulate()</code>, <code>find()</code>, or <code>adjacent_find()</code></li> <li>Simpler example<ul> <li><code>greater&lt;T&gt;</code> is a wrapper around the <code>&gt;</code> operator</li> </ul> </li> </ul> </li> </ul>"},{"location":"8-semester/sP/06-double-dispatch/#use-of-function-objects-in-stl","title":"Use of Function Objects in STL","text":"<ul> <li>Wrapping operator predicates<ul> <li>Predicates such as <code>==</code> , <code>&lt;</code> and <code>&gt;</code></li> <li>Available as <code>equal_to</code>, <code>less</code>, and <code>greater</code></li> </ul> </li> <li>Wrapping arithmetic operators<ul> <li>Operators such as <code>+</code> and <code>-</code></li> <li>Available as <code>plus</code> and <code>minus</code></li> </ul> </li> <li>Binding one argument of a two argument function</li> <li>Allowing a member function to be used as a function</li> <li>Negating a predicate</li> </ul>"},{"location":"8-semester/sP/07-generic-programming/","title":"Generic Programming","text":""},{"location":"8-semester/sP/07-generic-programming/#type-aliasing","title":"Type Aliasing","text":"<pre><code>typedef vector&lt;int&gt;::iterator vi_t;     // old way\nusing vi_t = vector&lt;int&gt;::iterator;     // new, broader way\n\ntypedef void (*FP) (int, string&amp;);      // old way\nusing FP = void (*) (int, string&amp;);     // new, broader way\n</code></pre> <ul> <li><code>typedef</code> is not supported in templatization, use <code>using</code></li> <li>Alias avoid <code>::type</code> sufix workaround:</li> </ul> <pre><code>template &lt;typename t&gt;\nstruct MyAllocList {\ntypedef list&lt;T, MyAlloc&lt;T&gt;&gt; list_type;\n}\nauto lw = MyAllocList&lt;Widget&gt;::list_type();\n</code></pre> <ul> <li>C++14 offers aliased types for C++11 type traits</li> </ul> <pre><code>template &lt;class T&gt; // rich library of type manipulation\nusing remove_const_t = typename remove_const&lt;T&gt;::type\n</code></pre>"},{"location":"8-semester/sP/07-generic-programming/#function-vs-class-templates","title":"Function vs Class Templates","text":"Function templates Class templates Function overloading \"Forward declaration\" Argument type deduction,no partial specialization Type deductionvia Partial specialization Complete specialization Complete specialization SFINAE Argument substitution"},{"location":"8-semester/sP/07-generic-programming/#function-overload-resolution","title":"Function Overload Resolution","text":""},{"location":"8-semester/sP/07-generic-programming/#narrow-overloading-static_assert","title":"Narrow Overloading: static_assert","text":"<ul> <li>Suppose we want to handle both lvalue and rvalue at once:</li> </ul> <pre><code>void dump(std::ostream&amp; os);    // dump(cerr);\nvoid dump(std::ostream&amp;&amp; os); // dump(ofstream(\"err.txt\"));\n</code></pre> <pre><code>void dump(auto&amp;&amp; os) {...}      // binds to both &amp; anything (GNU extension)\n</code></pre> <pre><code>template &lt;typename StreamRef&gt;                       // binds to anything (C++ standard)\nvoid dump(StreamRef&amp;&amp; os) { os &lt;&lt; blah; } // no checks \u21d2 may break, may err a lot\n</code></pre> <ul> <li>User <code>static_assert</code> to produce error if assumptions are not met</li> </ul> <pre><code>template &lt;typename StreamRef&gt;\nvoid dump(StreamRef&amp;&amp; os) {                                                     // still binds to anything,\nusing Stream = std::remove_reference_t&lt;StreamRef&gt;;  // Compute type\nstatic_assert(std::is_base_of_v&lt;ostream, Stream, \"expecting ostream interface\");\nos &lt;&lt; blah; // Implementation details\n}\n</code></pre> <ul> <li><code>static_assert()</code> - breaks at compile time (fail-fast \\Rightarrow robust code)</li> <li><code>assert()</code> - breaks debug build at run time (fail-late \\Rightarrow\\Rightarrow fragile code)</li> <li><code>REQUIRE(), ASSERT()</code> - fail the unit test (one assertion stops)</li> <li><code>CHECK()</code> - fail the unit test but continue (checks many assertions)</li> </ul>"},{"location":"8-semester/sP/07-generic-programming/#substitution-failure-is-not-an-error-sfinae","title":"Substitution Failure Is Not An Error (SFINAE)","text":"<ul> <li>Based on function overloading:<ul> <li>Find and consider all available overloads.</li> <li>If type substitution fails, just drop it and do not complain, consider another</li> <li>(fail hard if multiple overloads match)</li> </ul> </li> <li>Function template parameters are substituted twice:<ul> <li>explicitly specified template arguments are substituted before template argument deduction</li> <li>deduced arguments and the arguments obtained from the defaults are substituted after template argument deduction.</li> </ul> </li> </ul> <p>Example</p> <pre><code>template &lt;typename C, typename Op, typename V = C::value_type&gt;  // default-computed\nvoid algorithm(C&amp;&amp; c, Op&amp;&amp; fun = std::plus&lt;V&gt;{}) { // default-computed\nauto sum = V{0};\nauto i = std::begin(c), e = std::end(c);\nwhile (i!=e) sum = fun(sum, *i++);\n}\nauto vi = std::vector&lt;int&gt;{1,2,3,4};\n\nalgorithm&lt;std::vector, std::plus&lt;int&gt;&gt;(vi); // explicit\n\nalgorithm(vi, std::plus&lt;int&gt;{}); // deduced\n</code></pre>"},{"location":"8-semester/sP/07-generic-programming/#narrow-overloading-sfinae","title":"Narrow Overloading: SFINAE","text":"<ul> <li>Enable through return type</li> </ul> <pre><code>template &lt;typename StreamRef, typename Stream=std::remove_reference_t&lt;StreamRef&gt;&gt;\nenable_if_t&lt;std::is_base_of_v&lt;ostream, Stream&gt;, void&gt; dump(StreamRef&amp;&amp; os) {...}// only ostream derivatives\n</code></pre> <ul> <li>Enable through (anonymous) default typename</li> </ul> <pre><code>template &lt;typename StreamRef, typename Stream=std::remove_reference_t&lt;StreamRef&gt;, typename = std::enable_if_t&lt;std::is_base_of_v&lt;ostream, Stream&gt;&gt; // argument\n\nvoid dump(StreamRef&amp;&amp; os) {...} // only derivatives\n</code></pre>"},{"location":"8-semester/sP/07-generic-programming/#sfinae-where","title":"SFINAE - Where","text":"<pre><code>// In all types of the function signature:\ntemplate &lt;typename T&gt;\ntypename enable_if&lt;cond, retType&gt;::type fun();\n\n// In all types of the template parameters:\ntemplate &lt;typename C, typename V = typename C::value_type&gt;\nretType fun(C ..., V ...);\n\n// In all expressions of the function signature:\ntemplate &lt;typename T, int X&gt;\nRetType fun(T t, char(*)[X%2]=0);\n\n// In all expressions of the template parameters:\ntemplate &lt;typename C, typename = typename C::value_type&gt;\nretType fun();\n</code></pre> <ul> <li>Only the failures in the types and expressions in the immediate context of the function type or template parameter types are SFINAE errors.</li> <li>Failures in side-effects such as instantiation of some template specialization, implicitly-defined member function generation, etc., are treated as hard errors.</li> </ul>"},{"location":"8-semester/sP/07-generic-programming/#sfinae-fails-softly-when","title":"SFINAE Fails Softly When","text":"<ul> <li>Instantiate a pack expansion containing multiple packs of different lengths</li> <li>Create array of: void, reference, function, abstract class types, negative or zero size</li> <li>Use a type that is not a class or enumeration on the left of a scope resolution operator <code>::</code></li> <li>Use a member of a type, where:<ul> <li>the type does not contain the specified member</li> <li>the specified member is not a type where a type is required</li> <li>the specified member is not a template where a template is required</li> <li>the specified member is not a non-type where a non-type is required</li> </ul> </li> <li>Create a pointer to reference</li> <li>Create a reference to void</li> <li>Create pointer to member of T, where T is not a class type</li> <li>Give an invalid type to a non-type template parameter</li> </ul> <p>For more see: https://en.cppreference.com/w/cpp/language/sfinae</p>"},{"location":"8-semester/sP/07-generic-programming/#template-specialization","title":"Template Specialization","text":"<ul> <li>Primary template must be (at least) declared first</li> </ul> <pre><code>template &lt;typename T&gt;\nclass Vector; // class template declaration\n//  Implementation can be omitted if never instantiated\n</code></pre> <ul> <li>Specializations come after:</li> </ul> <pre><code>template &lt;typename T&gt;\nclass Vector&lt;T*&gt; { ... }; // specialized for any ptr\n// Specialization must be defined before any usage.\n</code></pre> <ul> <li>More specialized must come even later</li> </ul> <pre><code>template &lt;&gt;\nclass Vector&lt;void*&gt; { ... }; // complete specialization\n</code></pre> <ul> <li>The most specialized is preferred over the others</li> <li>Functions cannot be partially specialized</li> </ul>"},{"location":"8-semester/sP/07-generic-programming/#complete-specialization","title":"Complete Specialization","text":"<p>Customize implementation for concrete cases, e.g.:</p> <pre><code>template &lt;typename T&gt;\nclass Vector { ... };       // primary declaration\n\ntemplate &lt;&gt;                             // template with zero arguments\nclass Vector&lt;bool&gt; {            // complete specialization\npublic:                                     // implement compact storage of bits:\nstruct ref {                        // nested inner class\noperator bool();            // read bit via conversion op\nref&amp; operator=(bool); // writing by via assign\n};\nref operator[](int i) { return ref{i}; } // proxy\n};\n</code></pre> <p>The result is a dependent template with zero arguments</p>"},{"location":"8-semester/sP/07-generic-programming/#partial-specialization","title":"Partial Specialization","text":"<p>Uses deduction</p> <pre><code>template &lt;&gt;                     // template with zero arguments\nclass Vector&lt;void*&gt; { // complete specialization for void*\nvoid** data; ...\nvoid*&amp; operator[](int i);\n};\n\ntemplate &lt;typename T&gt;                                           // template with arg T\nclass Vector&lt;T*&gt;: private Vector&lt;void*&gt; {   // partial \u21d2 deduction\nusing Base = Vector&lt;void*&gt;;                             // type aliasing\nT*&amp; operator[](int i) {                                     // reuse Base:\nreturn reinterpret_cast&lt;T*&amp;&gt;(Base::operator[](i));\n}\n};\nVector&lt;Widget*&gt; vw;         // uses partial spec. with T=Widget\n</code></pre> <p>Functions cannot be partially specialized</p>"},{"location":"8-semester/sP/07-generic-programming/#specialization-and-overloading","title":"Specialization and Overloading","text":"<pre><code>template &lt;typename T&gt;                           // primary declaration\nbool less(T a, T b) { return a&lt;b; } // can be specialized\n\ntemplate &lt;typename T&gt;\nvoid sort(Vector&lt;T&gt;&amp; v) { // fn-template depends on less\nfor (...) for (...)\nif (less(v[i], v[j])    // customizable\nswap(v[i], v[j]);   // customizable\n}\n</code></pre> <pre><code>template &lt;&gt;\nbool less&lt;const char*&gt;(const char* a, const char* b);\n\ntemplate &lt;&gt;\nbool less(const char* a, const char* b); // T=const char*\n\n// Overloaded function (does not depend on primary template):\nbool less(const char* a, const char* b); // plain function\n</code></pre>"},{"location":"8-semester/sP/07-generic-programming/#combine-class-and-function-templates","title":"Combine Class and Function Templates","text":""},{"location":"8-semester/sP/10-lambda/","title":"Lambda Expressions","text":""},{"location":"8-semester/sP/10-lambda/#map-of-stl-algorithms","title":"Map of STL Algorithms","text":""},{"location":"8-semester/sP/10-lambda/#lambda-expressions_1","title":"Lambda Expressions","text":""},{"location":"8-semester/sP/10-lambda/#map-of-stl-algorithms_1","title":"Map of STL Algorithms","text":"<p>The World Map of C++ STL Algorithms</p> <p></p> <p>List of algorithms</p>"},{"location":"8-semester/sP/10-lambda/#lambda","title":"Lambda","text":"<p>Lambda expression creates anonymous function object</p> <pre><code>[capture-list] (parameter-list) {statement-list}\n</code></pre> <p>Minimal lambda: <code>[] {}</code></p> <p>With return type:</p> <pre><code>[capture-list] (parameter-list) -&gt; return-type {statement-list}\n</code></pre> <p>Lambdas without capture (stateless) are compatible with plain C functions</p> <pre><code>auto lambda = [](int i) -&gt; int { return 42*i; } // precise type\n\nusing func_t = int(*)(int);         // type of function-pointer\ntypedef int (*func_t)(int);         // C version using typedef\nfunc_t p_lambda = lambda;           // type decay from lambda to function pointer\n</code></pre> <ul> <li>Default capture by reference may lead to dangling references to destroyed scope.</li> <li>Default capture by values may lead to dangling pointers to destroyed scope (through this).</li> <li>Default capture by values does not capture static variables, but uses them by reference instead.</li> <li>Default capture is safe when used locally, but even then someone may copy-paste them into unsafe environment</li> <li>\\Rightarrow explicit capture forces to think, hence safer </li> </ul>"},{"location":"8-semester/sP/10-lambda/#lambda-init","title":"Lambda Init","text":"<ul> <li>Capture ownership (unique_ptr, future, thread)</li> <li><code>[ var = initExpr ] (...) {...}</code></li> <li>Left of <code>=</code> is inner scope, right of <code>=</code> is outer scope</li> </ul> <pre><code>class Widget {\nbool isValidated() const;\nbool isArchived() const;\n};\nauto pw     = std::make_unique&lt;Widget&gt;();\nauto test = [pw = std::move(pw)] // reuse the \"pw\" name\n{ return pw-&gt;isValidated() &amp;&amp; pw-&gt;isArchived(); }\n</code></pre>"},{"location":"8-semester/sP/10-rval-and-forward/","title":"Rvalue and Forwarding References","text":"<p>Consider the following data and function declarations:</p> <pre><code>struct data {\nint x, y;\n};\n\ndata d{};\ndata get_value(){ return data{}; }\ndata* get_ptr(){ return &amp;d; }\ndata&amp; get_lref(){ return d; }\nconst data&amp; get_lcref(){ return d; }\ndata&amp;&amp; get_rref(){ return std::move(d); }\n\nvoid value(data d){}\nvoid ptr(data* d){}\nvoid lval_ref(data&amp; d){}\nvoid lval_cref(const data&amp; d){}\nvoid rval_ref(data&amp;&amp; d){}\ntemplate &lt;typename T&gt;\nvoid univ_ref(T&amp;&amp; d){}\n</code></pre> <p>The table below combines various functions and arguments into function calls. Expressions in <code>light-blue</code> are valid in both C and C++, whereas expressions in <code>cyan</code> have new meaning since C++11.</p> <p>Fill out each table cell for each combination what should happen: should the compiler issue an Error? should the expression be allowed (OK)? Should the expression create an extra Copy? Why do you think so?</p> <p>You may consult with the compiler: for example, the cell at row <code>&amp;d</code> and column <code>ptr(data*);</code> is OK, because the expression <code>ptr(&amp;d)</code> compiles fine.</p> <p></p>"},{"location":"8-semester/sP/11-concurrency/","title":"Concurrency","text":""},{"location":"8-semester/sP/11-concurrency/#threads-low-level-api","title":"Threads - Low Level API","text":"<ul> <li>Default constructed std::thread has no function</li> <li>Moved std::thread transfers ownership</li> <li>Joined std::thread does not correspond to any</li> <li>Detached std::thread does not have connection to the executing thread</li> <li>Deleting a joinable thread is forbidden</li> <li>Before deleting make it unjoinable<ul> <li>Either join,</li> <li>or detach</li> </ul> </li> </ul>"},{"location":"8-semester/sP/11-concurrency/#mutex","title":"Mutex","text":"<p><code>std::mutex</code></p> <ul> <li>With multiple mutexes it is easy to fall into circular dependency leading to deadlock</li> <li>To avoid the circular dependency:</li> <li>Release locks in reverse order they were acquired.</li> <li>Don't reacquire a mutex while still holding another;</li> <li>Maintain two phases: acquire all, release all.</li> <li>Use recursive_mutex if the same thread may lock the same mutex multiple times.</li> <li><code>lock(), ... , unlock()</code> use RAII: <code>std::lock_guard</code>, <code>unique_lock</code>.</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#c17-scoped-lock","title":"C++17: Scoped Lock","text":"<pre><code>std::scoped_lock lock(mutex1, mutex2); // easy!\n</code></pre> <ul> <li>Deduces the mutex types (unlike <code>lock_guard</code> and <code>unique_lock</code>)</li> <li>May use multiple mutexes at once (no need to think about order!)</li> </ul> <p>Equivalent C++11:</p> <pre><code>std::lock(mutex1, mutex2);\nstd::lock_guard&lt;std::mutex&gt; lk1(mutex1, std::adopt_lock);\nstd::lock_guard&lt;std::mutex&gt; lk2(mutex2, std::adopt_lock);\n</code></pre> <pre><code>std::unique_lock&lt;std::mutex&gt; lk1(mutex1, std::defer_lock);\nstd::unique_lock&lt;std::mutex&gt; lk2(mutex2, std::defer_lock);\nstd::lock(lk1, lk2);\n</code></pre>"},{"location":"8-semester/sP/11-concurrency/#atomic","title":"Atomic","text":"<p>Use atomic for concurrency</p> <ul> <li>Atomic read-modify-write operations:</li> </ul> <pre><code>std::atomic&lt;int&gt; ai{0}; // initialization (C++11/14)\nauto cpp17 = std::atomic&lt;int&gt;{17}; // C++17\nai = 10;                        // write, what may happen here?\nai = 20;                        // write again\n5 std::cout &lt;&lt; ai;  // read, output may interleave\n++ai;                           // guarantees no lost updates\n</code></pre> <ul> <li>Compiler may optimize writes.</li> <li>Atomic operations guarantee no lost updates.</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#volatile","title":"Volatile","text":"<p>Use volatile for special memory</p> <pre><code>volatile int x = 0;\nauto y = x;     // read x, what is the type of y?\ny = x;              // what if y is not volatile?\nx = 10;             // what if x is not volatile?\nx = 20;             // write again\n++x;                    // what may happen if threads share?\n</code></pre> <ul> <li>Compiler will not optimize writes</li> <li>No protection against lost updates</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#atomic-and-auto","title":"Atomic and Auto","text":"<ul> <li>auto drops const and volatile (why?)</li> <li>auto deduces <code>std::atomic</code></li> <li><code>std::atomic</code> has no copy-assignment (no AAA).</li> </ul> <pre><code>std::atomic&lt;int&gt; x;\nauto broken = x;                                        // copying is not allowed\nstd::atomic&lt;int&gt; y{x.load()};           // assign, but not atomic\nstd::atomic&lt;int&gt; cpp17 = x.load();  // C++17, not atomic\ny.store(x.load());                                  // read may get optimized:\nreg = x.load();                                         // load again(!) into reg\nstd::atomic&lt;int&gt; y(reg);                        // init from reg\ny.store(reg);                                               // store again from reg \n</code></pre> <p>Atomic and volatile cannot be optimized away:</p> <pre><code>volatile std::atomic&lt;int&gt; vai;\n</code></pre>"},{"location":"8-semester/sP/11-concurrency/#atomic-operations","title":"Atomic Operations","text":"<ul> <li>Use <code>atomic::load()</code> and <code>store()</code> to emphasise specialty.</li> <li><code>std::atomic::compare_exchange_weak(ptr)</code> for lock-free algorithms</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#controlling-memory-order","title":"Controlling Memory Order","text":"<pre><code>// thread 1:\nr1 = y.load(memory_order_relaxed); // A\nx.store(r1, memory_order_relaxed); // B\n</code></pre> <pre><code>// thread 2:\nr2 = x.load(memory_order_relaxed); // C\ny.store(r2, memory_order_relaxed); // D\n</code></pre> <pre><code>enum memory_order {         // from namespace std\nmemory_order_relaxed, // no guarantees, only atomicity\nmemory_order_consume, // no read reordering, no optimization\nmemory_order_acquire, // ensure read of released\nmemory_order_release, // ensure writes are visible\nmemory_order_acq_rel, // both acquire and release\nmemory_order_seq_cst  // both + total order \u2013 default\n};\n</code></pre>"},{"location":"8-semester/sP/11-concurrency/#tasks-higher-level-api","title":"Tasks - Higher Level API","text":"<pre><code>auto fut = std::async(doAsyncWork, args); // schedule a task\nauto res = fut.get();                                       // retrieve results\n</code></pre> <ul> <li>Shifts the thread management to system/library.</li> <li>May be executed asynchronously or synchronously.</li> <li>Effortless result synchronization.</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#launch-policies","title":"Launch Policies","text":"<pre><code>int doSomeWork(Args args) { ... }\nauto fut = std::async(policy, doSomeWork, args);\n</code></pre> <ul> <li><code>std::launch::async</code> - run on a different thread</li> <li><code>std::launch::deferred</code> \u2013 run when <code>get()</code>/<code>wait()</code> called</li> <li>Default: <code>std::launch::async</code> | <code>std::launch::deferred</code></li> <li>May even not run if <code>get()/wait()</code> are not called</li> <li>May block other threads waiting with <code>wait_for()</code></li> <li>Defer missed at testing, appear in production.</li> <li>Not clear which <code>thread_local</code> variables will be used.</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#async-policy-check","title":"Async Policy Check","text":"<pre><code>auto fut = std::async(someWork, args); // async or deferred?\nif (fut.wait_for(0s) == std::future_status::deferred) {\n... // use wait()/get() on fut to call f\n} else {\nwhile (fut.wait_for(100ms) != std::future_status::ready) {\n... // do something else\n... // fut will be ready when someWork terminates\n}\n... // fut is ready\n}\n</code></pre> <ul> <li>Otherwise just use <code>std::launch::async</code></li> <li>(see \"realAsync\" in EMC++)</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#future-and-promises","title":"Future and Promises","text":"<pre><code>void consumer(std::future&lt;int&gt;&amp; fut) {\nint x = fut.get();          // block and wait for promised delivery\nstd::cout &lt;&lt; \"Got \" &lt;&lt; x &lt;&lt; std::endl;\n}\n\nint main() {\nstd::promise&lt;int&gt; prom;           // creates a shared state\nauto fut = prom.get_future(); // prepare the receiving end\nauto thread = std::thread(consumer, fut); // launch thread\nprom.set(42);                                 // produce what has been promised\nthread.join();\n}\n</code></pre>"},{"location":"8-semester/sP/11-concurrency/#varying-future-promise-destructor","title":"Varying Future-Promise Destructor","text":"<ul> <li><code>std::future</code> can be converted to <code>std::shared_future</code> and be read multiple times</li> <li>Where is the promised result stored?</li> <li><code>std::future</code> <code>std::promise</code> share the state</li> <li>Destructor of the last <code>std::future</code> destroys the shared state<ul> <li>like reference counting in <code>shared_ptr</code></li> </ul> </li> <li>Destructors of other futures simply destroy the <code>std::future</code> objects</li> <li>Threads are made unjoinable cleanly (i.e. never terminates the program)</li> </ul>"},{"location":"8-semester/sP/11-concurrency/#packaged-tasks","title":"Packaged Tasks","text":"<ul> <li><code>std::packaged_task</code></li> </ul> <pre><code>int calcValue(int arg); // task to be computed async\nstd::packaged_task&lt;int(int)&gt; task{calcValue};\nauto fut = task.get_future();\nstd::thread th{std::move(task), 42};\n... // potentially do something else\nint result = fut.get(); // gather the result\n</code></pre> <ul> <li>Holds <code>std::future</code> and <code>std::promise</code> pair</li> <li>Calls <code>promise::set_value()</code> with return value</li> <li>If an exception is thrown, then it is passed to <code>promise::set_exception()</code> and rethrown at <code>future::get()</code></li> </ul>"},{"location":"8-semester/sP/11-concurrency/#latency-numbers","title":"Latency Numbers","text":"<p>Latency Numbers Every Programmer Should Know (2012)</p> <pre><code>L1 cache reference ......................... 0.5 ns\nBranch mispredict ............................ 5 ns\nL2 cache reference ........................... 7 ns\nMutex lock/unlock ........................... 25 ns\nMain memory reference ...................... 100 ns\nCompress 1K bytes with Zippy ............. 3,000 ns = 3 \u03bcs\nSend 2K bytes over 1 Gbps network ....... 20,000 ns = 20 \u03bcs\nSSD random read ........................ 150,000 ns = 150 \u03bcs\nRead 1 MB sequentially from memory ..... 250,000 ns = 250 \u03bcs\nRound trip within same datacenter ...... 500,000 ns = 0.5 ms\nRead 1 MB sequentially from SSD* ..... 1,000,000 ns = 1 ms\nDisk seek ........................... 10,000,000 ns = 10 ms\nRead 1 MB sequentially from disk .... 20,000,000 ns = 20 ms\nSend packet CA-&gt;Netherlands-&gt;CA .... 150,000,000 ns = 150 ms\n</code></pre> <ul> <li>Note the cost of mutex operations.</li> </ul>"},{"location":"8-semester/sP/99-exam/","title":"Exam Notes","text":""},{"location":"8-semester/sP/99-exam/#requirements","title":"Requirements","text":"<ul> <li>Requirement 1<ul> <li>Page 7-8 - Line 80-<ul> <li>Vessel class in <code>simulation.h</code></li> </ul> </li> <li>Page 15-16 - Line 13-90<ul> <li><code>Reactant</code> and <code>ReactantCollection</code> class in <code>data.h</code></li> </ul> </li> </ul> </li> <li>Requirement 2<ul> <li>Page 9 - Line 13-77<ul> <li>in <code>simulation.cpp</code></li> </ul> </li> </ul> </li> <li>Requirement 3<ul> <li>Page 21 - Line 17-110<ul> <li><code>SymbolTable</code> and <code>SymbolTableException</code> in <code>SymbolTable.h</code></li> </ul> </li> </ul> </li> <li>Requirement 4<ul> <li>Page 11-12 - Line 145-206<ul> <li><code>Vessel::do_simulation</code></li> </ul> </li> </ul> </li> <li>Requirement 5<ul> <li>Page 1-3<ul> <li><code>main.cpp</code></li> </ul> </li> </ul> </li> <li>Requirement 6<ul> <li>Page 15 - Line 334-353<ul> <li><code>SimulationTrajectory::write_csv</code></li> </ul> </li> </ul> </li> <li>Requirement 7<ul> <li>Page 20<ul> <li><code>simulation_monitor.h</code></li> </ul> </li> <li>Page 1-3<ul> <li>Usage of monitor in <code>main.cpp</code></li> </ul> </li> </ul> </li> <li>Requirement 8<ul> <li>Page 13 - Line 209-249<ul> <li><code>Vessel::do_multiple_simulations</code></li> </ul> </li> </ul> </li> <li>Requirement 9<ul> <li>Page 13-15 - Line 252-331<ul> <li><code>SimulationTrajectory::compute_interpolated_value</code></li> <li><code>SimulationTrajectory::compute_mean_trajectory</code></li> </ul> </li> </ul> </li> <li>Requirement 10<ul> <li>Page 10-11 - Line 80-142<ul> <li><code>Vessel::do_simulation2</code></li> </ul> </li> <li>Page 18-19 - Line 55-82<ul> <li><code>Reaction::compute_delay2</code></li> </ul> </li> </ul> </li> </ul>"}]}